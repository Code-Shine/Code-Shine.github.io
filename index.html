<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="CodeShine&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="CodeShine&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="CodeShine">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CodeShine's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">CodeShine's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">To be a man what you want</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">CodeShine</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2026/01/05/AWS%20%E9%A2%98%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2026/01/05/AWS%20%E9%A2%98%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">AWS知识点</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2026-01-05 07:10:18" itemprop="dateCreated datePublished" datetime="2026-01-05T07:10:18+08:00">2026-01-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2026-01-12 09:40:45" itemprop="dateModified" datetime="2026-01-12T09:40:45+08:00">2026-01-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS-题目知识点总结"><a href="#AWS-题目知识点总结" class="headerlink" title="AWS 题目知识点总结"></a>AWS 题目知识点总结</h1><h2 id="一、存储服务（S3-相关）"><a href="#一、存储服务（S3-相关）" class="headerlink" title="一、存储服务（S3 &amp; 相关）"></a>一、<strong>存储服务（S3 &amp; 相关）</strong></h2><ul>
<li>S3 传输加速（Upload Acceleration）</li>
<li>S3 存储类别：<ul>
<li>S3 Standard 标准 - 频繁访问的数据</li>
<li>S3 Standard-IA 标准-不常访问 - 不常访问但需快速读取(毫秒级) - 成本高于Glacier 加急检索</li>
<li>S3 Glacier - 长期归档，偶尔访问</li>
<li><strong>S3 Glacier Flexible Retrieval</strong> 是 AWS 的归档存储服务，专为<strong>很少访问但需要长期保留的数据</strong>设计。<ul>
<li><strong>标准检索（Standard Retrieval）</strong> 需要 3–5 小时 </li>
<li><strong>加急检索（Expedited Retrieval）</strong> 通常在 1–5 分钟内可取回</li>
<li><strong>Bulk (批量)</strong> 5-12 小时</li>
<li>即时检索<strong>Instant Retrieval</strong> 毫秒级</li>
</ul>
</li>
<li>S3 Glacier Deep Archive - 极少访问的长期归档 - 检索时间至少 12 小时</li>
</ul>
</li>
<li>S3 智能分层（Intelligent-Tiering）- 访问模式不确定&#x2F;变化以及自动化管理</li>
<li>S3 生命周期策略（Lifecycle Policy）- **基于规则的手动策略 **-  自动转换对象存储类或过期删除对象</li>
<li>S3 版本控制（Versioning）-  防止数据永久丢失（删除后可以恢复旧版本）</li>
<li>S3 对象锁定（Object Lock）<ul>
<li>合规模式：在保留期内<strong>任何人都无法删除或覆盖</strong>对象，包括根用户</li>
<li>治理模式：有特殊权限的用户可覆盖保留设置</li>
</ul>
</li>
<li>S3 MFA 删除（MFA Delete）- 可防止意外或未授权的删除。</li>
<li>S3 事件通知（S3 Event Notifications）</li>
<li>S3 网关终端节点（Gateway VPC Endpoint）</li>
<li>S3数据传输定价关键点：<ul>
<li>数据传出到互联网：会产生费用（按GB计费）</li>
<li>请求者付费：由<strong>数据请求方</strong>承担数据传输费用</li>
<li>S3跨区域复制：会产生跨区域数据转移费用</li>
<li>直接跨账户访问：数据传出到互联网，由数据所有者付费</li>
</ul>
</li>
<li>S3 静态网站托管（Static Website Hosting）- 无服务器</li>
<li>S3 与 CloudFront 集成</li>
<li>S3复制<ul>
<li>跨区域复制（Cross-Region Replication）<strong>跨区域复制（CRR）</strong> 在原桶开启 CRR 的话，已有数据不会自动复制，必须额外操作 ， 创建新桶就可以</li>
<li>S3 存储桶支持同区域复制，自动处理新对象复制</li>
<li>S3 支持 S3 存储桶之间配置双向复制。</li>
</ul>
</li>
<li><strong>S3 预签名 URL</strong> 允许客户端直接上传文件到 S3，无需经过应用,可以授予对特定对象的临时访问权限。</li>
<li>S3 Storage Lens 是专门为 S3 存储分析和成本优化设计的工具，可以直接报告<strong>分块上传计数</strong>，检查桶配置（如版本控制、加密、生命周期策略等）-识别跨区域所有未启用版本控制的 S3 存储桶</li>
<li><strong>S3 多区域访问点（MRAP）<strong>提供</strong>单一全局端点</strong>，可将请求自动路由到<strong>延迟最低</strong>的 S3 存储桶（基于 AWS 内部网络测量）。流量通过 <strong>AWS 骨干网</strong> 传输，避免公共互联网拥堵。</li>
<li><strong>S3 访问点</strong> 可以为同一存储桶的不同前缀定义不同的策略，限制特定 IAM 用户&#x2F;角色只能通过该访问点访问指定前缀。</li>
<li>S3 存储桶策略可以指定 <code>&quot;Principal&quot;: &#123;&quot;AWS&quot;: &quot;lambda-function-arn&quot;&#125;</code> 来允许特定 Lambda 函数访问</li>
<li>S3 存储桶密钥（Bucket Keys）功能可以在使用 SSE-KMS 加密的同时，大幅减少 KMS API 调用次数（从每次对象操作减少到每小时每存储桶一次），从而显著降低加密相关成本</li>
<li>EBS 存储类型<ul>
<li>固态硬盘（SSD）<ul>
<li>通用型gp3 和 gp2 </li>
<li>预配置IOPS SSD (io1&#x2F;io2)</li>
</ul>
</li>
<li>硬盘驱动器（HDD）</li>
<li>只有 <strong>io1 和 io2（包括 io2 Block Express）</strong> 卷支持 Multi-Attach 多挂载</li>
</ul>
</li>
<li>EBS 卷是<strong>块存储</strong>，只能挂载到<strong>同一可用区</strong>的单个 EC2 实例</li>
<li>EBS 卷<strong>不支持多实例同时挂载读写</strong></li>
<li><strong>Data Lifecycle Manager（DLM）</strong> 是 <strong>AWS 托管服务</strong>，可自动创建、保留和删除 EBS 快照</li>
</ul>
<hr>
<h2 id="二、数据库服务"><a href="#二、数据库服务" class="headerlink" title="二、数据库服务"></a>二、<strong>数据库服务</strong></h2><ul>
<li>Amazon Aurora（多可用区、只读副本、<strong>自动扩展</strong>）- <strong>为云重写的数据库</strong><ul>
<li>Aurora Serverless v2 是 AWS 提供的支持自动扩缩容的托管关系数据库服务</li>
<li>Babelfish 是 Aurora PostgreSQL 的功能，允许数据库理解 <strong>SQL Server 的 T-SQL 语法和通信协议</strong>，从而让为 SQL Server 编写的应用程序几乎无需修改即可连接到 Aurora PostgreSQL。减少代码更改</li>
<li><strong>Aurora 全局数据库 + 托管故障转移</strong>。- 满足 RPO ≤ 5 分钟、RTO ≤ 20 分钟、配置改动少、运营效率最高</li>
<li>端点类型<ul>
<li><strong>集群端点</strong>：指向主实例（读写）。</li>
<li><strong>读取器端点</strong>：自动在所有副本之间负载均衡（无法指定特定几个副本）。</li>
<li><strong>自定义端点</strong>：用户自定义的端点，可指向<strong>指定的一个或多个副本</strong>（支持按实例规格、角色等条件选择实例）。</li>
<li><strong>实例端点</strong>：指向单个特定实例（需应用管理多个端点，不自动负载均衡）</li>
</ul>
</li>
</ul>
</li>
<li>Amazon RDS（MySQL、PostgreSQL、SQL Server）<ul>
<li>只读副本</li>
<li>多可用区部署 RDS -  Multi-AZ 切换对应用程序透明</li>
<li>存储类型：gp2 vs. io1&#x2F;io2（更高的写入性能）</li>
<li>RDS 实例停止时，只收存储费，不收计算费</li>
<li>RDS Proxy（连接池管理）- 也支持Aurora<ul>
<li>用于数据库连接池和管理，可复用连接，防止数据库被大量并发连接压垮</li>
<li>故障转移时保持应用程序连接，自动将流量路由到新实例，显著减少中断时间</li>
</ul>
</li>
<li>RDS Custom for Oracle - <em>允许访问底层操作系统</em>，自定义配置、安装第三方软件</li>
<li>RDS 多可用区数据库实例（Multi-AZ DB Instance）一个主实例 + 一个同步备用实例（在不同 AZ）</li>
<li>RDS 多可用区数据库集群（Multi-AZ DB Cluster）一个主实例 + 两个可读备用实例（共 3 个 AZ）<ul>
<li>读负载指向 <strong>读取端点</strong>（自动负载均衡到两个可读备用实例）</li>
<li>在单个区域内提供<strong>同步多副本高可用，且所有副本均可处理读取请求</strong>，</li>
</ul>
</li>
<li>对于<strong>固定时间运行</strong>的 RDS 实例，使用 <strong>AWS Instance Scheduler</strong> 配置启动&#x2F;停止计划是最佳实践</li>
<li>RDS自动备份最多可以设置35天保留，超过则需要Backup</li>
</ul>
</li>
<li>Amazon DynamoDB<ul>
<li>按需容量 vs. 预置容量(成本更低)</li>
<li>时间点恢复（Point-in-Time Recovery）</li>
<li>AWS Backup 备份</li>
<li>TTL（生存时间）- TTL过期，DynamoDB 服务会自动在后台扫描并删除过期项</li>
<li>DAX（DynamoDB Accelerator）- <strong>为 DynamoDB 专门设计的完全托管的内存缓存服务</strong>，可解决读操作密集的问题</li>
<li>只读副本和DAX都可以缓解读性能问题，但是只读副本成本更低</li>
<li>DynamoDB 默认提供<strong>最终一致性读取</strong> - 意味着读取操作可能不反映最近完成的写入操作的结果，通常会在一秒内达成一致</li>
<li><strong>强一致性读取</strong>（Strongly Consistent Reads）返回反映所有先前写入操作结果的读取结果，但可能延迟稍高且成本更高。</li>
</ul>
</li>
<li>Amazon Redshift（数据仓库）- 专门为<strong>大规模数据分析</strong>设计 - 存储 PB 级数据</li>
<li>Amazon EMR（Elastic MapReduce） 是亚马逊 AWS 提供的<strong>云原生大数据处理平台</strong>，用于快速、经济高效地处理海量数据，用于数据清洗等 – <strong>类似自建 Hadoop</strong><ul>
<li><strong>临时集群</strong>：按需启动和终止，适合每天 6 小时的运行模式。</li>
<li>在按需实例上运行主节点（大脑）和核心节点（存储数据），在竞价型实例上运行任务节点（只负责计算）</li>
<li>EMR 运行时角色（Runtime Role）允许每个 Spark 作业使用独立的 IAM 角色，实现工作负载级别的细粒度权限控制，并且作业无需访问 EC2 实例的 IMDSv2 来获取凭证，从而满足权限隔离和禁止访问 IMDSv2 的双重要求。</li>
</ul>
</li>
<li>Amazon Athena（直接查询 S3 数据）</li>
<li>Amazon DocumentDB（兼容 MongoDB）</li>
<li>Amazon ElastiCache（Redis&#x2F;Memcached- 简单键值对）<ul>
<li>ElastiCache 是一个<strong>托管的内存缓存服务</strong>,可减少读取次数</li>
<li>ElastiCache for Redis 集群模式的高可用方案就是<strong>多可用区集群部署</strong>，每个分片跨 AZ</li>
<li>Redis Cluster（集群模式）- 数据分片到多个分片（Shard），每个分片是一个复制组（主节点 + 副本）</li>
<li>Redis（非集群模式）- 通过<strong>多可用区复制组</strong>实现高可用，包含一个主节点（在一个 AZ）和最多 5 个只读副本（可在不同 AZ）。</li>
<li>Memcached- 简单键值对 且不支持快照</li>
</ul>
</li>
<li>AWS Schema Conversion Tool（SCT）：专门用于<strong>异构数据库转换</strong></li>
<li>AWS DMS 数据库迁移服务</li>
<li>AWS Neptune 是专门为图数据设计的数据库，Neptune Streams 提供原生的变更捕获，无需额外搭建流处理管道，减少了运营复杂性和开销。</li>
<li>AWS QLDB 是账本数据库，专注于不可变、可验证的交易日志</li>
</ul>
<hr>
<h2 id="三、计算与容器"><a href="#三、计算与容器" class="headerlink" title="三、计算与容器"></a>三、<strong>计算与容器</strong></h2><ul>
<li><p>EC2 实例类型与计费模式：</p>
<ul>
<li>预留实例 - 稳定，适合长期负载</li>
<li>按需实例 - 无需稳定，但不可容忍中断</li>
<li>Spot 实例 - 可容忍中断</li>
<li>Spot 块 - 有<strong>持续时间保证</strong>的Spot实例（1-6小时）</li>
</ul>
</li>
<li><p>EC2 Auto Scaling</p>
<ul>
<li><p>横向扩展（Scale-out&#x2F;Horizontal Scaling）是指<strong>增加实例数量</strong>来应对负载增加</p>
</li>
<li><p>配置 ASG 横向扩展 + 启动模板。按需求自动启动新实例，用完后自动缩减 - 应对突发流量</p>
</li>
</ul>
</li>
<li><p>EC2 实例</p>
<ul>
<li>M5 实例（通用型，平衡的计算、内存、网络资源）</li>
<li>R5 是内存优化型实例，适合内存中任务，可能解决单实例性能瓶颈</li>
<li>计算节省计划（Compute Savings Plans） 提供最大的灵活性</li>
<li>实例节省计划（EC2 Instance Savings Plans） 提供更高的折扣率，但灵活性较低：仅允许在<strong>特定区域、特定实例系列</strong>内更改实例大小（如 C5.large 到 C5.xlarge），<strong>不能跨实例系列更改</strong>（如 C5 到 M5）</li>
<li>区域性预留实例（Regional RIs） 可在同一 AWS 区域内的不同可用区之间灵活应用，但<strong>仍然绑定特定的实例系列</strong></li>
<li>标准预留实例（Standard RIs） 绑定到<strong>特定可用区、实例系列、大小、操作系统</strong>，灵活性最差</li>
</ul>
</li>
<li><p><strong>Amazon ECS Anywhere</strong> - <strong>单一容器解决方案</strong> 跨本地与云 - 可以在本地服务器上加入 ECS 集群作为外部实例。</p>
</li>
<li><p><strong><strong>Fargate</strong></strong>：按 vCPU 和内存使用量收费（按需价格）。</p>
</li>
<li><p>Fargate Spot：利用 AWS 多余容量，价格比普通 Fargate 低，但可能被中断</p>
</li>
<li><p>ECR 是 AWS 容器镜像托管服务，与 ECS 无缝集成，提供原生 CVE漏洞 扫描，只需配置推送时扫描即可自动执行，改动最小</p>
</li>
<li><p>AWS Lambda（无服务器计算）- 15 分钟限制</p>
<ul>
<li>SQS 集成</li>
<li>S3 事件触发</li>
<li>并发限制与超时处理</li>
<li>预置并发（Provisioned Concurrency） 是 Lambda 的功能，预先初始化一定数量的函数实例，使其处于<strong>就绪状态</strong>，避免冷启动。</li>
<li>预留并发（Reserved Concurrency）：是限制函数的最大并发数，不是用于降低延迟的主要手段</li>
<li><strong>SnapStart</strong> 是 AWS 提供的专为减少冷启动延迟而设计的原生功能，且不需要像预置并发那样持续付费，因此<strong>最具成本效益</strong>。</li>
<li>内存最大 10 GB</li>
<li>Lambda 不支持 Windows 容器运行，只支持自定义容器镜像基于 Linux</li>
<li>Lambda 函数 URL - 可以为一个函数创建唯一的 HTTPS 端点，无需配置 API Gateway 或其他服务，直接通过 URL 调用函数</li>
</ul>
</li>
<li><p>Amazon ECS + AWS Fargate（容器无服务器）</p>
</li>
<li><p>Amazon EKS（Kubernetes 服务）</p>
<ul>
<li>扩缩容 - Pod 级别-水平 Pod 自动扩缩容（HPA），根据 CPU、内存等指标调整 Pod 副本数</li>
<li>扩缩容 -节点级别：集群自动扩缩器（Cluster Autoscaler），根据 Pod 调度需求自动调整节点数量（即调整节点组大小）。</li>
<li><strong>EKS Connector</strong> 是 AWS 提供的功能，允许将<strong>外部 Kubernetes 集群（包括本地集群）注册到 AWS 控制台的 EKS 页面</strong>。</li>
</ul>
</li>
<li><p>AWS Elastic Beanstalk（托管应用平台）- 专门用于部署和扩展Web应用程序。它自动处理容量配置</p>
</li>
<li><p>AWS Amplify 是完整的前端开发平台，可以托管前端并集成 CloudFront，但可能比简单 S3 + CloudFront 成本高</p>
</li>
</ul>
<hr>
<h2 id="四、消息与流处理"><a href="#四、消息与流处理" class="headerlink" title="四、消息与流处理"></a>四、<strong>消息与流处理</strong></h2><ul>
<li>Amazon SNS（发布&#x2F;订阅）</li>
<li>Amazon SQS（消息队列）<ul>
<li>标准队列(无严格顺序) vs. FIFO 队列(成本高于标准)</li>
<li>可见性超时（Visibility Timeout）</li>
<li>死信队列（DLQ）- 用于接收和处理<strong>无法正常消费的消息</strong>的中间队列</li>
<li>SQS 支持基于资源的策略（队列策略），允许其他 AWS 账户或 IAM 用户访问该队列</li>
</ul>
</li>
<li>Amazon Kinesis<ul>
<li>Data Streams（实时数据流）秒级延迟 - 默认<strong>数据保留期</strong>为 <strong>24 小时</strong>。</li>
<li>Data Firehose（流式数据传输至存储）也可以接入Amazon Kinesis Data Analytics 进行实时数据分析</li>
<li>Data Analytics（实时 SQL 分析）</li>
</ul>
</li>
<li>Amazon EventBridge（事件驱动调度）</li>
<li>Amazon MQ（托管消息队列，支持 RabbitMQ&#x2F;ActiveMQ）</li>
<li><strong>Amazon AppFlow</strong> 是一项完全托管的 <strong>SaaS 集成服务</strong>，用于在 AWS 服务和 SaaS 应用程序（如 Salesforce、Slack、Zendesk 等）之间<strong>安全地传输数据</strong></li>
</ul>
<hr>
<h2 id="五、网络与连接"><a href="#五、网络与连接" class="headerlink" title="五、网络与连接"></a>五、<strong>网络与连接</strong></h2><ul>
<li>VPC 架构：<ul>
<li>公有&#x2F;私有子网 - 房子</li>
<li>安全组（Security Group）- 防盗门- 安全组<strong>不支持“拒绝”规则</strong>，只支持“允许”规则</li>
<li>网络 ACL （NACL 访问控制列表）- 围墙 检查IP 阻止特定 IP 范围- 可显式拒绝</li>
<li>NAT 网关(IPV4<strong>私有子网的出站代理</strong>)- 只能部署在公有子网 vs. 互联网网关（IGW <strong>VPC 与互联网的桥梁</strong>）</li>
<li>仅出口互联网网关（Egress-Only Internet Gateway） 是专门为 IPv6 设计的组件，它允许实例主动发起出站连接，但阻止互联网对实例的入站连接</li>
</ul>
</li>
<li>VPC 终端节点：<ul>
<li>网关终端节点（S3, DynamoDB）- 不经过互联网<ul>
<li>创建网关端点时，需<strong>关联到 VPC 和路由表</strong>，并<strong>自动在指定路由表中添加路由</strong>（目标前缀列表 → 端点）</li>
</ul>
</li>
<li>接口终端节点（使用AWS PrivateLink）- 允许其他VPC能够通过<strong>接口VPC终端节点</strong>以私有方式连接到你的服务<ul>
<li>EKS 控制平面的私有端点实际上是通过 <strong>接口 VPC 端点（Interface VPC Endpoint）</strong> 实现的</li>
</ul>
</li>
<li>网关终端节点不支持关联安全组。安全组是用于<strong>接口 VPC 终端节点</strong>的</li>
<li>接口端点**（VPC Endpoint）**：通过ENI访问服务（AWS服务）</li>
</ul>
</li>
<li><strong>AWS PrivateLink</strong> 是一项服务，允许您<strong>安全、私密地将 VPC 中的服务暴露给其他 VPC 或本地网络</strong>，或者<strong>通过私有网络访问 AWS 或其他 SaaS 提供商托管的服务</strong>。– 只打通特定的服务，而VPN是连接网络</li>
<li>VPC 对等连接（VPC Peering）<ul>
<li>VPC之间的私有网络，不经过互联网</li>
<li>支持跨账户 跨区域</li>
<li>同一区域、同一账户的 VPC 对等流量不收费</li>
</ul>
</li>
<li><strong>AWS VPC Lattice</strong> 是一项完全托管的服务，用于在 AWS 中<strong>安全地连接、监控和管理服务间的通信</strong><ul>
<li>VPC Lattice 抽象了底层网络连接（跨账户、跨 VPC），自动处理服务发现，支持 HTTPS 监听器，并将服务注册到服务网络，团队只需将资源关联到服务网络即可通信，管理开销最小。</li>
<li>在于HTTPS 应用层，Transit Gateway 在IP层</li>
</ul>
</li>
<li>AWS Direct Connect（专线连接）- 本地数据中心到VPC<ul>
<li>Direct Connect 网关 -  想要连接多个区域的VPC</li>
</ul>
</li>
<li>VPN 连接（站点到站点）<ul>
<li>Site-to-Site VPN：本地网络与VPC之间的IPsec VPN</li>
<li>Client VPN：远程用户到VPC的SSL VPN</li>
<li><strong>Transit Gateway</strong> VPN：通过中转网关的VPN连接集中连接所有 VPC，实现 VPC 间通信</li>
</ul>
</li>
<li><strong>公共 VIF（A）</strong>：直接访问 S3，无需 VPC，无需 NAT 网关或接口端点费用，只需 Direct Connect 端口费和少量数据传输费</li>
<li>Gateway Load Balancer（GWLB） 专用于第三方网络虚拟设备（防火墙、IDS&#x2F;IPS）的流量引导</li>
<li>负载均衡器：<ul>
<li>ALB（应用层）HTTP&#x2F;HTTPS - 来实现负载均衡、Internet 公开和粘性会话<ul>
<li>支持两种负载均衡算法：<ul>
<li><strong>轮询（Round Robin）</strong>：按顺序分发请求，不考虑实例当前负载。</li>
<li><strong>最少未完成请求（Least outstanding requests）</strong>：将新请求发送给当前未完成请求数最少的实例，能动态避免过载实例。</li>
</ul>
</li>
</ul>
</li>
<li>NLB（网络层）TCP&#x2F;UDP</li>
<li>CLB（传统负载均衡器）</li>
<li>网关负载均衡器（GWLB）：主要用于将流量转发到第三方虚拟设备（如防火墙、IDS）不适合常规 Web&#x2F;应用流量负载均衡。</li>
</ul>
</li>
<li>EFA 是一种AWS专用的网络接口，专为高性能计算（HPC）和机器学习（ML）工作负载设计，提供超低延迟和可扩展的节点间通信。</li>
</ul>
<hr>
<h2 id="六、安全与身份管理"><a href="#六、安全与身份管理" class="headerlink" title="六、安全与身份管理"></a>六、<strong>安全与身份管理</strong></h2><ul>
<li><p>IAM（身份与访问管理）</p>
<ul>
<li>IAM 角色（Role）<ul>
<li>让 EC2 实例、Lambda 函数、ECS 任务安全地访问其他服务</li>
<li>安全地向供应商授予访问权限 - 可创建一个角色</li>
<li>IAM 角色是用于委派临时权限的实体，<strong>不能直接附加到 IAM 组</strong></li>
</ul>
</li>
<li>IAM 策略（Policy）<ul>
<li><strong>基于身份的策略（Identity-based policies）</strong>：附加到IAM身份（用户、组、角色）的策略，定义这些身份可以做什么。</li>
<li><strong>基于资源的策略（Resource-based policies）</strong>：附加到AWS资源（如S3存储桶、Lambda函数）的策略，定义谁可以访问该资源。</li>
</ul>
</li>
<li>条件键：<code>aws:PrincipalOrgID</code>、<code>aws:SourceIP</code>、<code>ec2:Region</code></li>
<li>Lambda 访问 AWS 资源（如 S3），可以创建一个允许读写S3的 iam role 并更新到Lambda 函数</li>
<li><strong>AdministratorAccess</strong>：AWS托管策略，提供完全管理权限（Amazon官方提供）。</li>
<li><strong>SystemAdministrator</strong>：如果存在，可能是自定义策略</li>
<li>IAM Identity Center 实现以本地Active Directory 通过<strong>AWS Directory Service</strong> 实现SSO</li>
<li>AWS IAM 访问分析器（IAM Access Analyzer）审查公司的所有资源和账户。<strong>审查授予 IAM 用户的所有权限</strong></li>
<li>IAM Identity Center 的权限集（Permission Sets）是专门为多账户或多团队场景设计的权限管理方案，可以精细化控制对 RDS 和 S3 的访问，并分配给不同团队组，实现最小权限</li>
<li>IAM Roles Anywhere 允许本地虚拟机通过证书认证获取临时 AWS 凭证，从而安全地访问 S3 存储桶，无需长期密钥，且与 IAM Identity Center 集成可实现集中权限管理</li>
</ul>
</li>
<li><p>AWS Secrets Manager（密钥管理 + 自动轮换）</p>
</li>
<li><p>AWS KMS（密钥管理服务）</p>
<ul>
<li>客户管理密钥（CMK）- 自定义加密需求</li>
<li><strong>客户端加密</strong>指的是<strong>数据在发送到数据库之前，在应用层就用 KMS 密钥加密</strong>，数据库无法查看明文</li>
<li>AWS 管理 CMK-  AWS服务自动创建</li>
<li>AWS 自有密钥</li>
<li>多区域密钥（Multi-Region Key）</li>
<li>对于导入的密钥材料，KMS不支持自动轮换。轮换需要手动操作</li>
<li><strong>服务器端加密（SSE-S3、SSE-KMS、SSE-C）</strong>：数据在传输过程中是明文（TLS 加密传输），到达 S3 后才加密。</li>
<li>SSE-C 用户自己管理密</li>
<li>SSE-S3（B）密钥由S3管理</li>
<li>SSE-KMS AWS KMS 密钥 –支持密钥轮换 CloudTrail 会记录日志</li>
</ul>
</li>
<li><p>AWS Certificate Manager（ACM）</p>
<ul>
<li>导入外部证书</li>
<li>在ALB或者NLB上进行SSL终止，避免解密造成服务的性能瓶颈</li>
<li>需要使用第三方 CA 签名的证书，必须<strong>自行从第三方 CA 获取证书，然后导入到 ACM</strong>（Import Certificate），或者直接将证书部署到服务上（如果服务支持上传自定义证书）。</li>
<li><strong>AWS ACM + DNS 验证</strong> 是实现 TLS 证书<strong>全生命周期自动化管理</strong>的最佳实践</li>
</ul>
</li>
<li><p>AWS Shield（DDoS 防护）</p>
<ul>
<li>Shield Standard</li>
<li>Shield Advanced</li>
</ul>
</li>
<li><p>AWS WAF（Web 应用防火墙）</p>
<ul>
<li>防止SQL注入，XSS 防护，也可以支持阻止特定国家的流量（地理匹配条件）</li>
<li>WAF 仅支持 ALB、CloudFront 、API Gateway</li>
<li>不支持NLB</li>
<li>ALB 后的应用层 DDoS，AWS 推荐使用 <strong>AWS WAF</strong> 的速率限制规则。</li>
<li>支持基于 IP 地址、地理位置、规则等条件阻止请求</li>
</ul>
</li>
<li><p>AWS Network Firewall - 托管的网络防火墙服务，可部署在 VPC 中，通过<strong>规则组</strong>控制流量。</p>
</li>
<li><p>AWS Security Hub 监控所有账户中安全控制措施的当前状态。- 可以集成 GuardDuty 和 Inspector</p>
</li>
<li><p>Amazon Inspector（漏洞扫描）</p>
</li>
<li><p>Amazon Macie（敏感数据发现）- 发现 S3 中敏感数据（如 PII）</p>
</li>
<li><p>AWS GuardDuty -  是威胁检测服务，通过分析 VPC 流日志、CloudTrail 事件等识别恶意活动</p>
</li>
<li><p>AWS Config（配置审计与合规） </p>
<ul>
<li>可记录资源配置历史</li>
<li>可记录资源配置标签并评估是否符合规则</li>
<li>持续监控资源配置变化和历史合规状态，当安全组规则违规时会触发通知</li>
<li>支持 <strong>AWS Organizations 资源类型</strong>（<code>AWS::Organizations::Organization</code>、<code>AWS::Organizations::OrganizationalUnit</code> 等），可以通过 Config 规则监控 OU 变更</li>
<li>提供预定义的托管规则 <code>ebs-encryption-by-default</code> 或自定义规则，可自动检查 EBS 卷是否加密</li>
</ul>
</li>
<li><p>AWS CloudTrail（API 调用历史日志）- 存储在 S3 中，格式为 JSON。可使用 Amazon Athena查询</p>
</li>
<li><p>AWS Control Tower（多账户治理）</p>
<ul>
<li>设置和管理安全、合规的多账户AWS环境的<strong>最佳实践服务</strong></li>
<li>Control Tower 自动启用 CloudTrail 组织跟踪，并可集成 Security Hub 进行 FSBP 合规检查，是满足审计与安全合规需求的一站式托管解决方案</li>
<li>Control Tower 在后台利用 **AWS Organizations 的服务控制策略（SCP）**来实现这些防护</li>
<li>SCP是一种策略，可以<strong>集中控制</strong>组织内所有账户对AWS服务和资源的访问权限</li>
<li>SCP 在 Organizations 中可附加到<strong>根 OU、OU 或直接附加到账户</strong></li>
<li>SCP 不支持资源标签条件，只能基于资源类型、区域等</li>
<li><strong>Control Tower</strong> 控制类型：<ul>
<li><strong>主动控制（Proactive Controls）</strong>：在资源创建之前进行策略检查（如 CloudFormation 预检），防止部署不合规资源。</li>
<li><strong>检测控制（Detective Controls）</strong>：在资源创建后评估合规性，不合规则发出警报或修复</li>
</ul>
</li>
</ul>
</li>
<li><p>Amazon Cognito（用户身份管理）- <strong>管”用户是谁”（认证）</strong></p>
<ul>
<li>主要用于移动&#x2F;Web 应用的用户身份管理</li>
<li>不是为企业目录集成 AWS 多账户访问</li>
<li><strong>用户池 (User Pool)</strong>：<strong>身份验证</strong> - 你是谁？（用户名&#x2F;密码、社交登录、短信验证等）</li>
<li><strong>身份池 (Identity Pool)</strong>：<strong>授权访问</strong> - 你能做什么？（提供AWS凭证访问AWS资源）</li>
<li>Amazon Cognito 更适合面向互联网的用户身份联合（如移动端、Web 应用），不太适合企业内部员工直接访问 AWS 管理资源，且配置较复杂，不如 IAM Identity Center 直接集成 AD 来得简洁。</li>
</ul>
</li>
<li><p>AWS Organizations 集中管理多个账户</p>
</li>
<li><p>AWS Systems Manager（SSM）是一个<strong>统一的运维管理服务</strong>，提供对 AWS 和混合基础设施的安全、可扩展的操作可见性和控制。</p>
<ul>
<li>Session Manager（无 SSH 访问）允许通过浏览器或 AWS CLI 直接连接 EC2 实例<ul>
<li>可以在 Systems Manager 控制台中启用 S3 日志记录，将日志进行存档</li>
</ul>
</li>
<li>Run Command（批量命令执行）</li>
<li><strong>AWS Systems Manager Parameter Store</strong> 存储安全参数<ul>
<li>对于<strong>不需要轮换的应用程序机密信息</strong>，<strong>Parameter Store</strong> 是<strong>更具成本效益</strong>的选择。</li>
<li>对于<strong>需要自动轮换的数据库凭证、API 密钥等</strong>，应使用 Secrets Manager</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>AmazonSSMManagedInstanceCore</strong> 是一个 AWS 托管的 IAM 策略，它授予 EC2 实例与 AWS Systems Manager 服务通信所需的最小权限集合,包括SSH远程连接，补丁管理</p>
</li>
<li><p>AWS 为每个区域提供了<strong>根证书</strong>（CA 证书），客户端需配置信任该证书以建立 SSL 连接</p>
<ul>
<li>启用传输加密不需要重新创建或恢复实例，只需配置客户端使用 SSL 连接</li>
</ul>
</li>
<li><p>为了共享加密 AMI</p>
<ul>
<li>将目标账户 ID 添加到 AMI 启动权限（D）。</li>
<li>在 KMS 密钥策略中允许目标账户使用该密钥（或在密钥策略中添加组织级条件允许组织内所有账户）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="七、内容分发与加速"><a href="#七、内容分发与加速" class="headerlink" title="七、内容分发与加速"></a>七、<strong>内容分发与加速</strong></h2><ul>
<li>Amazon CloudFront（CDN）<ul>
<li>为 <strong>HTTP&#x2F;HTTPS</strong> 流量优化</li>
<li>源站配置（S3、ALB、自定义）</li>
<li>CloudFront 仅支持使用在 <strong>us-east-1（弗吉尼亚北部）区域</strong> 的 ACM 证书</li>
</ul>
</li>
<li>AWS Global Accelerator（全局加速DNS）<ul>
<li>在传输层（TCP&#x2F;UDP） 工作，完美支持游戏常用的 UDP 协议</li>
</ul>
</li>
<li>Amazon API Gateway<ul>
<li>完全托管的 API 管理服务，仅支持 HTTP&#x2F;HTTPS 协议</li>
<li>处理高并发 API 请求</li>
<li>API Gateway 的<strong>边缘优化端点</strong>使用 <strong>Amazon CloudFront 全球边缘网络</strong></li>
<li>API Gateway 有 <strong>REST API</strong> 和 <strong>HTTP API</strong> 两种，HTTP API 成本低于 REST API（功能较少，但适用于简单代理、Lambda 集成）</li>
<li>API Gateway 资源策略是专门用于控制谁可以访问 API 的机制，支持基于 IP 的条件限制。</li>
</ul>
</li>
<li>Route 53（DNS 管理）<ul>
<li>别名记录（Alias）</li>
<li>多值路由（Multi-Value Routing）- 会随机返回多个健康资源记录，客户端随机选择一个</li>
<li>延迟路由（Latency Routing）- 将用户 DNS 查询解析到延迟最低的区域端点</li>
<li>故障转移路由（Failover Routing）- 故障转移策略用于<strong>主-备</strong>场景，不适合负载均衡 10 个实例</li>
<li>地理位置路由 - 根据用户的地理位置返回特定的记录</li>
<li><strong>公共托管区域</strong>：管理公共互联网可解析的域名</li>
<li><strong>私有托管区域</strong>：管理仅在公司 VPC 内可解析的内部域名</li>
</ul>
</li>
</ul>
<hr>
<h2 id="八、混合云与迁移"><a href="#八、混合云与迁移" class="headerlink" title="八、混合云与迁移"></a>八、<strong>混合云与迁移</strong></h2><ul>
<li>AWS Snowball （大规模数据传输）<ul>
<li>Snowone 8-14TB - 也支持DataSync</li>
<li>Snowball Egde 42-210TB</li>
<li>Snowmobile 100PB级 - 需要卡车</li>
</ul>
</li>
<li>AWS DataSync（本地与云间同步）- 在线迁移,适合持续变化的数据，且支持加密、验证。</li>
<li>AWS Storage Gateway（文件网关、卷网关）<ul>
<li>文件网关（File Gateway）- 是一个本地缓存设备&#x2F;虚拟机，它提供 <strong>NFS 或 SMB 文件共享</strong> 接口。与S3连接</li>
<li>卷网关（Volume Gateway）数据<strong>主要存储在 AWS</strong>（Amazon EBS），本地网关仅存储元数据，应用通过 iSCSI 访问。</li>
<li>缓存卷网关（Cached Volume Gateway）数据<strong>主要存储在 AWS（S3）</strong>，本地网关设备<strong>缓存频繁访问的数据</strong>（最近访问的数据保留在本地）</li>
</ul>
</li>
<li>Amazon FSx（托管文件系统）<strong>亚毫秒级延迟</strong><ul>
<li>FSx for Windows File Server（SMB文件共享 + AD 集成）</li>
<li>FSx for Lustre（<strong>高性能</strong>并行文件系统）- 不支持SMB</li>
<li>FSx for NetApp ONTAP（同时支持 NFS 和 SMB）linux 和 window都支持</li>
<li>FSx for OpenZFS 支持 NFS（v3、v4）和 SMB，但<strong>延迟通常高于 Lustre</strong></li>
</ul>
</li>
<li>Amazon EFS（网络文件系统，跨 AZ 共享） - 分层目录结构<ul>
<li><strong>延迟在毫秒级</strong></li>
<li><strong>配置文件系统</strong>是基于 <strong>NFS</strong> 协议的文件存储服务，主要面向 <strong>Linux</strong> 工作负载。</li>
<li>简单共享 → 类似云盘</li>
<li>EFS 文件系统在所在区域内的 <strong>每个可用区自动提供挂载目标</strong></li>
<li>便于跨可用区的 EC2&#x2F;ECS 容器挂载同一文件系统。</li>
</ul>
</li>
<li>AWS Transfer Family（托管 SFTP&#x2F;FTPS&#x2F;FTP 服务）协议上传文件到 AWS（如 Amazon S3、EFS）不支持EBS<ul>
<li>Transfer Family 托管工作流可在文件上传完成后自动触发 Lambda</li>
</ul>
</li>
<li><strong>Application Discovery Service</strong> 来收集本地服务器配置、性能和使用数据，用于迁移规划</li>
<li>AWS Outposts 是将 AWS 基础设施、服务、API 扩展到客户本地数据中心的解决方案，可以运行 EKS 控制平面和工作节点，数据保留在本地。</li>
<li><strong>AWS MGN</strong> 是 AWS 推荐的<strong>直接迁移（lift-and-shift）服务</strong>，可自动将物理机、虚拟机或云虚拟机迁移到 AWS</li>
</ul>
<hr>
<h2 id="九、AI-ML-与智能服务"><a href="#九、AI-ML-与智能服务" class="headerlink" title="九、AI&#x2F;ML 与智能服务"></a>九、<strong>AI&#x2F;ML 与智能服务</strong></h2><ul>
<li>Amazon Pinpoint（营销与通信）-支持电子邮件、SMS、推送通知等。配置用于发送营销确认短信</li>
<li>Amazon Rekognition（图像与视频分析）内置了<strong>内容安全审查</strong>功能</li>
<li>Amazon Textract（文档文本提取）</li>
<li>Amazon Comprehend Medical（医疗文本分析）</li>
<li>Amazon Comprehend（自然语言处理）- 提供预训练的实体识别功能（包括检测食品、材料等）文本情感分析设计</li>
<li>Amazon SES（电子邮件服务）</li>
<li>Amazon Transcribe（语音转文本，多说话人识别）</li>
<li>Amazon Translate 将任何语言的文本翻译成英语</li>
<li>Amazon SageMaker（机器学习平台）构建和训练模型</li>
<li>Amazon Forecast 是 AWS 完全托管的<strong>时间序列预测</strong>服务，无需 ML 经验，适合基于历史数据做资源需求预测。</li>
<li>Amazon Polly（文本转语音）</li>
<li>Amazon Lex 是用于构建对话机器人的服务</li>
</ul>
<hr>
<h2 id="十、监控、日志与成本管理"><a href="#十、监控、日志与成本管理" class="headerlink" title="十、监控、日志与成本管理"></a>十、<strong>监控、日志与成本管理</strong></h2><ul>
<li>Amazon CloudWatch（监控与仪表板）主要监控资源性能指标（如 CPU、内存），不能直接监控成本异常</li>
<li>监控成本：  AWS 计费和成本管理控制台中创建一个 AWS 成本异常检测监控器</li>
<li>AWS Cost Explorer（成本分析）</li>
<li>AWS Backup（统一备份管理）- 可配置跨区域复制备份，完全托管，自动化执行,支持 EFS 备份</li>
<li>AWS Organizations（多账户管理）</li>
<li>AWS SSO（单点登录）</li>
<li>AWS Budgets（预算与告警）<ul>
<li>支持设置节省计划预算，可配置“覆盖率”阈值并触发警报（如电子邮件、SNS）</li>
</ul>
</li>
<li>Amazon QuickSight（BI 可视化）</li>
<li>AWS CloudFormation - 用<strong>模板文件</strong>描述你的AWS资源（EC2、S3、RDS等）可一键部署</li>
<li>AWS 服务目录（Service Catalog） 允许组织集中管理和部署预先批准的 AWS 产品（包括 CloudFormation 模板、AMI、Marketplace 产品等），并让最终用户（客户）通过自助服务门户按需部署，同时保持治理和合规</li>
<li>计算节省计划（Compute Savings Plans） 提供最大的灵活性，可以自动应用于任何 EC2 实例类型、系列、区域（包括 Fargate、Lambda），只要使用量在承诺范围内即可享受折扣，适合需要频繁更换实例类型的场景</li>
<li>Trusted Advisor 提供成本、安全、性能等建议 - 闲置资源识别等</li>
<li>Compute Optimizer 成本优化- 调整实例类型，优化卷配置等，比Trusted Advisor更具体</li>
<li>成本分配标签是 AWS 推荐的跟踪成本责任的方法。- 将每个资源标记上所属应用程序的名称。</li>
<li>AWS 预算是设置预算和警报的标准服务。</li>
<li><strong>AWS Cost Explorer</strong> 或成本和使用情况报告，配合标签筛选，生成定期报告。</li>
</ul>
<hr>
<h2 id="十一、无服务器与微服务架构"><a href="#十一、无服务器与微服务架构" class="headerlink" title="十一、无服务器与微服务架构"></a>十一、<strong>无服务器与微服务架构</strong></h2><ul>
<li>API Gateway（REST&#x2F;WebSocket API）</li>
<li>Lambda + SQS + SNS 解耦架构</li>
<li>DynamoDB 作为无服务器数据库</li>
<li>EventBridge 定时触发<ul>
<li>EventBridge 专为事件路由和过滤设计，支持复杂事件模式匹配</li>
</ul>
</li>
<li>AWS Glue <ul>
<li><strong>无服务器 ETL 服务</strong>，专为数据转换设计,简化数据准备</li>
<li>让你<strong>轻松构建数据湖、数据仓库、ETL管道</strong>，无需管理服务器</li>
</ul>
</li>
<li>AWS Step Functions（状态机、人工审批）</li>
<li>X-Ray 用于分布式跟踪、分析应用程序请求流（微服务层面），不是用于发现底层 AWS 资源清单和绘制静态架构图 X-Ray 是 AWS 的分布式追踪服务，专门用于跟踪微服务架构中的请求流，帮助识别延迟和错误。</li>
<li><strong>AWS 上的工作负载发现功能</strong> 生成工作负载的架构图</li>
<li>在 组织管理账户的 <strong>AWS 账单控制台 中</strong>启用 <strong>成本分配标签（Cost Allocation Tags）</strong>，特别是 <strong>用户定义标签</strong>，以便在成本报告中包含这些标签。</li>
<li>Amazon MSK 是一项<strong>全托管的服务</strong>，让您可以在AWS上轻松地构建、运行和维护使用 <strong>Apache Kafka</strong> 处理流式数据的应用程序。</li>
</ul>
<hr>
<h2 id="十二、高可用与灾难恢复"><a href="#十二、高可用与灾难恢复" class="headerlink" title="十二、高可用与灾难恢复"></a>十二、<strong>高可用与灾难恢复</strong></h2><ul>
<li><p>多可用区部署（Multi-AZ）</p>
</li>
<li><p>跨区域复制（Cross-Region）</p>
</li>
<li><p>RPO&#x2F;RTO 设计 - RPO&#x2F;RTO 均为 24 小时的灾难恢复场景，使用 <strong>RDS 自动快照跨区域复制</strong> 是最简单、成本最低的方案</p>
</li>
<li><p>自动故障转移（如 Aurora、RDS Multi-AZ）</p>
</li>
<li><p>容量预留（Capacity Reservations）</p>
</li>
<li><p><strong>Aurora 全局数据库 + 多区域应用部署 + Route 53 故障转移</strong> 是 AWS 推荐的高容错全球扩展方案。</p>
</li>
<li><p>AWS 中分散部署组件运行 EC2 实例是构建<strong>高可用、可扩展、容错</strong>架构的关键策略 - 物理隔离</p>
</li>
<li><p>预测扩展 vs 计划扩展：Auto Scaling 组策略详解</p>
</li>
<li><p><strong>AWS Outposts</strong> 是将 AWS 基础设施（计算、存储、数据库等）部署到本地数据中心的解决方案，可运行 Amazon EMR 等 AWS 托管服务，实现本地数据处理，同时享受 AWS 的管理和扩展性。</p>
</li>
<li><p>AWS 提供了 <strong>集群置放组（Cluster Placement Group）<strong>将实例集中放置在单个可用区的一个低延迟分组内，使实例之间通过</strong>高速、低延迟网络</strong>连接。支持HPC工作负载</p>
</li>
<li><p><strong>AWS App2Container</strong>A2C 用于将现有应用程序<strong>容器化</strong>（迁移到容器）</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T1000/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T1000/" class="post-title-link" itemprop="url">AWS架构师T1000</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-29 10:13:29" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2026-01-10 20:51:47" itemprop="dateModified" datetime="2026-01-10T20:51:47+08:00">2026-01-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T1000"><a href="#AWS架构师T1000" class="headerlink" title="AWS架构师T1000"></a>AWS架构师T1000</h1><p><br>901 一家公司正将其工作负载迁移到 AWS，目前有：</p>
<ul>
<li>运行在 <strong>SQL Server 实例</strong> 上的本地关系数据库；</li>
<li>数据<strong>敏感且关键</strong>。</li>
</ul>
<p><strong>目标</strong>：</p>
<ol>
<li>提高安全性；</li>
<li>减少数据库的运营开销（如修补、备份、高可用等运维工作）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 将数据库迁移到 Amazon EC2 实例，使用 AWS KMS 的 AWS 托管密钥加密。<br>B. <u>将数据库迁移到多可用区的 Amazon RDS for SQL Server 数据库实例，使用 AWS KMS 的 AWS 托管密钥加密。</u><br>C. 将数据迁移到 Amazon S3 存储桶，使用 Amazon Macie 确保数据安全。<br>D. 将数据库迁移到 Amazon DynamoDB 表，使用 Amazon CloudWatch Logs 确保数据安全。</p>
<ul>
<li>RDS 是托管服务，自动处理备份、补丁、多可用区高可用，减少运营开销。</li>
<li>启用 KMS 加密可提高静态数据安全性，符合“提高安全性</li>
</ul>
<p><br>902 一家公司希望将一个应用程序迁移到 AWS，要求：</p>
<ol>
<li>提高该应用程序当前的可用性；</li>
<li>在应用程序的架构中使用 AWS WAF（Web 应用程序防火墙）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. <u>创建一个包含多个 Amazon EC2 实例的自动扩展组，这些实例在两个可用区中托管应用程序。配置一个应用程序负载均衡器（ALB），并将该自动扩展组设置为目标。将 WAF 连接到 ALB。</u><br>B. 创建一个包含多个托管该应用程序的 Amazon EC2 实例的集群放置组。配置一个应用程序负载均衡器，并将 EC2 实例设置为目标。将 WAF 连接到该放置组。<br>C. 创建两个在两个可用区中托管应用程序的 Amazon EC2 实例。将这些 EC2 实例配置为应用程序负载均衡器（ALB）的目标。将 WAF 连接到该 ALB。<br>D. 创建一个包含多个 Amazon EC2 实例的自动扩展组，这些实例在两个可用区中托管应用程序。配置一个应用程序负载均衡器（ALB）并将自动扩展组设置为目标。将 WAF 连接到自动扩展组。</p>
<ul>
<li><strong>提高可用性</strong>：需要在多个可用区（AZ）部署，使用负载均衡器分散流量，并最好有自动扩展能力以应对实例故障。</li>
<li><strong>使用 AWS WAF</strong>：WAF 必须部署在能够检查 HTTP&#x2F;HTTPS 流量的地方，通常连接到 ALB、CloudFront 或 API Gateway。WAF 不能连接到“放置组”</li>
</ul>
<p><br>903 一家公司在 Amazon S3 存储桶中管理一个数据湖，多个应用程序都可访问该存储桶。</p>
<ul>
<li>存储桶中每个应用程序有一个 <strong>唯一的前缀</strong>（如 <code>app1/</code>、<code>app2/</code>）。</li>
<li>要求：<ol>
<li>将每个应用程序限制在其特定的前缀范围内；</li>
<li>对每个前缀下的对象进行精细化控制。</li>
</ol>
</li>
<li>条件：以 <strong>最少的运营开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>为每个应用程序创建专用的 S3 访问点和访问点策略</u>。<br>B. 创建一个 S3 批量操作作业，为 S3 存储桶中的每个对象设置 ACL 权限。<br>C. 将 S3 存储桶中的对象复制到每个应用程序的新 S3 存储桶中，按前缀创建复制规则。<br>D. 将 S3 存储桶中的对象复制到每个应用程序的新 S3 存储桶中，为每个应用程序创建专用的 S3 访问点。</p>
<ul>
<li><strong>S3 访问点</strong> 可以为同一存储桶的不同前缀定义不同的策略，限制特定 IAM 用户&#x2F;角色只能通过该访问点访问指定前缀。</li>
<li>无需复制数据到多个桶，无需为每个对象单独设置 ACL，运营开销最小</li>
</ul>
<p><br>904 一家公司拥有一个应用程序，客户可以上传图片到 <strong>Amazon S3 存储桶</strong>。</p>
<ul>
<li>目前：每天晚上启动 <strong>Amazon EC2 Spot 实例集群</strong>，批量处理当天收到的所有图片。</li>
<li>每张图片处理需要 2 分钟，内存 512 MB。</li>
<li>现在需要修改应用程序，实现 <strong>在上传图像时实时处理</strong>（而不是等到晚上）。</li>
<li>目标：<strong>最具成本效益</strong> 的变更方案。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>使用 S3 事件通知将图像详情的消息写入 Amazon SQS 队列，配置一个 AWS Lambda 函数从队列读取消息并处理图像</u>。<br>B. 使用 S3 事件通知将图像详情的消息写入 Amazon SQS 队列，配置一个 EC2 预留实例从队列读取消息并处理图像。<br>C. 使用 S3 事件通知将图像详情的消息发布到 Amazon SNS 主题，在 Amazon ECS 中配置一个容器实例订阅该主题并处理图像。<br>D. 使用 S3 事件通知将图像详情的消息发布到 Amazon SNS 主题，配置 AWS Elastic Beanstalk 应用程序订阅该主题并处理图像。</p>
<p><br>905 一家公司希望提高其混合应用程序的 <strong>可用性和性能</strong>。<br>应用程序由两部分组成：</p>
<ol>
<li><strong>有状态、基于 TCP 的工作负载</strong> → 托管在不同 AWS 区域的 Amazon EC2 实例上。</li>
<li><strong>无状态、基于 UDP 的工作负载</strong> → 托管在本地。</li>
</ol>
<p>问：应采取哪些行动组合来提高可用性和性能？（选两项）</p>
<p><strong>选项复述：</strong></p>
<p>A. <u>使用 AWS Global Accelerator 创建一个加速器，将负载均衡器添加为端点</u>。<br>B. 创建一个 Amazon CloudFront 分发，其源站使用 Amazon Route 53 的基于延迟的路由将请求路由到负载均衡器。<br>C. 在每个区域配置两个应用程序负载均衡器（一个路由到 EC2 端点，一个路由到本地端点）。<br>D. <u>在每个区域配置一个网络负载均衡器指向 EC2 端点，并在每个区域配置一个网络负载均衡器指向本地端点</u>。<br>E. 在每个区域配置一个网络负载均衡器处理 EC2 端点，在每个区域配置一个应用程序负载均衡器路由到本地端点。</p>
<p>CloudFront 主要用于 HTTP&#x2F;HTTPS 缓存分发，不适合基于 TCP&#x2F;UDP 的非 HTTP 工作负载，且题目未提到 HTTP</p>
<p>ALB 不支持 UDP，本地 UDP 工作负载无法用 ALB。</p>
<p><br>906 一家公司在 Amazon EC2 实例和 Amazon EBS 上运行自管理的 Microsoft SQL Server。</p>
<ul>
<li><strong>目前做法</strong>：EBS 卷每天创建快照。</li>
<li><strong>问题</strong>：运行一个清理过期快照的脚本时，意外删除了所有 EBS 快照。</li>
<li><strong>需求</strong>：<ol>
<li>防止数据丢失（防止快照被意外删除）；</li>
<li>不能无限期保留 EBS 快照（需要合理生命周期管理）；</li>
<li>以<strong>最少的开发工作量</strong>满足要求。</li>
</ol>
</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 更改用户的 IAM 策略以拒绝 EBS 快照删除操作。<br>B. 每天完成快照后，将 EBS 快照复制到另一个 AWS 区域。<br>C. <u>在回收站中创建一个 7 天的 EBS 快照保留规则，并将该规则应用于所有快照。</u><br>D. 将 EBS 快照复制到 Amazon S3 标准不频繁访问（S3 Standard-IA）</p>
<ul>
<li><strong>EBS 快照回收站</strong> 是 AWS 原生功能，设置后删除的快照会进入回收站保留指定天数（例如 7 天），之后才永久删除。</li>
<li>可防止脚本意外删除导致的立即数据丢失，同时有自动清理机制（7 天后清理），不无限期保留。</li>
</ul>
<p><br>907 一家公司希望在测试环境中为其应用程序使用 AWS CloudFormation 堆栈。</p>
<ul>
<li>CloudFormation 模板存储在 <strong>阻止公共访问的 Amazon S3 存储桶</strong> 中。</li>
<li>需要根据<strong>特定用户请求</strong>，授予 CloudFormation 访问 S3 存储桶中模板的权限。</li>
<li>要求：遵循安全最佳实践。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 为 Amazon S3 创建网关 VPC 端点，配置 CloudFormation 堆栈以使用 S3 对象 URL。<br>B. 创建一个以 S3 存储桶为目标的 Amazon API Gateway REST API，配置 CloudFormation 堆栈以使用该 API Gateway URL。<br>C<u>. 为模板对象创建一个预签名 URL，配置 CloudFormation 堆栈以使用该预签名 URL。</u><br>D. 允许对 S3 存储桶中的模板对象进行公共访问，在测试环境创建后，阻止公共访问。</p>
<ul>
<li>预签名 URL 允许临时访问 S3 私有对象（无需公共访问）。</li>
<li>用户请求时生成预签名 URL（例如通过 CLI、SDK 或临时凭证），将该 URL 提供给 CloudFormation 堆栈创建操作，CloudFormation 可用该 URL 读取模板，不需要长期存储桶策略公开访问</li>
</ul>
<p><br>908 一家公司：</p>
<ul>
<li>应用程序在 <strong>AWS Organizations 某个组织内</strong> 运行。</li>
<li>将运营支持外包给<strong>外部支持工程师</strong>。</li>
<li>需求：<ol>
<li>外部支持工程师需要访问 <strong>AWS 管理控制台</strong>。</li>
<li>需要获得<strong>操作系统访问权限</strong>，访问私有子网中的 Amazon Linux EC2 实例集群。</li>
</ol>
</li>
<li>目标：以<strong>最安全的方式</strong>满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>确认已安装 SSM 代理，为实例分配具有必要策略的实例配置文件以连接到 Systems Manager。</u><br><u>使用 AWS IAM Identity Center 为外部工程师提供控制台访问权限，使用 Systems Manager 会话管理器分配所需权限。</u></p>
<p>B. 确认已安装 SSM 代理，为实例分配实例配置文件以连接到 Systems Manager。<br>使用 Systems Manager 会话管理器，并在每个 AWS 账户中为外部工程师创建本地 IAM 用户凭证以进行控制台访问。</p>
<p>C. 确认实例安全组仅允许来自外部工程师 IP 地址范围的 SSH 访问，为每个账户创建本地 IAM 用户给工程师控制台访问，并为每个工程师提供 SSH 密钥对登录实例。</p>
<p>D. 在公共子网创建堡垒主机，仅允许工程师 IP 范围访问。<br>实例安全组允许来自堡垒主机的 SSH 访问。为每位工程师提供 SSH 密钥对登录实例，并为每个账户创建本地 IAM 用户凭证用于控制台访问。</p>
<p>SSM 会话管理器部分正确，但为每个账户创建本地 IAM 用户（而非集中身份管理）不安全且管理开销大</p>
<p><br>909 一家公司在 <strong>us-east-1</strong> 使用 <strong>Amazon RDS for PostgreSQL</strong> 运行应用程序。</p>
<ul>
<li>还使用机器学习模型根据<strong>近实时报告</strong>预测年度收入。</li>
<li>这些报告是通过<strong>同一个 RDS 数据库</strong>生成的。</li>
<li>问题：在<strong>营业时间</strong>，数据库性能下降。</li>
<li>需求：提高数据库性能。</li>
<li>条件：以<strong>最具成本效益</strong>的方式满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 创建一个跨区域只读副本，将报告配置为从该只读副本生成。<br>B. 为 RDS for PostgreSQL 激活多可用区数据库实例部署，配置从备用数据库生成报告。<br>C. 使用 AWS DMS 将数据逻辑复制到新数据库，配置从新数据库生成报告。<br>D. <u>在 us-east-1 创建一个只读副本，配置从该只读副本生成报告。</u></p>
<p><br>910 一家公司在 AWS 云中托管多层公共 Web 应用程序：</p>
<ul>
<li>Web 层运行在 <strong>Amazon EC2 实例</strong>上。</li>
<li>数据库是 <strong>Amazon RDS</strong>。</li>
<li>预计假日周末销售额大幅增长。</li>
<li>需要构建解决方案，以 <strong>不超过 2 分钟的粒度</strong> 分析 Web 应用程序的性能。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 将 Amazon CloudWatch Logs 发送到 Amazon Redshift，使用 Amazon QuickSight 进行分析。<br>B. <u>启用所有 EC2 实例的详细监控，使用 Amazon CloudWatch 指标进行进一步分析。</u><br>C. 创建一个 AWS Lambda 函数，从 Amazon CloudWatch Logs 获取 EC2 日志，使用 Amazon CloudWatch 指标进行分析。<br>D. 将 EC2 日志发送到 Amazon S3，使用 Amazon Redshift 从 S3 获取日志并处理原始数据，再用 Amazon QuickSight 进行分析。</p>
<ul>
<li>实时性能分析（≤2 分钟粒度）通常用 <strong>CloudWatch 指标</strong>。</li>
<li>启用 EC2 详细监控（1 分钟粒度）可以收集系统指标，但应用性能需要自定义指标。</li>
</ul>
<p><br>911 一家公司运行照片存储和分享应用程序：</p>
<ul>
<li>用户上传照片到 <strong>Amazon S3 存储桶</strong>。</li>
<li>每天大约 <strong>150 张照片</strong>。</li>
<li>要求：为每张新照片<strong>创建缩略图</strong>并存储在第二个 S3 桶。</li>
<li>目标：以<strong>最具成本效益</strong>的方式满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 配置 Amazon EventBridge 定时规则，每分钟在长期运行的 Amazon EMR 集群上调用一个脚本，检查没有缩略图的照片并生成缩略图，上传到第二个桶。<br>B. 配置 Amazon EventBridge 定时规则，每分钟在始终开启的内存优化型 EC2 实例上调用脚本，检查没有缩略图的照片并生成缩略图，上传到第二个桶。<br>C. <u>配置 S3 事件通知，每次上传新照片时调用 AWS Lambda 函数，生成缩略图并上传到第二个桶。</u><br>D. 配置 S3 Storage Lens（这是 S3 存储分析工具），使其在用户上传照片时调用 Lambda 函数，生成缩略图并上传到第二个桶。</p>
<p><br>912 一家公司在 Amazon S3 存储桶中使用 <strong>S3 Glacier Deep Archive</strong> 存储类存储数百万对象（按多个前缀组织）。</p>
<ul>
<li>需要删除所有 <strong>超过 3 年的旧数据</strong>，但<strong>有一部分数据必须保留</strong>。</li>
<li>公司已经<strong>确定了必须保留的数据</strong>（即知道哪些数据要排除）。</li>
<li>要求：实施一个<strong>无服务器解决方案</strong>。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 使用 S3 Inventory 列出所有对象，使用 AWS CLI 创建在 EC2 实例上运行的脚本，从清单列表中删除对象。<br>B. 使用 AWS Batch 删除 3 年以上的对象，但必须保留的数据除外。<br>C. 配置 AWS Glue 爬虫来查询超过 3 年的对象，保存旧对象的清单文件，创建一个脚本来删除清单中的对象。<br>D. <u>启用 S3 清单，创建一个 AWS Lambda 函数来筛选和删除对象，通过 S3 批量操作，使用清单报告删除对象。</u></p>
<ul>
<li>S3 清单可生成包含对象元数据（包括最后修改日期）的 CSV&#x2F;ORC 报告。</li>
<li>S3 批量操作（Batch Operations）可以直接使用清单报告作为输入，执行大规模删除操作（支持筛选条件）。</li>
<li>可以结合 Lambda 做更复杂的筛选（例如排除要保留的数据），然后调用批量操作任务。</li>
</ul>
<p><br>913 一家公司在 AWS 上构建应用程序，使用 <strong>多个 Lambda 函数</strong> 从 <strong>单个 Amazon S3 存储桶</strong> 检索敏感数据处理。</p>
<ul>
<li>要求：确保 <strong>只有授权的 Lambda 函数</strong> 才能访问这些数据。</li>
<li>必须符合 <strong>最小权限原则</strong>。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 通过共享的 IAM 角色向所有 Lambda 函数授予完整的 S3 存储桶访问权限。<br>B. 配置 Lambda 函数在 VPC 内运行，配置存储桶策略基于 Lambda 函数的 VPC 终端节点 IP 地址授予访问权限。<br>C. 为每个 Lambda 函数创建单独的 IAM 角色，授予这些 IAM 角色对 S3 存储桶的访问权限，并为每个 IAM 角色分配为对应 Lambda 函数的执行角色。<br>D. <u>配置存储桶策略，根据 Lambda 函数的函数 ARN 授予其访问权限。</u></p>
<ul>
<li>S3 存储桶策略可以指定 <code>&quot;Principal&quot;: &#123;&quot;AWS&quot;: &quot;lambda-function-arn&quot;&#125;</code> 来允许特定 Lambda 函数访问。</li>
</ul>
<p><br>914 一家公司开发了一个<strong>非生产应用程序</strong>，由多个微服务组成，分别对应不同业务部门。</p>
<ul>
<li>当前架构：静态 Web 前端 + 基于 Java 的后端（应用逻辑） + MySQL 数据库托管在 <strong>Amazon EC2 实例</strong> 上。</li>
<li>一个开发团队维护所有微服务。</li>
<li>要求：<ol>
<li>确保应用程序<strong>安全</strong>。</li>
<li>确保应用程序<strong>能在全球范围内可用</strong>。</li>
</ol>
</li>
<li>目标：以 <strong>最少的运营开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 使用 <strong>Amazon CloudFront + AWS Amplify</strong> 托管静态前端，重构微服务为 <strong>Lambda 函数通过 API Gateway</strong> 访问，将 MySQL 迁移到 <strong>Amazon EC2 预留实例</strong>。<br>B. <u>使用 <strong>Amazon CloudFront + Amazon S3</strong> 托管静态前端，重构微服务为 <strong>Lambda 函数通过 API Gateway</strong> 访问，将 MySQL 迁移到 <strong>Amazon RDS for MySQL</strong>。</u><br>C. 使用 <strong>Amazon CloudFront + Amazon S3</strong> 托管静态前端，重构微服务为 <strong>Lambda 函数位于网络负载均衡器后</strong>，将 MySQL 迁移到 <strong>Amazon RDS for MySQL</strong>。<br>D. 使用 <strong>Amazon S3</strong> 托管静态前端，重构微服务为 <strong>Lambda 函数位于应用程序负载均衡器后</strong>，将 MySQL 迁移到 <strong>Amazon EC2 预留实例</strong>。</p>
<p>Lambda 放在 NLB 后面 → NLB 不支持基于内容的路由、身份验证等，且不直接提供全球端点，需要额外搭配 Route 53&#x2F;GA，运营更复杂</p>
<p><br>915 一家视频游戏公司为其全球用户部署新游戏应用。</p>
<ul>
<li>需要提供<strong>近乎实时的玩家评价和排名</strong>。</li>
<li>解决方案必须：<ol>
<li><strong>快速访问数据</strong>（低延迟）。</li>
<li><strong>确保在公司重启应用程序时数据能保存在磁盘上</strong>（持久化）。</li>
</ol>
</li>
<li>目标：以<strong>最少的运营开销</strong>满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 配置一个以 Amazon S3 存储桶为源的 Amazon CloudFront 分发，将玩家数据存储在 S3 中。<br>B. 在多个 AWS 区域创建 EC2 实例存储玩家数据，配置 Amazon Route 53 地理位置记录将用户引导至最近的 EC2 实例。<br><u>C. 部署一个 Amazon ElastiCache for Redis 集群，将玩家数据存储在 ElastiCache 集群中。</u><br>D. 部署一个 Amazon ElastiCache for Memcached 集群，将玩家数据存储在 ElastiCache 集群中。</p>
<ul>
<li>Redis 支持内存高速访问，满足近乎实时需求。</li>
<li>ElastiCache for Redis 支持<strong>持久化（RDB&#x2F;AOF）</strong>，重启时可以从磁盘恢复数据。</li>
</ul>
<p><br>916 一家公司在 AWS 上设计处理敏感数据的应用程序，为多个客户存储和处理财务数据。</p>
<ul>
<li>合规要求：<strong>每位客户的数据在静态时必须使用安全的集中式密钥管理解决方案进行单独加密</strong>。</li>
<li>希望使用 <strong>AWS KMS</strong> 实施加密。</li>
<li>目标：以 <strong>最小的运营开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 为每位客户生成唯一的加密密钥，将密钥存储在 Amazon S3 存储桶中，启用服务器端加密。<br>B. 在 AWS 环境中部署硬件安全设备，存储客户提供的加密密钥，将该安全设备与 AWS KMS 集成，对数据进行加密。<br>C. 创建一个 AWS KMS 密钥来加密应用程序中的所有敏感数据。<br>D. <u>为每个客户的数据创建单独的 AWS KMS 密钥，并启用精细的访问控制和日志记录。</u></p>
<ul>
<li>每个客户有独立的 KMS 密钥，实现客户数据单独加密。</li>
<li>KMS 是集中式密钥管理服务，支持精细访问控制（密钥策略、IAM 策略）和日志记录（AWS CloudTrail）</li>
</ul>
<p><br>917 一家公司需要设计一个<strong>具有弹性的 Web 应用程序</strong>来处理客户订单。<br>要求：</p>
<ol>
<li>能自动应对<strong>网络流量和应用程序使用量的增长</strong>。</li>
<li><strong>不影响客户体验或丢失客户订单</strong>（意味着高可用、不丢消息）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 使用 NAT 网关管理网络流量，使用 EC2 自动扩展组接收、处理和存储已处理的订单，使用 Lambda 函数捕获和存储未处理的订单。<br>B. 使用网络负载均衡器管理网络流量，使用应用程序负载均衡器接收来自 NLB 的客户订单，使用具有多可用区部署的 Amazon Redshift 存储未处理和已处理的订单。<br>C. 使用网关负载均衡器管理网络流量，使用 Amazon ECS 接收和处理订单，使用网关负载均衡器捕获并存储未处理的订单，使用 DynamoDB 存储已处理的订单。<br>D. <u>使用应用程序负载均衡器管理 Web 流量，使用 EC2 Auto Scaling 组接收和处理订单，使用 Amazon SQS 存储未处理的订单，使用具有多可用区部署的 Amazon RDS 存储已处理的订单。</u></p>
<p><br>918 一家公司使用 <strong>AWS DataSync</strong> 将数百万个文件（平均 10KB）从本地迁移到 AWS，希望使用 <strong>Amazon S3</strong> 存储。</p>
<ul>
<li>迁移后<strong>第一年</strong>：文件将被访问 1-2 次，必须能<strong>立即获取</strong>。</li>
<li><strong>一年后</strong>：文件必须<strong>归档至少 7 年</strong>。</li>
<li>目标：<strong>最具成本效益</strong> 的方案。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>使用归档工具将文件分组为大型对象，用 DataSync 迁移，第一年存储在 S3 Glacier 即时检索，1 年后用生命周期配置转换为 S3 Glacier 深度归档（保留期 7 年）。</u><br>B. 使用归档工具将文件分组为大型对象，用 DataSync 复制到 S3 Standard-IA，1 年后用生命周期配置转换为 S3 Glacier 即时检索（保留期 7 年）。<br>C. 将文件目标存储类别配置为 S3 Glacier 即时检索，1 年后用生命周期策略转换为 S3 Glacier 灵活检索（保留期 7 年）。<br>D. 配置 DataSync 任务将文件传输到 S3 Standard-IA，1 年后用生命周期配置转换为 S3 Glacier 深度归档（保留期 7 年）。</p>
<ul>
<li><strong>立即获取</strong>的归档存储类：<strong>S3 Glacier Instant Retrieval</strong>（延迟毫秒级，适合一年访问 1-2 次的场景）。</li>
<li><strong>长期归档</strong>：<strong>S3 Glacier Deep Archive</strong>（成本最低，检索时间 12 小时）。</li>
<li><strong>S3 Standard-IA</strong> 也可立即获取，但比 Glacier Instant Retrieval 贵（如果访问频率低于每月一次，Glacier Instant Retrieval 更经济）。</li>
</ul>
<p><br>919 一家公司将本地 Oracle 数据库直接迁移到 AWS，目前运行在：</p>
<ul>
<li><strong>EC2 内存优化型 Linux 实例</strong></li>
<li><strong>EBS 卷</strong>：<strong>1 TB 预配置 IOPS SSD (io1)</strong>，<strong>64,000 IOPS</strong></li>
<li>迁移后数据库存储性能比本地慢。</li>
<li>问：哪种解决方案能<strong>提高存储性能</strong>？</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>添加更多预配置 IOPS SSD (io1) EBS 卷，使用操作系统命令创建逻辑卷管理（LVM）条带化。</u><br>B. 将预配置 IOPS SSD (io1) EBS 卷的 IOPS 提升到 64,000 以上。<br>C. 将预配置 IOPS SSD (io1) EBS 卷的大小增加到 2 TB。<br>D. 将 EC2 Linux 实例更改为存储优化的实例类型，不更改 EBS 卷。</p>
<ul>
<li>提升吞吐量方法：<ol>
<li><strong>增加卷大小</strong>（C 选项）→ io1 卷吞吐量随卷大小增加而增加吗？<ul>
<li><strong>io1</strong> 吞吐量取决于配置的 IOPS（如前公式），<strong>与卷大小无关</strong>（除了最低 334 GiB 以上时吞吐量可达 1000 MiB&#x2F;s，但需要足够 IOPS 支持）。</li>
<li>在 64,000 IOPS 下，吞吐量已达 256 MiB&#x2F;s 上限（除非提高 IOPS）。</li>
<li>因此单纯增加到 2 TB 不会提高吞吐量，除非<strong>同时提升 IOPS</strong>。</li>
</ul>
</li>
<li><strong>增加 IOPS（B 选项）</strong> → 提高 IOPS 可提升吞吐量上限（每 1000 IOPS 对应 4 MiB&#x2F;s）。</li>
<li><strong>使用多个 EBS 卷并条带化（A 选项）</strong> → 通过 RAID 0&#x2F;LVM 条带化聚合多个卷的 IOPS 和吞吐量，可突破单个卷的限制。</li>
<li><strong>实例类型（D 选项）</strong> → 存储优化型实例（如 i3）使用本地 NVMe 存储，延迟更低、吞吐量更高，但需迁移数据，且 EBS 卷需重新挂载或改为实例存储。</li>
</ol>
</li>
</ul>
<p><br>920 一家公司正将托管在 EC2 上的单体 Web 应用程序迁移到 <strong>无服务器微服务架构</strong>。<br>要求：</p>
<ol>
<li>使用支持 <strong>事件驱动、松耦合架构</strong> 的 AWS 服务。</li>
<li>采用 <strong>发布&#x2F;订阅（pub&#x2F;sub）模式</strong>。</li>
<li><strong>最具成本效益</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 配置 Amazon API Gateway REST API 调用 Lambda 函数，将事件发布到 Amazon SQS 队列，配置一个或多个订阅者从 SQS 队列读取事件。<br>B. 配置 Amazon API Gateway REST API 调用 Lambda 函数，将事件发布到 Amazon SNS 主题，配置一个或多个订阅者从 SNS 主题接收事件。<br>C. 配置 Amazon API Gateway WebSocket API 通过增强型扇出写入 Kinesis Data Streams，配置一个或多个订阅者从数据流接收事件。<br>D. <u>配置 Amazon API Gateway HTTP API 调用 Lambda 函数，将事件发布到 Amazon SNS 主题，配置一个或多个订阅者从该主题接收事件。</u></p>
<p>API Gateway 有 <strong>REST API</strong> 和 <strong>HTTP API</strong> 两种，HTTP API 成本低于 REST API（功能较少，但适用于简单代理、Lambda 集成）</p>
<p><br>921 一家公司将单体应用迁移到：</p>
<ul>
<li><strong>Amazon EC2 实例</strong>（单实例运行，模块紧耦合，无法多实例扩展）。</li>
<li><strong>Amazon RDS</strong> 数据库。</li>
<li>问题：<ol>
<li>使用高峰期 <strong>EC2 实例 CPU 利用率很高</strong>。</li>
<li>CPU 过高导致 <strong>RDS 读取请求性能下降</strong>（可能因为应用处理慢，堆积了更多数据库连接&#x2F;查询）。</li>
</ol>
</li>
<li>要求：<ul>
<li>降低 CPU 利用率。</li>
<li>提升读取请求性能。</li>
</ul>
</li>
</ul>
<p>A<u>. 将 EC2 实例调整为更大 CPU 容量的实例类型，配置一个最小和最大大小为 1 的自动扩展组，为读取请求配置一个 RDS 只读副本。</u><br>B. 将 EC2 实例调整为更大 CPU 容量的实例类型，配置一个最小和最大大小为 1 的自动扩展组，添加一个 RDS 只读副本，并将所有读写流量重定向到该副本。<br>C. 配置一个最小 1、最大 2 的自动扩展组，将 RDS 数据库实例调整为更高 CPU 容量。<br>D. 将 EC2 实例调整为更大 CPU 容量的实例类型，配置一个最小和最大大小为 1 的自动扩展组，将 RDS 数据库实例调整为更大 CPU 容量</p>
<p>在保持单实例应用的前提下，通过垂直扩展 EC2 降低 CPU 压力，并通过 RDS 只读副本提升读取性能的最佳方案是 <strong>A</strong></p>
<p><br>922 一家公司需要向开发团队授予访问公司 AWS 资源的权限。<br>要求：</p>
<ol>
<li>对资源保持 <strong>高度的安全性</strong>。</li>
<li>需要一种访问控制解决方案，防止对敏感数据的 <strong>未授权访问</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 与团队其他成员共享每个开发团队成员的 IAM 用户凭证，以简化访问管理并优化开发工作流程。<br>B. <u>基于最小权限原则定义具有细粒度权限的 IAM 角色，为每个开发人员分配一个 IAM 角色。</u><br>C. 创建 IAM 访问密钥以授予编程访问权限，仅允许开发人员使用这些访问密钥通过 API 调用与 AWS 资源交互。<br>D. 创建一个 Amazon Cognito 用户池，通过该用户池授予开发人员访问 AWS 资源的权限。</p>
<p>Amazon Cognito 用户池用于管理应用程序的用户身份（如移动端、Web 端用户），不适合直接管理开发人员对 AWS 资源的管理访问</p>
<p><br>923 一家公司在 <strong>Amazon EC2 实例</strong>上托管了一个单体 Web 应用程序。</p>
<ul>
<li>问题：特定时间性能不佳，CloudWatch 显示 CPU 利用率达到 100%。</li>
<li>目标：<ol>
<li>解决性能问题。</li>
<li>提高应用程序的可用性。</li>
</ol>
</li>
<li>条件：以 <strong>最具成本效益</strong> 的方式，选择 <strong>两个步骤组合</strong>。</li>
</ul>
<p>A<u>. 使用 AWS Compute Optimizer 获取用于垂直扩展的实例类型建议。</u><br>B. 从 Web 服务器创建一个亚马逊机器镜像（AMI），在新的启动模板中引用该 AMI。<br>C. 创建一个自动扩展组和一个应用程序负载均衡器以进行垂直扩展。<br>D. 使用 AWS Compute Optimizer 获取用于横向扩展的实例类型建议。<br>E. <u>创建一个自动扩展组和一个应用程序负载均衡器以进行水平扩展。</u></p>
<p>先使用 Compute Optimizer 分析实例优化建议（可能建议垂直扩展更换实例类型），然后基于新实例类型创建自动扩展组进行水平扩展。<br>因此组合是 <strong>A（获取垂直扩展建议 → 可能更换实例类型）</strong> 和 <strong>E（创建 ASG + ALB 水平扩展）</strong>。</p>
<p><br>924 一家公司使用 <strong>AWS Organizations</strong> 管理多个 AWS 账户，所有业务应用程序运行在 AWS 云中。</p>
<ul>
<li>解决方案架构师需要 <strong>审查授予 IAM 用户的所有权限</strong>，以确定哪些 IAM 用户拥有超出所需的权限（过度特权）。</li>
<li>目标：以 <strong>最少的管理开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 使用网络访问分析器检查公司 AWS 账户中的所有访问权限。<br>B. 创建一个 AWS CloudWatch 告警，当 IAM 用户在 AWS 账户中创建或修改资源时触发。<br>C<u>. 使用 AWS IAM 访问分析器（IAM Access Analyzer）审查公司的所有资源和账户。</u><br>D. 使用 Amazon Inspector 查找现有 IAM 策略中的漏洞。</p>
<p>IAM Access Analyzer 的 <strong>策略验证（policy validation）</strong> 和 <strong>策略生成（policy generation）</strong> 功能可分析现有策略，识别过度权限，并提供建议策略（基于访问活动）</p>
<p><br>925 一家公司为符合监管要求，需实施新的数据保留政策。<br>要求：存储在 <strong>Amazon S3</strong> 中的敏感文档在 <strong>固定时间段内</strong> 必须受到保护，<strong>防止被删除或修改</strong>。</p>
<ul>
<li>关键词：固定时间段、防删除、防修改。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 对所需对象激活 S3 对象锁定并启用治理模式。<br>B. <u>对所需对象启用 S3 对象锁定，并启用合规模式。</u><br>C. 启用 S3 存储桶的版本控制，设置生命周期策略在指定时间段后删除对象。<br>D. 配置 S3 生命周期策略，将对象转换到 S3 Glacier Flexible Retrieval 以满足保留期限。</p>
<ul>
<li><strong>治理模式</strong>：允许某些特殊权限（如具有 <code>s3:BypassGovernanceRetention</code> 权限的用户）在覆盖保留设置的情况下删除或修改对象。</li>
<li><strong>合规模式</strong>：<strong>任何人（包括 root 账户）都不能在保留期内删除或修改对象</strong>，符合严格的合规要求。</li>
</ul>
<p><br>926 一家公司在 <strong>AWS Fargate（Amazon ECS）</strong> 上运行面向客户的 Web 应用程序。</p>
<ul>
<li>应用程序是 <strong>资源密集型</strong> 的。</li>
<li>需要 <strong>每周 7 天、每天 24 小时</strong> 提供服务。</li>
<li>预计会经历 <strong>短时间的高流量爆发</strong>。</li>
<li>工作负载必须具备 <strong>高可用性</strong>。</li>
<li>目标：以 <strong>最具成本效益</strong> 的方式满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 使用 Fargate 配置 ECS 容量提供程序，通过第三方工具进行负载测试，在 CloudWatch 中调整 Fargate 任务的大小。<br><u>B. 配置一个 ECS 容量提供程序，其中 Fargate 用于稳定状态，Fargate Spot 用于突发流量。</u><br>C. 配置一个 ECS 容量提供程序，使用 Fargate Spot 处理稳定状态的流量，使用 Fargate 处理突发流量。<br>D. 使用 Fargate 配置 ECS 容量提供程序，使用 AWS Compute Optimizer 来优化 Fargate 任务的大小。</p>
<ul>
<li><strong>Fargate</strong>：按 vCPU 和内存使用量收费（按需价格）。</li>
<li><strong>Fargate Spot</strong>：利用 AWS 多余容量，价格比普通 Fargate 低（约 30-70% 折扣），但可能被中断（不适合不能中断的关键任务）</li>
</ul>
<p><br>927 一家公司在 AWS 云中构建应用程序：</p>
<ul>
<li>架构：ALB 后的 EC2 实例 + Route 53 DNS 解析。</li>
<li>需求：需要一个 <strong>具有主动参与功能的托管解决方案</strong> 以检测分布式拒绝服务（DDoS）攻击。<ul>
<li>“主动参与功能” 可能指 AWS 提供主动防护、缓解协助或实时响应支持。</li>
</ul>
</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 启用 AWS Config，配置一个 AWS Config 托管规则来检测 DDoS 攻击。<br>B. 在 ALB 上启用 AWS WAF，创建带有检测和防止 DDoS 攻击规则的 WAF Web ACL 并与 ALB 关联。<br>C. 将 ALB 访问日志存储在 S3 中，配置 Amazon GuardDuty 检测 DDoS 攻击并采取自动预防措施。<br>D. <u>订阅 AWS Shield Advanced，在 Route 53 中配置托管区域，将 ALB 资源添加为受保护资源。</u></p>
<p><br>928 一家公司在 <strong>VPC</strong> 中托管视频流 Web 应用程序，使用 <strong>网络负载均衡器（NLB）</strong> 处理 <strong>TCP 流量</strong>（实时数据处理）。</p>
<ul>
<li>已出现 <strong>未经授权访问尝试</strong>。</li>
<li>需求：提高应用程序安全性，防止未经授权的访问尝试。</li>
<li>限制：<strong>尽量减少架构变更</strong>。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 直接在 NLB 上实施一系列 AWS WAF 规则，以过滤未授权流量。<br>B. <u>使用安全组重新创建 NLB，仅允许受信任的 IP 地址访问。</u><br>C. 与配置了严格 IP 地址允许列表的现有 NLB 并行部署第二个 NLB。<br>D. 使用 AWS Shield Advanced 提供增强的 DDoS 保护，并防止未授权访问尝试。</p>
<ul>
<li>NLB 本身没有安全组（NLB 是网络层服务，不由安全组控制流量）。</li>
<li>NLB 的目标组（如 EC2 实例）可以使用安全组，但 NLB 监听器无法直接通过安全组限制客户端 IP。</li>
<li>不过 NLB 可以与安全组关联吗？实际上 NLB <strong>不支持安全组</strong>，其流量控制依赖 <strong>网络 ACL（NACL）</strong> 或目标实例的安全组。</li>
</ul>
<p><br>929 一家医疗保健公司开发 <strong>AWS Lambda 函数</strong>，向<strong>加密的 Amazon SNS 主题</strong>发布通知，通知包含 <strong>PHI（受保护的健康信息）</strong>。</p>
<ul>
<li>SNS 主题使用 <strong>AWS KMS 客户托管密钥</strong> 加密。</li>
<li>必须确保应用程序有必要的权限，以<strong>安全地向 SNS 主题发布消息</strong>。</li>
</ul>
<p>问：哪些步骤组合可以满足这些要求？（选三项）</p>
<p><strong>选项复述：</strong></p>
<p>A. <u>为 SNS 主题创建一个资源策略，允许 Lambda 函数向该主题发布消息。</u><br>B. 对 SNS 主题使用带有 AWS KMS 密钥的服务端加密（SSE-KMS），而非客户管理的密钥。<br>C. <u>为 SNS 主题使用的加密密钥创建一个资源策略，该策略应具备必要的 AWS KMS 权限。</u><br>D. 在 SNS 主题的资源策略中指定 Lambda 函数的 Amazon 资源名称（ARN）。<br>E. 将 Amazon API Gateway HTTP API 与 SNS 主题相关联，以使用 API Gateway 资源策略控制对该主题的访问。<br>F. 配置一个 Lambda 执行角色，该角色具有使用 AWS KMS 中客户托管密钥所需的 IAM 权限。</p>
<ul>
<li><strong>SNS 主题策略</strong>允许 Lambda 发布（A&#x2F;D）。</li>
<li><strong>KMS 密钥策略或 IAM 角色权限</strong>允许 Lambda 使用密钥加密（C 和 F）。</li>
</ul>
<p>关联 API Gateway HTTP API 与 SNS 主题 → 不必要，题目只是 Lambda 直接发布到 SNS，无需通过 API Gateway</p>
<p><br>930 一家公司拥有员工门户网站：</p>
<ul>
<li>员工登录查看工资明细（现有门户）。</li>
<li>新功能：员工上传扫描件申请报销，程序从文档提取文本数据，提取信息附加到员工的报销 ID。</li>
<li>要求：<ol>
<li>员工门户网站需要 <strong>100% uptime</strong>。</li>
<li>文档提取程序在一天中根据需求不定期运行。</li>
<li>构建一个<strong>可扩展且经济高效</strong>的新系统。</li>
<li>对现有门户网站的改动需<strong>最小化</strong>，<strong>不希望进行任何代码更改</strong>。</li>
<li>以 <strong>最少的实施工作量</strong> 满足要求。</li>
</ol>
</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>在 Auto Scaling 组中为门户网站运行 EC2 按需实例，使用 AWS Lambda 函数运行文档提取程序，当员工上传新报销文档时调用该 Lambda 函数</u>。<br>B. 在 Auto Scaling 组中为门户网站运行 EC2 Spot 实例，在 EC2 Spot 实例上运行文档提取程序，当员工上传新文档时启动提取程序实例。<br>C. 购买储蓄计划以运行门户网站和文档提取程序，在自动扩展组中运行门户网站和提取程序。<br>D. 创建一个 Amazon S3 存储桶托管门户网站，使用 Amazon API Gateway 和 AWS Lambda 实现现有功能，用 Lambda 运行文档提取程序，当与新文档上传相关的 API 被调用时触发 Lambda。</p>
<p><br>931 一家媒体公司在 <strong>us-east-1</strong> 有多账户 AWS 环境：</p>
<ul>
<li><strong>生产账户</strong> 中有一个 <strong>Amazon SNS 主题</strong>，用于发布性能指标。</li>
<li><strong>管理员账户</strong> 中有一个 <strong>AWS Lambda 函数</strong>，用于处理和分析日志数据。</li>
<li>要求：当报告重要指标时，管理员账户中的 <strong>Lambda 函数必须由生产账户中的 SNS 主题发送的消息调用</strong>（跨账户调用 Lambda）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A<u>. 为 Lambda 函数创建一个 IAM 资源策略，允许 Amazon SNS 调用该函数。</u><br><u>B. 在管理员账户中实施 Amazon SQS 队列缓冲来自生产账户 SNS 主题的消息，配置 SQS 队列调用 Lambda 函数。</u><br>C. 为 SNS 主题创建一个 IAM 策略，允许 Lambda 函数订阅该主题。<br>D. 在生产账户中使用 Amazon EventBridge 规则捕获 SNS 主题通知，配置 EventBridge 规则将通知转发到管理员账户中的 Lambda 函数。<br>E. 将性能指标存储在生产账户中的 Amazon S3 存储桶中，使用 Amazon Athena 从管理员账户分析这些指标。</p>
<ol>
<li><strong>跨账户 SNS 触发 Lambda 的可行方法</strong>：<ul>
<li><strong>方法 1</strong>：SNS 主题（生产账户）直接调用 Lambda 函数（管理员账户） → 需要：<ol>
<li>Lambda 函数的资源策略允许来自生产账户 SNS 主题的调用（A 选项）。</li>
<li>生产账户 SNS 主题有权限发布到该 Lambda（可通过 Lambda 资源策略实现，无需 SNS 主题策略）。</li>
</ol>
</li>
<li><strong>方法 2</strong>：通过 SNS 跨账户订阅其他服务（如 SQS、HTTP 端点等）再触发 Lambda。<ul>
<li>例如 B 选项：SNS 主题 → 跨账户发送消息到管理员账户的 SQS 队列 → SQS 触发 Lambda。</li>
<li>这需要配置 SNS 主题策略允许跨账户发布到 SQS，并配置 SQS 队列策略允许 SNS 发布。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><br>932 一家公司正将应用程序从本地迁移到 <strong>Amazon EKS</strong>。<br>要求：</p>
<ol>
<li>必须为 VPC 中的 <strong>pods 使用自定义子网</strong>（不是默认的节点子网）。</li>
<li>需要确保这些 pods 能够在 VPC 中 <strong>安全通信</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 配置 AWS Transit Gateway 直接管理 EKS Pod 的自定义子网配置。<br>B. 从公司的本地 IP 地址范围创建一个 AWS Direct Connect 连接到 EKS Pod。<br>C. <u>使用适用于 Kubernetes 的 Amazon VPC CNI 插件，在 VPC 集群中为 Pod 定义自定义子网以供其使用</u>。<br>D. 实施一个 Kubernetes 网络策略，具有 Pod 反亲和性规则，将 Pod 放置限制在位于自定义子网内的特定节点上。</p>
<ul>
<li><strong>Pod 使用自定义子网</strong>：在 EKS 中，Pod 的 IP 地址分配由 <strong>VPC CNI 插件</strong> 管理。可以通过配置 VPC CNI 的 <strong>ENIConfig</strong> 或 <strong>自定义网络</strong>（例如使用 <code>aws-node</code> DaemonSet 配置 <code>WARM_ENI_TARGET</code> 和子网选择）来指定 Pod 从特定子网获取 IP。</li>
<li><strong>Pod 间安全通信</strong>：可通过 Kubernetes <strong>NetworkPolicy</strong> 或 VPC 安全组实现网络层隔离。</li>
</ul>
<p><br>933 一家公司托管一个电子商务应用程序，数据存储在 <strong>完全托管的 Amazon RDS for MySQL</strong> 数据库实例中。</p>
<ul>
<li>需要降低单点故障风险。</li>
<li>目标：以 <strong>最少的实施工作量</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>将 RDS 数据库实例修改为使用多可用区部署，在下次维护窗口期应用这些更改。</u><br>B. 将当前数据库迁移到新的 Amazon DynamoDB 多可用区部署，使用 AWS DMS 和异构迁移策略迁移到 DynamoDB。<br>C. 在多可用区部署中创建新的 RDS 数据库实例，从现有 RDS 数据库实例的最新快照中手动恢复数据。<br>D. 在 Amazon EC2 Auto Scaling 组中配置数据库实例，最小组大小为 3，使用 Route 53 简单路由分发请求到所有数据库实例。</p>
<ul>
<li>RDS 单点故障风险可通过 <strong>多可用区（Multi-AZ）</strong> 部署解决，主数据库实例在一个可用区，同步备用实例在另一个可用区，自动故障转移。</li>
</ul>
<p><br>934 一家公司在本地拥有：</p>
<ul>
<li><strong>Microsoft Windows SMB 文件服务器</strong></li>
<li><strong>Linux NFS 文件服务器</strong></li>
</ul>
<p>作为 AWS 迁移计划，希望将它们整合到 AWS 云中。<br>要求：</p>
<ol>
<li>使用 <strong>托管的 AWS 存储服务</strong>。</li>
<li>支持 <strong>NFS 和 SMB 访问</strong>。</li>
<li>能够在协议之间 <strong>共享数据</strong>（即同一份数据可通过 SMB 和 NFS 同时访问）。</li>
<li>必须在 <strong>可用区级别具备冗余能力</strong>（即单可用区内高可用，不要求跨区域）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. <u>使用 <strong>Amazon FSx for NetApp ONTAP</strong> 作为存储，配置多协议访问。</u><br>B. 创建两个 EC2 实例，一个用于 Windows SMB，另一个用于 Linux NFS。<br>C. 使用 <strong>Amazon FSx for NetApp ONTAP</strong> 实现 SMB 访问，使用 <strong>Amazon FSx for Lustre</strong> 实现 NFS 访问。<br>D. 使用 <strong>Amazon S3 存储</strong>，通过 <strong>Amazon S3 文件网关</strong> 访问 S3。</p>
<p>FSx for Lustre <strong>不支持 SMB</strong>，FSx for ONTAP 可支持 NFS 和 SMB，但使用两个不同文件系统会导致数据无法在协议间共享</p>
<p><br>935 一家软件公司需要升级关键 Web 应用程序。<br><strong>当前架构</strong>：</p>
<ul>
<li>单个 EC2 实例（公共子网）。</li>
<li>EC2 实例上运行 <strong>MySQL 数据库</strong>（与应用同机）。</li>
<li>DNS 记录在 <strong>Route 53</strong> 中。</li>
</ul>
<p><strong>需求</strong>：</p>
<ol>
<li>重新配置应用程序，使其具备 <strong>可扩展性和高可用性</strong>。</li>
<li>降低 <strong>MySQL 的读取延迟</strong>。<br>（选择两个解决方案组合）</li>
</ol>
<p>A. 在第二个 AWS 区域中启动第二个 EC2 实例，使用 Route 53 故障转移路由策略将流量重定向到第二个 EC2 实例。<br>B. <u>创建并配置一个自动扩展组，以便在多个可用区中启动私有 EC2 实例，将这些实例添加到新的应用程序负载均衡器后的目标组。</u><br>C<u>. 将数据库迁移到 Amazon Aurora MySQL 集群，创建主数据库实例和读取器数据库实例，位置在不同的可用区。</u><br>D. 创建并配置一个自动扩展组，以便在多个 AWS 区域中启动私有 EC2 实例，将这些实例添加到新的应用程序负载均衡器后的目标组。<br>E. 将数据库迁移到具有跨区域只读副本的 Amazon Aurora MySQL 集群。</p>
<ul>
<li><strong>B</strong> 解决应用层高可用与扩展。</li>
<li><strong>C</strong> 解决数据库高可用与降低读取延迟。</li>
</ul>
<p><br>936 一家公司运行 <strong>数千个 AWS Lambda 函数</strong>，需要：</p>
<ol>
<li>安全存储所有 Lambda 函数使用的 <strong>敏感信息</strong>（如 API 密钥、数据库密码等）。</li>
<li>管理敏感信息的 <strong>自动轮换</strong>（定期更新凭证）。</li>
<li>以 <strong>最少的运营开销</strong> 满足要求。（选择两项）</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 使用 Lambda@Edge 检索和创建敏感信息，以创建 HTTP 安全标头。<br>B. <u>创建一个检索敏感信息的 Lambda 层。</u><br>C. <u>将敏感信息存储在 AWS Secrets Manager 中。</u><br>D. 将敏感信息存储在 AWS Systems Manager Parameter Store 中。<br>E. 创建一个具有专用吞吐量的 Lambda 消费者，以检索敏感信息并创建环境变量。</p>
<p>Parameter Store 支持 SecureString 参数（用 KMS 加密），<strong>但不支持自动轮换</strong></p>
<ul>
<li>Lambda 层可共享代码库，但<strong>层本身不存储敏感信息</strong>，仍需从外部服务获取，且不解决自动轮换问题。</li>
</ul>
<p><br>937 一家公司有内部应用程序运行在 <strong>自动扩展组中的 EC2 实例</strong> 上：</p>
<ul>
<li>EC2 实例是 <strong>计算优化型</strong>，使用 <strong>Amazon EBS 卷</strong>。</li>
<li>希望 <strong>在 EC2 实例、自动扩展组和 EBS 卷中找到成本优化方案</strong>。</li>
<li>要求：以 <strong>最高的运营效率</strong> 满足要求（即用最少的操作获得优化建议）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 创建一个新的 AWS 成本和使用情况报告，在报告中搜索有关自动扩展组的 EC2 实例和 EBS 卷的成本建议。<br>B. 创建新的 Amazon CloudWatch 账单告警，检查 EC2 实例、自动扩展组和 EBS 卷的成本建议的告警状态。<br>C. <u>为 EC2 实例、自动扩展组和 EBS 配置 AWS Compute Optimizer 以获取成本建议。</u><br>D. 为 EC2 实例配置 AWS Compute Optimizer 以获取成本建议，创建新的 AWS 成本和使用情况报告，在报告中搜索有关自动扩展组和 EBS 卷的成本建议。</p>
<ul>
<li><strong>AWS Compute Optimizer</strong>：专门用于分析 EC2 实例类型、EBS 卷、自动扩展组和 Lambda 函数的资源利用率，并提供成本&#x2F;性能优化建议（如调整实例类型、EBS 卷类型、ASG 配置等）。</li>
<li><strong>AWS 成本和使用情况报告</strong>：主要用于详细账单数据和成本分析，不直接提供资源级别的优化建议（虽然可以结合 Cost Explorer 查看建议，但不如 Compute Optimizer 自动化程度高）。</li>
<li><strong>CloudWatch 账单告警</strong>：仅用于在费用超过阈值时报警，不提供优化建议</li>
</ul>
<p><br>938 一家公司在 <strong>单一 VPC 内跨多个可用区</strong> 的多台 EC2 实例上运行媒体商店。<br>要求：</p>
<ol>
<li>获得一个 <strong>高性能</strong> 的解决方案，用于在所有 EC2 实例之间 <strong>共享数据</strong>。</li>
<li>倾向于将数据 <strong>仅保留在 VPC 内部</strong>（即不通过公网访问）。</li>
<li>选项需选择最合适的推荐。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 创建一个 Amazon S3 存储桶，并从每个实例的应用程序中调用服务 API。<br>B. 创建一个 Amazon S3 存储桶，并将所有实例配置为以挂载卷的方式访问它（可能指 S3 文件网关或类似工具，但 S3 不能直接挂载为通用文件系统）。<br>C. 配置一个 Amazon EBS 卷，并在所有实例上挂载该卷。<br>D. <u>配置一个 Amazon Elastic File System（Amazon EFS）文件系统，并在所有实例上挂载它。</u></p>
<ul>
<li>全托管、可扩展的 NFS 文件系统，支持跨多个可用区并发访问。</li>
<li>可通过 VPC 内的挂载目标访问（数据保持在 VPC 内部）</li>
</ul>
<p><br>939 一家公司使用 <strong>Amazon RDS for MySQL 实例</strong>：</p>
<ul>
<li>为年末处理添加了一个 <strong>只读副本</strong>，以应对报告工具的额外只读查询。</li>
<li>只读副本 CPU 使用率 <strong>60%</strong>，主实例 CPU 使用率 <strong>60%</strong>。</li>
<li>年终活动结束后：<ul>
<li>只读副本 CPU 使用率 <strong>25%</strong>（负载下降）。</li>
<li>主实例 CPU 使用率仍 <strong>60%</strong>（依然较高）。</li>
</ul>
</li>
<li>需求：调整数据库大小，同时为未来的增长提供足够的性能。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 删除只读副本，不对主实例进行任何更改。<br>B. <u>将只读副本调整为更小的实例大小，不要对主实例进行更改。</u><br>C. 将只读副本调整为更大的实例大小，将主实例调整为更小的实例大小。<br>D. 删除只读副本，将主实例调整为更大的实例大小。</p>
<p>最合理的方案是 <strong>保留副本</strong>（为未来读扩展和可用性），<strong>缩小副本</strong>（因当前负载低），<strong>主实例暂不调整</strong>（60% 虽高但未饱和，可监控后续增长再决定是否升级）。</p>
<p><br>940 一家公司正在迁移到：</p>
<ul>
<li><strong>Amazon RDS for PostgreSQL</strong>（数据库）</li>
<li><strong>Amazon EC2 实例</strong>（应用程序）</li>
<li>希望 <strong>优化长期运行工作负载的成本</strong>（即长期稳定运行）。</li>
<li>目标：以 <strong>最具成本效益</strong> 的方式满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 对 RDS 使用按需实例，为 EC2 购买 1 年期计算节省计划（无预付）。<br>B. 为 RDS 购买 1 年期预留实例（无预付），为 EC2 购买 1 年期 EC2 实例节省计划（无预付）。<br>C. 为 RDS 购买 1 年期预留实例（部分预付），为 EC2 购买 1 年期 EC2 实例节省计划（部分预付）。<br>D. <u>为 RDS 购买 3 年期预留实例（全额预付），为 EC2 购买 3 年期 EC2 实例节省计划（全额预付）。</u></p>
<ul>
<li>在<strong>确定工作负载会长期运行且稳定</strong>的前提下，选择 <strong>3 年期全额预付</strong> 可获得最高折扣，成本最低。</li>
<li>对 <strong>RDS</strong>：用 <strong>预留实例</strong>（RI）。</li>
<li>对 <strong>EC2</strong>：用 <strong>计算节省计划</strong>（Savings Plans）更灵活（自动适用于多种实例类型、操作系统、可用区）。</li>
</ul>
<p><br>941 一家公司使用 <strong>Amazon EKS 集群</strong>，要求：<br>确保 EKS 集群中的 <strong>Kubernetes 服务账户</strong> 能够通过 <strong>IRSA（IAM Roles for Service Accounts）</strong>，安全且精细地访问特定的 AWS 资源。</p>
<p>问：哪种解决方案组合能够满足这些要求？（选两项）</p>
<p><strong>选项复述：</strong></p>
<p>A. 创建一个定义所需权限的 IAM 策略，将该策略直接附加到 EKS 节点的 IAM 角色。<br>B. 在 EKS 集群中实施网络策略，以防止 Kubernetes 服务账户访问特定的 AWS 服务。<br>C. 修改 EKS 集群的 IAM 角色，使其包含每个 Kubernetes 服务账户的权限，确保 IAM 角色与 Kubernetes 角色之间存在一对一的映射。<br>D. <u>定义一个包含必要权限的 IAM 角色，用 Amazon IAM 角色的 ARN 注释 Kubernetes 服务账户。</u><br><u>E. 在服务账户的 IAM 角色与 OpenID Connect（OIDC）身份提供商之间建立信任关系。</u></p>
<p>满足 IRSA 要求的两项必要步骤是 <strong>D（定义 IAM 角色并用 ARN 注释服务账户）</strong> 和 <strong>E（建立 IAM 角色与 OIDC 提供商的信任关系）</strong>。</p>
<ol>
<li>为 EKS 集群配置 <strong>IAM OIDC 身份提供商</strong>（建立信任关系）。</li>
<li>创建 IAM 角色，信任关系设置为允许来自该 OIDC 提供商和特定服务账户的请求（即建立角色与 OIDC 提供商的信任策略）。</li>
<li>在 Kubernetes 中创建服务账户，并使用注解 <strong><a target="_blank" rel="noopener" href="https://eks.amazonaws.com/role-arn">eks.amazonaws.com&#x2F;role-arn</a></strong> 指定该 IAM 角色的 ARN。</li>
<li>将 Pod 配置为使用该服务账户。</li>
</ol>
<p>将策略附加到 EKS 节点角色 → 这样节点上所有 Pod 共享权限，不满足<strong>精细访问控制</strong>（按服务账户区分）</p>
<p>网络策略控制 Pod 间网络通信，不控制 AWS API 访问</p>
<p>修改 EKS 集群 IAM 角色为每个服务账户包含权限 → 仍是通过节点角色，且无法实现一对一精细映射（节点角色只有一个）</p>
<p><br>942 一家公司定期将机密数据上传到 Amazon S3 存储桶进行分析。<br>安全政策要求：</p>
<ol>
<li>静态对象必须加密。</li>
<li>必须<strong>每年自动轮换加密密钥</strong>。</li>
<li>必须能够使用 <strong>AWS CloudTrail 跟踪密钥轮换情况</strong>。</li>
<li>尽量<strong>降低加密密钥的成本</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 使用客户提供的密钥进行服务器端加密（SSE-C）。<br>B. 使用带有亚马逊 S3 托管密钥的服务器端加密（SSE-S3）。<br>C. <u>使用带有 AWS KMS 密钥的服务器端加密（SSE-KMS）。</u><br>D. 使用客户管理的 AWS KMS 密钥进行服务器端加密。</p>
<ol>
<li><strong>关键要求</strong>：<ul>
<li><strong>自动密钥轮换</strong>：<ul>
<li>SSE-S3（B）密钥由 AWS 管理，但不提供自动轮换（AWS 内部管理，不向客户暴露轮换）。</li>
<li>SSE-KMS（C、D）支持 KMS 密钥自动轮换（每年一次）。</li>
</ul>
</li>
<li><strong>CloudTrail 跟踪密钥轮换</strong>：<ul>
<li>KMS 密钥轮换事件会记录到 CloudTrail（满足）。</li>
<li>SSE-C（A）和 SSE-S3（B）没有 CloudTrail 日志记录密钥轮换。</li>
</ul>
</li>
<li><strong>降低成本</strong>：<ul>
<li>KMS 密钥有每月费用（每密钥 1 美元）和 API 调用费用。</li>
<li>SSE-S3 免费。但 SSE-S3 不满足自动轮换和 CloudTrail 跟踪要求。</li>
<li>SSE-KMS 使用 <strong>AWS 托管密钥（AWS managed key）</strong> 免费（CMK 收费），但 AWS 托管密钥不支持自动轮换（由 AWS 内部管理，轮换不暴露给客户，且无 CloudTrail 轮换日志）。</li>
<li>所以必须在 <strong>客户管理的 KMS 密钥（D）</strong> 和 <strong>AWS 托管密钥（隐含在 C 中）</strong> 之间选择。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>如果是 <strong>客户管理密钥</strong>，则支持自动轮换和 CloudTrail 跟踪，但需要成本。</p>
<p><br>943 一家公司过去 3 个月已将多个应用程序迁移到 AWS。<br>要求：</p>
<ol>
<li>了解 <strong>每个应用程序的成本明细</strong>（按应用拆分成本）。</li>
<li>希望 <strong>定期收到包含此信息的报告</strong>。</li>
<li>以 <strong>最具成本效益</strong> 的方式满足要求（即花费最少额外成本&#x2F;工作量）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 使用 AWS 预算将过去 3 个月的数据下载到 .csv 文件中，查找所需信息。<br>B. 将 AWS 成本和使用情况报告加载到 Amazon RDS 数据库实例中，运行 SQL 查询获取信息。<br>C. <u>为所有 AWS 资源添加一个成本键标签，并将其值设为应用程序的名称，激活成本分配标签，使用成本资源管理器。</u><br>D. 为所有 AWS 资源添加一个成本键和应用程序名称的值作为标签，使用 AWS 账单和成本管理控制台下载过去 3 个月的账单，查找所需信息。</p>
<ul>
<li><strong>按应用程序分拆成本</strong> → 需要<strong>成本分配标签</strong>（Cost Allocation Tags），将每个资源标记上所属应用程序的名称。</li>
<li><strong>定期报告</strong> → 可利用 <strong>AWS Cost Explorer</strong> 或成本和使用情况报告，配合标签筛选，生成定期报告。</li>
<li><strong>成本效益</strong> → 使用 AWS 原生免费工具（标签、Cost Explorer）而不额外付费（如 RDS 数据库存储报告数据需费用）。</li>
</ul>
<p><br>944 一家电子商务公司准备在 AWS 上部署 Web 应用程序，确保<strong>为客户提供持续服务</strong>。<br>架构包括：</p>
<ol>
<li>Web 应用程序托管在 <strong>Amazon EC2 实例</strong>。</li>
<li>关系型数据库在 <strong>Amazon RDS</strong>。</li>
<li>静态资产存储在 <strong>Amazon S3</strong>。<br>要求：设计一个 <strong>稳健且具有弹性的架构</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 在单个可用区部署 EC2 实例，在同一可用区部署 RDS 数据库实例，使用启用了版本控制的 S3 存储静态资源。<br>B. <u>在多个可用区的自动扩展组中部署 EC2 实例，部署多可用区 RDS 数据库实例，使用 Amazon CloudFront 分发静态资源。</u><br>C. 在单个可用区部署 EC2 实例，在第二个可用区部署 RDS 数据库实例（跨可用区冗余），直接从 EC2 实例提供静态资产。<br>D. 使用 AWS Lambda 函数运行 Web 应用程序，使用 Amazon Aurora Serverless v2 作为数据库，将静态资产存储在 Amazon EFS One Zone-IA 中。</p>
<p><br>945 一家电子商务公司在 <strong>多个 AWS 账户</strong> 中运行多个内部应用程序，使用 <strong>AWS Organizations</strong> 管理账户。</p>
<ul>
<li>公司有一个 <strong>网络账户（Network Account）</strong>，其中有<strong>安全设备</strong>（例如防火墙、IDS&#x2F;IPS 等）。</li>
<li>要求：安全设备必须 <strong>检查跨 AWS 账户的应用程序之间的交互</strong>（即不同账户中应用间的流量需经过网络账户的安全设备检查）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 在网络账户中部署网络负载均衡器（NLB）将流量发送到安全设备，通过使用应用账户中的接口 VPC 终端节点（Interface VPC Endpoint），配置应用账户将流量发送到 NLB。<br>B. 在应用程序账户中部署应用程序负载均衡器（ALB）将流量直接发送到安全设备。<br>C. <u>在网络账户中部署网关负载均衡器（GWLB）将流量发送到安全设备，通过在应用账户中使用接口 GWLB 终端节点（Interface GWLB Endpoint），配置应用账户将流量发送到 GWLB。</u><br>D. 在应用程序账户中部署接口 VPC 终端节点将流量直接发送到安全设备。</p>
<ul>
<li><strong>Gateway Load Balancer (GWLB)</strong> 是专门设计用于与第三方安全设备集成的服务，它结合了 <strong>Transparent Network Gateway</strong>（GENEVE 封装）和负载均衡功能，可将流量引导到一组安全设备进行检查。</li>
<li><strong>GWLB Endpoint (GWLBE)</strong> 是 VPC 终端节点的一种，部署在应用账户中，可以将流量通过 AWS 内部网络发送到网络账户的 GWLB。</li>
</ul>
<p><br>946 一家公司在 <strong>Amazon Aurora MySQL 数据库集群</strong> 上运行生产工作负载，集群包含 <strong>六个 Aurora 副本</strong>。<br>要求：</p>
<ul>
<li>某部门的近实时报表查询<strong>自动分配到其中三个 Aurora 副本</strong>上。</li>
<li>这三个副本的<strong>计算和内存规格与其他副本不同</strong>（即特殊规格的节点组）。</li>
<li>需要将查询只路由到这三个特定副本。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>为工作负载创建并使用自定义端点。</u><br>B. 创建一个三节点集群克隆并使用读取端点。<br>C. 使用所选三个节点的任何实例端点。<br>D. 使用读取器端点自动分配只读工作负载。</p>
<ol>
<li><strong>Aurora 端点类型</strong>：<ul>
<li><strong>集群端点</strong>：指向主实例（读写）。</li>
<li><strong>读取器端点</strong>：自动在所有副本之间负载均衡（无法指定特定几个副本）。</li>
<li><strong>自定义端点</strong>：用户自定义的端点，可指向<strong>指定的一个或多个副本</strong>（支持按实例规格、角色等条件选择实例）。</li>
<li><strong>实例端点</strong>：指向单个特定实例（需应用管理多个端点，不自动负载均衡）。</li>
</ul>
</li>
</ol>
<p><br>947 一家公司当前：</p>
<ul>
<li>在本地服务器运行 Node.js 函数，连接 PostgreSQL 数据库。</li>
<li>将凭据存储在<strong>服务器环境变量</strong>的连接字符串中。</li>
<li>计划迁移到 AWS：<ol>
<li>用 <strong>AWS Lambda</strong> 替换 Node.js 应用服务器。</li>
<li>迁移到 <strong>Amazon RDS for PostgreSQL</strong>。</li>
<li>确保数据库凭据得到<strong>安全管理</strong>。</li>
</ol>
</li>
<li>目标：以 <strong>最小的运营开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 将数据库凭证存储为 AWS Systems Manager Parameter Store 中的参数，配置 Parameter Store 每 30 天自动轮换密钥，更新 Lambda 函数从该参数中检索凭证。<br>B. <u>将数据库凭证作为密钥存储在 AWS Secrets Manager 中，配置 Secrets Manager 每 30 天自动轮换凭证，更新 Lambda 函数从密钥中检索凭证。</u><br>C. 将数据库凭据存储为加密的 Lambda 环境变量，编写自定义 Lambda 函数来轮换凭据，每 30 天运行一次。<br>D. 将数据库凭证作为密钥存储在 AWS KMS 中，配置密钥的自动轮换，更新 Lambda 函数从 KMS 密钥检索凭证。</p>
<p>Secrets Manager 提供全托管凭据存储、自动轮换（可设置为每 30 天）、与 RDS 集成（轮换时自动更新数据库密码），并可通过 SDK 轻松从 Lambda 获取</p>
<p><br>948 一家公司希望将本地 Oracle 数据库的现有和持续数据变化复制到 <strong>Amazon RDS for Oracle</strong>。</p>
<ul>
<li>每天需要复制的数据量<strong>各不相同</strong>（波动）。</li>
<li>使用 <strong>AWS DMS（Database Migration Service）</strong> 进行复制。</li>
<li>要求：<strong>仅分配复制实例所需的容量</strong>（即按需分配，避免过度配置）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 配置具有多可用区部署的 AWS DMS 复制实例，以便在多个可用区中配置实例。<br>B. <u>创建一个 AWS DMS 无服务器复制任务，以便在配置所需资源的同时分析和复制数据容量。</u><br>C. 使用 Amazon EC2 Auto Scaling 根据要复制的数据量来向上或向下调整 AWS DMS 复制实例的大小。<br>D. 通过使用具有 AWS Fargate 启动类型的 Amazon ECS 来配置 AWS DMS 复制容量，以便在配置所需容量的同时分析和复制数据。</p>
<ul>
<li><strong>传统 DMS 复制实例</strong>：预分配固定容量（如 dms.c5.large），即使数据量变化，实例大小不变，可能过度配置或配置不足。</li>
<li><strong>DMS 无服务器复制（Serverless）</strong>：根据负载<strong>自动扩缩容</strong>，按实际使用的容量计费，符合“仅分配所需容量”的要求。 ✅</li>
</ul>
<p><br>949 一家公司拥有一个多层 Web 应用程序，内部服务组件部署在 <strong>Amazon EC2 实例</strong> 上。</p>
<ul>
<li>这些内部服务需要访问<strong>托管在 AWS 上的第三方 SaaS API</strong>（即 SaaS 提供商的应用程序也在 AWS 上运行）。</li>
<li>要求：<ol>
<li>提供从应用程序内部服务到第三方 SaaS 应用的 <strong>安全且私密的连接</strong>。</li>
<li>确保 <strong>公共互联网暴露面最小化</strong>（即流量不经过公共互联网）。</li>
</ol>
</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 部署 AWS 站点到站点 VPN，与第三方 SaaS 提供商建立安全连接。<br>B. 部署 AWS Transit Gateway 以管理和路由应用程序的 VPC 与第三方 SaaS 提供商之间的流量。<br>C. 配置 AWS PrivateLink，仅允许来自 VPC 的出站流量，不允许第三方 SaaS 提供商建立连接。<br>D. <u>使用 AWS PrivateLink 在应用程序的 VPC 和第三方 SaaS 提供商之间创建私有连接。</u></p>
<ul>
<li>需要 <strong>私密连接</strong>（流量不经过公共互联网）→ 使用 <strong>AWS PrivateLink</strong> 可实现 VPC 到另一个 VPC（或 AWS 服务）的私有连接，流量通过 AWS 内部网络。</li>
</ul>
<p><br>950 一位解决方案架构师需要将公司<strong>企业网络</strong>与其 <strong>VPC</strong> 相连，以允许本地访问 AWS 资源。<br>要求：</p>
<ol>
<li>在网络层和会话层对<strong>企业网络与 VPC 之间的所有流量进行加密</strong>。</li>
<li>提供<strong>安全控制措施</strong>，防止 AWS 与本地系统之间的无限制访问（即需要精细化访问控制）。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. 配置 AWS Direct Connect 以连接到 VPC，根据需要配置 VPC 路由表允许和拒绝流量。<br>B. 创建一个 IAM 策略，仅允许从一组已定义的公司 IP 地址访问 AWS 管理控制台，通过 IAM 策略和角色根据工作职责限制用户访问。<br>C. <u>配置 AWS 站点到站点 VPN 连接到 VPC，配置路由表将流量从本地引导至 VPC，配置实例安全组和网络 ACL 仅允许来自本地的必要流量。</u><br>D. 配置 AWS Transit Gateway 以连接到 VPC，配置路由表将流量从本地环境导向 VPC，配置实例安全组和网络 ACL 只允许来自本地环境的必要流量。</p>
<ul>
<li><strong>Direct Connect</strong>（A）本身不加密，若需加密需额外在 L3&#x2F;L4 以上层配置（如 IPsec over Direct Connect 或应用层加密），不是默认加密方案，且题目强调“必须在网络层和会话层对所有流量加密”，VPN 更直接符合。</li>
<li><strong>Transit Gateway</strong>（D）是路由中枢，本身不提供加密，需要搭配 VPN 或 Direct Connect + 加密。</li>
</ul>
<p>防止无限制访问 → 需要<strong>安全组（实例级）</strong> 和<strong>网络 ACL（子网级）</strong> 限制来源 IP 和端口，这是精细控制网络流量的方法</p>
<p><br>951 一家公司有一个自定义应用程序，内置凭证用于从 <strong>Amazon RDS for MySQL 数据库集群</strong> 检索信息。</p>
<ul>
<li>需要以 <strong>最少的编程工作</strong> 提高应用程序的安全性。</li>
<li>已在 RDS for MySQL 上为应用程序用户创建了凭证。</li>
<li>目标：提高安全性（可能指安全存储和轮换凭证）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 将凭证存储在 AWS KMS 中，创建密钥，配置应用从 KMS 加载凭证，启用自动密钥轮换。<br>B. 将凭据存储在加密的本地存储中，配置应用从本地存储加载凭证，通过创建定时任务设置轮换计划。<br>C. <u>将凭据存储在 AWS Secrets Manager 中，配置应用从 Secrets Manager 加载凭证，通过为 Secrets Manager 创建 Lambda 函数设置凭证轮换计划。</u><br>D. 将凭据存储在 AWS Systems Manager Parameter Store 中，配置应用从 Parameter Store 加载凭证，通过使用 Parameter Store 在 RDS MySQL 中设置凭证轮换计划。</p>
<p><br>952 一家公司希望将其应用程序迁移到无服务器解决方案，需要：</p>
<ul>
<li>使用 <strong>SQL 分析现有数据和新数据</strong>。</li>
<li>数据存储在 <strong>Amazon S3</strong> 中。</li>
<li>要求：<ol>
<li>数据静态时<strong>必须加密</strong>。</li>
<li>数据必须<strong>复制到另一个 AWS 区域</strong>（跨区域复制）。</li>
</ol>
</li>
<li>目标：以 <strong>最少的运营开销</strong> 满足要求。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. <u>创建一个新的 S3 存储桶，使用带有 AWS KMS 多区域密钥的 SSE-KMS，配置跨区域复制（CRR），将数据加载到新桶，使用 Amazon Athena 查询数据。</u><br>B. 创建一个新的 S3 存储桶，使用带有 S3 托管密钥的 SSE-S3，配置跨区域复制（CRR），将数据加载到新桶，使用 Amazon RDS 查询数据。<br>C. 在现有的 S3 存储桶上配置跨区域复制（CRR），使用带有 S3 托管密钥的 SSE-S3，使用 Amazon Athena 查询数据。<br>D. 在现有 S3 存储桶上配置跨区域复制（CRR），使用带有 AWS KMS 多区域密钥的 SSE-KMS，使用 Amazon RDS 查询数据。</p>
<ol>
<li><ul>
<li><strong>静态加密</strong>：SSE-S3 或 SSE-KMS 均可满足。</li>
<li><strong>跨区域复制（CRR）</strong>：需要启用 CRR。</li>
<li><strong>SQL 分析</strong>：无服务器 SQL 查询服务是 <strong>Amazon Athena</strong>（直接查询 S3 数据），RDS 是关系数据库服务（不适合直接查询 S3 中的原始数据，除非先导入）。</li>
<li><strong>最少运营开销</strong>：尽量使用托管服务、无服务器架构（Athena 无服务器，按查询付费，无需管理基础设施）。</li>
</ul>
</li>
<li><strong>跨区域复制与加密的关系</strong>：<ul>
<li>如果使用 <strong>SSE-KMS</strong> 加密，跨区域复制时需要在目标区域使用相同的 <strong>KMS 多区域密钥</strong>（或允许复制服务访问目标区域密钥）。</li>
<li><strong>SSE-S3</strong> 使用 AWS 托管的密钥，跨区域复制自动处理加密，无需管理密钥。<br>但题目未强制要求 KMS，因此 SSE-S3 也可以满足加密要求，且运营更简单（无密钥管理成本）。</li>
</ul>
</li>
</ol>
<p><br>953 一家公司拥有一个拥有数千用户的 Web 应用程序：</p>
<ol>
<li>用户上传 <strong>8-10 张图片</strong>，用于生成 AI 图像。</li>
<li>用户每 <strong>6 小时可以下载一次生成的 AI 图像</strong>（普通用户）。</li>
<li>高级用户可以 <strong>随时下载生成的 AI 图像</strong>。</li>
<li>公司每年使用用户上传的图像进行 <strong>两次 AI 模型训练</strong>（即上传的图片每年访问 2 次）。</li>
<li>需要一个 <strong>存储解决方案</strong> 存储这些图像，要求 <strong>最具成本效益</strong>。</li>
</ol>
<p><strong>选项复述：</strong></p>
<p>A. <u>将上传的图片移至 Amazon S3 Glacier Deep Archive，将高级用户生成的 AI 图片移至 S3 Standard，将非付费用户生成的 AI 图像移至 S3 Standard-IA</u>。<br>B. 将上传的图像移至 Amazon S3 Glacier Deep Archive，将所有生成的 AI 图像移至 S3 Glacier Flexible Retrieval。<br>C. 将上传的图像移至 Amazon S3 One Zone-IA，将高级用户生成的 AI 图像移至 S3 标准存储，将非高级用户生成的 AI 图像移至 S3 Standard-IA。<br>D. 将上传的图像移至 Amazon S3 One Zone-IA，将所有生成的 AI 图像移至 S3 Glacier Flexible Retrieval。</p>
<ul>
<li>上传图片 → Glacier Deep Archive（成本最低，适合归档）。</li>
<li>高级用户 AI 图片 → S3 Standard（随时下载，低延迟）。</li>
<li>普通用户 AI 图片 → S3 Standard-IA（访问频率较低，每 6 小时一次，符合低频访问模式，比 Standard 便宜）。</li>
</ul>
<p><br>954 一家公司正在 AWS 上开发 <strong>机器学习模型</strong>，作为独立微服务：</p>
<ul>
<li>微服务启动时从 <strong>Amazon S3</strong> 获取约 <strong>1GB 模型数据</strong> 加载到内存。</li>
<li>用户通过 <strong>异步 API</strong> 访问模型（可发送单个或批量请求）。</li>
<li>使用模式：<ul>
<li>用户数：<strong>数百名</strong>。</li>
<li>使用不规律：有些模型<strong>数天或数周无人使用</strong>，有些模型<strong>一次收到数千个批量请求</strong>。</li>
</ul>
</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A. 将来自 API 的请求定向到网络负载均衡器（NLB），将机器学习模型部署为 AWS Lambda 函数供 NLB 调用，使用自动扩展根据 NLB 流量扩展 Lambda 函数。<br>B. 将来自 API 的请求定向到应用程序负载均衡器（ALB），将机器学习模型部署为 Amazon ECS 服务供 ALB 调用，使用自动扩展根据 ALB 流量扩展 ECS 集群实例。<br>C. 将来自 API 的请求定向到 Amazon SQS 队列，将机器学习模型部署为 AWS Lambda 函数由 SQS 事件触发，基于 SQS 队列大小自动扩展 Lambda 函数的虚拟 CPU 数量。<br>D. <u>将来自 API 的请求定向到 Amazon SQS 队列，将机器学习模型部署为从队列读取数据的 Amazon ECS 服务，为 ECS 使用自动扩展根据 SQS 队列大小扩展集群容量和服务数量。</u></p>
<ul>
<li>D 方案利用 SQS 缓冲突发请求，ECS 根据队列长度自动扩展，更适合处理不定时批量请求和可能长期闲置的场景（通过缩放到零节省成本）。</li>
</ul>
<p><br>955 一家公司在 <strong>ALB + Auto Scaling 组 EC2</strong> 上运行 Web 应用程序，数据库是 <strong>Amazon Aurora MySQL 集群</strong>。<br>需要创建 <strong>灾难恢复（DR）解决方案</strong>：</p>
<ul>
<li><strong>RTO（恢复时间）≤ 30 分钟</strong>。</li>
<li><strong>当主基础设施正常运行时，DR 解决方案无需支持客户使用</strong>（即<strong>暖待机&#x2F;热待机</strong>模式，不是主动-主动）。</li>
</ul>
<p><strong>选项复述：</strong></p>
<p>A<u>. 在第二个 AWS 区域部署 DR 基础设施（ALB + Auto Scaling 组），将 ASG 的期望&#x2F;最大容量设为最小（如 0 或 1），将 Aurora MySQL 转换为 Aurora 全局数据库，配置 Route 53 主备故障转移。</u><br>B. 在第二个区域部署 DR 基础设施，更新 ASG 包含第二区域 EC2 实例，使用 Route 53 主动-主动故障转移，将 Aurora 转换为全局数据库。<br>C. 使用 AWS Backup 备份数据库数据，在第二区域部署 DR 基础设施（ALB + ASG 含第二区域实例），使用 Route 53 双活故障转移，在第二区域创建 Aurora 集群并从备份恢复。<br>D. 使用 AWS Backup 备份基础设施配置，利用备份在第二区域创建基础设施，将 ASG 期望容量设为 0，使用 Route 53 主备故障转移，将 Aurora 转换为全局数据库。</p>
<ol>
<li><strong>DR 模式选择</strong>：<ul>
<li>要求：主基础设施正常时 <strong>DR 不服务客户</strong> → 适合 <strong>暖待机（warm standby）</strong> 或 <strong>热待机（hot standby）</strong>，但不是主动-主动（B、C 的“主动-主动”或“双活”不符合）。</li>
<li>RTO ≤ 30 分钟 → 需要数据库和应用程序能快速恢复。</li>
</ul>
</li>
<li><strong>数据库 DR 方案</strong>：<ul>
<li><strong>Aurora 全局数据库</strong> 提供跨区域只读副本（次级区域集群），支持 <strong>RPO 近 0</strong> 和快速故障转移（RTO 通常 &lt; 1 分钟），适合 ≤30 分钟 RTO 要求。</li>
<li>仅用 <strong>AWS Backup 恢复</strong>（C、D）可能导致 RTO 较长（需要从备份恢复数据库）。</li>
</ul>
</li>
<li><strong>应用程序层 DR</strong>：<ul>
<li>暖待机：在第二区域部署 ASG 但容量设为 0 或最小（如 1 台小实例），故障时快速扩容。</li>
<li>Route 53 配置 <strong>主备故障转移</strong>（非主动-主动）。</li>
</ul>
</li>
</ol>
<p><br>956 一家公司正在将其数据处理应用程序迁移到 AWS 云。该应用程序处理多个短期批处理作业，这些作业不能被中断。作业完成后会生成数据，这些数据在 30 天内会被访问，然后需要保留 2 年。<br>公司希望尽可能降低运行应用程序的成本。<br>请从以下选项中选择满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 将数据处理应用程序迁移到 Amazon EC2 Spot 实例。数据存储在 Amazon S3 Standard 中。30 天后将数据移至 Amazon S3 Glacier Instant 检索层。设置过期时间，2 年后删除数据。<br>B. 将数据处理应用程序迁移到 Amazon EC2 按需实例。数据存储在 Amazon S3 Glacier 即时检索中。30 天后将数据移至 S3 Glacier 深度归档。设置过期时间，2 年后删除数据。<br>C. 部署 Amazon EC2 Spot 实例来运行批处理作业。数据存储在 Amazon S3 标准存储中。30 天后将数据移至 Amazon S3 Glacier 灵活检索存储。设置过期时间，2 年后删除数据。<br>D. <u>部署 Amazon EC2 按需实例来运行批处理作业。数据存储在 Amazon S3 标准存储中。30 天后将数据移至 Amazon S3 Glacier Deep Archive。设置过期时间，2 年后删除数据。</u></p>
<ul>
<li>批处理作业不能中断 → 不能使用 Spot 实例，只能用按需实例（或预留实例，但选项里只有按需和 Spot）。</li>
<li>数据 30 天内需要访问 → S3 Standard 适合频繁访问。</li>
<li>30 天后到 2 年之间几乎不访问 → 移至 S3 Glacier Deep Archive（成本最低的归档存储）。</li>
<li>2 年后删除 → 可通过 S3 生命周期策略设置过期。</li>
</ul>
<p><br>957 一家公司需要设计混合网络架构，其工作负载分别在 AWS 云和本地数据中心，并且它们之间的通信需要个位数毫秒（ms）的延迟。<br>公司已经使用了 AWS Transit Gateway 连接多个 VPC。<br>问哪两种步骤组合最能<strong>经济高效地</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 为每个 VPC 建立单独的 AWS Site-to-Site VPN 连接。<br>B. <u>将 AWS Direct Connect 网关与连接到 VPC 的 Transit Gateway 相关联。</u><br>C. 建立 AWS Site-to-Site VPN 连接到 AWS Direct Connect 网关。<br>D. <u>建立 AWS Direct Connect 连接，创建一个中转虚拟接口（Transit VIF）连接到 Direct Connect 网关。</u><br>E. 将 AWS Site-to-Site VPN 连接与连接到 VPC 的 Transit Gateway 相关联。</p>
<ul>
<li>D：建立 Direct Connect 连接并创建中转 VIF 到 Direct Connect 网关 → 这是物理专线建立的必要步骤。</li>
<li>B：将 Direct Connect 网关与 Transit Gateway 关联 → 使得本地数据中心可以通过专线访问所有 Transit Gateway 连接的 VPC，实现集中、低延迟、低成本的混合网络架构。</li>
</ul>
<p><br>958 一家全球电子商务公司在 AWS 上运行关键工作负载，使用 Amazon RDS for PostgreSQL 数据库，配置为多可用区（Multi-AZ）部署。<br>当数据库发生故障转移（failover）时，应用程序会出现超时情况。<br>公司需要一个有弹性的解决方案来缩短故障转移时间。<br>选择能满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. <u>创建一个 Amazon RDS 代理，将该代理分配给数据库实例。</u><br>B. 为数据库实例创建一个只读副本，将读取流量转移到该只读副本。<br>C. 启用 Performance Insights，监控 CPU 负载以识别超时情况。<br>D. 定期进行自动快照，将自动快照复制到多个 AWS 区域。</p>
<p>RDS Proxy 通过维护连接池和快速重连机制，使应用在数据库故障转移期间几乎不感知连接中断，从而减少或消除超时，满足“缩短故障转移时间”的要求（从应用程序角度看）</p>
<p><br>959 一家公司在开发 AWS 账户中有多个 Amazon RDS 数据库实例，这些实例都带有标识为开发资源的标签。<br>要求：开发数据库实例仅在工作时间按计划运行，非工作时间应停止以节省成本。<br>问哪种解决方案能以最少的运营开销满足要求？</p>
<p><strong>选项复述：</strong><br>A. 创建一个 Amazon CloudWatch 警报，以识别需要停止的 RDS 实例。创建一个 AWS Lambda 函数来启动和停止 RDS 实例。<br>B. 创建一个 AWS Trusted Advisor 报告，以识别需要启动和停止的 RDS 实例。创建一个 AWS Lambda 函数来启动和停止这些 RDS 实例。<br>C. 创建 AWS Systems Manager State Manager 关联以启动和停止 RDS 实例。<br>D<u>. 创建一个 Amazon EventBridge 规则，该规则调用 AWS Lambda 函数来启动和停止 RDS 实例。</u></p>
<p><br>960 一家消费者调查公司将历史数据存储在 AWS 区域的一个 Amazon S3 存储桶中。<br>现在要开始与位于新地理区域（不同 AWS 区域）的一家营销公司共享这些数据。<br>已经授予营销公司的 AWS 账户访问该 S3 存储桶的权限。<br>要求：在营销公司从 S3 存储桶请求数据时，最大限度降低数据传输成本。<br>问哪种解决方案能满足要求？</p>
<p><strong>选项复述：</strong><br>A. <u>在公司的 S3 存储桶上配置请求者付费（Requester Pays）功能。</u><br>B. 配置从公司的 S3 存储桶到营销公司其中一个 S3 存储桶的 S3 跨区域复制（CRR）。<br>C. 配置 AWS 资源访问管理器（RAM），将 S3 存储桶与营销公司的 AWS 账户共享。<br>D. 配置公司的 S3 存储桶使用 S3 智能分层，并将该存储桶同步到营销公司的 S3 存储桶。</p>
<ul>
<li>当启用“请求者付费”时，<strong>请求数据的用户（即营销公司）需要支付数据传输费用和请求费用</strong>，而不是数据所有者（公司）支付。</li>
<li>由于营销公司是新区域访问，会产生跨区域数据传输费，此功能可以<strong>将费用转移给营销公司</strong>，从而降低公司的成本</li>
</ul>
<p><br>961 一家公司在 AWS 上托管公共电子商务网站，使用 <strong>AWS Global Accelerator</strong> 将互联网流量转发至作为自动扩展组入口的 <strong>ALB</strong>。<br>最近网站遭受 DDoS 攻击，需要解决方案来缓解未来攻击，且要求<strong>实施工作量最少</strong>。<br>选择能满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 为 Global Accelerator 配置 AWS WAF Web ACL，使用基于速率的规则阻止流量。<br>B. 配置 Lambda 函数读取 ALB 指标，通过更新 VPC 网络 ACL 来阻止攻击。<br>C<u>. 在 ALB 上配置 AWS WAF Web ACL，使用基于速率的规则阻止流量</u>。<br>D. 在 Global Accelerator 之前配置 Amazon CloudFront 分发。</p>
<ul>
<li>ALB 原生支持集成 AWS WAF，可以通过基于速率的规则（rate-based rules）限制请求频率，有效应对应用层（第7层）DDoS。</li>
</ul>
<p><br>962 一家公司使用 Amazon DynamoDB 表存储来自设备的数据，该表支持面向客户的网站（显示客户设备的近期活动）。<br>表的读写吞吐量是<strong>预配置（Provisioned）模式</strong>。<br>公司希望每天计算客户设备数据的性能指标，且解决方案必须对表的预配置读写容量影响最小。<br>选择能满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 使用带有 Amazon Athena DynamoDB 连接器的 Amazon Athena SQL 查询，按重复计划计算性能指标。<br>B. <u>使用带有 AWS Glue DynamoDB 导出连接器的 AWS Glue 作业定期计算性能指标。</u><br>C. 使用 Amazon Redshift COPY 命令按定期计划计算性能指标。<br>D. 使用带有 Apache Hive 外部表的 Amazon EMR 作业，按定期计划计算性能指标。</p>
<p>AWS Glue 作业配合 DynamoDB 导出连接器，可以利用 DynamoDB 的<strong>导出到 S3</strong> 功能（该功能不消耗表的预置读容量），将数据导出到 S3 后再进行 ETL 和指标计算，从而最小化对原 DynamoDB 表性能的影响。</p>
<p><br>963 解决方案架构师为新无状态应用程序设计云架构，已创建 AMI 和启动模板。<br>要求：</p>
<ol>
<li>处理过程必须并行运行，根据需要添加或移除 EC2 实例。</li>
<li>应用程序必须是松耦合的。</li>
<li>作业项必须持久存储。<br>选择能满足这些要求的解决方案。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 创建 Amazon SNS 主题发送需要处理的作业。使用启动模板创建自动扩展组，扩展策略基于 CPU 使用率添加&#x2F;移除实例。<br>B. 创建 Amazon SQS 队列存放任务。使用启动模板创建自动扩展组，扩展策略基于网络使用情况添加&#x2F;移除实例。<br>C. <u>创建 Amazon SQS 队列存放作业。使用启动模板创建自动扩展组，扩展策略基于 <strong>SQS 队列中的项目数量</strong> 添加&#x2F;移除实例。</u><br>D. 创建 Amazon SNS 主题发送需要处理的任务。使用启动模板创建自动扩展组，扩展策略基于发布到 SNS 主题的消息数量添加&#x2F;移除实例。</p>
<ul>
<li>使用 <strong>SQS 队列深度（ApproximateNumberOfMessages）</strong> 作为 ASG 扩展指标，可以直接根据待处理作业数量扩缩实例，实现负载驱动扩缩，完美匹配并行处理和动态扩缩需求。</li>
</ul>
<p><br>964 一家全球电子商务公司当前是单体架构，需要管理不断增长的产品数据量。<br>要求：</p>
<ol>
<li>解决方案必须具备可扩展性，并采用模块化服务架构。</li>
<li>需要维护其结构化数据库模式。</li>
<li>需要一个存储解决方案来存储产品数据（结构化）和产品图像（非结构化）。</li>
<li>要以最少的运营开销满足要求。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 在自动扩展组中使用 Amazon EC2 实例部署容器化应用程序，用 ALB 分配流量，用 Amazon RDS 存储产品数据和产品图像。<br>B. 使用 AWS Lambda 管理现有单体应用，用 DynamoDB 存储产品数据和产品图像，用 SNS 实现 Lambda 之间的事件通信。<br>C. 使用 Amazon EKS 和 EC2 部署容器化应用，用 Amazon Aurora 存储产品数据，用 AWS Step Functions 管理工作流，将产品图像存储在 S3 Glacier Deep Archive。<br>D<u>. 使用 Amazon ECS with AWS Fargate 部署容器化应用程序，用多可用区部署的 Amazon RDS 存储产品数据，将产品图像存储在 Amazon S3 存储桶中</u>。</p>
<p>ECS Fargate 提供无服务器的容器运行环境，无需管理 EC2 实例，减少运营开销；<br>RDS 保持结构化数据库模式，适合产品数据；<br>S3 是存储产品图像的标准解决方案（高可用、可扩展、成本低）。</p>
<p><br>965 一家公司正在将应用程序从本地迁移到 AWS，应用程序将在 Amazon S3 中存储敏感数据。<br>要求：必须在将数据存储到 Amazon S3 之前对数据进行加密。<br>问哪种解决方案能满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. <u>使用客户管理的密钥通过客户端加密来加密数据。</u><br>B. 使用 AWS KMS 密钥通过服务器端加密（SSE-KMS）对数据进行加密。<br>C. 使用客户提供的密钥进行服务器端加密（SSE-C）来加密数据。<br>D. 使用带有 Amazon S3 托管密钥的客户端加密对数据进行加密。</p>
<ul>
<li>客户端加密意味着数据在发送到 S3 之前，在客户端使用自己的密钥进行加密。</li>
</ul>
<p><br>966 一家公司要创建一个多团队共享的 Amazon EMR 集群。要求：</p>
<ol>
<li>每个团队的大数据工作负载只能访问该团队所需的 AWS 服务。</li>
<li>工作负载不能访问集群底层 EC2 实例上的 IMDSv2（实例元数据服务版本 2）。<br>选择能满足这些要求的解决方案。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 为团队所需的每个 AWS 服务配置接口 VPC 终端节点。使用所需的接口 VPC 终端节点提交大数据工作负载。<br>B. <u>创建 EMR 运行时角色。配置集群以使用运行时角色。使用运行时角色提交大数据工作负载。</u><br>C. 为每个团队创建具有所需权限的 EC2 IAM 实例配置文件。使用该实例配置文件提交大数据工作负载。<br>D. 创建一个 EMR 安全配置，将 EnableApplicationScopedIAMRole 选项设置为 false。使用该安全配置提交大数据工作负载。</p>
<p>EMR 运行时角色（Runtime Role）允许每个 Spark 作业使用独立的 IAM 角色，实现工作负载级别的细粒度权限控制，并且作业无需访问 EC2 实例的 IMDSv2 来获取凭证，从而满足权限隔离和禁止访问 IMDSv2 的双重要求。</p>
<p><br>967 解决方案架构师正在设计一个处理用户注册表单的应用程序，采用两层架构：</p>
<ul>
<li>Web 应用服务器层（前端接收表单）</li>
<li>工作层（后端处理表单）</li>
</ul>
<p>要求：</p>
<ol>
<li>需要快速处理提交的表单。</li>
<li>需要准确处理每个表单<strong>一次且仅一次</strong>（exactly-once processing）。</li>
<li>必须确保没有数据丢失。<br>选择能满足要求的解决方案。</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>在 Web 层与工作层之间使用 Amazon SQS FIFO 队列来存储和转发表单数据。</u><br>B. 在 Web 层与工作层之间使用 Amazon API Gateway HTTP API 来存储和转发表单数据。<br>C. 在 Web 层与工作层之间使用 Amazon SQS 标准队列来存储和转发表单数据。<br>D. 使用 AWS Step Functions 工作流，在 Web 层与工作层之间创建同步工作流。</p>
<p>SQS FIFO 队列提供消息持久化（防丢失）、顺序处理、以及 exactly-once 语义，同时实现异步解耦让 Web 层快速响应，完全满足“快速处理、准确一次、无数据丢失”的要求。</p>
<p><br>968 一家金融公司目前使用本地搜索应用程序收集各个数据源产生的流数据，并为搜索和可视化功能提供实时更新。<br>计划迁移到 AWS，希望使用 AWS 原生解决方案。<br>选择能满足这些要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 使用 Amazon EC2 实例接收和处理数据流，传输至 Amazon S3 存储。使用 Amazon Athena 搜索数据，使用 Amazon Managed Grafana 创建可视化。<br>B. 使用 Amazon EMR 提取和处理数据流，存储到 Amazon Redshift。使用 Amazon Redshift Spectrum 搜索数据，使用 Amazon QuickSight 创建可视化。<br>C. 使用 Amazon EKS 摄取和处理数据流，存储到 Amazon DynamoDB。使用 Amazon CloudWatch 创建图形化仪表板来搜索和可视化数据。<br>D<u>. 使用 Amazon Kinesis Data Streams 摄入数据流并将其处理至 Amazon OpenSearch Service。使用 OpenSearch Service 搜索数据，使用 Amazon QuickSight 创建可视化内容。</u></p>
<ul>
<li><strong>Kinesis Data Streams</strong> 是 AWS 原生流数据摄入和实时处理服务。</li>
<li><strong>Amazon OpenSearch Service</strong>（原 Elasticsearch）专为实时搜索和可视化设计，支持从 Kinesis 直接摄入数据，提供低延迟搜索和 Kibana 可视化。</li>
<li><strong>QuickSight</strong> 可以与 OpenSearch 集成或直接用于商业智能可视化</li>
</ul>
<p><br>969 一家公司目前在本地 Linux 机器上运行一个资源密集型的 <a target="_blank" rel="noopener" href="https://asp.net/">ASP.NET</a> 应用程序，直接为客户服务。<br>公司希望：</p>
<ol>
<li>将应用程序现代化到 .NET 版本。</li>
<li>在容器中运行该应用。</li>
<li>根据 Amazon CloudWatch 指标自动扩展。</li>
<li>减少运维活动时间（运营开销最小化）。<br>选择能满足要求的解决方案。</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>使用 AWS App2Container 将应用程序容器化。使用 AWS CloudFormation 模板将其部署到 <strong>AWS Fargate 上的 Amazon ECS</strong>。</u><br>B. 使用 AWS App2Container 将应用程序容器化。使用 AWS CloudFormation 模板将其部署到 <strong>Amazon EC2 实例上的 Amazon ECS</strong>。<br>C. 使用 AWS App Runner 将应用程序容器化。使用 App Runner 将其部署到 <strong>AWS Fargate 上的 Amazon ECS</strong>。<br>D. 使用 AWS App Runner 将应用程序容器化。使用 App Runner 将其部署到 <strong>Amazon EC2 实例上的 Amazon EKS</strong>。</p>
<p><br>970 一家公司在 AWS 云中设计新的内部 Web 应用程序，需要从一项 AWS 托管服务中安全地检索和存储多个员工的用户名和密码凭证。<br>要求：以最少的运营开销满足要求。<br>选择能满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 将员工凭证存储在 AWS Systems Manager Parameter Store 中。使用 AWS CloudFormation 和 <strong>BatchGetSecretValue API</strong> 从 Parameter Store 中检索用户名和密码。<br>B. 将员工凭证存储在 AWS Secrets Manager 中。使用 AWS CloudFormation 和 <strong>AWS Batch</strong> 以及 <strong>BatchGetSecretValue API</strong> 从 Secrets Manager 检索用户名和密码。<br>C. 将员工凭证存储在 AWS Systems Manager Parameter Store 中。使用 AWS CloudFormation 和 <strong>AWS Batch</strong> 以及 <strong>BatchGetSecretValue API</strong> 从 Parameter Store 检索用户名和密码。<br>D. <u>将员工凭证存储在 AWS Secrets Manager 中。使用 AWS CloudFormation 和 <strong>BatchGetSecretValue API</strong> 从 Secrets Manager 检索用户名和密码</u>。</p>
<p>WS Secrets Manager 是专门为存储密码、API 密钥等敏感数据设计的托管服务，符合安全存储和检索要求。<br>使用 CloudFormation 自动化部署基础设施和密钥引用，减少手动操作。<br>BatchGetSecretValue 可一次获取多个密钥，适合批量检索员工凭证。</p>
<p><br>971 一家公司在亚太地区（东京）区域有数千台 AWS Outposts 服务器，部署在全球各地偏远位置。<br>这些服务器定期下载包含 100 个文件的新软件版本。目前在所有服务器都运行新版本前，存在显著延迟。<br>公司必须减少新软件版本的部署延迟，且要以最小的运营开销满足要求。</p>
<p><strong>选项复述：</strong><br>A. 在亚太东北（东京）区域创建一个 Amazon S3 存储桶。在该区域设置一个包含 <strong>CachingDisabled 缓存策略</strong> 的 Amazon CloudFront 分发，将 S3 存储桶配置为源站。使用签名 URL 下载软件。<br>B. 在 ap-northeast-1 区域创建一个 S3 存储桶，在 us-east-1 创建第二个 S3 存储桶，配置存储桶间复制。设置一个 CloudFront 分发，将 ap-northeast-1 作为主要源，us-east-1 作为次要源。使用签名 URL 下载软件。<br>C. 在亚太东北（东京）区域创建一个 Amazon S3 存储桶。配置 Amazon S3 Transfer Acceleration。使用 S3 Transfer Acceleration 端点下载软件。<br>D. <u>在 ap-northeast-1 创建一个 Amazon S3 存储桶。设置 Amazon CloudFront 分发，将 S3 存储桶配置为源站。使用签名 URL 下载该软件。</u></p>
<p><br>972 一家公司目前在本地使用 Windows Server 运行股票交易应用程序，希望迁移到 AWS。<br>要求：</p>
<ol>
<li>设计高可用解决方案。</li>
<li>在多个可用区之间提供对<strong>块存储的低延迟访问</strong>。</li>
<li>以最少的实施工作量满足要求。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 在 Amazon EC2 实例上配置跨两个可用区的 Windows Server 集群，两个节点安装应用，使用 <strong>Amazon FSx for Windows File Server</strong> 作为共享存储。<br>B. 配置跨两个可用区的 Windows Server 群集，两个节点安装应用，使用 <strong>Amazon EBS gp3 卷</strong>附加到 EC2 实例，设置<strong>应用程序级复制</strong>将数据从一个 EBS 卷同步到另一个可用区的 EBS 卷。<br>C. <u>在两个可用区的 EC2 实例上部署应用（一主一备），使用 <strong>Amazon FSx for NetApp ONTAP 多可用区文件系统</strong>，通过 iSCSI 协议访问数据。</u><br>D. 在两个可用区的 EC2 实例上部署应用（一主一备），使用 <strong>Amazon EBS io2 卷</strong>，设置 <strong>EBS 级别的复制</strong>同步跨可用区数据。</p>
<ul>
<li>FSx for NetApp ONTAP 提供多可用区高可用文件系统，<strong>支持 iSCSI 协议</strong>，可以提供块级存储访问。</li>
</ul>
<p>题目要求<strong>块存储</strong>低延迟访问，而 FSx for Windows 提供的是文件级共享</p>
<p><br>973 公司设计一个 Web 应用程序，使用面向互联网的应用程序负载均衡器（ALB）。<br>要求：</p>
<ol>
<li>ALB 从公共互联网接收 HTTPS 流量（通过 443 端口）。</li>
<li>ALB 只能通过 443 端口将 HTTPS 流量发送到托管在 EC2 实例上的 Web 应用服务器。</li>
<li>ALB 必须通过 8443 端口以 HTTPS 方式对 Web 应用服务器执行健康检查。<br>问与 ALB 关联的安全组的哪些配置组合能满足这些要求？（选三项）</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>允许来自 0.0.0.0&#x2F;0 的 HTTPS 入站流量通过端口 443。</u><br>B. 允许所有发往 0.0.0.0&#x2F;0 的 443 端口出站流量。<br>C. <u>允许对 Web 应用实例的 443 端口进行 HTTPS 出站流量。</u><br>D. 允许来自 Web 应用实例的 443 端口 HTTPS 入站流量。<br>E. <u>允许对 Web 应用实例的 HTTPS 出站流量，用于 8443 端口上的健康检查</u>。<br>F. 允许来自 Web 应用实例的 HTTPS 入站流量，用于 8443 端口上的健康检查。</p>
<ul>
<li>ALB 安全组（Security Group）需要配置规则来控制流量流向和来源。</li>
<li>安全组是有状态的：允许入站流量时，相应的出站响应自动允许，反之亦然。</li>
<li>需要配置的规则是针对 <strong>ALB 的安全组</strong>，而不是 Web 服务器的安全组。</li>
</ul>
<p> <strong>ALB 从互联网接收 HTTPS 流量（端口 443）</strong><br>→ ALB 安全组必须允许来自任意 IP（0.0.0.0&#x2F;0）的 443 端口入站。<br>→ 对应选项 <strong>A</strong>。</p>
<p><strong>2. ALB 通过 443 端口将 HTTPS 流量发送到 Web 服务器</strong><br>→ ALB 安全组必须允许出站流量到 Web 服务器的安全组（或特定 IP）的 443 端口。<br>→ 对应选项 <strong>C</strong>。</p>
<p><strong>3. ALB 通过 8443 端口对 Web 服务器进行 HTTPS 健康检查</strong><br>→ ALB 安全组必须允许出站流量到 Web 服务器的 8443 端口。<br>→ 对应选项 <strong>E</strong>。</p>
<p><br>974 一家公司在 AWS 上托管一个应用程序，允许用户上传照片到位于 <strong>eu-west-1 区域</strong> 的 S3 存储桶。<br>希望使用 <strong>Amazon CloudFront 和自定义域名</strong> 将照片上传到 S3 存储桶。<br>问哪两种解决方案能满足这些要求？（选两项）</p>
<p><strong>选项复述：</strong><br>A. <u>使用 AWS Certificate Manager（ACM）在 <strong>us-east-1（弗吉尼亚北部）</strong> 区域创建公共证书，在 CloudFront 中使用该证书</u>。<br>B. 使用 ACM 在 <strong>eu-west-1</strong> 区域创建公共证书，在 CloudFront 中使用该证书。<br>C. 配置 Amazon S3 以允许来自 CloudFront 的上传，配置 <strong>S3 Transfer Acceleration</strong>。<br>D<u>. 配置 Amazon S3 以允许来自 <strong>CloudFront 源站访问控制（OAC）</strong> 的上传。</u><br>E. 配置 Amazon S3 以允许来自 CloudFront 的上传，配置一个 <strong>Amazon S3 网站端点</strong></p>
<p>CloudFront 自定义域名需 HTTPS 时，必须在 us-east-1 申请 ACM 证书。</p>
<p><br>975 一家天气预报公司持续从传感器收集温度读数，聚合为更大的 Apache Parquet 文件，使用 <strong>KMS 管理的密钥进行客户端加密（CSE-KMS）</strong> 加密文件，然后写入 Amazon S3，并按日历日设置前缀（例如 <code>2023/01/01/</code>）。<br>公司希望偶尔对数据运行 SQL 查询，以获取特定日历日的样本移动平均值。<br>问哪种解决方案能最具成本效益地满足要求？</p>
<p><strong>选项复述：</strong><br>A. <u>配置 Amazon Athena 以读取加密文件，直接在 Amazon S3 中对数据运行 SQL 查询。</u><br>B. 使用 Amazon S3 Select 直接在 Amazon S3 中对数据运行 SQL 查询。<br>C. 配置 Amazon Redshift 以读取加密文件，使用 Redshift Spectrum 和 Redshift Query Editor v2 直接在 Amazon S3 上对数据运行 SQL 查询。<br>D. 配置 Amazon EMR Serverless 以读取加密文件，使用 Apache SparkSQL 直接在 Amazon S3 上对数据运行 SQL 查询。</p>
<p>Athena 是无服务器查询服务，支持 Parquet 格式和 CSE-KMS 加密，可按分区减少扫描量，按查询数据量付费，非常适合偶尔的复杂 SQL 查询</p>
<p><br>976 一家公司正在 AWS 上部署新应用程序，会在<strong>多个 AWS 区域</strong>内的多个可用区中的多台 EC2 实例上运行此应用程序。<br>应用程序通过互联网提供服务，用户从全球各地访问。<br>要求：确保每个访问用户被分配到<strong>距离用户所在地最近的 EC2 实例</strong>。<br>问哪种解决方案能够满足要求？</p>
<p><strong>选项复述：</strong><br>A. 实施 Amazon Route 53 <strong>地理位置路由策略</strong>，使用面向互联网的应用程序负载均衡器（ALB）在同一区域内的所有可用区之间分配流量。<br>B. <u>实施 Amazon Route 53 <strong>地理邻近路由策略</strong>，使用面向互联网的网络负载均衡器（NLB）在同一区域内的所有可用区之间分配流量</u>。<br>C. 实施 Amazon Route 53 <strong>多值答案路由策略</strong>，使用面向互联网的应用程序负载均衡器在同一区域内的所有可用区之间分配流量。<br>D. 实施 Amazon Route 53 <strong>加权路由策略</strong>，使用面向互联网的网络负载均衡器在同一区域内的所有可用区之间分配流量。</p>
<p>“地理位置路由”是静态的（根据用户位置配置固定区域映射），不是基于实时延迟或距离测量。</p>
<p><strong>地理邻近路由（Geoproximity Routing）</strong> 根据用户地理位置和资源位置的接近程度进行路由，并可设置偏差（bias）调整流量范围</p>
<p><br>977 一家金融服务公司在 AWS 上推出新应用，处理敏感金融交易，部署在 EC2 实例上，并使用 Amazon RDS for MySQL 作为数据库。<br>安全政策要求：数据在静态和传输过程中都必须加密。<br>问哪种解决方案能以最低的运营开销满足要求？</p>
<p><strong>选项复述：</strong><br>A. <u>使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。配置 AWS Certificate Manager（ACM）SSL&#x2F;TLS 证书以实现传输中加密。</u><br>B. 使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。配置 IPsec 隧道以实现传输中加密。<br>C. 在将数据存储到 RDS 之前，实施第三方应用级数据加密。配置 ACM SSL&#x2F;TLS 证书以实现传输中加密。<br>D. 使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。配置 VPN 连接以启用私有连接，从而对传输中的数据进行加密。</p>
<p>RDS 内置静态加密（使用 KMS 托管密钥）和 SSL&#x2F;TLS 传输加密（可使用 ACM 或 RDS 内置证书），均为完全托管服务，配置简单，无需维护，符合最低运营开销要求，同时满足静态和传输加密的安全政策。</p>
<p><br>978 一家公司正在将本地 Oracle 数据库迁移到 Amazon RDS for Oracle。<br>要求：</p>
<ol>
<li>保留数据 90 天以满足监管要求。</li>
<li>能够在最多 14 天内将数据库恢复到特定时间点（Point-in-time Recovery, PITR）。</li>
<li>最少的运营开销。<br>选择能满足要求的解决方案。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 创建 Amazon RDS 自动备份，将保留期设置为 90 天。<br>B. 每天创建一个 Amazon RDS 手动快照，删除超过 90 天的手动快照。<br>C. 使用 Amazon Aurora for Oracle 的克隆功能创建时间点恢复，删除超过 90 天的克隆。<br>D. 使<u>用 AWS Backup 为 Amazon RDS 创建一个保留期为 90 天的备份计划</u></p>
<ul>
<li>RDS 自动备份包括<strong>自动快照</strong>和<strong>事务日志备份</strong>，启用后自动支持时间点恢复（PITR）到保留期内的任意时间点（最多可设置 35 天保留）。</li>
</ul>
<p><br>979 一家公司开发新应用，使用关系型数据库存储用户数据和配置。<br>预计：用户稳步增长，数据库使用情况有波动，且以读取操作为主，偶尔有写入。<br>要求：</p>
<ol>
<li>对数据库解决方案进行<strong>成本优化</strong>。</li>
<li>使用 <strong>AWS 托管的数据库解决方案</strong>，并提供必要性能。</li>
<li>最具成本效益。</li>
</ol>
<p><strong>选项复述：</strong><br>A. 在 Amazon RDS 上部署数据库，使用预配置 IOPS SSD 存储（如 io1&#x2F;io2），确保读写性能稳定。<br>B. <u>在 <strong>Amazon Aurora Serverless</strong> 上部署数据库，根据实际使用情况自动扩展数据库容量以适应工作负载</u>。<br>C. 在 <strong>Amazon DynamoDB</strong> 上部署数据库，使用按需容量模式自动扩展吞吐量。<br>D. 在 Amazon RDS 上部署数据库，使用磁性存储并利用读取副本以适应工作负载</p>
<p>Amazon Aurora Serverless 是关系型数据库，支持自动弹性伸缩（根据负载调整容量），按使用付费，非常适合用户稳步增长且使用波动（尤其是读多写少）的场景</p>
<p><br>980 一家公司在一个 VPC 内的多个 EC2 实例上托管应用程序，并为每个客户创建了专用的 Amazon S3 存储桶（所有存储桶都位于该公司的 AWS 账户内）。<br>要求：确保在 EC2 实例上运行的应用程序<strong>只能安全访问属于该公司 AWS 账户的 S3 存储桶</strong>（即不能访问其他账户的存储桶）。<br>问哪种解决方案能以最少的运营开销满足要求？</p>
<p><strong>选项复述：</strong><br>A<u>. 为 Amazon S3 创建一个附加到 VPC 的<strong>网关端点</strong>。更新 IAM 实例配置文件策略，仅允许访问应用程序所需的特定存储桶。</u><br>B. 在公有子网中创建一个 <strong>NAT 网关</strong>，配置仅允许访问 Amazon S3 的安全组。更新路由表以使用该 NAT 网关。<br>C. 为 Amazon S3 创建一个附加到 VPC 的<strong>网关终端节点</strong>。使用拒绝操作和以下条件键更新 IAM 实例配置文件策略：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;StringNotFounds&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;s3:ResourceAccount&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;CompanyAWSAcctNumber&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>D. 在公有子网中创建一个 <strong>NAT 网关</strong>。更新路由表以使用该 NAT 网关。为所有存储桶分配具有拒绝操作的存储桶策略，并包含以下条件键：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;StringNotFounds&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;s3:ResourceAccount&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;CompanyAWSAcctNumber&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>NAT 网关用于使私有子网访问互联网，但 S3 可以通过网关端点免费私有访问，不需要 NAT（增加成本且复杂）。</li>
</ul>
<p>安全组不能用于限制 S3 存储桶访问（安全组是实例级网络控制，不是资源级权限控制）</p>
<p><br>981 一家公司在 AWS 上构建处理敏感客户数据的云应用，使用 RDS、S3 和 Lambda。<br>公司使用 <strong>AWS IAM Identity Center</strong> 管理用户凭证。<br>开发、测试和运维团队需要安全访问 RDS 和 S3，确保敏感数据机密性，且遵循<strong>最小权限原则</strong>。<br>要求解决方案在满足要求的同时<strong>使运营开销最小</strong>。</p>
<p><strong>选项复述：</strong><br>A. 使用具有最小权限的 IAM 角色授予所有团队访问权限。为每个团队分配 IAM 角色，并配备自定义的 IAM 策略，根据团队职责定义 RDS 和 S3 访问的特定权限。<br>B. <u>使用 IAM Identity Center 目录启用 IAM Identity Center。创建并配置<strong>权限集</strong>，使其对 RDS 和 S3 拥有精细化访问权限。将所有团队分配到通过这些权限集获得特定访问权限的组中。</u><br>C. 为每个团队成员创建单独的 IAM 用户，分配基于角色的权限，为每个用户分配具有预定义策略的 IAM 角色。实施 IAM Access Analyzer 进行定期凭证评估。<br>D. 使用 AWS Organizations 为每个团队创建单独的账户。实施具有最小权限的跨账户 IAM 角色，根据团队角色授予特定 RDS 和 S3 访问权限。</p>
<p>IAM Identity Center 的权限集（Permission Sets）是专门为多账户或多团队场景设计的权限管理方案，可以精细化控制对 RDS 和 S3 的访问，并分配给不同团队组，实现最小权限。</p>
<p><br>982 一家公司有一个包含敏感数据文件的 Amazon S3 存储桶，以及一个运行在本地数据中心的虚拟机上的应用程序。<br>公司目前使用 <strong>AWS IAM Identity Center</strong>。<br>应用程序需要临时访问 S3 存储桶中的文件，希望授予该应用程序对 S3 存储桶的安全访问权限。<br>选择能满足要求的解决方案。</p>
<p><strong>选项复述：</strong><br>A. 创建一个 S3 存储桶策略，允许从公司本地数据中心的公共 IP 地址范围访问该存储桶。<br>B. 使<u>用 <strong>IAM Roles Anywhere</strong> 在 IAM Identity Center 中获取授予 S3 存储桶访问权限的安全凭证。配置虚拟机以通过 AWS CLI 来承担该角色。</u><br>C. 在虚拟机上安装 AWS CLI，使用有权访问存储桶的 IAM 用户的访问密钥配置 AWS CLI。<br>D. 创建 IAM 用户和策略，授予存储桶访问权限，将该 IAM 用户的访问密钥和秘密密钥存储在 AWS Secrets Manager 中，配置应用程序在启动时检索密钥。</p>
<p>IAM Roles Anywhere 允许本地虚拟机通过证书认证获取临时 AWS 凭证，从而安全地访问 S3 存储桶，无需长期密钥，且与 IAM Identity Center 集成可实现集中权限管理</p>
<p><br>983 一家公司的核心网络服务（目录服务和 DNS）托管在本地数据中心，该数据中心通过 <strong>AWS Direct Connect（DX）</strong> 与 AWS 云相连。<br>计划增设更多 AWS 账户，这些账户需要<strong>快速、经济、一致</strong>地访问这些网络服务。<br>问解决方案架构师应实施什么方案，才能以最少的运营开销满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 在每个新账户中创建一个 Direct Connect 连接，将网络流量路由到本地服务器。<br>B. 在 DX VPC 中为所有所需服务配置 VPC 终端节点，将网络流量路由到本地服务器。<br>C. 在每个新账户和 DX VPC 之间创建 VPN 连接，将网络流量路由到本地服务器。<br>D. <u>在账户之间配置 <strong>AWS Transit Gateway</strong>，将 DX 分配给中转网关，并将网络流量路由至本地服务器。</u></p>
<p>Transit Gateway 实现多账户 VPC 与本地网络的集中连接，通过共享现有的 Direct Connect 专线，让所有新账户快速、经济、一致地访问本地网络服务</p>
<p><br>984 一家公司在单个 AWS 区域的多个可用区托管其主要公共 Web 应用，使用 EC2 自动扩展组和 ALB。<br>网页开发团队需要一个<strong>成本优化的计算解决方案</strong>，以提高向全球数百万客户提供<strong>动态内容</strong>的能力。<br>问哪种解决方案能满足要求？</p>
<p><strong>选项复述：</strong><br>A<u>. 创建一个 Amazon CloudFront 分发，将现有的 ALB 配置为源站。</u><br>B. 使用 Amazon Route 53 根据客户地理位置将流量导向 ALB 和 EC2 实例。<br>C. 创建一个启用了公共读取权限的 Amazon S3 存储桶，将 Web 应用程序迁移到该 S3 存储桶，配置 S3 存储桶以进行网站托管。<br>D. 使用 AWS Direct Connect 直接从 Web 应用程序向每个客户所在位置提供内容。</p>
<p>CloudFront 作为 CDN 可以加速动态内容（通过优化路由和 TCP 优化），将用户请求就近接入 AWS 边缘节点，再通过高效网络传输到源站（ALB），从而降低全球用户的延迟，提升动态内容交付能力。</p>
<p><br>985 一家公司将用户数据存储在 AWS 中，数据被持续使用，在营业时间达到使用峰值。访问模式各异，有些数据一次会有数月不被使用。<br>解决方案架构师必须选择一种经济高效的解决方案，在保持高可用性的同时维持最高级别的耐久性。<br>问哪种存储解决方案能满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 亚马逊 S3 Standard<br>B<u>. 亚马逊 S3 Intelligent-Tiering</u><br>C. 亚马逊 S3 Glacier Deep Archive<br>D. 亚马逊 S3 One Zone-IA（单区域 - 不频繁访问）</p>
<p>S3 Intelligent-Tiering 自动根据访问频率将数据在频繁访问层和不频繁访问层之间移动</p>
<p><br>986 一家公司正在测试运行在 Amazon EC2 Linux 实例上的应用程序，使用一个 500 GB 的 <strong>Amazon EBS gp2 卷</strong>附加到该实例。<br>计划在自动扩展组中的多个 EC2 实例上部署此应用程序，所有实例都需要访问存储在 EBS 卷中的数据。<br>需要一个<strong>高可用、弹性</strong>的解决方案，且<strong>不对应用程序代码进行重大更改</strong>。<br>问哪种解决方案能满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 配置一个使用 NFS 服务器软件的 EC2 实例，为该实例附加一个 500 GB 的 gp2 EBS 卷。<br>B. 配置一个 <strong>Amazon FSx for Windows File Server</strong> 文件系统，将该文件系统配置为单一可用区内的 SMB 文件存储。<br>C. 配置一个带有两个 250 GB 预配置 IOPS SSD EBS 卷的 EC2 实例。<br><u>D. 配置一个 <strong>Amazon Elastic File System（Amazon EFS）</strong> 文件系统，将该文件系统配置为使用通用性能模式。</u></p>
<p>Amazon EFS 提供共享、高可用、弹性的文件存储，支持多个 EC2 实例同时访问同一文件系统，且与 Linux 应用程序兼容（NFS），无需修改代码。</p>
<p><br>987 一家公司最近推出了新应用，在两个可用区的多台 EC2 实例上运行。<br>终端用户通过 <strong>TCP</strong> 与应用通信。<br>要求：</p>
<ol>
<li>应用必须具备高可用性。</li>
<li>必须能随着用户数量增加自动扩展。</li>
<li>需要<strong>最具成本效益</strong>的步骤组合。<br>问哪两个步骤组合能满足要求？（选两项）</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>在 EC2 实例前添加<strong>网络负载均衡器</strong>（NLB）。</u><br><u>B. 为 EC2 实例配置一个<strong>自动扩展组</strong>（ASG）。</u><br>C. 在 EC2 实例前添加一个<strong>应用程序负载均衡器</strong>（ALB）。<br>D. 为应用程序<strong>手动添加</strong>更多 EC2 实例。<br>E. 在 EC2 实例前添加<strong>网关负载均衡器</strong>（GWLB）。</p>
<p>NLB（A）提供 TCP 层的高可用负载均衡，适合非 HTTP 应用且成本较低。</p>
<ul>
<li>GWLB 主要用于将流量分发到第三方虚拟设备（如防火墙、入侵检测），不适合常规 Web&#x2F;应用流量负载均衡。</li>
</ul>
<p><br>988 一家公司为新的移动应用设计架构，使用 AWS Organizations 并通过组织单元（OU）管理账户。<br>公司希望通过使用“敏感”和“非敏感”值，为 EC2 实例添加<strong>数据敏感度标签</strong>。<br>要求：</p>
<ol>
<li>IAM 身份<strong>不得删除标签</strong>。</li>
<li>IAM 身份<strong>不得在没有标签的情况下创建实例</strong>。<br>问哪些步骤组合可以满足这些要求？（选两项）</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>在组织中创建一个新的<strong>标签策略</strong>，指定数据敏感性标签键和所需的值，对 EC2 实例<strong>强制执行标签值</strong>，将标签策略附加到相应的 OU。</u><br>B. 在组织中创建一个新的<strong>服务控制策略（SCP）</strong>，指定数据敏感性标签键和所需的标签值，对 EC2 实例实施这些标签值，将该 SCP 附加到相应的 OU。<br>C. 创建一个标签策略以在未指定标签键时拒绝运行实例，创建另一个标签策略防止身份删除标签，将这些标签策略附加到相应的 OU。<br>D. <u>创建一个 SCP 以在未指定标签键时拒绝创建实例，再创建另一个 SCP 用于防止身份删除标签，将 SCP 附加到相应的 OU。</u><br>E. 创建一条 AWS Config 规则检查 EC2 实例是否使用数据敏感性标签及指定值，配置 Lambda 函数在发现不合规资源时将其删除。</p>
<ul>
<li>SCP 用于控制 IAM 权限，但 SCP <strong>不能直接基于标签键值进行条件控制</strong>（SCP 不支持资源标签条件，只能基于资源类型、区域等）。</li>
</ul>
<p><br>989 一家公司在 AWS 上运行数据库工作负载作为客户门户的后端，使用 <strong>Amazon RDS for PostgreSQL 多可用区集群</strong>。<br>要求：</p>
<ol>
<li>实施 <strong>30 天备份保留政策</strong>。</li>
<li>公司目前有<strong>自动 RDS 备份</strong>和<strong>手动 RDS 快照</strong>。</li>
<li>希望保留所有两种类型且不足 30 天的现有备份。<br>问哪种解决方案能最具成本效益地满足要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. 使用 AWS Backup 将 RDS 自动备份的保留策略配置为 30 天，手动删除超过 30 天的手动备份。<br>B. 禁用 RDS 自动备份，删除超过 30 天的自动和手动备份，将 RDS 自动备份的备份保留策略配置为 30 天。<br>C. <u>将 RDS 备份保留策略配置为自动备份 30 天，手动删除超过 30 天的手动备份。</u><br>D. 禁用 RDS 自动备份，使用 AWS CloudFormation 自动删除超过 30 天的自动和手动备份，将 RDS 自动备份的备份保留策略配置为 30 天。</p>
<ul>
<li>DS 自动备份保留期设置后，系统会自动删除超过 30 天的自动备份（符合政策且无需额外操作）。</li>
<li>手动备份需要手动管理删除（可通过脚本或定期清理），但这是成本最低的方式（无需额外服务）。</li>
</ul>
<p><br>990 一家公司计划将一个遗留应用程序迁移到 AWS。该应用程序目前使用 <strong>NFS</strong> 与本地存储解决方案通信以存储应用数据。<br>该应用程序<strong>无法修改</strong>为使用 NFS 以外的任何其他通信协议。<br>问解决方案架构师应该推荐哪种存储解决方案用于迁移后？</p>
<p><strong>选项复述：</strong><br>A. AWS DataSync<br>B. 亚马逊弹性块存储（Amazon EBS）<br>C. 亚<u>马逊弹性文件系统（Amazon EFS）</u><br>D. 亚马逊 EMR 文件系统（Amazon EMRFS）</p>
<p>Amazon EFS 是 AWS 原生的、完全托管的 NFS 文件系统，兼容遗留应用的 NFS 协议要求，无需修改应用程序，且提供可扩展、高可用的共享文件存储，是迁移此类应用的标准推荐方案。</p>
<p><br>991 一家公司使用 GPS 追踪器记录数千只海龟的迁徙模式。追踪器每 5 分钟检查海龟是否移动超过 100 码，如果移动则发送新坐标到运行在<strong>多个可用区 EC2 实例</strong>上的 Web 应用程序。<br>最近 Web 应用在处理意外大量追踪器数据时不堪重负，导致<strong>数据丢失且无法重新播放这些事件</strong>。<br>解决方案架构师必须防止此问题再次发生，且需要<strong>操作开销最小的解决方案</strong>。<br>问应采取什么措施来满足要求？</p>
<p><strong>选项复述：</strong><br>A. 创建一个 Amazon S3 存储桶来存储数据，配置应用程序以扫描存储桶中的新数据进行处理。<br>B. 创建一个 Amazon API Gateway 端点来处理传输的位置坐标，使用 AWS Lambda 函数并发处理每个项目。<br>C. <u>创建一个 Amazon SQS 队列来存储传入的数据，配置应用程序以轮询新消息进行处理。</u><br>D. 创建一个 Amazon DynamoDB 表来存储传输的位置坐标，配置应用程序以查询该表中的新数据进行处理，使用 TTL 删除已处理数据。</p>
<p><br>992 一家公司的软件开发团队需要一个 <strong>Amazon RDS 多可用区集群</strong>，该集群将作为部署在<strong>本地</strong>的桌面客户端的后端。<br>桌面客户端需要与 RDS 集群<strong>直接连接</strong>。<br>当开发团队在办公室时，必须让他们能够通过客户端连接到集群。<br>问哪种解决方案能<strong>最安全地</strong>提供所需的连接？</p>
<p><strong>选项复述：</strong><br>A. 创建一个 VPC 和两个<strong>公有子网</strong>，在公有子网中创建 RDS 集群，使用 AWS Site-to-Site VPN，并在公司办公室部署客户网关。<br>B. <u>创建一个 VPC 和两个<strong>私有子网</strong>，在私有子网中创建 RDS 集群，使用 AWS Site-to-Site VPN，并搭配公司办公室的客户网关</u>。<br>C. 创建一个 VPC 和两个私有子网，在私有子网中创建 RDS 集群，使用 RDS 安全组允许公司办公室的 IP 范围访问该集群。<br>D. 创建一个 VPC 和两个公有子网，在公有子网中创建 RDS 集群，为每个开发人员创建集群用户，使用 RDS 安全组允许用户访问该集群。</p>
<p>将 RDS 部署在私有子网确保数据库不暴露在互联网，通过 Site-to-Site VPN 建立从公司办公室到 VPC 的安全加密隧道，实现客户端安全直接连接，符合最高安全标准且满足连接要求。</p>
<p><br>993 解决方案架构师正在创建一个处理大量数据批处理的应用程序。</p>
<ul>
<li>输入数据存储在 Amazon S3 中，输出数据存储在另一个 S3 存储桶中。</li>
<li>处理过程中，应用程序将在多个 EC2 实例之间通过网络传输数据。<br>问应采取什么措施来降低总体数据传输成本？</li>
</ul>
<p><strong>选项复述：</strong><br>A. 将所有 EC2 实例放入一个自动扩展组中。<br>B. 将所有 EC2 实例放置在同一个 AWS 区域中。<br><u>C. 将所有 EC2 实例放置在同一个可用区中。</u><br>D. 将所有 EC2 实例放置在多个可用区的私有子网中。</p>
<p>将 EC2 实例部署在同一个可用区内，实例之间的网络流量免费，可以显著降低批处理过程中实例间数据传输的成本</p>
<p>994一家公司托管多层 Web 应用程序，使用 <strong>Amazon Aurora MySQL 数据库集群</strong>存储，应用程序层运行在 EC2 实例上。<br>IT 安全指南要求：</p>
<ol>
<li>数据库凭证必须加密。</li>
<li>每 14 天轮换一次。<br>问解决方案架构师应采取什么措施，以<strong>最小的运维工作量</strong>满足要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. <u>创建一个新的 AWS KMS 加密密钥，使用 <strong>AWS Secrets Manager</strong> 创建一个使用 KMS 密钥的新密钥，将该密钥与 Aurora 数据库集群关联，配置一个 14 天的自定义轮换周期。</u><br>B. 在 <strong>AWS Systems Manager Parameter Store</strong> 中创建两个参数（字符串用户名 + SecureString 密码），为密码选择 KMS 加密，在应用层加载这些参数，实现一个 Lambda 函数每 14 天轮换密码。<br>C. 将凭证文件存储在经 KMS 加密的 <strong>Amazon EFS</strong> 文件系统中，在应用层 EC2 实例挂载 EFS，限制文件访问权限，实现 Lambda 函数每 14 天轮换 Aurora 凭证并写入文件。<br>D. 将凭证文件存储在经 KMS 加密的 <strong>Amazon S3</strong> 存储桶中，定期下载到应用程序，实现 Lambda 函数每 14 天轮换 Aurora 凭证并上传到 S3。</p>
<p><br>995 一家流媒体公司正在重建基础设施，以满足用户对视频内容日益增长的需求。<br>要求：</p>
<ol>
<li>处理 TB 级别的视频，进行内容屏蔽（如模糊、打码等处理）。</li>
<li>视频处理可能需要长达 20 分钟（长时任务）。</li>
<li>解决方案需要能够随需求扩展（弹性伸缩）。</li>
<li>保持成本效益。<br>问哪种解决方案能满足这些要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. 使用 <strong>AWS Lambda</strong> 函数处理视频，将视频元数据存储在 DynamoDB 中，视频内容存储在 S3 Intelligent-Tiering 中。<br>B. <u>使用 <strong>Amazon ECS with AWS Fargate</strong> 实施微服务处理视频，将视频元数据存储在 Amazon Aurora 中，视频内容存储在 S3 Intelligent-Tiering 中</u>。<br>C. 在 ALB 后面的自动扩展组中使用 <strong>Amazon EC2 实例</strong> 处理视频，将视频内容存储在 S3 Standard 中，使用 <strong>Amazon SQS</strong> 进行任务排队和解耦。<br>D. 在 <strong>Amazon EKS on EC2</strong> 上部署容器化视频处理应用，将视频元数据存储在单可用区 RDS 中，视频内容存储在 S3 Glacier Deep Archive 中。</p>
<ul>
<li>Fargate 是无服务器容器平台，可以运行长时间任务（无 15 分钟限制），且自动弹性伸缩。</li>
</ul>
<p><br>996 一家公司在 Kubernetes 集群上运行本地应用程序，最近新增数百万客户，本地基础设施无法应对，需要将应用迁移到 AWS 云。<br>公司将迁移到 <strong>Amazon Elastic Kubernetes Service (Amazon EKS) 集群</strong>，且<strong>不希望在 AWS 上管理新架构的底层计算基础设施</strong>。<br>问哪种解决方案能以最少的运营开销满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 使用<strong>自管理节点</strong>提供计算能力，将应用程序部署到新的 EKS 集群。<br>B. 使用<strong>托管节点组</strong>提供计算容量，将应用程序部署到新的 EKS 集群。<br>C. <u>使用 <strong>AWS Fargate</strong> 提供计算容量，创建一个 Fargate 配置文件，使用该配置文件部署应用程序。</u></p>
<p>D. 使用带有Karpenter的托管节点组来提供计算容量。将应用程序部署到新的EKS集群。</p>
<p>EKS with Fargate 提供无服务器的 Kubernetes 计算，用户无需管理 EC2 节点，只需关注应用部署和 Pod 配置，最大程度减少运营开销，同时满足迁移到 EKS 的需求。</p>
<p><br>997 一家公司推出新应用，需要结构化数据库存储用户资料、应用设置和交易数据。<br>要求：</p>
<ol>
<li>数据库必须能随应用流量扩展（弹性伸缩）。</li>
<li>必须提供备份功能。</li>
<li>最具成本效益。<br>问哪种解决方案能满足这些要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. 使用开源软件在 <strong>Amazon EC2</strong> 上部署自管理数据库，使用 Spot 实例优化成本，配置自动备份到 Amazon S3。<br>B. 使用 <strong>Amazon RDS</strong>，为数据库采用按需容量模式，搭配通用型 SSD 存储，配置自动备份保留 7 天。<br>C. <u>使用 <strong>Amazon Aurora Serverless</strong>，使用无服务器容量扩展，配置自动备份到 Amazon S3。</u><br>D. 在 <strong>Amazon EC2</strong> 上部署自管理的 NoSQL 数据库，使用预留实例优化成本，配置自动备份到 S3 Glacier Flexible Retrieval。</p>
<p>Amazon Aurora Serverless 提供自动弹性伸缩、完全托管的关系数据库服务，按实际使用量计费，无需预置或管理实例</p>
<p><br>998 一家公司在 AWS 上运行遗留 Web 应用程序，Web 服务器运行在 VPC 的<strong>公有子网</strong>中的 EC2 实例上。<br>应用程序从客户端收集图像，存储在<strong>本地连接的 EBS 卷</strong>中。<br>图像文件每晚会上传到 <strong>Amazon S3 存储桶</strong>进行备份。<br>发现图像文件正<strong>通过公共端点上传到 S3</strong>（即走公网）。<br>解决方案架构师需要确保到 S3 的流量<strong>不使用公共端点</strong>（即通过私有网络路径）。<br>问哪种解决方案能满足要求？</p>
<p><strong>选项复述：</strong><br>A. <u>为具有 VPC 必要权限的 S3 存储桶创建<strong>网关 VPC 终端节点</strong>，配置子网路由表以使用网关 VPC 终端节点</u>。<br>B. 将 S3 存储桶移至 VPC 内部，配置子网路由表以通过私有 IP 地址访问 S3 存储桶。<br>C. 为 VPC 内的 EC2 实例创建一个 <strong>S3 访问点</strong>，配置 Web 应用程序使用该 S3 访问点进行上传。<br>D. 在 VPC 与 S3 之间配置 <strong>AWS Direct Connect</strong> 连接，以提供专用网络路径                                                                                                                                                  </p>
<p>创建 S3 网关 VPC 终端节点（Gateway VPC Endpoint）可以让 VPC 内的 EC2 实例通过 AWS 内部网络直接访问 S3，</p>
<p><br>999 一家公司在 AWS 上创建电子商务网站原型，架构包括：</p>
<ul>
<li>应用程序负载均衡器（ALB）</li>
<li>EC2 自动扩展组（Web 服务器）</li>
<li>单可用区的 <strong>Amazon RDS for MySQL</strong> 数据库实例<br>问题：搜索产品目录时网站响应慢，且此时数据库 CPU 利用率很高。<br>产品目录是 MySQL 中的一组表，<strong>不经常更新</strong>。<br>问解决方案架构师应推荐什么来提高搜索性能？</li>
</ul>
<p><strong>选项复述：</strong><br>A. 将产品目录迁移到 <strong>Amazon Redshift</strong> 数据库，使用 COPY 命令加载表。<br>B. <u>部署一个 <strong>Amazon ElastiCache for Redis</strong> 集群来缓存产品目录，使用懒加载填充缓存。</u><br>C. 向自动扩展组添加额外的扩展策略，以便在数据库响应缓慢时启动额外的 EC2 实例。<br>D. 为数据库实例开启多可用区配置，配置 EC2 实例限制发送到数据库的产品目录查询。</p>
<ul>
<li>缓存可以显著降低对数据库的重复查询，尤其适用于<strong>不经常更新</strong>的读密集型数据（如产品目录）。</li>
<li>懒加载（lazy loading）模式在请求时填充缓存，减少首次加载开销，后续请求直接从缓存读取，大幅降低数据库 CPU 并提升响应速度</li>
</ul>
<p><br>1000 一家公司目前在本地块存储系统中存储了 5 TB 数据，当前存储解决方案提供的额外空间有限。<br>公司在本地运行应用程序，这些应用程序必须能够以<strong>低延迟检索频繁访问的数据</strong>。<br>公司需要一个基于云的存储解决方案。<br>问哪种解决方案能以<strong>最高的运营效率</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 使用 <strong>Amazon S3 文件网关</strong>，将 S3 文件网关与本地应用程序集成，以使用 SMB 文件系统存储和直接检索文件。<br>B. 使<u>用带有<strong>缓存卷</strong>的 <strong>AWS Storage Gateway 卷网关</strong>作为 iSCSI 目标。</u><br>C. 使用带有<strong>存储卷</strong>的 AWS Storage Gateway 卷网关作为 iSCSI 目标。<br>D. 使用 <strong>AWS 存储网关磁带网关</strong>，将磁带网关与本地应用程序集成，以在 Amazon S3 中存储虚拟磁带。</p>
<p>Storage Gateway 卷网关的<strong>缓存卷模式</strong>将热数据缓存在本地，冷数据存储在 S3，既提供了云存储的扩展性，又保证了频繁访问数据的低延迟</p>
<p><br>1001 一家公司经营食品配送服务，订单处理系统在高峰时段遇到扩展问题。<br>当前架构：</p>
<ul>
<li>第一组 EC2 实例（自动扩展组）用于<strong>收集订单</strong>。</li>
<li>第二组 EC2 实例（自动扩展组）用于<strong>处理&#x2F;履行订单</strong>。<br>订单收集很快，但订单履行可能需要更长时间。<br><strong>不能因为扩容事件而丢失数据</strong>。<br>要求：确保订单收集和订单履行流程在高峰期都能充分扩展。<br>问哪种解决方案能满足要求？</li>
</ul>
<p><strong>选项复述：</strong><br>A. 使用 CloudWatch 监控两个自动扩展组中每个实例的 CPU 利用率，将每个自动扩展组的<strong>最小容量配置为满足峰值负载</strong>。<br>B. 使用 CloudWatch 监控 CPU 利用率，配置 CloudWatch 告警调用 SNS 主题，根据需求创建额外的自动扩展组。<br>C. 提供两个 <strong>Amazon SQS 队列</strong>（一个用于订单收集，一个用于订单履行），配置 EC2 实例轮询各自队列，<strong>根据队列发送的通知来扩展自动扩展组</strong>。<br>D. <u>提供两个 <strong>Amazon SQS 队列</strong>（一个用于订单收集，一个用于订单履行），配置 EC2 实例轮询各自队列，<strong>根据每个队列中的消息数量来扩展自动扩展组</strong>。</u></p>
<p><br>1002 一家在线游戏公司正在将用户数据迁移到 <strong>Amazon DynamoDB</strong>，以支持不断增长的用户群。<br>当前 DynamoDB 表存储用户资料、成就和游戏内交易记录。<br>要求：设计一个<strong>强大、持续可用且具有弹性</strong>的 DynamoDB 架构，以维持用户流畅的游戏体验。<br>问哪种解决方案能<strong>最具成本效益地</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 在单个 AWS 区域创建 DynamoDB 表，使用<strong>按需容量模式</strong>，使用<strong>全局表（Global Tables）</strong> 在多个区域间复制数据。<br>B. 使用 <strong>DynamoDB Accelerator（DAX）</strong> 缓存频繁访问的数据，在单个区域部署表并启用自动扩展，手动配置跨区域复制到其他区域。<br>C. 在多个 AWS 区域创建 DynamoDB 表，使用按需容量模式，使用 <strong>DynamoDB Streams</strong> 实现区域间的跨区域复制。<br>D. <u>使用 <strong>DynamoDB 全局表</strong>进行自动多区域复制，在多个区域部署表，使用<strong>预置容量模式</strong>，启用自动扩展。</u></p>
<p>DynamoDB 全局表提供自动、多区域、多主复制，实现跨区域高可用和低延迟访问（满足游戏体验）。</p>
<p><br>1003 一家公司本地运行媒体渲染应用程序，希望降低存储成本，已将<strong>所有数据迁移到 Amazon S3</strong>。<br>但本地渲染应用程序需要对存储进行<strong>低延迟访问</strong>。<br>需要为该应用设计存储解决方案，必须保持预期的应用程序性能。<br>问哪种存储解决方案能以<strong>最具成本效益</strong>的方式满足要求？</p>
<p><strong>选项复述：</strong><br>A. 使用 <strong>Amazon S3 Mountpoint</strong>，让本地应用程序访问 Amazon S3 中的数据。<br>B. <u>配置 <strong>Amazon S3 文件网关</strong>，为本地应用程序提供存储</u>。<br>C. 将数据从 Amazon S3 复制到 <strong>Amazon FSx for Windows File Server</strong>，配置 <strong>Amazon FSx 文件网关</strong>，为本地应用程序提供存储。<br>D. 配置本地文件服务器，使用 Amazon S3 API 连接到 S3，配置应用程序从本地文件服务器访问存储。</p>
<ul>
<li>S3 文件网关提供 <strong>NFS 或 SMB 协议</strong>访问 S3 中的数据，部署在本地（虚拟机或硬件设备）。</li>
<li>它会<strong>缓存频繁访问的数据在本地</strong>，提供低延迟访问，同时将数据持久化在 S3，降低成本。</li>
</ul>
<p>FSx for Windows 是托管 Windows 文件服务器，成本较高（存储和吞吐量费用），且需要将数据从 S3 复制到 FSx，增加存储成本和复杂性</p>
<p><br>1004 一家公司将其 ERP 系统托管在 <strong>us-east-1 区域</strong>，运行在 EC2 实例上。<br>客户通过 EC2 实例上托管的<strong>公共 API</strong> 与 ERP 系统交换信息。<br><strong>国际客户</strong>反馈从他们的数据中心访问该 API 时响应很慢。<br>问哪种解决方案能<strong>最具成本效益地</strong>提高国际客户的响应时间？</p>
<p><strong>选项复述：</strong><br>A. 创建具有公共虚拟接口（VIF）的 <strong>AWS Direct Connect</strong> 连接，从每个客户的数据中心连接到 us-east-1，使用 Direct Connect 网关路由请求。<br>B. 在 API 前设置 <strong>Amazon CloudFront 分发</strong>，配置 CachingOptimized 缓存策略提高缓存效率。<br>C. <u>设置 <strong>AWS Global Accelerator</strong>，为必要端口配置监听器，配置终端节点组，在适当区域分配流量，为该组中的 API 创建端点。</u><br>D. 使用 <strong>AWS Site-to-Site VPN</strong> 在各区域和客户网络之间建立专用 VPN 隧道，通过 VPN 连接路由流量到 API。</p>
<p>AWS Global Accelerator 通过将用户流量接入 AWS 全球骨干网，优化网络路径到 us-east-1 的 API 端点，减少国际客户访问延迟，适合动态 API 加速</p>
<p><br>1005 一家公司通过网站调查跟踪客户满意度，有时每小时覆盖数千名客户。<br>目前调查结果通过电子邮件发送，员工手动查看并评估客户情绪。<br>公司希望<strong>自动化</strong>调查流程，且调查结果必须能提供<strong>过去 12 个月</strong>的数据。<br>问哪种解决方案能以<strong>最具可扩展性的方式</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. <u>将调查结果数据发送到连接 <strong>Amazon SQS 队列</strong> 的 <strong>Amazon API Gateway</strong> 端点，创建 <strong>AWS Lambda</strong> 函数轮询 SQS 队列，调用 <strong>Amazon Comprehend</strong> 进行情感分析，将结果保存到 <strong>Amazon DynamoDB</strong> 表中，将所有记录的 <strong>TTL</strong> 设置为未来 365 天。</u><br>B. 将调查结果数据发送到运行在 <strong>Amazon EC2 实例</strong> 上的 API，配置该 API 将结果存储在 DynamoDB 表中，调用 Amazon Comprehend 分析，结果保存到第二个 DynamoDB 表，将所有记录的 TTL 设为 365 天。<br>C. 将调查结果数据写入 <strong>Amazon S3</strong> 存储桶，使用 <strong>S3 事件通知</strong>调用 Lambda 函数读取数据，调用 <strong>Amazon Rekognition</strong> 进行情感分析，将结果存储在第二个 S3 存储桶中，对每个存储桶使用 S3 生命周期策略使对象 365 天后过期。<br>D. 将调查结果数据发送到连接 <strong>SQS 队列</strong> 的 <strong>API Gateway</strong> 端点，配置 SQS 队列调用 Lambda 函数，该函数调用 <strong>Amazon Lex</strong> 进行情感分析，将结果保存到 DynamoDB，将 TTL 设为未来 365 天。</p>
<ul>
<li><strong>API Gateway</strong> 可处理高并发请求，将消息推送到 <strong>SQS</strong> 队列（缓冲，防止数据丢失）。</li>
<li><strong>Lambda</strong> 从 SQS 拉取消息，调用 <strong>Amazon Comprehend</strong>（专为文本情感分析设计）进行分析。</li>
<li><strong>DynamoDB</strong> 存储结果，支持高吞吐，TTL 自动删除过期数据。</li>
<li>全托管、无服务器架构，自动扩展，无需管理基础设施，最具可扩展性。</li>
</ul>
<p><br>1006 一家公司使用 AWS Systems Manager 对 EC2 实例进行日常管理和补丁更新。<br>这些 EC2 实例位于<strong>应用程序负载均衡器（ALB）后的 IP 地址类型目标组中</strong>。<br>新的安全协议要求：在打补丁期间将 EC2 实例<strong>从服务中移除</strong>（即从负载均衡器目标组中注销）。<br>当尝试遵循此协议时，在补丁窗口期内收到了错误提示。<br>问哪两种解决方案组合可以解决这些错误？（选两项）</p>
<p><strong>选项复述：</strong><br>A. 将目标组的目标类型从 <strong>IP 地址类型</strong>更改为<strong>实例类型</strong>。<br>B. 继续使用现有的 Systems Manager 文档，无需更改，因为它已经过优化，可处理位于 ALB 后面的 IP 地址类型目标组中的实例。<br>C. <u>实施 <strong>AWSEC2-PatchLoadBalancerInstance</strong> Systems Manager 自动化文档以管理补丁流程</u>。<br>D. <u>使用 <strong>Systems Manager 维护时段</strong>自动将实例从服务中移除，以便对实例进行补丁更新。</u><br>E. 配置 <strong>Systems Manager State Manager</strong> 以将实例从服务中移除并管理补丁计划，使用 ALB 健康检查重新路由流量。</p>
<ul>
<li>ALB 目标组类型：<ul>
<li><strong>实例类型</strong>：直接注册 EC2 实例（通过实例 ID）。</li>
<li><strong>IP 地址类型</strong>：通过 IP 地址注册目标（可以是 EC2 实例或其他 IP）。</li>
</ul>
</li>
<li>当使用 Systems Manager 对 IP 地址类型目标组中的实例打补丁时，如果实例在补丁过程中重启或网络变化，IP 可能变化，导致目标组失效。</li>
<li><strong>AWS 提供了专门的自动化文档 <code>AWSEC2-PatchLoadBalancerInstance</code></strong> 用于处理此场景，它会在补丁前将实例从目标组注销，补丁完成后再重新注册。</li>
</ul>
<p><br>1007 一家医疗公司需要对来自多个客户的大量临床试验数据进行转换。<br>流程：</p>
<ol>
<li>从包含客户数据的<strong>关系型数据库</strong>提取数据。</li>
<li>使用一系列复杂规则转换数据。</li>
<li>转换完成后，将数据加载到 <strong>Amazon S3</strong>。<br>要求：</li>
</ol>
<ul>
<li>在数据存储到 Amazon S3 <strong>之前</strong>，所有数据在处理时都必须加密。</li>
<li>所有数据必须使用<strong>客户特定的密钥</strong>进行加密。</li>
<li><strong>最少的运维工作量</strong>。</li>
</ul>
<p><strong>选项复述：</strong><br>A. 为每个客户创建一个 <strong>AWS Glue 作业</strong>，为每个作业附加一个安全配置，使用 <strong>SSE-S3（S3 托管密钥）</strong> 的服务器端加密。<br>B. 为每个客户创建一个 <strong>Amazon EMR 集群</strong>，为每个集群附加一个安全配置，使用 <strong>CSE-Custom（客户端自定义密钥）</strong> 加密。<br>C. 为<u>每个客户创建一个 <strong>AWS Glue 作业</strong>，为每个作业附加一个安全配置，使用 <strong>客户端加密（CSE-KMS）</strong>，使用 <strong>AWS KMS 托管密钥</strong> 加密数据。</u><br>D. 为每个客户创建一个 <strong>Amazon EMR 集群</strong>，为每个集群附加一个安全配置，使用 <strong>SSE-KMS（服务器端 KMS 密钥）</strong> 加密数据。</p>
<p>AWS Glue 支持<strong>客户端加密（CSE-KMS）</strong>，可以在数据写入 S3 之前使用 KMS 密钥进行加密，且可以为每个客户创建不同的 KMS 密钥</p>
<p>SSE-KMS 是<strong>服务器端加密</strong>，数据写入 S3 后由 S3 使用 KMS 密钥加密，不满足“存储到 S3 之前加密”要求</p>
<p><br>1008 一家公司在单个 <strong>Amazon EC2 按需实例</strong>上托管一个网站分析应用程序。该应用程序具有很强的弹性，设计为以<strong>无状态模式</strong>运行。<br>公司注意到，在繁忙时段应用程序出现<strong>性能下降和 5xx 错误</strong>。<br>公司需要让应用程序实现<strong>无缝扩展</strong>。<br>问哪种解决方案能以<strong>最具成本效益的方式</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 创建该 Web 应用程序的 <strong>AMI</strong>，使用该 AMI 启动第二个 EC2 按需实例，使用<strong>应用程序负载均衡器（ALB）</strong> 在两个 EC2 实例之间分配负载。<br>B. 创建该 Web 应用程序的 <strong>AMI</strong>，使用该 AMI 启动第二个 EC2 按需实例，使用 <strong>Amazon Route 53 加权路由</strong> 在两个 EC2 实例之间分配负载。<br>C. 创建一个 <strong>AWS Lambda</strong> 函数来停止 EC2 实例并更改实例类型，创建一个 <strong>CloudWatch 告警</strong> 在 CPU 超过 75% 时调用该 Lambda 函数。<br>D. <u>创建该 Web 应用程序的 <strong>AMI</strong>，将该 AMI 应用于<strong>启动模板</strong>，创建包含该启动模板的<strong>自动扩展组（ASG）</strong>，配置启动模板以使用 <strong>Spot Fleet</strong>，将<strong>应用程序负载均衡器</strong>附加到自动扩展组。</u></p>
<ul>
<li><p><strong>Spot Fleet</strong> 使用 Spot 实例（比按需实例成本低 60-90%），大幅降低成本。</p>
</li>
<li><p>A扩展了容量（2 个实例），但<strong>不是无缝自动扩展</strong>（固定数量，无法根据流量自动增减），且全部使用按需实例，成本不是最优。</p>
</li>
</ul>
<p><br>1009 一家公司运行的环境将数据存储在 Amazon S3 存储桶中，这些对象在一天中被频繁访问。<br>公司对存储在 S3 的数据有严格的数据加密要求，目前使用 <strong>AWS KMS</strong> 进行加密。<br>公司希望<strong>优化与加密 S3 对象相关的成本</strong>，同时<strong>无需额外调用 AWS KMS</strong>。<br>问哪种解决方案能满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 使用带有 <strong>Amazon S3 托管密钥的服务器端加密（SSE-S3）</strong>。<br>B. <u>对新对象使用 <strong>S3 存储桶密钥</strong>，通过 AWS KMS 密钥进行服务器端加密（SSE-KMS）。</u><br>C. 使用带有 <strong>AWS KMS 客户管理密钥的客户端加密（CSE-KMS）</strong>。<br>D. 使用存储在 AWS KMS 中的<strong>客户提供的密钥进行服务器端加密（SSE-C）</strong></p>
<p>S3 存储桶密钥（Bucket Keys）功能可以在使用 SSE-KMS 加密的同时，大幅减少 KMS API 调用次数（从每次对象操作减少到每小时每存储桶一次），从而显著降低加密相关成本</p>
<p><br>1010 一家公司在本地数据中心的虚拟机（VM）上运行多个工作负载，正在快速扩张，本地数据中心扩展速度不足，希望将工作负载迁移到 AWS。<br>迁移具有<strong>时间敏感性</strong>，且希望对<strong>非关键工作负载采用直接迁移（lift-and-shift）策略</strong>。<br>问哪些步骤组合可以满足这些要求？（选三项）</p>
<p><strong>选项复述：</strong><br>A. 使用 <strong>AWS 架构转换工具（AWS SCT）</strong> 收集有关虚拟机的数据。<br>B. <u>使用 <strong>AWS 应用迁移服务（AWS MGN）</strong>，在虚拟机上安装 AWS 复制代</u>理。<br>C. <u>完成虚拟机的初始复制，启动测试实例，对虚拟机进行验收测试</u>。<br>D. <u>停止虚拟机上的所有操作，启动一个切换实例。</u><br>E. 使用 <strong>AWS App2Container（A2C）</strong> 收集有关虚拟机的数据。<br>F. 使用 <strong>AWS 数据库迁移服务（AWS DMS）</strong> 迁移虚拟机。</p>
<p>AWS SCT（Schema Conversion Tool）主要用于<strong>数据库架构转换</strong>（如 Oracle 到 PostgreSQL），不是用于虚拟机直接迁移的工具，</p>
<p><strong>AWS MGN</strong> 是 AWS 推荐的<strong>直接迁移（lift-and-shift）服务</strong>，可自动将物理机、虚拟机或云虚拟机迁移到 AWS</p>
<ol>
<li><strong>安装复制代理</strong>（B）开始复制数据；</li>
<li><strong>完成复制并测试</strong>（C）确保迁移正确性；</li>
<li><strong>执行切换</strong>（D）最终迁移上线。</li>
</ol>
<p>A2C 用于将现有应用程序<strong>容器化</strong>（迁移到容器），不是直接迁移（lift-and-shift）工具</p>
<p>DMS 用于<strong>数据库迁移</strong>（数据复制），不是迁移整个虚拟机的服务</p>
<p><br>1011 一家公司在私有子网中托管了一个应用程序，并与 <strong>Amazon Cognito 用户池</strong> 集成进行用户身份验证。<br>公司需要修改应用程序，以便将用户文档<strong>安全地存储</strong>在 Amazon S3 存储桶中。<br>问哪些步骤组合可以将 Amazon S3 与应用程序安全集成？（选两项）</p>
<p><strong>选项复述：</strong><br>A. 创建一个 <strong>Amazon Cognito 身份池</strong>，以便在用户成功登录时为其生成安全的 Amazon S3 访问令牌。<br>B. 当用户成功登录时，使用现有的 Amazon Cognito 用户池为用户生成 Amazon S3 访问令牌。<br>C. 在<u>公司托管应用程序的同一 VPC 中创建一个 <strong>Amazon S3 VPC 终端节点</strong>。</u><br>D. 在公司托管应用程序的 VPC 中创建一个 NAT 网关，为 S3 存储桶分配一个策略，以拒绝任何并非来自 Amazon Cognito 的请求。<br>E. 为 S3 存储桶附加一个策略，仅允许来自用户 IP 地址的访问。</p>
<ul>
<li><strong>A</strong>：使用 Cognito 身份池为用户提供临时 AWS 凭证，实现基于身份的安全访问控制（IAM 角色权限），确保只有认证用户可以访问 S3。</li>
<li><strong>C</strong>：创建 S3 VPC 终端节点确保从私有子网到 S3 的流量通过 AWS 内部网络，避免经过互联网，增强网络安全。</li>
</ul>
<p><br>1012 一家公司拥有一个三层 Web 应用程序，用于处理客户订单：</p>
<ul>
<li><strong>Web 层</strong>：由应用程序负载均衡器后的 EC2 实例组成。</li>
<li><strong>处理层</strong>：由 EC2 实例构成，通过 <strong>Amazon SQS</strong> 与 Web 层解耦。</li>
<li><strong>存储层</strong>：使用 <strong>Amazon DynamoDB</strong>。</li>
</ul>
<p>在高峰时段，一些用户报告订单处理延迟和卡顿。<br>发现问题期间：</p>
<ol>
<li>EC2 实例的 <strong>CPU 使用率达到 100%</strong>。</li>
<li><strong>SQS 队列已满</strong>。</li>
<li>高峰时段<strong>不固定且不可预测</strong>。</li>
</ol>
<p>公司需要提高应用程序的性能。<br>问哪种解决方案能满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 对 Amazon EC2 Auto Scaling 使用<strong>定时扩展</strong>，以便在峰值使用期间扩展处理层实例。使用 <strong>CPU 利用率指标</strong> 来确定何时进行扩展。<br>B. 在 DynamoDB 后端层前使用 <strong>Amazon ElastiCache for Redis</strong>。使用 <strong>目标利用率</strong> 作为指标来确定何时进行扩展。<br>C. 添加一个 <strong>Amazon CloudFront 分发</strong> 以缓存 Web 层的响应。使用 <strong>HTTP 延迟</strong> 作为确定何时扩展的指标。<br>D. <u>使用 <strong>Amazon EC2 Auto Scaling 目标跟踪策略</strong> 来扩展处理层实例。使用 <strong>ApproximateNumberOfMessages 属性</strong> 来确定何时进行扩展。</u></p>
<p>处理层实例 CPU 100% 和 SQS 队列已满表明处理能力不足，且高峰不可预测。<br>使用 Auto Scaling 目标跟踪策略基于 <strong>SQS 队列深度</strong></p>
<p><br>1013 一家公司的生产环境由 <strong>Amazon EC2 按需实例</strong> 组成，这些实例在<strong>周一至周六持续运行</strong>。<br>这些实例在<strong>周日只需运行 12 小时</strong>，且<strong>不能容忍中断</strong>。<br>公司希望对生产环境进行<strong>成本优化</strong>。<br>问哪种解决方案能<strong>最具成本效益</strong>地满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. <u>为仅在周日运行 12 小时的 EC2 实例购买<strong>定时预留实例</strong>。为周一至周六持续运行的 EC2 实例购买<strong>标准预留实例</strong>。</u><br>B. 为仅在周日运行 12 小时的 EC2 实例购买<strong>可转换预留实例</strong>。为周一至周六持续运行的 EC2 实例购买<strong>标准预留实例</strong>。<br>C. 对于仅在周日运行 12 小时的 EC2 实例，使用 <strong>Spot 实例</strong>。为周一至周六持续运行的 EC2 实例购买<strong>标准预留实例</strong>。<br>D. 对于仅在周日运行 12 小时的 EC2 实例，使用 <strong>Spot 实例</strong>。为周一至周六持续运行的 EC2 实例购买<strong>可转换预留实例</strong>。</p>
<p><br>1014 一家数字图像处理公司希望将其本地单体应用迁移到 AWS 云。<br>公司处理数千张图像，并在处理工作流中生成大型文件。<br>要求：</p>
<ol>
<li>需要一个解决方案来管理日益增多的图像处理任务。</li>
<li>必须减少图像处理工作流程中的手动任务。</li>
<li><strong>不希望管理该解决方案的底层基础设施</strong>（即希望无服务器或全托管）。</li>
<li><strong>最少的运营开销</strong>。<br>问哪种解决方案能满足这些要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. 使用 <strong>Amazon ECS 和 EC2 Spot 实例</strong> 处理图像，配置 <strong>Amazon SQS</strong> 编排工作流，将处理后的文件存储在 <strong>Amazon EFS</strong> 中。<br>B. <u>使用 <strong>AWS Batch 作业</strong> 处理图像，使用 <strong>AWS Step Functions</strong> 编排工作流，将处理后的文件存储在 <strong>Amazon S3</strong> 存储桶中。</u><br>C. 使用 <strong>AWS Lambda 函数和 EC2 Spot 实例</strong> 处理图像，将处理后的文件存储在 <strong>Amazon FSx</strong> 中。<br>D. 部署一组 <strong>Amazon EC2 实例</strong> 处理图像，使用 <strong>AWS Step Functions</strong> 编排工作流，将处理后的文件存储在 <strong>Amazon EBS</strong> 卷中。</p>
<p>AWS Batch 提供全托管批处理计算，自动管理计算资源，适合数千张图像的处理任务；<br>Step Functions 实现工作流自动化，减少手动任务；<br>S3 提供无限扩展、高耐久的存储，适合大型文件。</p>
<p><br>1015 一家公司的图片托管网站让全球用户能够通过移动设备上传、查看和下载图片。<br>目前静态网站托管在 <strong>Amazon S3 存储桶</strong>中。<br>由于网站日益受欢迎，<strong>性能下降</strong>，用户反馈上传和下载图片时存在延迟问题。<br>公司必须提高网站性能，且要以<strong>最少的实施工作量</strong>满足要求。</p>
<p><strong>选项复述：</strong><br>A. <u>为 S3 存储桶配置 <strong>Amazon CloudFront 分发</strong> 以提高下载性能。启用 <strong>S3 传输加速</strong> 以提高上传性能。</u><br>B. 在多个 AWS 区域配置 Amazon EC2 实例，将应用程序迁移到 EC2，使用应用程序负载均衡器（ALB）分配流量，配置 <strong>AWS Global Accelerator</strong> 降低延迟。<br>C. 配置一个以 S3 存储桶为源的 <strong>Amazon CloudFront 分发</strong> 提高下载性能，配置应用程序使用 CloudFront 上传图像提高上传性能，在多个 AWS 区域创建 S3 存储桶并配置复制规则，根据用户位置重定向到最近的 S3 存储桶。<br>D. 为 S3 存储桶配置 <strong>AWS Global Accelerator</strong> 以提升网络性能，创建一个端点，让应用程序使用 Global Accelerator 而不是直接访问 S3 存储桶。</p>
<p>Global Accelerator 主要用于加速 TCP&#x2F;UDP 流量到 AWS 终端节点（如 ALB、EC2、NLB），但<strong>不支持直接加速 S3</strong></p>
<p><br>1016 一家公司在 VPC 中的应用程序负载均衡器（ALB）后方的私有子网中运行着一个应用程序。<br>VPC 配有一个 NAT 网关和一个互联网网关。<br>应用程序调用 <strong>Amazon S3 API</strong> 来存储对象。<br>根据安全政策，来自该应用程序的流量<strong>不得通过互联网传输</strong>。<br>问哪种解决方案能<strong>最具成本效益地</strong>满足这些要求？</p>
<p><strong>选项复述：</strong><br>A. 配置一个 <strong>S3 接口端点（Interface Endpoint）</strong>，创建一个允许向 Amazon S3 出站流量的安全组。<br>B. <u>配置一个 <strong>S3 网关终端节点（Gateway Endpoint）</strong>，更新 VPC 路由表以使用该终端节点。</u><br>C. 配置一个 <strong>S3 存储桶策略</strong>，允许来自分配给 NAT 网关的弹性 IP 地址的流量。<br>D. 在同一子网中创建第二个 NAT 网关，更新 VPC 路由表以使用第二个 NAT 网关。</p>
<p>接口端点适用于需要通过 DNS 解析且支持 PrivateLink 的服务，S3 支持 PrivateLink，但<strong>通常不推荐</strong>，因为 S3 有专门的 <strong>网关端点（Gateway Endpoint）</strong> 更经济。</p>
<p><br>1017 一家公司在 Amazon EKS 集群（部署在 EC2 实例上）运行一个应用程序。<br>应用程序包含：</p>
<ul>
<li>用户界面（UI）Pods → 使用 <strong>Amazon DynamoDB</strong></li>
<li>数据服务（Data Service）Pods → 使用 <strong>Amazon S3</strong><br>公司必须确保：</li>
</ul>
<ol>
<li>UI Pods <strong>只能访问 DynamoDB</strong>。</li>
<li>数据服务 Pods <strong>只能访问 S3</strong>。<br>公司使用 IAM 进行访问管理。<br>问哪种解决方案满足这些要求？</li>
</ol>
<p><strong>选项复述：</strong><br>A. 为 S3 和 DynamoDB 创建单独的 IAM 策略，将这两个策略附加到 <strong>EC2 实例配置文件</strong>，使用 <strong>Kubernetes RBAC</strong> 控制相应 Pod 对 S3 或 DynamoDB 的访问。<br>B. 为 S3 和 DynamoDB 创建单独的 IAM 策略，将 S3 IAM 策略<strong>直接附加到数据服务 Pods</strong>，将 DynamoDB 策略<strong>直接附加到 UI Pods</strong>。<br>C. <u>为 UI 和数据服务创建单独的 <strong>Kubernetes 服务账户</strong> 以承担 IAM 角色，将 <strong>AmazonS3FullAccess</strong> 策略附加到数据服务账户，将 <strong>AmazonDynamoDBFullAccess</strong> 策略附加到 UI 服务账户。</u><br>D. 为 UI 和数据服务创建单独的 <strong>Kubernetes 服务账户</strong> 以承担 IAM 角色，使用 <strong>服务账户的 IAM 角色（IRSA）</strong> 为 UI Pods 提供对 S3 的访问权限，为数据服务 Pods 提供对 DynamoDB 的访问权限。</p>
<ul>
<li>数据服务 Pods（应访问 S3）关联具有 AmazonS3FullAccess 策略的角色。</li>
<li>UI Pods（应访问 DynamoDB）关联具有 AmazonDynamoDBFullAccess 策略的角色。</li>
</ul>
<p><br>1018 一家公司拥有全球分布的开发团队，需要安全访问 AWS 资源，同时必须符合安全政策。公司当前使用本地 Active Directory（AD）进行内部身份验证，并使用 AWS Organizations 管理多个 AWS 账户。公司希望找到一种与现有基础设施集成的集中式身份管理与访问控制解决方案，且尽可能减少运营开销。</p>
<h3 id="选项复述"><a href="#选项复述" class="headerlink" title="选项复述"></a>选项复述</h3><p><strong>A.</strong> 设置 AWS Directory Service，在 AWS 上创建 AWS 托管的 Microsoft Active Directory，与本地 AD 建立信任关系，并通过分配给 AD 组的 IAM 角色来访问 AWS 资源。<br><strong>B.</strong> 为每位开发人员创建 IAM 用户，手动管理每个用户的权限，并实施多因素认证（MFA）。<br><strong>C.</strong> <u>使用 AWS Directory Service 中的 AD 连接器连接到本地 AD，将 AD 连接器与 AWS IAM Identity Center 集成，配置权限集，使每个 AD 组能够访问特定的 AWS 账户和资源。</u><br><strong>D.</strong> 使用 Amazon Cognito 部署身份联合解决方案，将其与本地 AD 集成，通过 Amazon Cognito 提供访问令牌供开发人员访问 AWS 资源。</p>
<ul>
<li>AD 连接器允许 AWS 服务直接使用现有本地 AD，无需同步用户或创建额外 AD 实例。</li>
<li>IAM Identity Center 与 AWS Organizations 深度集成，支持基于 AD 组的权限集分配，实现跨账户统一访问控制</li>
</ul>
<p>Amazon Cognito 更适合面向互联网的用户身份联合（如移动端、Web 应用），不太适合企业内部员工直接访问 AWS 管理资源，且配置较复杂，不如 IAM Identity Center 直接集成 AD 来得简洁。</p>
<p><br>1019 一家公司在 AWS 上开发应用程序，其 HTTP API 通过 Amazon API Gateway 发布，需要<strong>仅允许来自公司内部网络的一组可信 IP 地址</strong>访问，确保安全访问控制。</p>
<h3 id="选项复述-1"><a href="#选项复述-1" class="headerlink" title="选项复述"></a>选项复述</h3><p><strong>A.</strong> 设置 API Gateway 私有集成，以限制对预定义 IP 地址集的访问。<br><strong>B.</strong> <u>为 API 创建一个资源策略，拒绝来自任何未被明确允许的 IP 地址的访问。</u><br><strong>C.</strong> 直接在私有子网中部署 API。创建网络访问控制列表（NACL），设置规则以允许来自特定 IP 地址的流量。<br><strong>D.</strong> 修改附加到 API 网关的安全组，仅允许来自可信 IP 地址的入站流量。</p>
<ul>
<li>API Gateway 资源策略是专门用于控制谁可以访问 API 的机制，支持基于 IP 的条件限制。</li>
<li>通过在资源策略中设置 <code>Deny</code> 与 <code>Allow</code> 规则，可以精确控制允许的可信 IP 地址，拒绝其他所有流量。</li>
</ul>
<p>API Gateway 私有集成是将 API Gateway 与 VPC 内部资源（如 ELB、EC2）连接的方式，<strong>并不能直接限制客户端 IP</strong>，它是用来访问 VPC 内服务，而不是限制入口 IP。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T900/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T900/" class="post-title-link" itemprop="url">AWS架构师T900</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-29 10:13:29" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2026-01-08 22:06:42" itemprop="dateModified" datetime="2026-01-08T22:06:42+08:00">2026-01-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T900"><a href="#AWS架构师T900" class="headerlink" title="AWS架构师T900"></a>AWS架构师T900</h1><p><br>801 金融公司处理高度敏感数据。</p>
<ul>
<li>数据存储在 Amazon S3 存储桶。</li>
<li>需要确保数据在<strong>传输过程中</strong>和<strong>静态时</strong>都被加密。</li>
<li>必须在 <strong>AWS 云之外管理加密密钥</strong>（即密钥不能由 AWS 管理）。</li>
</ul>
<p><strong>选项：</strong><br>A. 使用 AWS KMS <strong>客户管理密钥</strong>（CMK）通过 SSE 加密 S3 数据。<br>B. 使用 AWS KMS <strong>AWS 托管密钥</strong> 通过 SSE 加密 S3 数据。<br>C. 使用默认的 SSE 加密（SSE-S3）。<br>D. <u>在将数据存储到 S3 之前，在公司的数据中心对数据进行加密。</u></p>
<p>唯一符合条件的是在数据上传到 S3 之前，在本地（公司数据中心）用本地管理的密钥加密数据，然后上传密文到 S3（客户端加密）。<br>这样静态加密由客户端加密保障，传输过程加密由 HTTPS 保障，密钥完全在 AWS 外部管理。</p>
<p><br>802 支付应用程序在 AWS 上运行。</p>
<ul>
<li>接收来自移动设备的支付通知。</li>
<li>支付通知需要<strong>基本验证</strong>，然后发送到<strong>后端处理应用程序</strong>。</li>
<li>后端处理程序<strong>运行时间长</strong>，需要<strong>调整计算和内存资源</strong>。</li>
<li>公司<strong>不想管理基础设施</strong>（即希望无服务器或完全托管）。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建 SQS 队列，用 EventBridge 规则接收移动设备支付通知，验证后发送到后端应用，后端应用部署在 <strong>EKS Anywhere</strong>（本地自管） → 需要管理基础设施，不符合“不想管理基础设施”。 ❌</p>
<p>B. 创建 API Gateway + Step Functions 状态机接收通知并验证，后端部署在 <strong>EKS（自管理节点）</strong> → 需要管理节点，不符合“不想管理基础设施”。 ❌</p>
<p>C. 创建 SQS 队列 + EventBridge 规则接收并验证，后端部署在 <strong>EC2 竞价型实例集群</strong> → 需要管理 EC2 实例，不符合“不想管理基础设施”。 ❌</p>
<p>D. 创建 API Gateway + Lambda 接收并验证通知，后端部署在 <strong>ECS with AWS Fargate</strong> → Fargate 是无服务器容器服务，无需管理节点，后端应用可配置 CPU 和内存，适应长时间运行任务。 ✅</p>
<p>移动设备 → API Gateway（HTTP 入口）→ Lambda（基本验证）是常用模式，无需自己管理服务器。</p>
<p>Fargate 适合长时间运行的任务（不同于 Lambda 有 15 分钟限制</p>
<p><br>803 公司需要用户认证解决方案。</p>
<ul>
<li>要求：对<strong>从不一致的地理位置、IP地址或设备登录的用户启用双因素认证（MFA）</strong>（即基于风险的动态 MFA）。</li>
<li>必须能<strong>扩展到数百万用户</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A<u>. 配置 Amazon Cognito <strong>用户池</strong>，启用<strong>基于风险的自适应身份验证</strong>功能，并结合 MFA。</u><br>B. 配置 Amazon Cognito <strong>身份池</strong>，启用 MFA。<br>C. 配置 <strong>IAM 用户</strong>进行用户认证，附加允许 <code>AllowManageOwnUserMFA</code> 操作的 IAM 策略。<br>D. 配置 <strong>AWS IAM Identity Center</strong>（原 AWS SSO），配置权限集要求 MFA。</p>
<ul>
<li>Amazon Cognito 用户池提供 <strong>基于风险的自适应身份验证</strong> 功能，可根据位置、IP、设备等风险因素动态要求 MFA。</li>
<li>身份池（B）主要用于提供临时 AWS 凭证，不是主要用户认证服务，且不提供基于风险的自适应认证。</li>
</ul>
<p><br>804 公司有 Amazon S3 数据湖。</p>
<ul>
<li>需要<strong>每天转换数据</strong>并加载到<strong>数据仓库</strong>。</li>
<li>数据仓库必须具备 <strong>MPP（大规模并行处理）</strong> 能力。</li>
<li>数据分析师需要用 <strong>SQL 命令</strong>创建和训练 <strong>机器学习（ML）</strong> 模型。</li>
<li>解决方案应<strong>尽可能使用无服务器 AWS 服务</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 运行每日 <strong>Amazon EMR</strong> 作业转换并加载到 <strong>Amazon Redshift</strong>，用 <strong>Redshift ML</strong> 创建和训练模型。<br>B. 运行每日 <strong>EMR</strong> 作业转换并加载到 <strong>Aurora Serverless</strong>，用 <strong>Aurora ML</strong> 创建和训练模型。<br>C. <u>运行每日 <strong>AWS Glue</strong> 作业转换并加载到 <strong>Amazon Redshift Serverless</strong>，用 <strong>Redshift ML</strong> 创建和训练模型</u>。<br>D. 运行每日 <strong>AWS Glue</strong> 作业转换并加载到 <strong>Amazon Athena 表</strong>，用 <strong>Athena ML</strong> 创建和训练模型。</p>
<ul>
<li>Amazon Redshift 是 MPP 数据仓库。</li>
<li>Aurora Serverless（B）不是 MPP 架构，它是关系型数据库，不适合大规模分析型 MPP 负载。</li>
<li>Athena（D）是无服务器查询服务，但不是数据仓库（它是查询引擎，不是存储密集型数据仓库）。</li>
</ul>
<p><br>805 公司目前在本地数据中心的 Kubernetes 环境中运行容器。</p>
<ul>
<li>希望使用 <strong>Amazon EKS</strong> 和其他 AWS 托管服务。</li>
<li>但合规要求：<strong>数据必须保留在本地数据中心</strong>，不能存储在远程站点或云中。</li>
</ul>
<p><strong>选项：</strong><br>A. 在公司的数据中心部署 AWS 本地区域（AWS Local Zones）。<br>B. 在公司的数据中心使用 AWS Snowmobile。<br>C. <u>在公司的数据中心安装一个 AWS Outposts 机架。</u><br>D. 在数据中心安装一个 AWS Snowball Edge 存储优化节点。</p>
<p>AWS Outposts 是将 AWS 基础设施、服务、API 扩展到客户本地数据中心的解决方案，可以运行 EKS 控制平面和工作节点，数据保留在本地。</p>
<ul>
<li>AWS Local Zones 是 AWS 区域的扩展，但仍位于 AWS 设施，不是客户自己的数据中心，可能不符合“数据不能存储在远程站点或云中”的严格要求。</li>
</ul>
<p><br>806 社交媒体公司有工作负载收集和处理数据。</p>
<ul>
<li>数据存储在<strong>本地 NFS 存储</strong>中。</li>
<li>该存储扩展速度不够满足业务增长需求。</li>
<li>希望迁移到 AWS。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 设置 AWS 存储网关<strong>卷网关</strong>，使用 S3 生命周期策略将数据转换到适当存储类别。<br>B. <u>设置 AWS 存储网关<strong>Amazon S3 文件网关</strong>，使用 S3 生命周期策略将数据转换到适当存储类别。</u><br>C. 使用 Amazon EFS <strong>Standard-IA</strong> 存储类别，激活不常访问生命周期策略。<br>D. 使用 Amazon EFS <strong>One Zone-IA</strong> 存储类别，启用不常访问生命周期策略。</p>
<ul>
<li>EFS 是按使用量计费的托管文件系统，成本相对较高（尤其对于大量数据）。</li>
<li>S3 存储成本远低于 EFS，但 S3 本身不是文件系统接口（是对象存储）。</li>
<li>存储网关文件网关可以在本地提供 NFS 接口，后端存储在 S3，并可利用 S3 生命周期策略（如到 Glacier）进一步降低成本。</li>
</ul>
<p><br>807 营销活动期间，<strong>高并发</strong>的 Lambda 函数处理消息队列中大量消息。</p>
<ul>
<li>Lambda 函数是 <strong>CPU 密集型</strong> 代码。</li>
<li>目标：<strong>降低计算成本</strong>，同时<strong>维持服务延迟</strong>（不降低延迟）。</li>
</ul>
<p><strong>选项：</strong><br>A. 配置 <strong>预留并发（Reserved Concurrency）</strong>，减少分配给 Lambda 函数的内存。<br>B. <u>配置 <strong>预留并发</strong>，根据 <strong>AWS Compute Optimizer</strong> 的建议增加内存。</u><br>C. 配置 <strong>预置并发（Provisioned Concurrency）</strong>，减少分配给 Lambda 函数的内存。<br>D. 配置 <strong>预置并发</strong>，根据 AWS Compute Optimizer 增加内存。</p>
<ul>
<li><strong>预留并发（Reserved Concurrency）</strong>：限制函数的最大并发实例数，防止过度并发影响其他函数，但不降低成本。</li>
<li><strong>预置并发（Provisioned Concurrency）</strong>：提前预热一定数量的函数实例，减少冷启动延迟，但<strong>不会降低计算成本</strong>（实际上可能增加成本，因为为预置实例付费）。</li>
</ul>
<p>AWS Compute Optimizer 可以分析 Lambda 函数的内存利用率，给出建议内存大小，以优化成本和性能。</p>
<p><br>808 公司在 Amazon ECS 上运行工作负载。</p>
<ul>
<li>ECS 任务定义使用的容器镜像需要<strong>扫描常见漏洞与暴露（CVE）</strong>。</li>
<li>新创建的容器镜像也需要扫描。</li>
<li>要求：<strong>对工作负载的改动最少</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>使用 <strong>Amazon ECR</strong> 作为私有镜像仓库，为 ECR <strong>基础扫描</strong> 指定推送时扫描筛选条件。</u><br>B. 将容器镜像存储在 <strong>Amazon S3</strong> 中，使用 <strong>Amazon Macie</strong> 扫描（Macie 是用于敏感数据发现，不是 CVE 扫描）。 ❌<br>C. 将工作负载迁移到 <strong>Amazon EKS</strong>，使用 ECR 作为仓库，为 ECR <strong>增强扫描</strong> 指定推送时扫描过滤器（但迁移到 EKS 改动大，不满足“对工作负载改动最少”）。 ❌<br>D. 将容器镜像存储在 <strong>S3</strong>（启用版本控制），用 S3 事件触发 <strong>Lambda</strong> 启动 <strong>Amazon Inspector</strong> 扫描（Inspector 用于 EC2 和容器镜像扫描，但需要手动或通过脚本集成，不如 ECR 原生集成简单）。</p>
<p>ECR 是 AWS 容器镜像托管服务，与 ECS 无缝集成，提供原生 CVE 扫描，只需配置推送时扫描即可自动执行，改动最小</p>
<p><br>809 公司使用 <strong>AWS Batch</strong> 运行每日销售流程。</p>
<ul>
<li>需要<strong>无服务器解决方案</strong>，在 <strong>Batch 作业成功时</strong>调用第三方报告应用程序。</li>
<li>第三方应用有 <strong>HTTP API</strong>，使用<strong>用户名和密码认证</strong>（基本认证或类似）。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>配置 <strong>EventBridge 规则</strong> 匹配 Batch 作业成功事件，将第三方 API 配置为带有用户名和密码的 <strong>EventBridge API 目标</strong>，并设为规则目标。</u><br>B. 配置 <strong>EventBridge 计划程序</strong>（scheduler）匹配 Batch 作业成功事件，配置 <strong>Lambda</strong> 函数用用户名密码调用第三方 API，将 Lambda 设为规则目标。<br>C. 配置 Batch 作业将成功事件发布到 <strong>API Gateway REST API</strong>，在 API Gateway 上配置 <strong>HTTP 代理集成</strong> 直接调用第三方 API（带用户名密码）。<br>D. 配置 Batch 作业将成功事件发布到 <strong>API Gateway REST API</strong>，在 API Gateway 上配置 <strong>Lambda 代理集成</strong>，Lambda 调用第三方 API（带用户名密码）。</p>
<p>EventBridge API 目标专为将事件转发到外部 HTTP 端点设计，支持基本认证，无需编写代码，符合无服务器且改动最少</p>
<p><br>810 公司从供应商处收集数据。</p>
<ul>
<li>供应商的数据存储在<strong>供应商自己的 AWS 账户</strong>的 <strong>Amazon RDS for MySQL</strong> 数据库中。</li>
<li>公司的 VPC <strong>没有互联网网关、Direct Connect 或 Site-to-Site VPN</strong>（即公司 VPC 无法通过公共互联网或专用物理线路访问外部）。</li>
<li>公司需要访问供应商数据库中的数据。</li>
</ul>
<p><strong>选项：</strong><br>A. 让供应商注册 <strong>AWS 托管连接直连计划</strong>，使用 <strong>VPC 对等连接</strong> 连接两个 VPC。<br>B. 在公司的 VPC 和供应商的 VPC 之间配置<strong>客户端 VPN 连接</strong>，使用 <strong>VPC 对等连接</strong>。<br>C. <u>让供应商创建一个<strong>网络负载均衡器（NLB）</strong> 放在 RDS 前面，使用 <strong>AWS PrivateLink</strong> 集成两个 VPC。</u><br>D. 使用 <strong>AWS Transit Gateway</strong> 整合两个 VPC，使用 <strong>VPC 对等连接</strong>（重复）</p>
<p>PrivateLink 是 AWS 推荐的服务跨账户共享方案，允许公司 VPC 通过弹性网络接口直接访问供应商 VPC 中的 NLB（进而访问 RDS），无需互联网网关或对等连接，安全且符合网络限制。</p>
<p>811公司想用 <strong>Amazon Managed Grafana</strong> 作为可视化工具。</p>
<ul>
<li>需要将 <strong>Amazon RDS 数据库</strong>中的数据作为数据源可视化。</li>
<li>需要<strong>安全解决方案</strong>，确保<strong>数据不通过互联网暴露</strong>（即私有连接）。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建<strong>不带 VPC</strong> 的 Grafana 工作区，为 RDS 创建<strong>公共端点</strong>，在 Grafana 中配置该公共端点作为数据源 → 数据通过互联网暴露。 ❌<br>B. <u>在 <strong>VPC 中</strong>创建 Grafana 工作区，为 RDS 创建<strong>私有终端节点</strong>，在 Grafana 中将该私有终端节点配置为数据源 → Grafana 与 RDS 在同一 VPC 或通过私有连接，数据不外泄</u>。 ✅<br>C. 创建<strong>不带 VPC</strong> 的 Grafana 工作区，创建 <strong>AWS PrivateLink 终端节点</strong> 连接 Grafana 与 RDS → Grafana 无 VPC 时无法使用 PrivateLink（PrivateLink 需要 VPC 终端节点）。 ❌<br>D. 在 VPC 中创建 Grafana 工作区，但为 RDS 创建<strong>公共端点</strong> → 数据仍通过互联网暴露。 ❌</p>
<p><br>812 数据湖在 S3，数据是 <strong>Apache Parquet</strong> 格式。</p>
<ul>
<li>多个转换步骤：异常值过滤、标准化日期时间值、聚合分析。</li>
<li>转换后数据存储在新的 S3 桶，供数据分析师访问。</li>
<li>需要<strong>无需代码的预制数据转换解决方案</strong>（即可视化、低代码或无代码工具）。</li>
<li>必须提供<strong>数据沿袭（data lineage）和数据剖析（data profiling）</strong> 功能。</li>
<li>需要与全公司员工<strong>共享数据转换步骤</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 配置 <strong>AWS Glue Studio 可视化画布</strong> 转换数据，通过 Glue 作业与员工共享转换步骤。<br>B. 配置 <strong>Amazon EMR Serverless</strong> 转换数据，通过 EMR Serverless 作业共享步骤。<br>C. <u>配置 <strong>AWS Glue DataBrew</strong> 转换数据，通过 DataBrew 配方（recipes）与员工共享转换步骤。</u><br>D. 创建 Amazon Athena 表，写 SQL 查询转换数据，与员工共享 SQL 查询。</p>
<ol>
<li><strong>无需代码的预制转换工具</strong><ul>
<li><strong>AWS Glue DataBrew</strong> 是专门的无代码&#x2F;可视化数据准备工具，提供交互式界面进行数据清洗、转换，并自动生成配方（recipe），可以共享。</li>
<li><strong>AWS Glue Studio</strong> 也提供可视化 ETL，但更多面向开发者，需要一些配置；而 DataBrew 更接近业务用户，无需代码。</li>
</ul>
</li>
<li><strong>数据沿袭和数据剖析</strong><ul>
<li>DataBrew 提供<strong>数据剖析</strong>（自动统计、模式识别、值分布）和<strong>数据质量检查</strong>，也支持查看数据的来源和转换步骤（沿袭）。</li>
<li>Glue Studio 也有一定沿袭和剖析功能，但 DataBrew 在这些方面更突出且用户友好。</li>
</ul>
</li>
</ol>
<p><br>813  Web 应用程序在 EC2 实例上运行，放在 <strong>ALB 后面的多个目标组</strong>中。</p>
<ul>
<li>公共网站通过 ALB 访问。</li>
<li>需要让工程师访问<strong>特定的开发 EC2 实例</strong>（网站的开发版本）。</li>
<li>使用 <strong>Amazon Route 53</strong> 托管区域让工程师访问开发实例。</li>
<li>要求：<strong>即使开发实例被替换，也必须能自动路由到开发实例</strong>（即不依赖固定 IP，需要弹性）。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>为开发网站创建一条 <strong>A 记录</strong> 指向 ALB，在 ALB 上创建<strong>监听器规则</strong>，将开发网站的请求转发到<strong>包含开发实例的目标组</strong>。</u><br>B. 用<strong>公共 IP 地址</strong>重新创建开发实例，为开发网站创建 A 记录指向该公共 IP。<br>C. 为开发网站创建 A 记录指向 ALB，在 ALB 上创建监听器规则，重定向到开发实例的<strong>公网 IP 地址</strong>。<br>D. 将所有实例放在同一个目标组，为开发网站创建 A 记录指向 ALB，在 ALB 上创建侦听器规则转发到该目标组</p>
<ol>
<li><strong>要求自动路由到开发实例，即使实例被替换</strong><ul>
<li>使用固定公共 IP（B 和 C）不满足弹性要求，因为实例替换后 IP 会变。</li>
<li>应该使用 <strong>目标组 + ALB</strong> 来动态路由到实例，目标组自动更新实例的 IP。</li>
</ul>
</li>
<li><strong>如何让 ALB 区分开发流量与生产流量</strong><ul>
<li>可以为开发网站使用不同的域名（如 <a target="_blank" rel="noopener" href="https://dev.example.com/">dev.example.com</a>），在 Route 53 中指向同一个 ALB。</li>
<li>在 ALB 上配置<strong>基于主机头的监听器规则</strong>，将 <a target="_blank" rel="noopener" href="https://dev.example.com/">dev.example.com</a> 的请求转发到<strong>专门的目标组</strong>（仅包含开发实例）。</li>
</ul>
</li>
</ol>
<p><br>814 公司目前在<strong>数据中心的 Kubernetes 集群</strong>上运行容器应用程序。</p>
<ul>
<li>应用程序使用 <strong>AMQP</strong>（高级消息队列协议）与消息队列通信。</li>
<li>因为数据中心扩展能力不足，希望迁移到 AWS。</li>
<li>要求：<strong>最低的运营开销</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 将容器应用迁移到 <strong>Amazon ECS</strong>，使用 <strong>Amazon SQS</strong> 检索消息。<br>B. <u>将容器应用程序迁移到 <strong>Amazon EKS</strong>，使用 <strong>Amazon MQ</strong> 检索消息。</u><br>C. 使用高可用性 <strong>Amazon EC2 实例</strong> 运行应用程序，使用 <strong>Amazon MQ</strong> 检索消息。<br>D. 使用 <strong>AWS Lambda</strong> 运行应用程序，使用 <strong>Amazon SQS</strong> 检索消息。</p>
<ol>
<li><strong>消息协议兼容性</strong><br>AMQP 是一种协议，常用的实现如 RabbitMQ、ActiveMQ。<ul>
<li>Amazon SQS 是 AWS 的托管消息队列，但<strong>不支持 AMQP 协议</strong>（支持 HTTP&#x2F;HTTPS 和 AWS SDK）。</li>
<li><strong>Amazon MQ</strong> 是 AWS 托管的消息代理服务，支持 <strong>AMQP、MQTT、OpenWire、STOMP</strong> 等协议，因此能兼容现有使用 AMQP 的应用程序，无需修改应用代码。</li>
</ul>
</li>
<li><strong>容器编排平台选择</strong><ul>
<li>现有应用在 Kubernetes 上运行，迁移到 <strong>Amazon EKS</strong> 可以保持相同的 Kubernetes 管理方式，降低迁移成本和运营开销。</li>
<li>迁移到 ECS 或 EC2 或 Lambda 可能需要重构应用或调整部署方式，增加运营开销。</li>
</ul>
</li>
</ol>
<p><br>815 在线游戏公司平台部署在<strong>多个 AWS 区域</strong>的 <strong>NLB</strong> 后面的 EC2 实例上。</p>
<ul>
<li>NLB 可以通过互联网将请求路由到目标。</li>
<li>目标：<strong>减少全球客户群的端到端加载时间</strong>（改善延迟）。</li>
</ul>
<p><strong>选项：</strong><br>A. 每个区域创建 <strong>ALB</strong> 替换 NLB，将 EC2 注册为 ALB 的目标 → 这只是在应用层负载均衡，不改善跨区域延迟。 ❌<br>B. 配置 <strong>Route 53</strong> 将权重相等的流量路由到每个区域的 NLB → 这是 DNS 负载均衡，不优化延迟，只做流量分配。 ❌<br>C. 在客户群多的其他区域创建额外 NLB 和 EC2 实例 → 增加区域可以降低部分用户延迟，但需要额外部署，且未提及智能路由。 ❌<br>D. <u>在 <strong>AWS Global Accelerator</strong> 中创建标准加速器，将现有 NLB 配置为目标端点 → Global Accelerator 使用 AWS 全球网络，提供静态入口 IP，并通过智能路由将用户流量引导到延迟最低的区域端点，从而减少端到端延迟</u>。 ✅</p>
<ol>
<li><strong>Global Accelerator 的作用</strong><ul>
<li>提供静态 Anycast IP 作为入口点。</li>
<li>自动将用户流量路由到<strong>延迟最低</strong>的 AWS 区域端点（基于实时网络性能）。</li>
<li>可跨多个区域负载均衡到 NLB、ALB、EC2 实例或弹性 IP。</li>
</ul>
</li>
</ol>
<p><br>816 公司原本有本地应用程序用 <strong>SFTP</strong> 从多个供应商收集财务数据。</p>
<ul>
<li>公司正在迁移到 AWS 云，并已创建一个新应用程序使用 <strong>Amazon S3 API</strong> 从供应商上传文件。</li>
<li>但是，一些供应商还在用<strong>遗留应用程序</strong>，这些应用<strong>不支持 S3 API</strong>，只支持 <strong>SFTP</strong>。</li>
<li>这些供应商希望继续使用 SFTP 上传数据。</li>
<li>公司希望为这些供应商的需求提供<strong>托管服务</strong>。</li>
<li>要求：<strong>最少的运营开销</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建 <strong>AWS DMS</strong> 实例，将供应商的数据从遗留存储复制到 S3，给供应商提供 DMS 实例凭证。 ❌（DMS 用于数据库迁移，不是 SFTP 接收）<br>B. <u>为使用遗留应用程序的供应商创建一个 <strong>AWS Transfer Family</strong> 端点。 ✅</u><br>C. 配置 <strong>Amazon EC2 实例</strong>运行 SFTP 服务器，指导供应商使用该 SFTP 服务器上传。 ❌（需要自己管理 EC2、SFTP 服务、安全、高可用等，运营开销大）<br>D. 为使用遗留应用程序将文件上传到 <strong>SMB 文件共享</strong> 的供应商配置 <strong>Amazon S3 文件网关</strong>。 ❌（SMB 不是 SFTP）</p>
<p><strong>WS Transfer Family</strong> 是 AWS 托管的文件传输服务，支持 <strong>SFTP、FTPS、FTP</strong> 协议。<br>它可以直接将上传的文件存储到 <strong>Amazon S3</strong>，无需自建服务器。</p>
<p><br>817 营销团队有过去五年的 PDF 格式新闻报道。</p>
<ul>
<li>需要提取新闻报道的<strong>内容见解和情感倾向</strong>。</li>
<li>解决方案<strong>必须使用 Amazon Textract</strong> 来处理新闻报道（Textract 用于从 PDF 中提取文本）。</li>
<li>要求：<strong>最少的运营开销</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 将提取的见解提供给 <strong>Amazon Athena</strong> 进行分析，将提取的见解和分析结果存储在 <strong>Amazon S3</strong>。<br>B. 将提取的见解存储在 <strong>Amazon DynamoDB</strong> 表中，使用 <strong>Amazon SageMaker</strong> 构建情感模型。<br>C. <u>将提取的见解提供给 <strong>Amazon Comprehend</strong> 进行分析，将分析结果保存到 <strong>Amazon S3</strong>。</u><br>D. 将提取的见解存储在 <strong>Amazon S3</strong>，使用 <strong>Amazon QuickSight</strong> 进行可视化和分析。</p>
<p><strong>Amazon Comprehend</strong> 是 AWS 托管的 NLP 服务，提供情感分析、实体识别、关键短语提取等功能，无需训练模型，完全托管，运营开销最小。</p>
<p><br>818 应用程序运行在<strong>多可用区的 EC2 实例</strong>上。</p>
<ul>
<li>应用程序需要从<strong>第三方应用程序嵌入实时数据</strong>（ingest real-time data）。</li>
<li>需要将嵌入的<strong>原始数据存储在 Amazon S3</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>创建 <strong>Amazon Kinesis Data Streams</strong> 用于数据嵌入，创建 <strong>Kinesis Data Firehose</strong> 传输流消费数据流，指定 S3 作为目的地。</u><br>B. 在 <strong>AWS DMS</strong> 中创建迁移任务，指定 EC2 实例作为源端点（复制实例？），S3 作为目标端点，迁移类型设为迁移现有数据并复制持续变化的数据。<br>C. 在 EC2 实例上创建 <strong>AWS DataSync 代理</strong>，配置 DataSync 任务将数据从 EC2 传输到 S3。<br>D. 创建 <strong>AWS Direct Connect</strong> 连接用于数据提取，创建 Kinesis Data Firehose 接收来自应用程序的 PUT 操作，指定 S3 作为目的地。</p>
<ul>
<li><strong>Kinesis Data Streams</strong> 可以实时收集和存储数据流，应用程序（或第三方应用）将数据推送到 Kinesis 数据流。</li>
<li><strong>Kinesis Data Firehose</strong> 可以从数据流读取数据，并自动传送到 S3（以及其他目的地），支持实时或近实时存储。</li>
</ul>
<p><br>819 应用程序接收来自多个数据源的数据，大小不一，目前最大 <strong>700 KB</strong>，但会随时间增长（可能超过 DynamoDB 单项目限制 400 KB）。</p>
<ul>
<li>决定使用 <strong>Amazon DynamoDB</strong> 作为主数据库。</li>
<li>需要能<strong>处理大数据量</strong>（大项目）的解决方案。</li>
<li>要求：<strong>最具运营效率</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建 Lambda 函数过滤超过 DynamoDB 项目大小限制的数据，将较大的数据存储在 <strong>Amazon DocumentDB</strong>。<br>B. <u>将大型数据作为对象存储在 <strong>Amazon S3</strong>，在 DynamoDB 表中创建一个属性指向数据的 S3 URL。</u><br>C. 将所有传入的大型数据拆分为具有相同分区键的项目集合，通过 <strong>BatchWriteItem</strong> 写入 DynamoDB。<br>D. 创建 Lambda 函数，在大型对象写入 DynamoDB 时用 <strong>gzip 压缩</strong>。</p>
<ul>
<li>大文件存 S3（低成本、无限大小）。</li>
<li>DynamoDB 存元数据和 S3 对象的引用（URL）。</li>
<li>查询时先从 DynamoDB 获取元数据，再按需从 S3 获取大对象。</li>
</ul>
<p><br>820 遗留应用程序从本地迁移到 AWS。</p>
<ul>
<li>应用依赖<strong>数百个定时任务</strong>，每天在不同重复时间表运行，运行时长 <strong>1 到 20 分钟</strong>。</li>
<li>希望在 AWS 上调度和运行定时任务，<strong>尽量减少代码重构</strong>。</li>
<li>必须支持<strong>根据未来的事件来运行定时任务</strong>（即可以根据事件触发，不完全是固定时间）。</li>
</ul>
<p><strong>选项：</strong><br>A. 为定时任务创建容器镜像，使用 <strong>EventBridge Scheduler</strong> 创建重复计划，将定时任务作为 <strong>Lambda 函数</strong>运行。<br>B. 为定时任务创建容器镜像，使用 <strong>Amazon ECS 上的 AWS Batch</strong> 配合调度策略运行。<br>C. <u>为定时任务创建容器镜像，使用 <strong>EventBridge Scheduler</strong> 创建重复计划，运行定时任务在 <strong>Amazon ECS</strong> 上。</u><br>D. 为定时任务创建容器镜像，在 <strong>AWS Step Functions</strong> 中创建工作流，使用等待状态在指定时间运行，使用 RunTask 操作在 <strong>AWS Fargate</strong> 上运行定时任务。</p>
<p> EventBridge Scheduler + ECS（或 Fargate）满足调度和事件触发需求，且运行时间不受限制。</p>
<p><br>821 公司使用 <strong>Salesforce</strong>。</p>
<ul>
<li>需要将 Salesforce 中的现有数据和持续变化的数据加载到 <strong>Amazon Redshift</strong> 进行分析。</li>
<li>要求：<strong>数据不能通过公共互联网传输</strong>（私有连接）。</li>
<li>要求：<strong>最少的开发工作量</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 从 VPC 建立到 Salesforce 的 <strong>VPN 连接</strong>，使用 <strong>AWS Glue DataBrew</strong> 传输数据。<br>B. 从 VPC 建立 <strong>AWS Direct Connect</strong> 到 Salesforce，使用 <strong>AWS Glue DataBrew</strong> 传输数据。<br>C. <u>在 VPC 中创建连接到 Salesforce 的 <strong>AWS PrivateLink</strong> 连接，使用 <strong>Amazon AppFlow</strong> 传输数据。</u><br>D. 创建与 Salesforce 的 <strong>VPC 对等连接</strong>，使用 <strong>Amazon AppFlow</strong> 传输数据。</p>
<ul>
<li><p>Amazon AppFlow 是低代码&#x2F;无代码的完全托管服务，只需在控制台配置源（Salesforce）和目标（Redshift）及映射字段即可。</p>
</li>
<li><p>Glue DataBrew 也可以做数据转换，但需要更多配置和开发工作来连接 Salesforce 并实现增量同步。</p>
</li>
<li><p>VPN 或 Direct Connect 也可实现私有连接，但设置更复杂，且不一定与 Salesforce 直接兼容（Salesforce 提供特定私有连接方案）。</p>
</li>
</ul>
<p><br>822 应用程序运行在 <strong>EC2 Linux 实例</strong>（跨多 AZ 的 Auto Scaling 组）。</p>
<ul>
<li>应用程序将数据存储在 <strong>Amazon EFS（Standard-IA）</strong> 文件系统中。</li>
<li>应用程序为文件建立索引，索引存储在 <strong>Amazon RDS</strong>。</li>
<li>目标：通过变更应用程序和服务来<strong>优化存储成本</strong>。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>创建使用 <strong>S3 智能分层</strong> 生命周期策略的 S3 存储桶，将所有文件复制到 S3，更新应用程序使用 <strong>S3 API</strong> 存储和检索文件。</u><br>B. 部署 <strong>Amazon FSx for Windows File Server</strong>，更新应用程序使用 <strong>CIFS</strong> 协议（但原应用是 Linux，CIFS 适合 Windows）。 ❌<br>C. 部署 <strong>Amazon FSx for OpenZFS</strong>，更新应用程序使用新挂载点（还是文件系统，可能成本不比 EFS-IA 低）。 ❌<br>D. 创建使用 <strong>S3 Glacier 灵活检索</strong> 的 S3 存储桶，复制文件到 S3，更新应用使用 S3 API 并以标准检索方式访问（Glacier 不适合频繁访问）。</p>
<ul>
<li>S3 智能分层是低成本、自动优化的对象存储方案，适合存储大量文件（相比 EFS 更便宜）。</li>
<li>虽然需要更新应用使用 S3 API，但一次修改后可长期节省存储成本。</li>
</ul>
<p><br>823 医疗手术机器人方案，需要在 AWS 云中部署一个<strong>公共负载均衡器</strong>。</p>
<ul>
<li>负载均衡器必须能够<strong>根据查询字符串（query string）将流量路由到不同的目标组</strong>。</li>
<li>流量必须<strong>加密</strong>（即 HTTPS&#x2F;TLS）。</li>
</ul>
<p><strong>选项：</strong><br>A. 使用<strong>网络负载均衡器（NLB）</strong>，附加 AWS Certificate Manager（ACM）证书，使用<strong>基于查询参数的路由</strong>。<br>B. 使用<strong>网关负载均衡器（GWLB）</strong>，在 IAM 中导入生成的证书并附加到负载均衡器，使用<strong>基于 HTTP 路径的路由</strong>。<br>C. <u>使用<strong>应用程序负载均衡器（ALB）</strong>，附加 ACM 证书，使用<strong>基于查询参数的路由</strong>。</u><br>D. 使用<strong>网络负载均衡器（NLB）</strong>，在 IAM 中导入证书并附加到负载均衡器，使用<strong>基于查询参数的路由</strong>。</p>
<ol>
<li><strong>查询字符串路由能力</strong><ul>
<li>只有 <strong>应用负载均衡器（ALB）</strong> 支持基于 HTTP 头部、路径、查询字符串等内容的路由规则。</li>
<li><strong>网络负载均衡器（NLB）</strong> 和 <strong>网关负载均衡器（GWLB）</strong> 工作在 TCP&#x2F;IP 层（第4层），无法查看 HTTP 查询字符串。</li>
</ul>
</li>
<li><strong>加密（HTTPS）</strong><ul>
<li>ALB 支持 HTTPS 监听器，并可从 ACM 自动获取和管理 TLS 证书。</li>
<li>NLB 虽然支持 TLS 终止（通过 TLS 监听器），但查询字符串路由不可能（因为 NLB 不解析 HTTP）</li>
</ul>
</li>
</ol>
<p><br>824 应用程序在<strong>单个 EC2 实例</strong>上运行，使用<strong>同一 EC2 实例上运行的 MySQL 数据库</strong>。</p>
<ul>
<li>需要<strong>高可用</strong>且<strong>自动扩展</strong>的解决方案，以应对增长流量。</li>
</ul>
<p><strong>选项：</strong><br>A. 将应用程序部署到 <strong>ALB 后 Auto Scaling 组</strong>中的 EC2 实例，创建一个具有多个兼容 MySQL 节点的 <strong>Amazon Redshift</strong> 集群。 ❌（Redshift 是数据仓库，不是事务型 MySQL 替代）<br>B. 将应用程序部署到 <strong>ALB 后目标组</strong>的 EC2 实例，创建具有多个实例的 <strong>Amazon RDS for MySQL 集群</strong>。 ✅<br>C. <u>将应用程序部署到 <strong>ALB 后 Auto Scaling 组</strong>的 EC2 实例，数据库层使用 <strong>Amazon Aurora Serverless MySQL 集群</strong></u>。 ✅<br>D. 将应用程序部署到 <strong>ALB 后目标组</strong>的 EC2 实例，创建使用 <strong>MySQL 连接器的 Amazon ElastiCache for Redis</strong> 集群。 ❌（Redis 是缓存，不是主数据库）</p>
<p>Aurora Serverless 在数据库层提供了自动伸缩（计算和存储），而 RDS MySQL 需要手动或脚本调整实例大小。<br>另外，Aurora Serverless 内置高可用（跨 AZ），满足高可用要求</p>
<p><br>825 数据迁移到 Amazon S3 存储桶。</p>
<ul>
<li>数据静态存放时必须加密。</li>
<li>加密密钥必须<strong>每年自动轮换</strong>。</li>
<li>要求：<strong>最少的运营开销</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 使用 <strong>SSE-S3（Amazon S3 托管密钥）</strong>，使用 SSE-S3 加密密钥的<strong>内置密钥轮换功能</strong>。<br><u>B. 创建一个 <strong>AWS KMS 客户管理密钥（CMK）</strong>，<strong>启用自动密钥轮换</strong>，设置 S3 存储桶默认加密使用该 CMK，然后迁移数据。</u><br>C. 创建 <strong>AWS KMS 客户管理密钥（CMK）</strong>，设置 S3 默认加密使用该 CMK，迁移数据，<strong>每年手动轮换密钥</strong>。<br>D. 使用客户密钥材料加密数据，迁移到 S3，创建无密钥材料的 KMS 密钥，导入客户密钥材料，启用自动密钥轮换。</p>
<p><br>826 公司正在将应用程序从本地 <strong>Microsoft Active Directory（AD）</strong> 迁移到 AWS。</p>
<ul>
<li>应用程序部署在<strong>多个 AWS 账户</strong>中，使用 <strong>AWS Organizations</strong> 集中管理。</li>
<li>安全团队需要一个能在<strong>所有 AWS 账户中使用的单点登录（SSO）</strong> 解决方案。</li>
<li>公司必须<strong>继续管理本地 AD 中的用户和组</strong>（即身份源保持本地）。</li>
</ul>
<p><strong>选项：</strong><br>A. 在 <strong>AWS Directory Service for Microsoft AD</strong>（托管 AD）中创建企业版 AD，将该 AD 配置为 <strong>IAM Identity Center</strong> 的身份源。<br>B. <u>启用 <strong>AWS IAM Identity Center</strong>，配置双向林信任关系连接公司的自管理 AD（通过 AWS Directory Service）与 IAM Identity Center。</u><br>C. 使用 <strong>AWS Directory Service</strong>，与公司的自管理 AD 建立双向信任关系。<br>D. 在 <strong>Amazon EC2</strong> 上部署身份提供商（IdP），将该 IdP 作为身份源链接到 IAM Identity Center。</p>
<ol>
<li><strong>单点登录需求</strong><br>需要在多个 AWS 账户之间实现 SSO，<strong>IAM Identity Center（原 AWS SSO）</strong> 是 AWS 提供的多账户 SSO 服务，可集中管理访问权限。</li>
<li><strong>身份源保持本地 AD</strong><br>需要将本地 AD 作为 IAM Identity Center 的身份源，而不是在 AWS 中重建用户目录。<br>AWS 提供 <strong>AD Connector</strong> 或 <strong>双向信任</strong> 方式将本地 AD 与 AWS 服务集成</li>
</ol>
<p><br>827 应用程序部署在 <strong>Amazon Aurora PostgreSQL Serverless v2</strong> 集群上。</p>
<ul>
<li>将接收<strong>大量流量</strong>，随着负载增加，希望<strong>优化集群的存储性能</strong>。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 配置集群使用 <strong>Aurora 标准存储配置</strong>（Standard storage configuration）。<br>B. 将集群存储类型配置为 <strong>预配置 IOPS</strong>（Provisioned IOPS）。<br>C. 将集群存储类型配置为 <strong>通用型</strong>（General Purpose）。<br>D. <u>配置集群使用 <strong>Aurora I&#x2F;O 优化存储配置</strong>（I&#x2F;O-Optimized storage configuration）</u></p>
<ol>
<li><strong>Aurora 存储类型</strong><br>Aurora 提供两种存储配置：<ul>
<li><strong>标准存储配置</strong>（原来的默认）：存储与 I&#x2F;O 费用分开计费，按实际 I&#x2F;O 次数收费。</li>
<li><strong>I&#x2F;O 优化存储配置</strong>（较新推出）：存储费用稍高，但<strong>包含 I&#x2F;O 费用</strong>，适合 I&#x2F;O 密集型工作负载。</li>
</ul>
</li>
<li><strong>大量流量与存储性能优化</strong><br>大量流量可能导致高 I&#x2F;O 操作，如果使用标准存储配置，I&#x2F;O 费用可能很高。<br>I&#x2F;O 优化存储配置<strong>将 I&#x2F;O 成本包含在存储价格中</strong>，可预测成本且在高 I&#x2F;O 场景下更经济。</li>
</ol>
<p><br>828 一家金融服务公司使用 AWS Organizations 管理数百个账户，需要满足 NIST 和 PCI DSS 的安全标准。第三方审计需要证据证明控制措施已实施并正常运行。公司需要监控所有账户中控制措施的当前状态。要求选出能够满足这些要求的解决方案。</p>
<p><strong>选项复述</strong>：</p>
<p><strong>A</strong>：指定一个账户作为 Amazon Inspector 委托管理员账户，集成组织并扫描所有账户中的资源，启用针对 NIST 和 PCI DSS 的 Inspector 行业标准。</p>
<p><strong>B</strong>：指定一个账户作为 Amazon GuardDuty 委托管理员账户，启用 GuardDuty 保护所有成员账户，启用适用于 NIST 和 PCI DSS 的 GuardDuty 行业标准。</p>
<p><strong>C</strong>：在组织管理账户中配置 AWS CloudTrail 组织跟踪，指定一个合规账户，并在其中为 NIST 和 PCI DSS 启用 CloudTrail 安全标准。</p>
<p><strong>D</strong>：<u>指定一个账户作为 AWS Security Hub 委托管理员账户，为所有成员账户启用 Security Hub，启用适用于 NIST 和 PCI DSS 的 Security Hub 标准。</u></p>
<ul>
<li><strong>A（Inspector）</strong>：主要用于漏洞评估，不提供全面的控制措施状态监控。</li>
<li><strong>B（GuardDuty）</strong>：专注于威胁检测，不是用于整体合规性状态监控。</li>
<li><strong>C（CloudTrail）</strong>：用于日志记录，不直接提供控制措施的状态评估或行业标准合规</li>
</ul>
<p><br>829 公司使用 S3 存储大量数据，<strong>多个团队和数百个应用程序随机访问</strong>。</p>
<ul>
<li>要求：<ol>
<li><strong>降低 S3 存储成本</strong></li>
<li><strong>为频繁访问的对象提供即时可用性</strong>（意味着低延迟）</li>
<li><strong>最具运营效率</strong>（也就是尽量自动化，不要复杂的手动或频繁转换操作）</li>
</ol>
</li>
</ul>
<p><strong>选项分析</strong>：</p>
<ul>
<li><u><strong>A. 创建一个 S3 生命周期规则，将对象转换到 S3 智能分层存储类别</strong></u><br>S3 智能分层（Intelligent-Tiering）有频繁访问和不频繁访问两个层，并且会自动根据访问模式在层之间移动对象，不需要人工干预。对随机访问模式来说，它可以保证频繁访问的对象有标准存储的访问延迟（即时可用性），同时对不常访问的自动降层节省成本，管理简单，符合“运营效率”的要求。</li>
<li><strong>B. 将对象存储在 Amazon S3 Glacier 中。使用 S3 Select 为应用程序提供数据访问权限</strong><br>Glacier 的存储类别（包括 Glacier Instant Retrieval）虽然也可以用于存档检索，但题目要求“即时可用性”，但 B 选项只说存储在 Glacier（可能是标准 Glacier 或 Flexible Retrieval），这需要数小时检索，不能满足即时可用。S3 Select 只是检索数据的子集功能，不解决检索延迟问题。不符合要求。</li>
<li><strong>C. 使用来自 S3 存储类别分析的数据创建 S3 生命周期规则，以自动将对象转换到 S3 标准 - 不常访问（S3 Standard-IA）存储类别</strong><br>只转向 Standard-IA 会降低存储成本，但 Standard-IA 有检索费用，并且如果对象仍被频繁访问，费用反而可能更高。而且它不会自动对频繁访问的对象移回标准层，这会导致频繁访问的对象仍然在 IA 中，费用高且不最优。同时，它需要依赖存储类别分析手动设置规则，不如智能分层自动。</li>
<li><strong>D. 将对象转换到 S3 Standard-IA。创建一个 Lambda 函数，当应用程序访问对象时，将对象转换到 S3 标准存储类别</strong><br>这个方案复杂且运营效率低，每次访问都要触发 Lambda 并可能转换存储类别（每次转换也有 API 成本），延迟也可能高，不满足“最具运营效率”的要求。</li>
</ul>
<p><br>830 一家公司拥有 5 TB 的数据集，包含 100 万个用户资料和 1000 万个连接（多对多关系）。需要一种<strong>性能高效</strong>的方法来查找最多 <strong>五级的共同连接</strong>（例如，查找两个用户之间最多经过 5 条边的共同关联路径）。</p>
<p><strong>选项复述</strong><br>A. 使用 Amazon S3 存储数据集，并用 Amazon Athena 执行 SQL 连接查询来查找关联。<br>B<u>. 使用 Amazon Neptune 存储为顶点和边的图结构，通过图查询查找关联。</u><br>C. 使用 Amazon S3 存储数据集，并用 Amazon QuickSight 来可视化连接。<br>D. 使用 Amazon RDS 存储多表形式的数据集，并执行 SQL JOIN 查询来查找关联。</p>
<ul>
<li><strong>A（Athena + S3）</strong>：<br>Athena 适合在 S3 上运行 SQL 查询，但它是为分析型查询设计的，不适合复杂的多级 JOIN 图遍历查询，性能会非常差，且成本高（扫描量大）。</li>
<li><strong>B（Neptune）</strong>：<br>Neptune 是 AWS 专门托管的<strong>图数据库</strong>，专门为存储顶点和边、执行高效的图遍历查询（如多跳查询、最短路径、共同连接）设计。这正是题目描述的“用户与连接的多对多关系”场景，并且 Neptune 支持 Gremlin 或 SPARQL 查询，可以高效查找 5 级连接。</li>
<li><strong>C（QuickSight + S3）</strong>：<br>QuickSight 是可视化工具，不能高效执行图遍历查询，不适合用来“查找”共同连接（只能展示已有结果）。</li>
<li><strong>D（RDS + SQL JOIN）</strong>：<br>RDS 是关系型数据库，虽然可以存储用户和连接表，但进行 5 级 JOIN 在大数据量下性能很差，维护复杂，不是“性能高效”的解决方案。</li>
</ul>
<p><br>831 一家公司需要在本地环境与 AWS 之间建立<strong>安全连接</strong>，要求是：</p>
<ul>
<li>不需要高带宽</li>
<li>仅处理少量流量</li>
<li>能够快速搭建</li>
<li><strong>最具成本效益</strong></li>
</ul>
<p><strong>选项复述</strong><br>A. 部署客户端 VPN<br>B. 实施 AWS Direct Connect<br>C. 在 Amazon EC2 上部署堡垒机<br>D. <u>建立 AWS 站点到站点 VPN 连接</u></p>
<ul>
<li><p>堡垒机（Bastion Host）用于安全访问私有 EC2 实例，并不是用于本地网络与 AWS 整体连接的方案，不能替代站点间 VPN。</p>
</li>
<li><p><strong>客户端 VPN</strong>通常指 AWS Client VPN（基于 OpenVPN），用于单个客户端连接到 VPC。</p>
</li>
</ul>
<p><strong>AWS Direct Connect</strong>需要物理线路安装，交付时间长</p>
<p><br>832 一家公司要将本地 SFTP 文件传输解决方案迁移到 AWS，利用 Amazon S3 降低成本，同时要求员工继续使用本地 Microsoft Active Directory（AD）凭据访问。公司希望保留现有身份验证和文件访问机制，并要求以最少运营开销满足需求。</p>
<p><strong>选项复述</strong><br>A. 配置 S3 文件网关，在文件网关上创建 SMB 文件共享，使用现有 AD 进行身份验证。<br>B. 配置一个包含 EC2 实例的自动扩展组来运行 SFTP 解决方案，根据 CPU 使用率扩容。<br>C. <u>创建一个带有 SFTP 端点的 AWS Transfer Family 服务器，选择 AWS Directory Service 作为身份标识，使用 AD 连接器连接本地 AD。</u><br>D. 创建一个 AWS Transfer Family SFTP 端点，将其配置为使用 AWS Directory Service 选项作为身份提供商，连接到现有 AD</p>
<ul>
<li>AWS Transfer Family 是全托管 SFTP 服务，原生集成 S3 作为后端存储，完美符合“用 S3 优化成本”和“支持 SFTP”。</li>
</ul>
<p><br>833 公司设计事件驱动的订单处理系统，订单创建后需经过多个独立的验证步骤，每个步骤由一个具有幂等性的 Lambda 函数执行，且仅需要订单事件的一部分信息。要求如下：</p>
<ol>
<li><strong>每个 Lambda 函数只能访问它所需的那部分订单信息</strong>（最小权限访问数据层面）。</li>
<li><strong>组件松耦合</strong>，以适应未来变化。</li>
</ol>
<p><strong>选项复述</strong><br>A. 为每个验证步骤创建独立的 SQS 队列，新增一个 Lambda 函数转换订单数据格式并推送到对应 SQS 队列，验证 Lambda 各自订阅自己的队列。<br>B. 创建一个 SNS 主题，所有验证 Lambda 订阅此主题，使用消息过滤仅向每个 Lambda 发送所需数据。<br>C. <u>创建一个 EventBridge 事件总线，为每个验证步骤创建事件规则，配置输入转换器，仅将所需数据发送给对应的 Lambda。</u><br>D. 创建一个 SQS 队列，由一个 Lambda 订阅并转换订单数据格式，然后在单独的线程中同步并行调用其他验证 Lambda。</p>
<ul>
<li>EventBridge 支持为每个规则配置 <strong>输入转换器（Input Transformer）</strong>，可以从原始事件中提取、转换数据，仅将需要的字段发送给目标 Lambda。</li>
</ul>
<p><br>834 公司正在迁移一个三层应用到 AWS，该应用使用 MySQL 数据库。过去用户在工作时间创建新条目时性能不佳，原因是用户同时生成了多种实时报告（报告查询影响了写入性能）。</p>
<p>迁移到 AWS 后，需要选择一种解决方案来提高性能。</p>
<p><strong>选项复述</strong><br>A. 将数据导入 DynamoDB 并重构应用，用 DynamoDB 生成报告。<br>B. 在计算优化的 EC2 实例上自建数据库，确保资源比本地多。<br>C. <u>创建带多个只读副本的 Amazon Aurora MySQL 多可用区数据库集群，配置应用使用读取端点来处理报告。</u><br>D. 创建 Amazon Aurora MySQL 多可用区数据库集群，配置应用使用集群的备份实例作为报表端点。</p>
<p><br>835 公司通过 Direct Connect 将安全的本地网络扩展到 AWS 云，本地网络没有直接的互联网访问权限。<br>本地网络上运行的应用程序需要访问一个 Amazon S3 存储桶。<br>要求用最具成本效益的方式满足需求。</p>
<p><strong>选项复述</strong><br>A. <u>创建一个公共虚拟接口（VIF），通过公共 VIF 路由 AWS 流量。</u><br>B. 创建一个 VPC 和 NAT 网关，将本地网络的 AWS 流量路由到 NAT 网关。<br>C. 创建一个 VPC 和 Amazon S3 接口端点，将本地网络的 AWS 流量路由到 S3 接口端点。<br>D. 在本地网络和 Direct Connect 之间创建一个 VPC 对等连接，通过该对等连接路由 AWS 流量。</p>
<ul>
<li><strong>公共 VIF（A）</strong>：直接访问 S3，无需 VPC，无需 NAT 网关或接口端点费用，只需 Direct Connect 端口费和少量数据传输费。</li>
<li><strong>S3 接口端点（C）</strong>：虽然也能实现且流量不走公网，但需要创建 VPC 并附加接口端点，有接口端点小时费，相比公共 VIF 成本更高。</li>
</ul>
<p>NAT 网关是让私有子网访问互联网，但本地网络并非 VPC 内子网，并且 NAT 网关需要通过 VPC 路由并通过互联网网关访问 S3（公共互联网），但本地无互联网访问</p>
<ul>
<li>S3 接口端点（VPC 终端节点）允许 VPC 内资源通过 AWS 内部网络访问 S3，但本地网络不在该 VPC 内。</li>
</ul>
<p>VPC 对等连接用于两个 VPC 之间的连接，与本地网络到 AWS 的访问无关</p>
<p><br>836 公司网站运行在单个区域中的 EC2 自动扩展组，没有数据库。<br>工程团队已在第二个区域部署了网站副本，现在要实现两个区域之间分配流量，并且：</p>
<ol>
<li>满足增长和灾难恢复需求</li>
<li><strong>不能从状态不健康的区域处理流量</strong>（即健康检查失败的区域应停止接收流量）<br>需要选择相应的策略或资源。</li>
</ol>
<p><strong>选项复述</strong><br>A. Amazon Route 53 简单路由策略<br>B. <u>Amazon Route 53 多值应答路由策略</u><br>C. 一个区域中的应用负载均衡器（ALB），其目标组包含两个区域的 EC2 实例 ID<br>D. 一个区域中的应用负载均衡器（ALB），其目标组包含两个区域的 EC2 实例 IP 地址</p>
<ul>
<li>多值应答策略可以返回多个资源记录（例如两个区域的负载均衡器端点或 IP），并且 <strong>可以配置健康检查</strong>，当某个端点的健康检查失败时，Route 53 将从应答中移除该记录。</li>
</ul>
<p>简单路由只是将域名解析到一组 IP&#x2F;主机名，没有健康检查，不会自动停用不健康的区域，不满足需求</p>
<ul>
<li>ALB 目标组不能直接包含另一区域的实例 ID 或 IP 并正常路由（网络不通，且 ALB 设计不支持跨区域目标组）。</li>
<li>即使网络打通，ALB 也无法感知另一区域实例的健康状态（除非跨区 VPC 对等 + 配置目标为 IP），但这不是标准跨区域容灾方案，且维护复杂，不符合题目简洁要求。</li>
</ul>
<p><br>837 公司在 EBS 支持的 EC2 实例上运行应用（使用最新版 Amazon Linux），员工在存储和检索 ≥25 GB 的文件时遇到可用性问题。需求如下：</p>
<ol>
<li>无需在 EC2 实例之间传输文件。</li>
<li>文件必须能被多个 EC2 实例访问（并发访问）。</li>
<li>文件必须在多个可用区中可用（跨 AZ 高可用）。</li>
<li>需要解决大文件存储&#x2F;检索的可用性问题。</li>
</ol>
<p><strong>选项复述</strong><br>A. 将所有文件迁移到 Amazon S3，让员工从 S3 访问文件。<br>B. 对 EBS 卷做快照，并挂载为 EBS 卷到多个 EC2 实例，让员工从这些实例访问文件。<br>C. <u>在所有 EC2 实例上挂载 Amazon EFS 文件系统，让员工从 EC2 实例访问文件</u>。<br>D. 从 EC2 实例创建 AMI，通过 AMI 配置使用实例存储的新 EC2 实例，让员工从这些实例访问文件。</p>
<ul>
<li>EFS 是完全托管、跨 AZ 的 NFS 共享文件系统，可以被同区域多个 AZ 的 EC2 实例同时挂载访问。</li>
<li>支持 NFS 协议，应用无需修改即可像访问本地文件系统一样访问文件</li>
</ul>
<p><br>838 公司 EC2 上运行高敏感应用，后端为 Amazon RDS 数据库。<br>合规要求：<strong>所有个人身份信息（PII）在静态时必须加密</strong>。<br>要求以<strong>最少的基础设施变更</strong>满足该要求。</p>
<p><strong>选项复述</strong><br>A. 部署 AWS Certificate Manager 生成证书，用证书加密数据库卷。<br>B. 部署 AWS CloudHSM，生成加密密钥并用它们加密数据库卷。<br>C. 使用 AWS KMS 密钥配置 SSL 加密，以加密数据库卷。<br>D<u>. 使用 AWS KMS 配置 Amazon EBS 加密和 Amazon RDS 加密</u></p>
<ul>
<li><p>EBS 加密可对 EC2 实例的存储卷进行静态加密（使用 KMS 密钥）。</p>
</li>
<li><p>RDS 加密可在创建数据库实例时启用，对底层存储、快照、备份等静态加密（使用 KMS 密钥）。</p>
</li>
<li><p>SSL 加密是传输加密，不是静态加密，混淆了概念。</p>
</li>
<li><p>CloudHSM 是专用硬件安全模块，可用于生成和管理密钥，可以与 EBS 和 RDS 加密集成（通过 KMS 集成）。</p>
</li>
</ul>
<p><br>839 公司在 VPC 的私有子网中运行 Lambda 函数，私有子网通过 EC2 NAT 实例访问互联网（默认路由指向 NAT 实例）。<br>Lambda 处理数据后需要将结果对象保存到 Amazon S3。<br><strong>问题</strong>：NAT 实例网络流量饱和，导致 Lambda 上传到 S3 时<strong>间歇性超时</strong>。<br><strong>要求</strong>：在不经过互联网的情况下访问 S3。<br>需要选出解决方案。</p>
<p><strong>选项复述</strong><br>A. 用 AWS 托管的 NAT 网关替换 EC2 NAT 实例。<br>B. 将 EC2 NAT 实例扩容为网络优化型实例。<br>C. <u>在 VPC 中为 Amazon S3 配置网关终端节点，并更新子网路由表。</u><br>D. 配置中转网关，将中转网关附件放置在运行 Lambda 的私有子网中。</p>
<p>Lambda 在私有子网中，默认去 S3 需要经过 NAT 实例访问互联网，NAT 实例饱和导致超时。<br>题目要求 <strong>不经过互联网访问 S3</strong>，意味着要通过 AWS 内部网络（VPC 终端节点）访问 S3，避免 NAT 流量。</p>
<ul>
<li><strong>网关终端节点</strong> 允许 VPC 内资源通过 AWS 内部网络直接访问 S3，无需经过 NAT、互联网网关或 NAT 网关。</li>
<li>创建后，只需在子网路由表中添加一条指向该终端节点的 S3 前缀路由（pl-xxxx），则去往 S3 的流量会走 AWS 内部网络，不经过 NAT，完全满足“不经过互联网访问 S3”的需求，同时解决了 NAT 实例饱和问题。</li>
</ul>
<p>NAT 网关是 AWS 托管服务，比自管理 NAT 实例更稳定、带宽更高，但仍是通过互联网访问 S3</p>
<p><br>840 新闻公司的广播系统托管在 AWS 上，全球各地的记者使用手机上的软件通过 RTMP 协议 发送直播流到该系统。<br>要求：</p>
<p>能发送最高质量的流（意味着高带宽、低延迟、稳定传输）。</p>
<p>提供加速的 TCP 连接 回到广播系统。</p>
<p>需要选出满足要求的服务。</p>
<p>选项复述<br>A. Amazon CloudFront<br>B. <u>AWS Global Accelerator</u><br>C. AWS Client VPN<br>D. Amazon EC2 实例和 AWS 弹性 IP 地址</p>
<p><br>841 公司使用 EC2 和 EBS 运行自管理数据库，共有 <strong>350 TB</strong> 数据分布在 EBS 卷中。<br>当前备份策略：<strong>每天创建 EBS 快照</strong>，保留 <strong>1 个月</strong>，每日变化率为 5%。</p>
<p><strong>新合规要求</strong>：每月快照需要保存 <strong>7 年</strong>。<br>目标：以 <strong>最具成本效益</strong> 且 <strong>管理负担最小</strong> 的方式满足该要求。</p>
<p><strong>选项复述</strong><br>A. <u>将每日快照在 EBS 快照标准层中保留 1 个月，将月度快照复制到 Amazon S3 Glacier Deep Archive 并保留 7 年。</u><br>B. 继续当前 EBS 快照策略，并添加新策略将月度快照移至 Amazon EBS 快照归档层，保留 7 年。<br>C. 将每日快照在标准层中保留 1 个月，将月度快照在标准层中保留 7 年，使用增量快照。<br>D. 将每日快照保存在标准层，使用 EBS 直接 API 每月对所有 EBS 卷做快照，并将快照存到 S3 低频访问层 7 年。</p>
<p>EBS 快照本身可以复制到 <strong>S3 Glacier Deep Archive</strong>（最便宜的存储层，适合 7 年保留），但 EBS 快照不能直接存到 Deep Archive，需要先通过 <strong>EBS Snapshot Archive</strong>（归档层）或 <strong>S3 Glacier</strong> 的集成</p>
<p><br>842 公司在多个 EC2 实例上运行应用，持久数据存储在 <strong>Amazon EFS</strong> 文件系统上。<br>需要将数据<strong>复制到另一个 AWS 区域</strong>，要求：</p>
<ol>
<li>通过 <strong>AWS 托管服务</strong> 解决方案</li>
<li><strong>最具成本效益</strong></li>
</ol>
<p><strong>选项复述</strong><br>A. 使用 EFS 到 EFS 备份解决方案将数据复制到另一个区域的 EFS 文件系统。<br>B. 运行夜间脚本将 EFS 数据复制到 S3 存储桶，然后在 S3 上启用跨区域复制（CRR）。<br>C. 在另一个区域创建 VPC，建立跨区域 VPC 对等连接，运行夜间 rsync 复制数据。<br>D<u>. 使用 AWS Backup 创建备份计划，每日备份 EFS 并复制到另一个区域</u>。</p>
<ul>
<li>AWS Backup 是全托管备份服务，支持 EFS 备份，并可配置<strong>跨区域复制</strong>（备份复制到目标区域）。</li>
</ul>
<p><br>843 电子商务公司正在将本地工作负载迁移到 AWS，工作负载包含：</p>
<ol>
<li>Web 应用程序</li>
<li>后端 Microsoft SQL Server 数据库</li>
</ol>
<p>要求：</p>
<ul>
<li>应对促销期间的大量客户（需可扩展性）</li>
<li>具备高可用性</li>
<li>以<strong>最少的管理开销</strong>满足要求</li>
</ul>
<p><strong>选项复述</strong><br>A. Web 应用迁移到两个可用区的两个 EC2 实例（在 ALB 后），数据库迁移到 RDS for SQL Server，在两个可用区设置只读副本。<br>B. Web 应用迁移到两个可用区的 Auto Scaling 组（在 ALB 后），数据库迁移到两个跨区域的 EC2 实例并做复制。<br>C. <u>Web 应用迁移到两个可用区的 Auto Scaling 组（在 ALB 后），数据库迁移到采用多可用区部署的 Amazon RDS。</u><br>D. Web 应用迁移到三个可用区的三个 EC2 实例（在 ALB 后），数据库迁移到三个可用区的三个 EC2 实例。</p>
<ul>
<li>Web 层 Auto Scaling 可以根据负载自动增减实例，满足可扩展性。</li>
<li>RDS 多可用区（Multi-AZ）为数据库提供同步复制和自动故障转移，实现高可用性，且是托管服务，管理开销小。</li>
</ul>
<p><br>844 公司有一个本地业务应用，每天生成数百个文件，存储在 <strong>SMB 文件共享</strong>上，并要求与应用程序服务器保持低延迟连接。<br>新政策要求所有生成的文件必须<strong>复制到 AWS</strong>。<br>现状：</p>
<ul>
<li>已经有到 AWS 的 VPN 连接</li>
<li>开发团队没有时间修改代码以将应用迁移到 AWS</li>
</ul>
<p>需要选择一种服务，允许应用程序将文件复制到 AWS。</p>
<p><strong>选项复述</strong><br>A. Amazon EFS<br>B. Amazon FSx for Windows File Server<br>C. AWS Snowball<br><u>D. AWS Storage Gateway</u></p>
<ul>
<li><strong>文件网关模式</strong>可以在本地作为 SMB 文件共享提供，应用直接以低延迟写入本地网关设备（物理或虚拟）。</li>
<li>Storage Gateway 会自动将文件异步上传到 Amazon S3，实现透明复制到 AWS，且应用无需任何修改。</li>
</ul>
<p><br>845 公司有 15 名员工，将入职日期存储在 Amazon DynamoDB 表中。<br>需要在每位员工的工作周年纪念日当天发送电子邮件。<br>要求：以最高的<strong>运营效率</strong>满足需求。</p>
<p><strong>选项复述</strong><br>A. 创建脚本扫描 DynamoDB 表，必要时用 Amazon SNS 发邮件，通过定时任务在 EC2 实例上每天运行。<br>B. 创建脚本扫描 DynamoDB 表，必要时用 Amazon SQS 发邮件，通过 cron 在 EC2 实例上每天运行。<br>C<u>. 创建 AWS Lambda 函数扫描 DynamoDB 表，必要时用 Amazon SNS 发邮件，安排为每天运行。</u><br>D. 创建 AWS Lambda 函数扫描 DynamoDB 表，必要时用 Amazon SQS 发邮件，安排为每天运行。</p>
<ul>
<li>C 用 SNS 发邮件：SNS 支持直接发送电子邮件（可通过订阅邮件终端或集成 SES），适合此场景。</li>
<li>D 用 SQS 发邮件：SQS 只是消息队列，不能直接发邮件，需要额外 Lambda 或服务消费队列再发邮件，增加架构复杂度，不必要。</li>
</ul>
<p><br>846 公司应用运行在 ELB 后的 Auto Scaling 组内的 EC2 实例上。<br>已知历史数据：每年某个假期期间<strong>流量会激增</strong>。<br>要求设计策略，<strong>主动增加容量</strong>，以将对用户性能的影响降至最低。</p>
<p><strong>选项复述</strong><br>A. 创建 CloudWatch 告警，当 CPU 利用率超过 90% 时扩展 EC2 实例。<br>B. <u>创建定期计划操作，在预期的需求高峰期之前扩大 Auto Scaling 组。</u><br>C. 在需求高峰期增加 Auto Scaling 组中 EC2 实例的最小和最大数量。<br>D. 配置 Amazon SNS 通知，当发生 autoscaling:EC2_INSTANCE_LAUNCH 事件时发送警报。</p>
<ul>
<li>Auto Scaling 组支持<strong>计划操作</strong>（scheduled actions），可以在特定时间调整期望容量（Desired Capacity），提前准备好资源。</li>
</ul>
<p><br>847 公司使用 Amazon RDS for PostgreSQL 数据库，需要为这些数据库<strong>实施密码轮换</strong>。<br>要求以<strong>最小的运营开销</strong>满足需求。</p>
<p><strong>选项复述</strong><br>A. <u>将密码存储在 AWS Secrets Manager 中，启用该密钥的自动轮换功能。</u><br>B. 将密码存储在 AWS Systems Manager Parameter Store 中，启用该参数的自动轮换功能。<br>C. 将密码存储在 Parameter Store 中，编写 Lambda 函数来轮换密码。<br>D. 将密码存储在 AWS KMS 中，启用 KMS 密钥的自动轮换功能</p>
<ul>
<li>Parameter Store 可以存储安全字符串（利用 KMS 加密），但<strong>不支持自动轮换密码</strong>（自动轮换是 Secrets Manager 的特性）。</li>
</ul>
<p><br>848 公司在 Oracle Database 企业版上运行应用，需将应用和数据库迁移到 AWS。<br>已知条件：</p>
<ul>
<li>可以使用 **BYOL（自带许可）**模式。</li>
<li>应用使用了需要<strong>特权访问</strong>的第三方数据库功能。<br>要求：以<strong>最具成本效益</strong>的方式设计数据库迁移方案。</li>
</ul>
<p><strong>选项复述</strong><br>A. 使用原生工具将数据库迁移到 Amazon RDS for Oracle，用 AWS Lambda 替换第三方功能。<br>B<u>. 使用原生工具将数据库迁移到 Amazon RDS Custom for Oracle，自定义数据库设置以支持第三方功能。</u><br>C. 使用 AWS DMS 将数据库迁移到 Amazon DynamoDB，自定义新数据库设置以支持第三方功能。<br>D. 使用 AWS DMS 将数据库迁移到 Amazon RDS for PostgreSQL，重写应用代码以消除对第三方功能依赖。</p>
<ul>
<li><p>标准 RDS for Oracle 不支持需要特权访问的第三方功能。</p>
</li>
<li><p><strong>RDS Custom for Oracle</strong> 专门为需要 OS 级别访问、自定义配置的 Oracle 数据库设计。</p>
</li>
<li><p>支持 BYOL 模式，允许安装第三方插件、修改数据库设置等。</p>
</li>
</ul>
<p><br>849 一所国际大学将所有计算服务部署在 AWS（EC2、RDS、DynamoDB 等）。<br>现状：目前依靠许多自定义脚本进行备份。<br>目标：希望通过 <strong>AWS 原生选项</strong> 实现 <strong>管理集中化</strong> 和 <strong>数据备份自动化</strong>。</p>
<p><strong>选项复述</strong><br>A. 使用第三方备份软件和 AWS Storage Gateway 磁带网关虚拟磁带库。<br>B. <u>使用 AWS Backup 配置和监控所有使用中的服务的备份。</u><br>C. 使用 AWS Config 设置生命周期管理，按计划对所有数据源进行快照。<br>D. 使用 AWS Systems Manager State Manager 管理备份任务的配置和监控</p>
<ul>
<li>State Manager 用于管理实例配置（如补丁、脚本运行），不是专门用于数据备份的服务，不适合统一管理跨服务备份。</li>
</ul>
<p>AWS Config 用于资源合规审计和配置历史记录，不是备份服务</p>
<p><br>850 公司希望构建 <strong>IT 基础设施地图</strong>，以识别并对存在安全风险的资源执行相关政策。<br>安全团队需要能<strong>查询地图中的数据</strong>并快速识别安全风险。<br>要求以<strong>最少的运营开销</strong>满足需求。</p>
<p><strong>选项复述</strong><br>A. 使用 Amazon RDS 存储数据，用 SQL 查询识别风险。<br>B. <u>使用 Amazon Neptune 存储数据，用 SPARQL 查询识别风险</u>。<br>C. 使用 Amazon Redshift 存储数据，用 SQL 查询识别风险。<br>D. 使用 Amazon DynamoDB 存储数据，用 PartiQL 查询识别风险。</p>
<ul>
<li><strong>Amazon Neptune</strong>是AWS 托管的<strong>图数据库</strong>，专门用于存储和查询图数据，支持 Gremlin 和 SPARQL 查询语言。</li>
</ul>
<p><br>851 一家大公司希望为全球的开发人员提供<strong>独立的、有限大小的、托管的 PostgreSQL 数据库</strong>用于开发。特点：</p>
<ul>
<li>交易量很低</li>
<li>开发人员只在<strong>积极工作时</strong>才需要这些数据库</li>
<li>要求<strong>最具成本效益</strong></li>
</ul>
<p><strong>选项复述</strong><br>A. 让开发人员启动独立 Amazon Aurora 实例，建立流程在工作日结束时关闭实例，次日早上启动。<br>B. 开发一个 AWS Service Catalog 产品，对启动 Amazon Aurora 实例实施大小限制，授予开发人员在需要时启动产品的权限。<br>C. <u>创建一个 Amazon Aurora Serverless 集群，开发一个 Service Catalog 产品以默认容量设置在该集群中启动数据库，授予开发人员访问权限。</u><br>D. 监控 AWS Trusted Advisor 的闲置 RDS 数据库检查，创建流程终止已识别的闲置数据库。</p>
<p>Aurora Serverless 提供自动暂停&#x2F;恢复能力，结合 Service Catalog 管理访问和限制，可以在开发人员需要时提供数据库，闲置时最小化成本</p>
<p><br>852 公司构建一个内容管理系统的 Web 应用，运行在 ALB 后的跨多可用区 Auto Scaling 组中的 EC2 实例上。<br>用户持续添加、更新文件、博客等网站资源。<br>要求：</p>
<ul>
<li>所有 EC2 实例共享最新的网站内容</li>
<li>延迟（lag time）尽可能短</li>
</ul>
<p>需要选出满足这些要求的解决方案。</p>
<p><strong>选项复述</strong><br>A. 在 Auto Scaling 组生命周期策略中更新 EC2 用户数据，从最新启动的 EC2 实例复制网站资产，配置 ALB 仅在最新 EC2 实例中对资产进行更改。<br>B. <u>将网站资产复制到 Amazon EFS 文件系统，每个 EC2 实例挂载 EFS，网站应用引用 EFS 中的资产。</u><br>C. 将网站资产复制到 Amazon S3 存储桶，每个 EC2 实例从 S3 下载到本地 EBS 卷，每小时运行 S3 同步命令。<br>D. 从包含网站资产的 EBS 快照还原，新启动 EC2 实例时附加该快照作为辅助 EBS 卷，应用引用辅助卷中的资产。</p>
<ul>
<li>EFS 是跨多可用区的共享文件系统（NFS），可以被多个 EC2 实例同时挂载。</li>
<li>文件写入 EFS 后，所有实例几乎立即可见（毫秒到秒级延迟），满足“延迟尽可能短”。</li>
</ul>
<p><br>853 公司 Web 应用由以下组成：</p>
<ul>
<li>多个 EC2 实例在 VPC 中的应用负载均衡器后</li>
<li>RDS for MySQL 数据库</li>
<li>已部署 <strong>AWS WAF</strong></li>
</ul>
<p>要求：</p>
<ul>
<li>自动检测并响应 AWS 环境中的<strong>可疑或意外行为</strong>（威胁检测与响应）</li>
</ul>
<p>问解决方案架构师下一步该做什么来防范威胁。</p>
<p><strong>选项复述</strong><br>A. <u>使用 Amazon GuardDuty 执行威胁检测，配置 EventBridge 筛选检测结果并调用 Lambda 来调整 AWS WAF 规则。</u><br>B. 使用 AWS Firewall Manager 执行威胁检测，配置 EventBridge 筛选检测结果并调用 Lambda 调整 AWS WAF Web ACL。<br>C. 使用 Amazon Inspector 执行威胁检测并更新 AWS WAF 规则，创建 VPC 网络 ACL 限制访问。<br>D. 使用 Amazon Macie 执行威胁检测并更新 AWS WAF 规则，创建 VPC 网络 ACL 限制访问。</p>
<ul>
<li>Firewall Manager 是策略管理和部署服务，本身<strong>不执行威胁检测</strong>，因此不适合。</li>
</ul>
<p>Inspector 用于漏洞评估，不是实时行为异常检测</p>
<p>Macie 用于敏感数据发现</p>
<p><br>854 公司计划运行一组连接到 Amazon Aurora 数据库的 EC2 实例。<br>已经构建了 CloudFormation 模板来部署 EC2 实例和 Aurora 集群。<br>要求：</p>
<ul>
<li>允许实例以<strong>安全的方式</strong>对数据库进行身份验证</li>
<li><strong>不想维护静态数据库凭据</strong>（即不要固定密码）</li>
<li>以<strong>最少的运维工作量</strong>满足要求</li>
</ul>
<p><strong>选项复述</strong><br>A. 创建带用户名密码的数据库用户，在 CloudFormation 模板添加参数，启动 EC2 时传参。<br>B. 创建带用户名密码的数据库用户，将凭据存储在 Systems Manager Parameter Store，EC2 实例从参数存储中获取凭据。<br>C. <u>配置数据库集群使用 <strong>IAM 数据库认证</strong>，创建用于 IAM 认证的数据库用户，为 EC2 实例关联一个角色以允许应用访问数据库。</u><br>D. 配置数据库集群使用带有 IAM 用户的 IAM 数据库认证，创建与 IAM 用户同名的数据库用户，将 IAM 用户与 EC2 实例关联。</p>
<ul>
<li>Aurora 支持 <strong>IAM 数据库认证</strong>，允许使用 IAM 身份验证到数据库，生成临时令牌（15 分钟有效）代替密码。</li>
<li>EC2 实例通过关联的 IAM 角色获取权限，应用使用 IAM 角色身份获取数据库临时令牌进行连接</li>
</ul>
<p> <strong>CloudFormation 参数传递静态凭据</strong></p>
<p><strong>Parameter Store 存储静态凭据</strong></p>
<p>IAM 用户用于人员或服务账户，不适合 EC2 实例</p>
<p><br>855 公司希望配置 CloudFront 分发使用 SSL&#x2F;TLS 证书，不想使用分发的默认域名，而要用另一个不同域名。<br>要求：部署证书且<strong>不会产生任何额外费用</strong>。</p>
<p><strong>选项复述</strong><br>A. 从美国东部（弗吉尼亚北部）区域的 AWS Certificate Manager (ACM) 申请亚马逊颁发的私有证书。<br>B. 从美国西部（俄勒冈）区域的 ACM 申请亚马逊颁发的私有证书。<br>C. <u>从美国东部（弗吉尼亚北部）区域的 ACM 申请亚马逊颁发的公共证书。</u><br>D. 从美国西部（俄勒冈）区域的 ACM 申请亚马逊颁发的公共证书。</p>
<ol>
<li>CloudFront 仅支持使用在 <strong>us-east-1（弗吉尼亚北部）区域</strong> 的 ACM 证书。</li>
<li><strong>ACM 公共证书免费</strong>（包括签发和续签）。</li>
<li><strong>ACM 私有证书</strong> 需要私有 CA（需付费创建和管理），通常用于内部域名，不适合 CloudFront 公网场景。</li>
</ol>
<ul>
<li><strong>CloudFront 的“大脑”在 <code>us-east-1</code></strong>：当您配置 CloudFront 分发时（例如创建、修改、关联证书），这些配置操作都由一个位于 <code>us-east-1</code> 的控制平面处理。</li>
</ul>
<p><br>856 公司运营数据存储在 Amazon S3 存储桶中。<br>外部顾问需要进行年度审计，需在 <strong>7 天内</strong> 访问存储桶中的年度报告。<br>要求：</p>
<ul>
<li>仅允许外部顾问访问该报告（而不是整个存储桶）</li>
<li>以最高的<strong>运营效率</strong>满足要求</li>
</ul>
<p><strong>选项复述</strong><br>A. 创建配置为托管公共静态网站的新 S3 存储桶，将数据迁移到新桶，与顾问共享网站 URL。<br>B. 允许公众访问该 S3 存储桶 7 天，审计完成后取消访问。<br>C. 创建新的 IAM 用户并授予访问 S3 报告的权限，向顾问提供访问密钥，7 天后撤销。<br>D<u>. 生成一个具有访问报告所需权限的预签名 URL，与顾问共享该 URL。</u></p>
<ul>
<li><strong>预签名 URL</strong> 是 S3 功能：使用 IAM 凭证（属于桶所有者）生成一个有时限的 URL，授予对特定对象的临时访问权限。</li>
<li>可设置过期时间（例如 7 天），无需创建用户、无需修改存储桶策略。</li>
</ul>
<p><br>857 公司计划在 EC2 实例上运行<strong>高性能计算（HPC）工作负载</strong>，要求：</p>
<ul>
<li>低延迟网络性能</li>
<li>高网络吞吐量</li>
<li>紧密耦合的节点间通信（即需要节点间超低延迟和高带宽）</li>
</ul>
<p>需要选出满足这些网络性能要求的解决方案。</p>
<p><strong>选项复述</strong><br>A. <u>将 EC2 实例配置为集群置放组的一部分</u>。<br>B. 使用专用实例租期启动 EC2 实例。<br>C. 将 EC2 实例作为竞价型实例启动。<br>D. 在启动 EC2 实例时配置按需容量预留。</p>
<ul>
<li><strong>节点间通信延迟极低</strong> → 需要实例在物理上紧邻，最好在同一机架内，通过高速网络互连。</li>
<li><strong>高网络吞吐量</strong> → 需要支持增强联网（如 Elastic Fabric Adapter - EFA）或集群网络模式。</li>
</ul>
<p><strong>AWS 如何满足 HPC 网络要求</strong><br>AWS 提供了 <strong>集群置放组（Cluster Placement Group）</strong>，它：</p>
<ul>
<li>将实例集中放置在单个可用区的一个低延迟分组内，使实例之间通过<strong>高速、低延迟网络</strong>连接。</li>
<li>支持 EFA（Elastic Fabric Adapter），提供类似 on-premise HPC 的 OS-bypass 网络性能。</li>
<li>专为紧密耦合、节点间通信密集的工作负载设计。</li>
</ul>
<p><br>858 公司有两个数据中心：主数据中心和备用数据中心，相距约 500 英里，通过高速光纤互连。<br>需要在数据中心与 AWS VPC 之间建立<strong>高可用性且安全</strong>的网络连接，以支持关键任务工作负载。<br>要求：提供<strong>最大弹性</strong>的连接方案。</p>
<p><strong>选项复述</strong><br>A. 从主数据中心建立两条 Direct Connect 连接，分别终止于两个不同设备上的两个 Direct Connect 位置。<br>B. 从主数据中心和备用数据中心各建立一个 Direct Connect 连接，终止于同一设备上的一个 Direct Connect 位置。<br>C. <u>从主数据中心和备用数据中心各建立两个 Direct Connect 连接，终止于两个独立设备上的两个 Direct Connect 位置。</u><br>D. 从主数据中心和备用数据中心各建立一个 Direct Connect 连接，终止于同一 Direct Connect 位置的两个独立设备上。</p>
<ul>
<li>完全满足所有冗余维度：<ul>
<li>数据中心冗余（主 + 备）</li>
<li>位置冗余（两个不同 Direct Connect 位置）</li>
<li>设备冗余（每个位置两个独立设备）</li>
</ul>
</li>
</ul>
<p><br>859 公司有多个利用率高的 Amazon RDS for Oracle 按需数据库实例，运行在 AWS Organizations 的成员账户中。<br>财务团队可以访问<strong>管理账户和成员账户</strong>，希望通过 AWS Trusted Advisor 找到优化成本的方法。</p>
<p>要求选择<strong>两个步骤组合</strong>来满足要求。</p>
<p><strong>选项复述</strong><br>A. <u>使用管理账户中的 Trusted Advisor 建议。</u><br>B. 在运行 RDS 数据库实例的成员账户中使用 Trusted Advisor 建议。<br>C<u>. 查看 Amazon RDS 预留实例优化的 Trusted Advisor 检查</u>。<br>D. 查看 Amazon RDS 闲置数据库实例的 Trusted Advisor 检查。<br>E. 检查 Trusted Advisor 中关于计算优化的检查项，使用 AWS Compute Optimizer 交叉验证结果。</p>
<p><strong>AWS Trusted Advisor 成本优化相关检查项</strong><br>与 RDS 成本优化相关的 Trusted Advisor 检查包括：</p>
<ol>
<li><strong>Amazon RDS 闲置数据库实例</strong>（Idle DB Instances）</li>
<li><strong>Amazon RDS 预留实例优化</strong>（Reserved Instance Optimization）</li>
<li>低利用率 EC2 实例等（但这里是 RDS，不是 EC2）。</li>
</ol>
<p><br>860 解决方案架构师创建的应用将在 VPC 中多个可用区的私有子网的 EC2 实例上运行。<br>这些 EC2 实例会频繁访问存储在 <strong>Amazon S3 存储桶</strong> 中的大型机密文件。<br>要求：<strong>优化网络架构，最大限度地降低数据传输成本</strong>。</p>
<p><strong>选项复述</strong><br>A. <u>在 VPC 中为 Amazon S3 创建一个网关终端节点（Gateway VPC Endpoint），并在私有子网路由表中添加相应条目。</u><br>B. 在公有子网中创建一个 NAT 网关，在私有子网路由表中添加指向 NAT 网关的默认路由。<br>C. 在 VPC 中为 Amazon S3 创建一个 AWS PrivateLink 接口端点（Interface VPC Endpoint），在私有子网路由表中添加条目。<br>D. 在公有子网中每个可用区创建 NAT 网关，每个私有子网路由指向同可用区的 NAT 网关。</p>
<ul>
<li><strong>网关终端节点（Gateway Endpoint）</strong>：仅支持 S3 和 DynamoDB，通过修改路由表将流量指向该终端节点，不经过 NAT&#x2F;互联网网关，流量通过 AWS 内部网络，成本最低。</li>
<li><strong>接口终端节点（Interface Endpoint）</strong>：基于 PrivateLink，支持更多服务，但会按小时和流量收费（比 NAT 网关便宜，但比网关端点贵）。对于 S3，网关端点是最经济的选择。</li>
</ul>
<p><br>861 公司希望将本地 MySQL 数据库迁移到 AWS。<br>特点：数据库定期接收来自面向客户应用的导入数据，导致<strong>大量写入操作</strong>。<br>担忧：这种写入流量可能导致应用性能问题。<br>问解决方案架构师应如何在 AWS 上设计架构。</p>
<p><strong>选项复述</strong><br>A<u>. 配置一个带<strong>预置 IOPS SSD 存储</strong>的 Amazon RDS for MySQL 实例，通过 CloudWatch 监控写入指标，必要时调整预置 IOPS</u>。<br>B. 配置一个带通用型 SSD 存储的 Amazon RDS for MySQL 实例，在数据库前放置 Amazon ElastiCache，将应用配置为查询 ElastiCache。<br>C. 配置一个采用内存优化实例类型的 Amazon DocumentDB（兼容 MongoDB）实例，通过 CloudWatch 监控性能，必要时更换实例类别。<br>D. 配置一个 EFS 文件系统（通用性能模式），监控 IOPS 瓶颈，必要时切换到预置吞吐量模式。</p>
<ul>
<li><strong>预置 IOPS</strong> 可确保提供稳定、高水平的 I&#x2F;O 性能，适合写入密集场景。</li>
<li>通过 CloudWatch 监控写入指标（如 Write IOPS、Write Latency），可随时根据需求调整预置 IOPS 大小。</li>
</ul>
<p>通用 SSD（gp2&#x2F;gp3）的 I&#x2F;O 性能受存储容量限制，对于大量写入可能不足</p>
<ul>
<li>DocumentDB 是文档数据库，不是关系型，与 MySQL 不兼容，迁移成本高。</li>
</ul>
<p>EFS 是网络文件系统（NFS），不适合作为关系数据库的存储后端（RDS 不支持 EFS 作为主存储）</p>
<p><br>862 公司运行的应用会生成敏感归档数据文件，需要重新架构数据存储以满足以下要求：</p>
<ol>
<li><strong>对数据文件进行加密</strong></li>
<li><strong>确保第三方在数据加密并发送至 AWS 之前无法访问这些数据</strong>（即数据离开客户端前已加密，传输过程中和存储后第三方都无法访问明文）</li>
<li>已创建 Amazon S3 存储桶</li>
</ol>
<p><strong>选项复述</strong><br>A. 配置 S3 存储桶使用 Amazon S3 托管的加密密钥进行客户端加密，配置应用使用该桶存储归档文件。<br>B. 配置 S3 存储桶使用带有 AWS KMS 密钥的服务器端加密（SSE-KMS），配置应用使用该桶存储归档文件。<br>C. 配置 S3 存储桶使用带有 AWS KMS 密钥的双层服务器端加密（SSE-KMS），配置应用使用该桶存储归档文件。<br>D. <u>配置应用使用客户端加密，并将密钥存储在 AWS KMS 中，配置应用将归档文件存储在 S3 存储桶中。</u></p>
<p>数据必须在离开客户端之前就被加密，即 <strong>客户端加密（Client-Side Encryption）</strong>，而不是在传输到 S3 后才加密（服务器端加密）。</p>
<ul>
<li><strong>服务器端加密（SSE-S3、SSE-KMS、SSE-C）</strong>：数据在传输过程中是明文（TLS 加密传输），到达 S3 后才加密。第三方（如 ISP、网络中间人）在传输过程中可能无法解密（因为 TLS），但题目强调“发送至 AWS 之前”，意味着他们希望即使数据在离开客户端后到 S3 之前的整个链路上都是密文。</li>
<li><strong>客户端加密</strong>：数据在客户端应用内就用密钥加密，然后上传密文到 S3，传输中和存储中都是密文，第三方在任何环节都无法看到明文，包括 AWS 本身（除非有密钥）。</li>
</ul>
<p><br>863 公司在数据库层使用具有<strong>默认备份设置</strong>的 Amazon RDS。<br>要求：</p>
<ul>
<li>每天对数据库进行备份（符合监管要求）</li>
<li>备份保留 30 天</li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p><strong>选项复述</strong><br>A. 编写 AWS Lambda 函数，每天创建一个 RDS 快照。<br>B<u>. 修改 RDS 数据库，将自动备份的保留期设置为 30 天。</u><br>C. 使用 AWS Systems Manager 维护时段修改 RDS 备份保留期。<br>D. 使用 AWS CLI 每天创建一个手动快照，修改 RDS 备份保留期。</p>
<p><br>864 公司在 AWS 上运行应用，使用 <strong>Amazon Aurora 数据库集群</strong>作为数据库。<br>问题：在<strong>高峰使用时段</strong>（多个用户访问和读取数据），<strong>写入查询的数据库性能下降</strong>。<br>目标：提高应用程序的<strong>可扩展性</strong>以满足高峰需求，并以<strong>最具成本效益</strong>的方式实现。</p>
<p><strong>选项复述</strong><br>A. 创建第二个 Aurora 数据库集群，配置复制作业将数据复制到新库，更新应用使用第二个数据库进行读取。<br>B. 在现有 Aurora 集群前创建 **Amazon DynamoDB Accelerator（DAX）**集群，更新应用使用 DAX 处理只读查询，直接写入 Aurora。<br>C. <u>在现有 Aurora 集群中创建一个 <strong>Aurora 只读副本</strong>，更新应用使用副本端点进行只读查询，使用集群端点进行写入。</u><br>D. 创建 Amazon Redshift 集群，复制用户数据到 Redshift，更新应用连接到 Redshift 执行只读查询。</p>
<p><br>865 公司有一个<strong>近实时流应用程序</strong>在 AWS 上运行。</p>
<ul>
<li>数据被摄入后，由一个作业处理，该作业需要 <strong>30 分钟完成</strong>。</li>
<li>由于大量传入数据，工作负载经常出现<strong>高延迟</strong>。<br>需要设计一个<strong>可扩展且无服务器的解决方案</strong>来提升性能。<br>要求选择<strong>两个步骤</strong>组合（选择两项）。</li>
</ul>
<p><strong>选项复述</strong><br>A. <u>使用 Amazon Kinesis Data Firehose 来摄入数据。</u><br>B. 使用 AWS Lambda 和 AWS Step Functions 来处理数据。<br>C. 使用 AWS DMS 来摄入数据。<br>D. 在自动扩展组中使用 Amazon EC2 实例来处理数据。<br>E. <u>使用 AWS Fargate 与 Amazon ECS 来处理数据。</u></p>
<p>DMS 是数据库迁移和复制服务，用于批量或 CDC 数据迁移，</p>
<ul>
<li>Firehose 是 AWS 无服务器的流数据摄取服务，可自动扩展，并将数据加载到 S3、Redshift、Elasticsearch 等。</li>
</ul>
<p><br>866 公司在 VPC 内的多台 EC2 实例上运行 Web 应用，应用需要将敏感数据写入 Amazon S3 存储桶。<br>要求：<strong>数据不能通过公共互联网传输</strong>（即必须通过 AWS 内部网络）。</p>
<p><strong>选项复述</strong><br>A. <u>为 Amazon S3 创建网关 VPC 终端节点（Gateway VPC Endpoint），并在 VPC 路由表中创建指向该终端节点的路由。</u><br>B. 创建一个内部网络负载均衡器，并将 S3 存储桶作为目标。<br>C. 在 VPC 内部置 S3 存储桶，在 VPC 路由表中创建指向该存储桶的路由。<br>D. 在 VPC 和 S3 区域终端节点之间创建一个 AWS Direct Connect 连接。</p>
<ul>
<li><strong>网关终端节点（Gateway Endpoint）</strong>：适用于 S3 和 DynamoDB，通过修改路由表将流量指向该终端节点，流量不经过互联网，且免费。</li>
<li><strong>接口终端节点（Interface Endpoint）</strong>：基于 PrivateLink，支持更多服务，但收费。对于 S3，通常选用网关终端节点（成本最低且功能满足）。</li>
</ul>
<p><br>867 公司在 EC2 实例上运行生产工作负载，使用 Amazon EBS 卷。<br>解决方案架构师需要：</p>
<ol>
<li>分析当前的 <strong>EBS 卷成本</strong></li>
<li>提出<strong>优化建议</strong></li>
<li>建议需包含<strong>每月预计的节省机会</strong></li>
</ol>
<p>问哪种解决方案能满足这些要求。</p>
<p><strong>选项复述</strong><br>A. 使用 Amazon Inspector 报告生成用于优化的 EBS 卷建议。<br>B. 使用 AWS Systems Manager 报告来确定用于优化的 EBS 卷建议。<br>C. 使用 Amazon CloudWatch 指标报告来确定用于优化的 EBS 卷建议。<br>D. 使<u>用 AWS Compute Optimizer 生成用于优化的 EBS 卷建议</u>。</p>
<ul>
<li><strong>EBS 卷成本优化</strong> → 可能涉及调整卷类型（如 gp2 转 gp3）、调整容量或 IOPS、删除未使用卷、使用快照归档等。</li>
<li><strong>每月预计节省机会</strong> → 需要服务能分析使用情况并给出量化节省估算。</li>
</ul>
<p><strong>AWS Compute Optimizer</strong></p>
<ul>
<li>AWS 提供的<strong>成本与性能优化建议服务</strong>，支持 EC2 实例、EBS 卷、Lambda 函数、Auto Scaling 组等。</li>
</ul>
<p><br>868 一家全球性公司在多个 AWS 区域使用 Amazon S3 存储桶存储和分析敏感数据，每天存储数百万个对象。<br>希望<strong>找出所有未启用版本控制的 S3 存储桶</strong>（跨区域）。<br>问哪种解决方案能满足要求。</p>
<p><strong>选项复述</strong><br>B. <u>使用 Amazon S3 Storage Lens 识别跨区域所有未启用版本控制的 S3 存储桶。</u><br>C. 为 S3 启用 IAM 访问分析器，以识别跨区域所有未启用版本控制的 S3 存储桶。<br>D. 创建一个 S3 多区域访问点，以识别跨区域所有未启用版本控制的 S3 存储桶。</p>
<ul>
<li>S3 Storage Lens 是 AWS 提供的存储分析和优化工具，提供组织级存储使用情况的可视化。</li>
<li>它包含 <strong>高级指标和筛选功能</strong>，可以检查桶配置（如版本控制、加密、生命周期策略等）并生成报告。</li>
</ul>
<p><br>869 公司希望增强其部署在 AWS 上的电子商务订单处理应用程序。要求：</p>
<ol>
<li><strong>必须精确处理每个订单一次</strong>（Exactly-once processing）</li>
<li><strong>在不可预测的流量激增期间不影响客户体验</strong>（可弹性扩展）</li>
</ol>
<p><strong>选项复述</strong><br>A. <u>创建一个 Amazon SQS FIFO 队列，将所有订单放入队列，配置 AWS Lambda 作为处理订单的目标。</u><br>B. 创建一个 Amazon SNS 标准主题，将所有订单发布到该主题，将应用程序配置为通知目标。<br>C. 使用 Amazon AppFlow 创建一个流，将订单发送到该流，将 AWS Lambda 配置为处理订单的目标。<br>D. 配置 AWS X-Ray 跟踪订单请求，配置应用程序从 Amazon CloudWatch 拉取订单进行处理。</p>
<p><br>870 公司有两个 AWS 账户：生产账户和开发账户。<br>需求：</p>
<ol>
<li>将开发账户中的代码更改推送到生产账户。</li>
<li><strong>Alpha 阶段</strong>：仅两名高级开发人员需要访问生产账户。</li>
<li><strong>Beta 阶段</strong>：更多开发人员需要访问权限进行测试。</li>
</ol>
<p>需要选出满足这些要求的解决方案。</p>
<p><strong>选项复述</strong><br>A. 在每个账户中使用 AWS 管理控制台创建两个策略文档，将该策略分配给需要访问的开发人员。<br>B. 在开发账户中创建一个 IAM 角色，授予该角色访问生产账户的权限，允许开发人员扮演该角色。<br>C. <u>在生产账户中创建一个 IAM 角色，定义指定开发账户的信任策略，允许开发人员承担该角色。</u><br>D. 在生产账户中创建一个 IAM 组，将该组作为主体添加到指定生产账户的信任策略中，将开发人员添加到该组。</p>
<ul>
<li>这是标准跨账户访问方案：<ul>
<li>生产账户角色信任开发账户（可以是特定用户或整个账户）。</li>
<li>Alpha 阶段：将信任策略限制为两名高级开发人员的 IAM 用户。</li>
<li>Beta 阶段：修改信任策略为开发账户的 IAM 角色，让更多开发人员通过该角色切换。</li>
</ul>
</li>
</ul>
<p><br>871 公司希望限制对其 Web 应用程序内容的访问，要求：</p>
<ol>
<li>使用 AWS 上的授权技术保护内容。</li>
<li>实施<strong>无服务器的授权和认证架构</strong>，实现<strong>低登录延迟</strong>。</li>
<li>解决方案必须与 Web 应用集成，并在<strong>全球范围内</strong>提供 Web 内容。</li>
<li>当前用户群小，但预计会增长（需可扩展）。</li>
</ol>
<p><strong>选项复述</strong><br>A. <u>配置 Amazon Cognito 进行身份验证，实施 <strong>Lambda@Edge</strong> 进行授权，配置 Amazon CloudFront 在全球提供 Web 应用。</u><br>B. 配置 AWS Directory Service for Microsoft AD 进行身份验证，实现 AWS Lambda 进行授权，使用 ALB 在全球提供 Web 应用。<br>C. 配置 Amazon Cognito 进行身份验证，实现 AWS Lambda 进行授权，使用 <strong>Amazon S3 Transfer Acceleration</strong> 在全球提供 Web 应用。<br>D. 配置 AWS Directory Service for Microsoft AD 进行身份验证，实施 Lambda@Edge 进行授权，使用 AWS Elastic Beanstalk 在全球提供 Web 应用。</p>
<ul>
<li><strong>认证（Authentication）</strong>：Amazon Cognito 是无服务器的用户目录和认证服务，适合 Web 应用，支持社交登录、自定义身份池等。</li>
<li><strong>授权（Authorization）</strong>：可以在 CDN 边缘执行授权检查，<strong>Lambda@Edge</strong> 允许在 CloudFront 边缘位置运行代码，验证用户权限，实现低延迟。</li>
<li><strong>全球分发</strong>：Amazon CloudFront 是 CDN，可缓存内容并利用边缘站点全球加速。</li>
</ul>
<p><br>872 开发团队在多个 AWS 账户（开发、staging、生产）中工作，团队成员一直在启动<strong>未充分利用的大型 EC2 实例</strong>。<br>需要防止在所有账户中启动大型实例。<br>要求以<strong>最小的运营开销</strong>满足要求。</p>
<p><strong>选项复述</strong><br>A. 更新 IAM 策略以禁止启动大型 EC2 实例，将这些策略应用于所有用户。<br>B. 在 AWS 资源访问管理器中定义一个资源，以防止大型 EC2 实例的启动。<br>C. 在每个账户中创建一个 IAM 角色，该角色拒绝启动大型 EC2 实例，向开发人员 IAM 用户组授予该角色的访问权限。<br>D. <u>在管理账户中使用 AWS Organizations 创建一个组织，创建一项服务控制策略（SCP）拒绝启动大型 EC2 实例，并将其应用于 AWS 账户。</u></p>
<p><strong>AWS Organizations 服务控制策略（SCP）</strong></p>
<ul>
<li>SCP 是 Organizations 的功能，可在<strong>组织单元（OU）或账户级别</strong>设置权限边界，限制成员账户中 IAM 用户和角色的最大权限，即使这些用户&#x2F;角色拥有本账户内的 IAM 策略允许启动大型实例，也会被 SCP 拒绝。</li>
<li>一条 SCP 可以从管理账户统一应用到多个账户，无需在每个账户重复配置，<strong>运营开销最小</strong>。</li>
</ul>
<p><br>873 公司将数百台本地虚拟机迁移到了 Amazon EC2 实例，运行多种 Windows Server 版本和多个 Linux 发行版。<br>需求：</p>
<ol>
<li><strong>自动对操作系统进行清点（inventory）和更新（patching）</strong>。</li>
<li>需要每个实例的<strong>常见漏洞摘要</strong>，用于<strong>每月常规审查</strong>。</li>
</ol>
<p>解决方案架构师应推荐满足这些要求的方案。</p>
<p><strong>选项复述</strong><br>A. 设置 AWS Systems Manager 补丁管理器管理所有 EC2 实例，配置 AWS Security Hub 生成月度报告。<br>B. <u>设置 AWS Systems Manager 补丁管理器管理所有 EC2 实例，部署 Amazon Inspector 并配置月度报告</u>。<br>C. 设置 AWS Shield Advanced 并配置月度报告，部署 AWS Config 自动在 EC2 实例上安装补丁。<br>D. 在账户中设置 Amazon GuardDuty 监控所有 EC2 实例，部署 AWS Config 自动在 EC2 实例上安装补丁。</p>
<ul>
<li><p>Security Hub 是安全态势聚合与合规检查服务，能接收 Inspector 等服务的发现，但本身不专门生成实例级别的漏洞摘要报告（除非 Inspector 集成进来）。</p>
</li>
<li><p>SSM Patch Manager 满足自动清点和更新操作系统的需求。</p>
</li>
<li><p>Amazon Inspector 可定期扫描 EC2 实例，发现漏洞并生成报告，支持按月发送摘要</p>
</li>
<li><p>Shield Advanced 是针对 DDoS 防护的高级服务，与漏洞评估和补丁管理无关。</p>
</li>
<li><p>AWS Config 用于资源配置历史与合规审计，不能自动安装补丁。</p>
</li>
<li><p>GuardDuty 是威胁检测服务（异常 API 调用、恶意 IP 等），不是漏洞评估服务，不提供漏洞摘要。</p>
</li>
</ul>
<p><br>874 公司在 AWS 上托管应用，架构为：</p>
<ul>
<li>应用运行在 ELB 后的 Auto Scaling 组中的 EC2 实例上</li>
<li>应用连接到一个 Amazon DynamoDB 表</li>
</ul>
<p>出于灾难恢复目的，需要确保应用可从另一个 AWS 区域访问，且<strong>停机时间最短</strong>。<br>要求选择满足要求且停机时间最短的解决方案。</p>
<p><strong>选项复述</strong><br>A. <u>在灾难恢复区域创建一个自动扩展组和一个 ELB，将 DynamoDB 表配置为<strong>全局表（Global Table）</strong>，配置 DNS 故障转移指向灾难恢复区域的 ELB。</u><br>B. 创建一个 CloudFormation 模板用于在必要时创建 EC2 实例、ELB 和 DynamoDB 表，配置 DNS 故障转移指向灾难恢复区域的 ELB。<br>C. 创建一个 CloudFormation 模板用于在必要时创建 EC2 实例和启动 ELB，将 DynamoDB 表配置为全局表，配置 DNS 故障转移指向灾难恢复区域的 ELB。<br>D. 在灾难恢复区域创建一个自动扩展组和一个 ELB，将 DynamoDB 表配置为全局表，创建一个 CloudWatch 告警（评估周期 10 分钟）调用 Lambda 函数来更新 Route 53 指向灾难恢复区域 ELB。</p>
<ul>
<li><p>为了实现最短停机时间的灾难恢复，需要在故障发生时能<strong>快速切换流量</strong>到另一个区域，且<strong>数据保持同步</strong>。</p>
</li>
<li><p>对于 DynamoDB：使用 <strong>DynamoDB 全局表</strong> 可以在多个区域之间自动复制数据（多主、毫秒级同步），无需手动配置复制。</p>
</li>
<li><p>对于应用层：需要在灾难恢复区域<strong>预先部署好</strong> EC2 实例（或至少 Auto Scaling 组和 ELB），而不是故障时才启动（那会增加恢复时间）。</p>
</li>
<li><p><strong>预先部署</strong> → 故障时只需切换 DNS，恢复时间短。</p>
</li>
<li><p><strong>DynamoDB 全局表</strong> → 数据实时跨区域同步，切换后无需担心数据一致性。</p>
</li>
<li><p><strong>DNS 故障转移</strong>（Route 53 Failover） → 可自动检测健康检查并切换流量。</p>
</li>
</ul>
<p><br>875 公司在私有子网的 EC2 实例上运行一个应用程序，该应用需要在 Amazon S3 存储桶中存储和检索数据。<br>监管要求：<strong>数据不得通过公共互联网传输</strong>。<br>要求：以<strong>最具成本效益</strong>的方式满足要求。</p>
<p><strong>选项复述</strong><br>A. 部署一个 NAT 网关以访问 S3 存储桶。<br>B. 部署 AWS Storage Gateway 以访问 S3 存储桶。<br>C. 部署一个 S3 接口端点（Interface Endpoint）来访问 S3 存储桶。<br>D. <u>部署一个 S3 网关终端节点（Gateway Endpoint）来访问 S3 存储桶。</u></p>
<ul>
<li><strong>网关终端节点（Gateway Endpoint）</strong> 免费（仅收取正常 S3 请求和存储费用）。</li>
<li><strong>接口终端节点（Interface Endpoint）</strong> 按小时和数据处理量收费。</li>
<li><strong>NAT 网关</strong> 按小时和数据处理量收费，且流量经公网。</li>
<li><strong>Storage Gateway</strong> 是混合云存储集成服务，通常用于本地与 S3 同步，不适合 VPC 内 EC2 直接访问 S3，且会涉及额外费用。</li>
</ul>
<p><br>876 公司在单个可用区的 EC2 实例上托管了一个应用，该应用可通过 <strong>OSI 传输层</strong> 访问（即通过 TCP&#x2F;UDP）。<br>需要使应用架构具备<strong>高可用性（HA）</strong>，要求<strong>最具成本效益</strong>。<br>需要选择<strong>两项</strong>步骤组合。</p>
<p><strong>选项复述</strong><br>A. 在不同可用区配置新的 EC2 实例，使用 Amazon Route 53 将流量路由到所有实例。<br>B. <u>在 EC2 实例前配置<strong>网络负载均衡器（Network Load Balancer，NLB）</strong></u>。<br>C. 为实例的 TCP 流量配置 NLB，为 HTTP&#x2F;HTTPS 流量配置应用负载均衡器（ALB）。<br>D. 为 EC2 实例创建一个<strong>自动扩展组（Auto Scaling Group）</strong>，配置该组使用多个可用区，并对实例运行应用健康检查。<br>E. <u>创建一个 CloudWatch 警报，在 EC2 实例停止时重启实例。</u></p>
<ol>
<li><strong>负载均衡器</strong>（B：NLB）实现流量分发与快速故障转移。</li>
<li><strong>跨多可用区的自动扩展组</strong>（D：ASG）确保实例层面的冗余与自动恢复。<br>两者结合（B + D）是最常见且经济的高可用架构。</li>
</ol>
<p><br>877 公司使用 Amazon S3 托管静态网站，希望在网页上添加一个<strong>联系表单</strong>，包含动态服务器端组件（收集姓名、邮箱、电话、留言）。<br>特点：</p>
<ul>
<li>每月网站访问量<strong>不到 100 次</strong>（极低流量）</li>
<li>当客户填写表单时，必须通过<strong>电子邮件通知公司</strong></li>
</ul>
<p>要求：以<strong>最具成本效益</strong>的方式满足要求。</p>
<p><strong>选项复述</strong><br>A. 在 Amazon ECS 中托管动态联系表单，设置 Amazon SES 连接到第三方电子邮件提供商。<br>B. <u>创建一个 Amazon API Gateway 端点，从 AWS Lambda 函数返回联系表单，在 API Gateway 上配置另一个 Lambda 函数向 Amazon SNS 主题发布消息（从而触发邮件）。</u><br>C. 使用 AWS Amplify Hosting 托管网站的静态和动态内容，使用服务器端脚本构建联系表单，配置 Amazon SQS 将消息传递给公司。<br>D. 将网站从 S3 迁移到运行 Windows Server 的 EC2 实例，使用 IIS 托管网页，使用客户端脚本构建表单，与 Amazon WorkMail 集成。</p>
<ul>
<li>API Gateway 和 Lambda 均按请求计费，每月少量请求成本极低（可能在免费套餐内）。</li>
<li>SNS 可集成 SES 发送邮件，或直接使用 SES（更直接），但 SNS 也能转发邮件</li>
</ul>
<p><br>878 公司在 AWS Organizations 中为业务部门创建了专用 AWS 账户。<br>问题：重要通知发送到了<strong>业务部门账户的根用户邮箱地址</strong>，而非指定的账户所有者。<br>目标：确保未来所有通知能根据<strong>账单、运营、安全</strong>等通知类别发送给不同的员工。<br>要求：<strong>最安全</strong>的解决方案。</p>
<p><strong>选项复述</strong><br>A. 配置每个 AWS 账户使用公司管理的单一电子邮件地址，确保所有账户所有者都能访问该邮箱，为每个账户配置备用联系人并为各团队的通讯组列表设置相应类别。<br>B. <u>为每个业务部门，将每个 AWS 账户配置为使用不同的电子邮件分发列表，为每个分发列表配置可响应警报的管理员邮箱，为每个账户配置备用联系人并为各团队设置相应的分发列表</u>。<br>C. 将每个 AWS 账户根用户的邮箱地址配置为业务部门中一个人的个人公司邮箱，为每个账户配置备用联系人并为各团队设置分发列表。<br>D. 配置每个 AWS 账户的根用户使用指向集中式邮箱的电子邮件别名，通过企业管理的电子邮件分发列表为账单、安全等团队分别设置备用联系人。</p>
<ul>
<li>AWS 可以向以下联系人发送通知：<ol>
<li><strong>根用户邮箱</strong>：账户注册邮箱，用于关键账户相关通知（如密码重置、服务终止警告）。</li>
<li><strong>备用联系人（Alternate Contacts）</strong>：可设置 <strong>账单（Billing）</strong>、<strong>运营（Operations）</strong>、<strong>安全（Security）</strong> 三类联系人，每类可设置单独的邮箱或邮件列表，用于接收相应类别的通知。</li>
</ol>
</li>
<li>最佳实践：<strong>避免将关键通知仅发送到个人邮箱</strong>，而应使用邮件列表或团队邮箱，确保人员变动时不遗漏通知。</li>
</ul>
<p><br>879 公司运行一个电子商务应用：</p>
<ul>
<li>EC2 实例处理购买交易，并将购买详情存储在 <strong>Aurora PostgreSQL</strong> 数据库集群中。</li>
<li>客户在<strong>使用高峰期遇到应用程序超时</strong>。</li>
<li>需要重新设计应用以<strong>扩展并满足高峰期需求</strong>，要求<strong>最具成本效益</strong>。</li>
<li>选择<strong>两项</strong>操作组合。</li>
</ul>
<p><strong>选项复述</strong><br>A. <u>配置新 EC2 实例的自动扩展组以重试购买直到完成，更新应用通过 <strong>Amazon RDS Proxy</strong> 连接到数据库集群。</u><br>B. 配置应用在 Aurora PostgreSQL 数据库集群前使用 <strong>Amazon ElastiCache</strong> 集群。<br>C. <u>更新应用将购买请求发送到 <strong>Amazon SQS 队列</strong>，配置一个自动扩展组包含从 SQS 队列读取数据的新 EC2 实例。</u><br>D. 配置一个 <strong>AWS Lambda 函数</strong>来重试门票购买直到处理完成。<br>E. 配置带有使用计划的 <strong>Amazon API Gateway REST API</strong>。</p>
<ul>
<li><strong>C</strong>：使用 SQS 队列和自动扩展组实现异步处理和计算弹性。</li>
<li><strong>A</strong>：通过 RDS Proxy 管理数据库连接池，提高数据库可扩展性。</li>
</ul>
<p><br>880 公司使用 AWS Organizations，在 30 个账户中运行 150 个应用。<br>已通过 <strong>AWS 成本和使用情况报告（Cost and Usage Report，CUR）</strong> 在管理账户中创建报告，并交付到 S3 存储桶，且<strong>复制到数据收集账户的一个存储桶</strong>。</p>
<p>管理层希望查看<strong>自定义仪表板</strong>，显示 <strong>从当月月初开始的每天的 NAT 网关成本</strong>。<br>问哪种解决方案满足要求。</p>
<p><strong>选项复述</strong><br>A. 分享包含所需表格可视化的 Amazon QuickSight 仪表板，配置 QuickSight 使用 <strong>AWS DataSync</strong> 查询新报告。<br>B. <u>分享包含所需表格可视化的 Amazon QuickSight 仪表板，配置 QuickSight 使用 <strong>Amazon Athena</strong> 查询新报告。</u><br>C. 共享包含所需表格可视化的 Amazon CloudWatch 仪表板，配置 CloudWatch 使用 AWS DataSync 查询新报告。<br>D. 共享包含所需表格可视化的 Amazon CloudWatch 仪表板，配置 CloudWatch 使用 Amazon Athena 查询新报告。</p>
<ul>
<li><strong>AWS 成本和使用情况报告（CUR）</strong> 是详细的 CSV 或 Parquet 格式报告，存储在 S3 中。</li>
<li>要查询 CUR 数据，常用 <strong>Amazon Athena</strong>（无服务器查询服务）直接对 S3 中的 CUR 文件执行 SQL 查询。</li>
<li>要可视化 CUR 数据，常用 <strong>Amazon QuickSight</strong>（商业智能服务），它可以连接 Athena 作为数据源，创建交互式仪表板。</li>
<li><strong>CloudWatch</strong> 主要用于监控指标和日志，不直接用于 CUR 成本数据分析（虽然有成本监控功能，但不如 QuickSight + Athena 灵活）。</li>
</ul>
<p><br>881 公司使用 Amazon S3 托管高流量静态网站，并使用 <strong>CloudFront 分发（默认 TTL &#x3D; 0 秒，即不缓存）</strong>。<br>目标：</p>
<ol>
<li><strong>实施缓存以提高网站性能</strong></li>
<li><strong>确保部署后，过时内容的提供时间不超过几分钟</strong>（即缓存刷新时间很短）</li>
</ol>
<p>要求选择<strong>两种缓存方法组合</strong>（选择两项）。</p>
<p><strong>选项复述</strong><br><u>A. 将 CloudFront 的默认 TTL 设置为 2 分钟。</u><br>B. 在 S3 存储桶上设置 2 分钟的默认 TTL。<br>C. 向 Amazon S3 中的对象添加 Cache-Control private 指令。<br>D. 创建一个 Lambda@Edge 函数，向 HTTP 响应添加 Expires 头部，将该函数配置为在查看器响应时运行。<br>E. <u>为 Amazon S3 中的对象添加 24 小时的 Cache-Control max-age 指令，在部署时创建一个 CloudFront 失效以从边缘缓存中清除所有已更改的文件</u>。</p>
<p><strong>缓存策略需求</strong></p>
<ul>
<li>当前 TTL&#x3D;0 → 每次请求都回源（S3），性能差。</li>
<li>需要<strong>提高性能</strong> → 增加缓存时间（TTL &gt; 0）。</li>
<li>但又要<strong>部署后内容更新快速生效</strong>（不超过几分钟） → 需要能在部署时<strong>主动刷新缓存</strong>或<strong>设置很短的 TTL</strong></li>
</ul>
<ol>
<li><strong>短 TTL 方案</strong>：A（默认 TTL 2 分钟）→ 自动过期，无需手动刷新，适合频繁更新且可接受短延迟的场景。</li>
<li><strong>长 TTL + 主动失效方案</strong>：E（长缓存 + 部署时失效）→ 性能更好，但需在部署时额外操作失效。</li>
</ol>
<p><br>882 公司应用程序通过 <strong>EC2 实例</strong> 和 <strong>Lambda 函数</strong> 运行。</p>
<ul>
<li>EC2 实例运行在 <strong>VPC 的私有子网</strong> 中。</li>
<li>Lambda 函数需要对 EC2 实例进行<strong>直接网络访问</strong>（即 Lambda 能连接到私有子网内的 EC2）。</li>
<li>应用程序将运行 <strong>1 年</strong>，期间 Lambda 函数数量会增加。</li>
<li>目标：<strong>将所有应用程序资源的成本降至最低</strong>。</li>
</ul>
<p><strong>选项复述</strong><br>A. 购买 <strong>EC2 实例节省计划</strong>，将 Lambda 函数连接到包含 EC2 实例的私有子网。<br>B. 购买 <strong>EC2 实例节省计划</strong>，将 Lambda 函数连接到同一 VPC 中的新公有子网。<br>C<u>. 购买 <strong>计算节省计划</strong>，将 Lambda 函数连接到包含 EC2 实例的私有子网。</u><br>D. 购买 <strong>计算节省计划</strong>，将 Lambda 函数保留在 Lambda 服务 VPC 中（即不连接到 VPC）。</p>
<p><strong>节省计划类型</strong></p>
<ul>
<li><strong>EC2 实例节省计划</strong>：仅适用于 EC2 实例使用量（特定实例系列和区域），不适用于 Lambda。</li>
<li><strong>计算节省计划</strong>：覆盖 EC2、Fargate、Lambda 使用量（按 vCPU&#x2F;内存&#x2F;计算时长计费的部分），更灵活且适用混合计算负载。</li>
</ul>
<p>由于应用包含 <strong>EC2 和 Lambda</strong>，且 Lambda 数量会增加，选择 <strong>计算节省计划（C&#x2F;D）</strong> 比仅 EC2 节省计划（A&#x2F;B）更能降低整体成本。</p>
<p><strong>VPC 连接与成本</strong></p>
<ul>
<li>Lambda 连接 VPC 时，会创建 <strong>ENI（弹性网络接口）</strong>，可能产生少量 VPC 数据流转发费（很低），且会增加 Lambda 冷启动延迟，但为了访问私有子网 EC2 是必须的。</li>
<li>如果 Lambda 不连接 VPC（选项 D），则无法访问私有子网 EC2，不符合功能需求。</li>
</ul>
<p><br>883 公司通过 <strong>AWS Control Tower</strong> 部署了多账户策略，为每位开发人员提供独立的 AWS 账户。<br>希望<strong>实施控制措施，以限制开发人员产生的 AWS 资源成本</strong>。<br>要求：<strong>以最少的运营开销</strong>满足要求。</p>
<p><strong>选项复述</strong><br>A. 要求开发人员为所有资源添加 CostCenter 标签（值为姓名），使用 AWS Config 的 required-tags 规则检查，创建 Lambda 函数终止无标签资源，配置 Cost Explorer 发送每日支出报告给开发人员。<br>B. <u>使用 <strong>AWS 预算（Budgets）</strong> 为每个开发者账户设定预算，设置预算警报（实际和预测），使用 <strong>AWS 预算操作（Budget Actions）</strong> 在超支时向开发者 IAM 角色应用 DenyAll 策略以防止启动额外资源。</u><br>C. 使用 AWS Cost Explorer 监控并报告每个账户成本，发送每日报告，使用成本异常检测发现异常支出并警报。<br>D. 使用 AWS Service Catalog 允许开发人员在有限成本范围内启动资源，在每个账户创建 Lambda 函数在每个工作日结束时停止运行中的资源，并在工作日开始时恢复。</p>
<p><strong>AWS 预算操作（Budget Actions）</strong></p>
<ul>
<li>AWS 预算不仅可设置预算和警报，还可配置 <strong>预算操作（Budget Actions）</strong>，当预算超支（实际或预测）时自动执行操作，例如：<ul>
<li>应用 IAM 策略，限制特定服务或所有服务的创建操作（如 <code>DenyAll</code> 策略）。</li>
</ul>
</li>
<li>这是 AWS 原生的、低运营开销的自动化成本控制方案。</li>
</ul>
<p><br>884 解决方案架构师正在设计一个三层 Web 应用，架构如下：</p>
<ol>
<li><strong>面向互联网的 ALB</strong>（应用负载均衡器）</li>
<li><strong>Web 层</strong>：在私有子网的 EC2 实例上</li>
<li><strong>应用层</strong>：在私有子网的 EC2 实例上（业务逻辑）</li>
<li><strong>数据库层</strong>：在私有子网的 EC2 实例上运行 Microsoft SQL Server<br>安全性是首要任务。</li>
</ol>
<p>需要选择<strong>三个正确的安全组配置组合</strong>。</p>
<p><strong>选项复述</strong><br>A. <u>为 Web 层配置安全组，允许来自 ALB 安全组的入站 HTTPS 流量</u>。<br>B. 为 Web 层配置安全组，允许向 0.0.0.0&#x2F;0 的出站 HTTPS 流量。<br>C. <u>为数据库层配置安全组，允许来自应用层安全组的入站 Microsoft SQL Server 流量。</u><br>D. 为数据库层配置安全组，允许出站 HTTPS 和 SQL Server 流量流向 Web 层的安全组。<br>E. <u>为应用层配置安全组，允许来自 Web 层安全组的入站 HTTPS 流量</u>。<br>F. 为应用层配置安全组，允许出站 HTTPS 和 SQL Server 流量流向 Web 层的安全组。</p>
<ul>
<li>最小权限原则：只允许必要的流量，使用<strong>安全组 ID 作为源&#x2F;目标</strong>，而不是开放到 0.0.0.0&#x2F;0（除非必要）。</li>
<li>分层架构流量方向：<ol>
<li><strong>客户端 → ALB</strong>（公网）</li>
<li><strong>ALB → Web 层</strong>（HTTPS&#x2F;HTTP）</li>
<li><strong>Web 层 → 应用层</strong>（HTTPS&#x2F;HTTP 或其他应用协议）</li>
<li><strong>应用层 → 数据库层</strong>（SQL Server 端口，如 1433）</li>
</ol>
</li>
</ul>
<p><br>885 公司发布了生产应用新版本，工作负载使用了以下服务：</p>
<ul>
<li><strong>Amazon EC2</strong></li>
<li><strong>AWS Lambda</strong></li>
<li><strong>AWS Fargate</strong></li>
<li><strong>Amazon SageMaker</strong></li>
</ul>
<p>目前使用量已稳定，希望对工作负载进行<strong>成本优化</strong>，且希望<strong>用最少的节省计划覆盖最多的服务</strong>。<br>问哪两种节省计划组合能够满足要求（选择两项）。</p>
<p><strong>选项复述</strong><br>A. 为 Amazon EC2 和 SageMaker 购买 EC2 实例节省计划。<br>B. 为 Amazon EC2、Lambda 和 SageMaker 购买计算节省计划。<br>C. 购买 SageMaker 节省计划。<br>D. <u>为 Lambda、Fargate 和 Amazon EC2 购买计算节省计划</u>。<br>E. <u>为 Amazon EC2 和 Fargate 购买 EC2 实例节省计划。</u></p>
<p><strong>节省计划类型</strong></p>
<ol>
<li><strong>EC2 实例节省计划（EC2 Instance Savings Plans）</strong>：仅适用于特定实例系列和区域的 EC2 使用量（包括 EC2 和 Fargate 的底层 EC2 容量，但不直接覆盖 Lambda 或 SageMaker）。</li>
<li><strong>计算节省计划（Compute Savings Plans）</strong>：适用于 EC2、Fargate、Lambda 的使用量（按 vCPU&#x2F;内存计算部分）。</li>
<li><strong>SageMaker 节省计划（SageMaker Savings Plans）</strong>：仅适用于 SageMaker 使用量。</li>
</ol>
<p><strong>目标</strong>：用最少的节省计划覆盖最多的服务。<br>服务列表：EC2、Lambda、Fargate、SageMaker（共 4 个）。</p>
<p><br>886 公司使用 Microsoft SQL Server 数据库，应用程序均与该数据库连接。<br>希望迁移到 <strong>Amazon Aurora PostgreSQL</strong> 数据库，同时<strong>尽可能减少对应用程序代码的更改</strong>。<br>需要选择<strong>两个步骤组合</strong>来满足要求。</p>
<p><strong>选项复述</strong><br>A. 使用 AWS Schema Conversion Tool（AWS SCT）重写应用程序中的 SQL 查询。<br>B. <u>在 Aurora PostgreSQL 上启用 <strong>Babelfish</strong> 以运行应用程序中的 SQL 查询</u>。<br>C. <u>使用 AWS Schema Conversion Tool（AWS SCT）和 AWS Database Migration Service（AWS DMS）将源数据库架构和数据迁移到 Aurora PostgreSQL。</u><br>D. 使用 Amazon RDS Proxy 将应用程序连接到 Aurora PostgreSQL。<br>E. 使用 AWS DMS 重写应用程序中的 SQL 查询。</p>
<p><strong>关键需求</strong></p>
<ul>
<li>从 <strong>SQL Server</strong> 迁移到 <strong>Aurora PostgreSQL</strong>（不同数据库引擎）。</li>
<li>尽量减少应用程序代码更改 → 意味着最好能让应用程序的 <strong>SQL Server 语法 T-SQL 查询</strong> 在 PostgreSQL 上直接运行，而不需要重写。</li>
</ul>
<p><strong>Babelfish for Aurora PostgreSQL</strong></p>
<ul>
<li>Babelfish 是 Aurora PostgreSQL 的功能，允许数据库理解 <strong>SQL Server 的 T-SQL 语法和通信协议</strong>，从而让为 SQL Server 编写的应用程序几乎无需修改即可连接到 Aurora PostgreSQL。</li>
<li>这是 AWS 专门为减少代码更改提供的解决方案。</li>
</ul>
<p><strong>迁移工具</strong></p>
<ul>
<li><strong>AWS SCT</strong>：用于转换数据库架构（表、视图、存储过程等）从 SQL Server 到 PostgreSQL 兼容格式。</li>
<li><strong>AWS DMS</strong>：用于迁移数据。</li>
</ul>
<p>配合 Babelfish 时，可能仍需要进行一定的架构转换（SCT），然后数据迁移（DMS），但应用代码可以几乎不改（因为 Babelfish 支持 T-SQL）。</p>
<p><br>887 公司计划将一个应用程序重新托管到使用 Amazon EBS 作为附加存储的 EC2 实例上。<br>需要设计一个解决方案，确保：</p>
<ol>
<li><strong>所有新创建的 EBS 卷默认都是加密的</strong></li>
<li><strong>防止创建未加密的 EBS 卷</strong></li>
</ol>
<p>问哪种解决方案能满足这些要求。</p>
<p><strong>选项复述</strong><br>A. <u>配置 EC2 账户属性，使新的 EBS 卷始终处于加密状态。</u><br>B. 使用 AWS Config，配置 <strong>encrypted-volumes</strong> 标识符，应用默认的 AWS KMS 密钥。<br>C. 配置 AWS Systems Manager 以创建 EBS 卷的加密副本，重新配置 EC2 实例以使用加密卷。<br>D. 在 AWS KMS 中创建一个客户管理的密钥，配置 AWS 迁移中心，使其在迁移工作负载时使用该密钥。</p>
<p><strong>AWS 实现强制 EBS 加密的方法</strong><br>最佳实践是：</p>
<ol>
<li>启用 <strong>EBS 加密默认设置</strong>（账户&#x2F;区域级别）。</li>
<li>配合 <strong>IAM 策略</strong>，显式拒绝 <code>CreateVolume</code> 和 <code>RunInstances</code> 操作中 <code>Encrypted=false</code> 的请求，从而强制加密。</li>
</ol>
<p>但题目选项中没有明确提到 IAM 策略，只有 A 最接近，因为启用 EBS 加密默认设置后，即使 API 请求 <code>Encrypted=false</code> 也会被强制加密（根据 AWS 文档，如果启用了默认加密，系统会忽略 <code>Encrypted=false</code> 参数并强制加密）。</p>
<p><br>888 一家电子商务公司希望从其网站收集<strong>用户点击流数据</strong>，用于<strong>实时分析</strong>。<br>特点：</p>
<ul>
<li>一天中流量模式波动较大</li>
<li>需要一个<strong>可扩展</strong>的解决方案以适应不同流量水平</li>
</ul>
<p><strong>选项复述</strong><br>A. <u>在按需模式下使用 <strong>Amazon Kinesis Data Streams</strong> 捕获点击流数据，使用 <strong>AWS Lambda</strong> 实时处理。</u><br>B. 使用 <strong>Amazon Kinesis Data Firehose</strong> 捕获点击流数据，使用 <strong>AWS Glue</strong> 实时处理。<br>C. 使用 <strong>Amazon Kinesis Video Streams</strong> 捕获点击流数据，使用 <strong>AWS Glue</strong> 实时处理。<br>D. 使用 <strong>适用于 Apache Flink 的 Amazon 托管服务（原 Kinesis Data Analytics）</strong> 捕获点击流数据，使用 AWS Lambda 实时处理。</p>
<p><strong>AWS 流数据处理服务对比</strong></p>
<ul>
<li><strong>Kinesis Data Streams</strong>：用于实时流式数据摄取，支持自定义处理（如 Lambda、Kinesis Data Analytics、消费者应用程序）。<strong>按需模式</strong>自动扩展吞吐量，适合流量波动大的场景。</li>
<li><strong>Kinesis Data Firehose</strong>：用于将流数据直接加载到存储（如 S3、Redshift、Elasticsearch）或进行简单转换，不是为复杂实时处理设计的，通常用于近实时批量加载。</li>
<li><strong>Kinesis Video Streams</strong>：专门用于视频和音频流，不适合点击流日志。</li>
<li><strong>适用于 Apache Flink 的托管服务</strong>：用于流处理和分析，但通常作为<strong>处理引擎</strong>，不是数据摄取层。</li>
</ul>
<p><br>889 一家跨国公司在多个 AWS 区域的 Amazon S3 存储桶中存储和分析敏感数据，每天存储数百万个对象。<br>需要<strong>找出所有未启用版本控制的 S3 存储桶</strong>（跨区域）。<br>问哪种解决方案能满足要求。</p>
<p><strong>选项复述</strong><br>A. 设置一个 AWS CloudTrail 事件，该事件包含一条规则，用于识别跨区域所有未启用版本控制的 S3 存储桶。<br>B. <u>使用 <strong>Amazon S3 Storage Lens</strong> 识别跨区域所有未启用版本控制的 S3 存储桶</u>。<br>C. 为 S3 启用 IAM 访问分析器，以识别跨区域所有未启用版本控制的 S3 存储桶。<br>D. 创建一个 S3 多区域访问点，以识别跨区域所有未启用版本控制的 S3 存储桶。</p>
<ul>
<li>S3 Storage Lens 是 AWS 提供的<strong>存储分析和优化仪表板</strong>，支持组织级跨账户、跨区域的 S3 存储可见性。</li>
<li>它包括 <strong>高级指标和筛选功能</strong>，可以检查桶配置（如版本控制、加密、生命周期策略等）并生成报告。</li>
</ul>
<p><br>890 公司需要为一个会生成许多<strong>无法重新创建</strong>的文件（每个约 5 MB）优化 Amazon S3 存储成本。<br>要求：</p>
<ul>
<li>文件必须存储 <strong>4 年后</strong> 才能删除。</li>
<li>文件必须能够<strong>立即访问</strong>。</li>
<li>文件在<strong>创建后前 30 天内频繁访问</strong>，30 天后<strong>很少访问</strong>。</li>
</ul>
<p>需要选择<strong>最具成本效益</strong>的解决方案。</p>
<p><strong>选项复述</strong><br>A. <u>创建 S3 生命周期策略，在对象创建 30 天后将文件移动到 <strong>S3 Glacier Instant Retrieval</strong>，4 年后删除文件</u>。<br>B. 创建 S3 生命周期策略，在对象创建 30 天后将文件移至 <strong>S3 One Zone-IA</strong>，4 年后删除文件。<br>C. 创建 S3 生命周期策略，在对象创建 30 天后将文件移至 <strong>S3 Standard-IA</strong>，4 年后删除文件。<br>D. 创建 S3 生命周期策略，在对象创建 30 天后将文件移至 S3 Standard-IA，4 年后将文件移至 <strong>S3 Glacier Flexible Retrieval</strong>。</p>
<ol>
<li><strong>文件无法重新创建</strong> → 必须保证高耐久性，避免使用单可用区存储（除非接受单 AZ 风险）。</li>
<li><strong>立即访问</strong> → 必须支持毫秒到秒级检索，不能使用需要恢复时间的 Glacier Deep Archive 或 Flexible Retrieval（需要数分钟到数小时）。</li>
<li><strong>访问模式</strong>：<ul>
<li>前 30 天：频繁访问 → 适合 S3 Standard。</li>
<li>30 天后：很少访问，但仍需立即访问 → 适合 <strong>S3 Standard-IA</strong> 或 <strong>S3 Glacier Instant Retrieval</strong>。</li>
</ul>
</li>
<li><strong>存储 4 年</strong> → 需要考虑长期存储成本。</li>
</ol>
<ul>
<li><strong>S3 Standard-IA</strong>：存储费比 Standard 低，但收取检索费（按 GB），适合不常访问但需立即访问的数据。</li>
<li><strong>S3 One Zone-IA</strong>：存储费比 Standard-IA 更低，但数据只存在单可用区，耐久性较低（99.999999999% → 99.999999999% vs 99.999999999%），风险较高。</li>
<li><strong>S3 Glacier Instant Retrieval</strong>：存储费与 Standard-IA 相近或略低，检索时间毫秒级，无检索费（与 Standard-IA 类似收费模式），<strong>对于长期不常访问且需立即检索的数据，通常是成本效益更高的选择</strong>（特别是小文件，检索成本影响小）。</li>
<li><strong>S3 Glacier Flexible Retrieval</strong>：需要数分钟恢复，不满足“立即访问”。</li>
</ul>
<p><br>891 公司在两个 AWS 区域运行关键存储应用，应用使用 <strong>Amazon S3</strong>。<br>要求：</p>
<ol>
<li>应用程序将远程用户数据发送到<strong>最近的 S3 存储桶</strong>，且<strong>不会出现公共网络拥堵</strong>。</li>
<li>应用程序能够<strong>故障转移</strong>，同时<strong>尽可能减少对 S3 的管理工作</strong>。</li>
</ol>
<p><strong>选项复述</strong><br>A. 在两个区域之间实现<strong>双活设计</strong>，将应用程序配置为使用距离用户最近的区域 S3 端点。<br>B. 使用带有 <strong>S3 多区域访问点（Multi-Region Access Points）</strong> 的<strong>主动 - 被动配置</strong>，为每个区域创建一个全局端点。<br>C. 将用户数据发送到离用户最近的区域 S3 终端节点，配置 <strong>S3 跨账户复制规则</strong>（应为跨区域复制）以保持 S3 存储桶同步。<br>D. <u>配置 Amazon S3 使用<strong>多区域访问点</strong>，采用<strong>双活配置并配备单一全局端点</strong>，配置 <strong>S3 跨区域复制</strong>。</u></p>
<p><strong>S3 多区域访问点（MRAP）功能</strong></p>
<ul>
<li>MRAP 提供<strong>单一全局端点</strong>，可将请求自动路由到<strong>延迟最低</strong>的 S3 存储桶（基于 AWS 内部网络测量）。</li>
<li>支持<strong>双活（active-active）配置</strong>，两个区域的桶同时可写，且数据通过 <strong>S3 跨区域复制（CRR）</strong> 自动同步（但 MRAP 本身不处理复制，需单独配置 CRR）。</li>
<li>流量通过 <strong>AWS 骨干网</strong> 传输，避免公共互联网拥堵。</li>
<li>故障转移自动处理（MRAP 根据健康检查自动路由到健康桶）。</li>
<li>减少应用层复杂逻辑（应用只需向一个端点写入）</li>
</ul>
<p><br>892 公司将数据中心从本地迁移到 AWS，有多个<strong>遗留应用</strong>，每个应用托管在<strong>独立的虚拟服务器</strong>上，<strong>无法对应用程序设计进行更改</strong>。<br>目前每个虚拟服务器作为独立的 EC2 实例运行。<br>目标：确保应用程序在迁移到 AWS 后具备<strong>可靠性和容错能力</strong>（即高可用性）。<br>应用将继续在 EC2 实例上运行。</p>
<p><strong>选项复述</strong><br>A. 创建一个最小&#x3D;1、最大&#x3D;1的自动扩展组，为每个应用实例创建一个 AMI，使用该 AMI 在自动扩展组中创建 EC2 实例，配置一个负载均衡器在自动扩展组前。<br>B. 使用 AWS Backup 为每个 EC2 实例创建每小时备份，将备份存储到另一个可用区的 S3，配置灾难恢复流程从最新备份恢复。<br>C. <u>为每个应用实例创建 AMI，从该 AMI 启动两个新的 EC2 实例并放置在不同的可用区，配置网络负载均衡器将这些实例作为目标。</u><br>D. 使用 AWS Migration Hub Refactor Spaces 将应用从 EC2 迁移出去，将应用拆分为独立组件，通过 AWS Fargate 在 ECS 上托管。</p>
<ul>
<li><strong>A</strong>：通过 Auto Scaling 组（min&#x3D;1, max&#x3D;1）可实现实例故障时自动替换，但替换期间服务中断（虽然时间短），不是同时运行的多实例容错。</li>
<li><strong>C</strong>：同时运行两个实例在不同 AZ，提供实时故障转移，真正满足“可靠性和容错能力”。</li>
</ul>
<p>虽然 A 在某些场景被视为基本高可用（通过自动恢复），但 C 更符合通常意义的<strong>高可用（多实例同时活跃）</strong>，且负载均衡器可处理健康检查和故障转移。</p>
<p><br>893 一家公司希望通过为每个工作负载创建一个 AWS 账户来实现工作负载隔离，并且需要：</p>
<ol>
<li>集中管理工作负载的网络组件。</li>
<li>创建具有自动安全控制（防护措施）的账户。</li>
<li>以最低的运营开销满足要求。</li>
</ol>
<p><strong>A.</strong> <u>使用 AWS Control Tower 部署账户。创建一个网络账户，该账户拥有一个带有私有子网和公共子网的 VPC。</u><br><u>使用 AWS 资源访问管理器（AWS RAM）与工作负载账户共享子网。</u></p>
<p><strong>B.</strong> 使用 AWS Organizations 部署账户。创建一个网络账户，该账户拥有一个包含私有子网和公有子网的 VPC。<br>使用 AWS 资源访问管理器（AWS RAM）与工作负载账户共享这些子网。</p>
<p><strong>C.</strong> 使用 AWS Control Tower 部署账户。在每个工作负载账户中部署一个 VPC。<br>通过使用中转网关附件，将每个 VPC 配置为通过检查 VPC 进行路由。</p>
<p><strong>D.</strong> 使用 AWS Organizations 部署账户。在每个工作负载账户中部署一个 VPC。<br>通过使用中转网关连接，将每个 VPC 配置为通过检查 VPC 进行路由。</p>
<ol>
<li>用 Control Tower → 自动安全防护措施+账户部署。</li>
<li>集中网络账户 + AWS RAM 共享子网 → 集中管理网络组件。</li>
<li>相比 Transit Gateway 方案，架构更简单，运营开销最低。</li>
</ol>
<p><br>894 一家公司目前在一个应用程序负载均衡器（ALB）后端的 Amazon EC2 实例上托管了一个静态内容的网站。随着网站流量的增长，公司希望找到一种能够最大限度地降低托管成本的解决方案。</p>
<ul>
<li>流量增长。</li>
<li>目标：<strong>最大限度地降低网站托管成本</strong>。</li>
</ul>
<p><strong>A.</strong> <u>将网站迁移到 Amazon S3 存储桶。为该 S3 存储桶配置 Amazon CloudFront 分发。</u><br><strong>B.</strong> 将网站迁移到 Amazon S3 存储桶。为该 S3 存储桶配置一个 Amazon ElastiCache 集群。<br><strong>C.</strong> 将网站迁移到 AWS Amplify。配置一个应用程序负载均衡器（ALB）以解析到该 Amplify 网站。<br><strong>D.</strong> 将网站迁移到 AWS Amplify。配置 EC2 实例以缓存该网站。</p>
<p><br>895 一家公司正在为其在 AWS 上托管的媒体应用程序实施共享存储解决方案。该公司需要能够使用 SMB 客户端访问存储的数据。</p>
<ol>
<li>为媒体应用程序提供 <strong>共享存储解决方案</strong>。</li>
<li>要求能用 <strong>SMB 客户端</strong> 访问存储的数据（SMB 是 Windows 文件共享常用协议）。</li>
<li>目标：<strong>管理开销最小</strong>（意味着要尽量用 AWS 托管的服务，而不是自己安装配置维护 EC2 实例）。</li>
</ol>
<p><strong>A.</strong> 创建一个 AWS 存储网关卷网关，创建一个使用所需客户端协议的文件共享，将应用服务器连接到该文件共享。<br><strong>B.</strong> 创建一个 AWS 存储网关磁带网关，配置磁带以使用 Amazon S3，将应用服务器连接到磁带网关。<br><strong>C.</strong> 创建一个 Amazon EC2 Windows 实例，在该实例上安装并配置 Windows 文件共享角色，将应用服务器连接到该文件共享。<br><strong>D.</strong> <u>创建一个适用于 Windows 文件服务器的 Amazon FSx 文件系统，将应用服务器连接到该文件系统。</u></p>
<p><br>896 一家公司正在设计生产应用程序的灾难恢复策略。</p>
<ul>
<li>生产环境：<strong>美国东部（us-east-1）</strong> 的 Amazon Aurora MySQL 集群。</li>
<li>灾难恢复区域：<strong>美国西部（us-west-1）</strong>。</li>
<li><strong>RPO ≤ 5 分钟</strong>，<strong>RTO ≤ 20 分钟</strong>。</li>
<li>希望尽量减少配置更改，并且要最高的运营效率。</li>
</ul>
<p>A. 在 us-west-1 创建一个 Aurora 只读副本，其大小与生产集群的写入实例相似。<br>B. <u>将 Aurora 集群转换为 Aurora 全局数据库，配置托管故障转移。</u><br>C. 在 us-west-1 创建一个具有跨区域复制功能的新 Aurora 集群。<br>D. 在 us-west-1 创建一个新的 Aurora 集群，使用 AWS DMS 同步两个集群。</p>
<p>满足 RPO ≤ 5 分钟、RTO ≤ 20 分钟、配置改动少、运营效率最高的方案是 <strong>Aurora 全局数据库 + 托管故障转移</strong>。</p>
<p><br>897 一家公司每周在工作日的第一天之前运行一项关键的数据分析任务。</p>
<ul>
<li>任务 <strong>至少需要 1 小时</strong> 才能完成。</li>
<li>任务 <strong>是有状态的，无法容忍中断</strong>（必须确保不会中途停止）。</li>
<li>需要在 AWS 上运行此任务。</li>
</ul>
<p><strong>问：</strong> 哪种解决方案能满足这些要求？</p>
<p>A. <u>为作业创建一个容器，在 Amazon ECS 上以 AWS Fargate 任务的形式运行，通过 Amazon EventBridge Scheduler 来触发。</u><br>B. 配置作业以在 AWS Lambda 函数中运行，在 Amazon EventBridge 中创建一个计划规则来调用该 Lambda 函数。<br>C. 配置一个运行 Amazon Linux 的 Amazon EC2 Spot 实例的自动扩展组，在实例上配置一个 crontab 条目来运行分析。<br>D. 配置 AWS DataSync 任务以运行作业，配置 cron 表达式以按计划运行该任务。</p>
<ul>
<li>Fargate 是无服务器容器服务，可以运行长时间任务（无时间限制）。</li>
<li>有状态：可搭配持久存储（如 EFS），若任务运行中 Fargate 任务不会被中断（除非底层故障，但可通过重试&#x2F;检查点处理）。</li>
<li>EventBridge Scheduler 可以触发一次性或周期性运行。</li>
</ul>
<p><br>898 一家公司在 AWS 云中运行工作负载，需要集中收集安全数据，以：</p>
<ol>
<li>评估整个公司的安全状况；</li>
<li>加强工作负载保护。<br>希望以<strong>最少的开发工作量</strong>满足要求。</li>
</ol>
<p>A. 在 AWS Lake Formation 中配置数据湖，使用 AWS Glue 爬虫将安全数据接入数据湖。<br>B. 配置一个 AWS Lambda 函数以 .csv 格式收集安全数据，将数据上传到 Amazon S3 存储桶。<br>C. <u>在 Amazon Security Lake 中配置数据湖以收集安全数据，将数据上传至 Amazon S3 存储桶。</u><br>D. 配置 AWS 数据库迁移服务（AWS DMS）复制实例，将安全数据加载到 Amazon RDS 集群中。</p>
<p>专门用于集中收集安全数据、一键配置、最少开发工作量的方案是 <strong>Amazon Security Lake</strong>。</p>
<p><br>899 一家公司正将 5 个本地应用程序迁移到 AWS 的 VPC 中。<br><strong>当前情况</strong>：</p>
<ul>
<li>在本地，这些应用程序部署在<strong>隔离的虚拟网络</strong>中。</li>
<li>在 AWS 中也需要<strong>类似的隔离部署方式</strong>（即每个应用程序有自己的 VPC）。</li>
</ul>
<p><strong>需求</strong>：</p>
<ol>
<li>这些应用程序需要访问一个<strong>共享服务 VPC</strong>（例如放置数据库、身份验证服务等共享组件的 VPC）。</li>
<li><strong>所有应用程序之间必须能够相互通信</strong>（也就是任两个应用程序 VPC 之间要能通信）。</li>
<li>迁移成功后，将对 <strong>100 多个应用程序</strong> 重复此迁移过程。</li>
<li><strong>以最少的管理开销</strong> 满足要求。</li>
</ol>
<p>A. 在应用程序 VPC 与共享服务 VPC 之间部署软件 VPN 隧道，并在应用程序 VPC 的子网中添加路由到共享服务 VPC。<br>B. 在应用程序 VPC 与共享服务 VPC 之间部署 VPC 对等连接，并在应用程序 VPC 的子网中添加通过对等连接的路由到共享服务 VPC。<br>C. 在应用程序 VPC 与共享服务 VPC 之间部署 AWS Direct Connect 连接，并在应用程序 VPC 的子网中添加路由到共享服务 VPC 和其他应用程序 VPC。<br>D. <u>部署一个中转网关，使其与应用程序 VPC 和共享服务 VPC 建立关联，通过中转网关在 VPC 之间添加路由（应用程序 VPC 之间、应用程序 VPC 与共享服务 VPC 之间）。</u></p>
<ul>
<li>创建一个中转网关，将所有 VPC（应用程序 VPC 和共享服务 VPC）连接到它。</li>
<li>在中转网关路由表中配置路由，使 VPC 之间可以互相访问或按需隔离。</li>
<li>扩展性极好：每新增一个 VPC，只需将其附加到中转网关，并更新路由表（通常可以自动化），不用为每对 VPC 单独建连接。</li>
</ul>
<p><br>900 一家公司希望使用 <strong>Amazon ECS</strong> 在混合环境中运行其本地应用程序。</p>
<ul>
<li>应用程序目前在本地的容器中运行。</li>
<li>需要一个<strong>单一的容器解决方案</strong>，能在本地、混合或云环境中扩展（即统一管理）。</li>
<li>必须在 AWS 云中运行新的应用程序容器。</li>
<li>必须为 HTTP 流量使用负载均衡器。</li>
</ul>
<p>问：哪些操作组合能满足这些要求？（选两项。）</p>
<p>A<u>. 为云应用容器设置一个使用 AWS Fargate 启动类型的 ECS 集群；使用 Amazon ECS Anywhere 外部启动类型用于本地应用程序容器。</u><br><u>B. 为云 ECS 服务设置应用程序负载均衡器。</u><br>C. 为云 ECS 服务设置网络负载均衡器。<br>D. 设置一个使用 AWS Fargate 启动类型的 ECS 集群，将 Fargate 用于云应用容器和本地应用容器。<br>E. 为云应用容器设置一个使用 Amazon EC2 启动类型的 ECS 集群，使用 Amazon ECS Anywhere 与 AWS Fargate 启动类型用于本地应用程序容器。</p>
<ul>
<li><strong>单一容器解决方案</strong> 跨本地与云 → 使用 <strong>Amazon ECS Anywhere</strong> 可以在本地服务器上加入 ECS 集群作为外部实例。</li>
<li>云中新容器运行 → 可以用 Fargate 或 EC2 启动类型。</li>
<li><strong>HTTP 流量用负载均衡器</strong> → 需要 ALB（应用负载均衡器）而不是 NLB（网络负载均衡器），因为题目明确要求 HTTP 流量。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T800/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T800/" class="post-title-link" itemprop="url">AWS架构师T800</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T800"><a href="#AWS架构师T800" class="headerlink" title="AWS架构师T800"></a>AWS架构师T800</h1><p><br>701 某城市在 ALB 后部署了一个在 EC2 实例上运行的 Web 应用程序。用户报告了零星的性能问题，似乎与来自随机 IP 地址的 DDoS 攻击有关。需要一个需要最少配置更改并为 DDoS 源提供审计跟踪的解决方案。</p>
<p><strong>选项</strong>：<br>A. 在 ALB 上启用 AWS WAF Web ACL，并配置规则以阻止来自未知来源的流量。<br>B. 订阅 Amazon Check tor。聘请 AWS DDoS 响应团队（DRT）将缓解控制集成到服务中。<br>C<u>. 订阅 AWS Shield Advanced。聘请 AWS DDoS 响应团队（DRT）将缓解控制集成到服务中。</u><br>D. 为应用程序创建 Amazon CloudFront 分发，并将 ALB 设置为源。在发行版上启用 AWS WAF Web ACL，并配置规则以阻止来自未知来源的流量。</p>
<p><br>702 一家公司已将 200 TB 海洋调查数据复制到 AWS Snowball Edge 存储优化设备上，并正在将其寄回 AWS。公司在 AWS 上托管了一个高性能计算（HPC）集群，用于寻找油气矿藏。解决方案架构师必须为该集群提供对数据的稳定亚毫秒级延迟和高吞吐量访问。<br>哪种解决方案能够满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 创建一个 Amazon S3 存储桶，将数据导入该 S3 存储桶。配置 AWS Storage Gateway 文件网关以使用该 S3 存储桶。从 HPC 集群实例访问该文件网关。<br>B. <u>创建一个 Amazon S3 存储桶，将数据导入该 S3 存储桶。配置一个 Amazon FSx for Lustre 文件系统，并将其与 S3 存储桶集成。从 HPC 集群实例访问 FSx for Lustre 文件系统</u>。<br>C. 创建一个 Amazon S3 存储桶和一个 Amazon EFS 文件系统。将数据导入 S3 存储桶，然后将数据从 S3 存储桶复制到 EFS 文件系统。从 HPC 集群实例访问 EFS 文件系统。<br>D. 创建一个 Amazon FSx for Lustre 文件系统。将数据直接导入 FSx for Lustre 文件系统。从 HPC 集群实例访问 FSx for Lustre 文件系统。</p>
<ul>
<li>符合 Snowball 数据导入流程（先到 S3）。</li>
<li>FSx for Lustre 专为 HPC 设计，提供亚毫秒级延迟和高吞吐量。</li>
<li>S3 与 Lustre 集成可实现数据自动同步，避免手动复制。</li>
</ul>
<p><br>703 一家公司在本地数据中心拥有 NFS 服务器，需要·定期将少量数据备份到 Amazon S3。<br>哪种解决方案能满足这些要求，并且最具成本效益？</p>
<p><strong>选项</strong>：<br>A. 设置 AWS Glue，将数据从本地服务器复制到 Amazon S3。<br>B. <u>在本地服务器上设置 AWS DataSync 代理，并将数据同步到 Amazon S3。</u><br>C. 使用 AWS Transfer for SFTP 设置 SFTP 同步，将数据从本地同步到 Amazon S3。<br>D. 在本地数据中心和 VPC 之间建立 AWS Direct Connect 连接，并将数据复制到 Amazon S3。</p>
<p>Direct Connect → 建立专线连接成本高，适合大量持续数据传输，不适合少量定期备份，不具成本效益。</p>
<p>AWS DataSync 代理 → ✅ DataSync 是专门用于在本地存储和 AWS 存储之间同步&#x2F;传输数据的服务，支持 NFS 作为源，S3 作为目标，可设置定时任务，按数据传输量计费，适合少量数据备份，成本效益高。</p>
<p><br>704 一家在线视频游戏公司必须为其游戏服务器维持超低延迟，游戏服务器运行在 EC2 实例上。需要一个能够每秒处理数百万个 UDP 互联网流量请求的解决方案。<br>哪种解决方案能以最具成本效益的方式满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为互联网流量配置具有所需协议和端口的应用程序负载均衡器。指定 EC2 实例作为目标。<br>B. 为互联网流量配置网关负载均衡器。将 EC2 实例指定为目标。<br>C. 为<u>互联网流量配置具有所需协议和端口网络负载均衡器。指定 EC2 实例作为目标。</u><br>D. 在不同的 AWS 区域的 EC2 实例上启动一套相同的游戏服务器。将互联网流量路由到这两套 EC2 实例。</p>
<p>NLB 是 AWS 推荐的用于游戏服务器 UDP 流量负载均衡的服务</p>
<ul>
<li>网关负载均衡器（GWLB）：主要用于将流量转发到第三方虚拟设备（如防火墙、IDS），不适合直接负载均衡游戏服务器。</li>
</ul>
<p><br>705 一家公司在 VPC 中运行三层应用程序，数据库层使用 Amazon RDS for MySQL 数据库实例。计划将 RDS MySQL 迁移到 Amazon Aurora PostgreSQL 数据库集群。需要复制迁移期间发生的数据变更并同步到新数据库。<br>哪些步骤组合可以满足这些要求？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. <u>使用 AWS DMS 的架构转换功能来转换数据库对象。</u><br>B. 使用 AWS DMS 架构转换在 RDS MySQL 数据库实例上创建 Aurora PostgreSQL 只读副本。<br>C. 为 RDS MySQL 数据库实例配置一个 Aurora MySQL 只读副本。<br>D. <u>定义一个带有变更数据捕获（CDC）的 AWS DMS 任务来迁移数据。</u><br>E. 当副本延迟为零时，将 Aurora PostgreSQL 只读副本提升为独立的 Aurora PostgreSQL 数据库集群。</p>
<p>DMS 不能创建只读副本，只读副本是数据库引擎功能（同引擎）。</p>
<p><br>706 一家公司在多可用区部署的 Amazon RDS 实例上运行数据库。定期运行一个脚本来报告数据库中新增的条目，但这个脚本对关键应用程序的性能产生了负面影响。需要在成本最低的情况下提升应用程序性能，并以最少的运营开销满足要求。</p>
<p><strong>选项</strong>：<br>A. 为脚本添加功能，以识别活动连接最少的实例。配置脚本从该实例读取数据，以报告新条目的总数。<br>B. <u>创建数据库的只读副本。配置脚本以仅查询该只读副本来报告新增条目的总数。</u><br>C. 指示开发团队在每天结束时手动导出数据库中当天的新条目。<br>D. 使用 Amazon ElastiCache 缓存脚本对数据库执行的常见查询</p>
<p><br>707 一家公司正在使用应用程序负载均衡器（ALB）向互联网展示其应用程序。发现应用程序存在异常的流量访问模式，解决方案架构师需要提高对基础设施的可见性，以帮助公司更好地了解这些异常情况。<br>满足这些要求的操作效率最高的解决方案是什么？</p>
<p><strong>选项</strong>：<br>A. 在 Amazon Athena 中为 AWS CloudTrail 日志创建一个表，创建一个查询以获取相关信息。<br>B. <u>启用 ALB 对 Amazon S3 的访问日志记录，在 Amazon Athena 中创建一个表，并查询日志。</u><br>C. 启用向 Amazon S3 的 ALB 访问日志记录，在文本编辑器中打开每个文件，并在每行中搜索相关信息。<br>D. 在专用的 Amazon EC2 实例上使用 Amazon EMR 直接查询 ALB 以获取流量访问日志信息。</p>
<ul>
<li>ALB 访问日志提供最相关的流量数据。</li>
<li>Athena 无需基础设施管理，直接对 S3 中的日志执行 SQL 查询，快速高效。</li>
<li>结合 S3 + Athena 是 AWS 推荐的分析 ALB 日志的标准模式。</li>
</ul>
<p><br>708 一家公司希望在其 AWS 环境中使用 NAT 网关。位于私有子网中的 Amazon EC2 实例必须能够通过这些 NAT 网关连接到公共互联网。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在与 EC2 实例相同的私有子网中创建公有 NAT 网关。<br>B. 在与 EC2 实例相同的私有子网中创建私有 NAT 网关。<br>C. <u>在与 EC2 实例相同的 VPC 中的公有子网中创建公有 NAT 网关。</u><br>D. 在与 EC2 实例相同的 VPC 中的公有子网中创建私有 NAT 网关。</p>
<p>是 AWS VPC 网络的标准设计：公有 NAT 网关放置在公有子网，私有子网实例通过它进行出站互联网连接。</p>
<p><br>709 一家公司在 AWS Organizations 中拥有一个组织，在根 OU 的四个 AWS 账户中运行 EC2 实例，包括三个非生产账户和一个生产账户。希望禁止用户在非生产账户中启动特定规格的 EC2 实例，并已创建了一项服务控制策略（SCP）以拒绝启动被禁止实例类型的权限。<br>部署 SCP 的哪些解决方案能够满足这些要求？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. 将 SCP 附加到组织的根 OU。<br>B. <u>将 SCP 附加到三个非生产组织成员账户。</u><br>C. 将 SCP 附加到组织的管理账户。<br>D. 为生产账户创建一个 OU，将 SCP 附加到该 OU，将生产成员账户移入新的 OU。<br>E. <u>为所需账户创建一个 OU，将 SCP 附加到该 OU，将非生产成员账户转移至新的 OU。</u></p>
<p>SCP 可直接附加到账户，仅对这些账户生效，生产账户不受影响。</p>
<ul>
<li>SCP 在 Organizations 中可附加到<strong>根 OU、OU 或直接附加到账户</strong>。</li>
<li>SCP 对附加对象及其下级对象生效。</li>
<li>需求是：非生产账户受限，生产账户不受限。</li>
<li>当前四个账户都在根 OU 下，无额外 OU 结构。</li>
</ul>
<p><br>710 一家公司托管在 EC2 实例上的网站处理存储在 Amazon S3 中的机密数据。出于安全考虑，公司要求在其 EC2 资源与 Amazon S3 之间建立一个私有且安全的连接。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>设置 S3 存储桶策略以允许从 VPC 终端节点进行访问。</u><br>B. 设置 IAM 策略以授予对 S3 存储桶的读写访问权限。<br>C. 设置一个 NAT 网关以访问私有子网外的资源。<br>D. 设置访问密钥 ID 和秘密访问密钥以访问 S3 存储桶。</p>
<p><br>711 一家电子商务公司在 AWS 上运行其应用程序，使用多可用区模式的 Amazon Aurora PostgreSQL 集群作为数据库。在最近促销期间，应用程序承受了巨大的读写负载，用户遇到了超时问题。<br>解决方案架构师需要使应用程序架构更具可扩展性和高可用性，并以最少的停机时间满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 创建一个以 Aurora 集群为源的 Amazon EventBridge 规则，创建一个 Lambda 函数来记录 Aurora 集群的状态变化事件，将该 Lambda 函数添加为 EventBridge 规则的目标，添加额外的读取节点以进行故障转移。<br>B. 修改 Aurora 集群并激活零停机重启（ZDR）功能，使用集群上的数据库活动流来跟踪集群状态。<br>C. <u>向 Aurora 集群添加额外的读取器实例，为 Aurora 集群创建一个 Amazon RDS Proxy 目标组。</u><br>D. 创建一个适用于 Redis 的 Amazon ElastiCache 缓存，使用 AWS DMS 并采用绕写方式将数据从 Aurora 集群复制到 Redis。</p>
<p><br>712 一家公司正在 AWS 上设计一个 Web 应用程序，应用程序将在公司现有数据中心和 VPC 之间使用 VPN 连接。公司使用 Amazon Route 53 作为 DNS 服务，应用程序必须使用私有 DNS 记录从 VPC 与本地服务进行通信。<br>哪种解决方案能以最安全的方式满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>创建一个 Route 53 解析器出站端点，创建一个解析器规则，将该解析器规则与 VPC 关联。</u><br>B. 创建一个 Route 53 Resolver 入站端点，创建一个解析器规则，将该解析器规则与 VPC 关联。<br>C. 创建一个 Route 53 私有托管区域，将该私有托管区域与 VPC 关联。<br>D. 创建一个 Route 53 公共托管区域，为每个服务创建一条记录，以允许服务通信。</p>
<ul>
<li>oute 53 Resolver 出站端点提供从 VPC 到本地 DNS 的安全 DNS 转发（通过 VPN 或 Direct Connect）。</li>
<li>解析器规则可指定特定域名后缀（如 .local）转发到本地 DNS 服务器，确保私有 DNS 查询仅在内部网络传输，安全可靠。</li>
</ul>
<p><br>713 一家公司正在美国东部 1 区运行一个照片托管服务，允许多个国家的用户上传和查看照片。有些照片在数月内被大量浏览，而另一些则在不到一周的时间内被浏览。每张照片上传大小最高为 20 MB。服务利用照片元数据来确定向每位用户展示哪些照片。<br>哪种解决方案能以最具成本效益的方式提供适当的用户访问权限？</p>
<p><strong>选项</strong>：<br>A. 将照片存储在 Amazon DynamoDB 中，开启 DynamoDB 加速器（DAX）以缓存频繁查看的项目。<br>B. <u>将照片存储在 Amazon S3 智能分层存储类别中，将照片元数据及其 S3 位置存储在 DynamoDB。</u><br>C. 将照片存储在 Amazon S3 标准存储类别中，设置 S3 生命周期策略将超过 30 天的照片移至 S3 标准不频繁访问（S3 Standard-IA）存储类别，使用对象标签来跟踪元数据。<br>D. 将照片存储在 Amazon S3 Glacier 存储类别中，设置 S3 生命周期策略将超过 30 天的照片移动到 S3 Glacier Deep Archive 存储类别，将照片元数据及其 S3 位置存储在 Amazon OpenSearch Service 中。</p>
<ul>
<li>S3 智能分层自动监控访问模式，并在 30 天无访问后自动移至不频繁访问层，既节省成本又不影响频繁访问的照片。</li>
<li>DynamoDB 提供低延迟元数据查询，支持快速决定向用户展示哪些照片。</li>
</ul>
<p><br>714 一家公司在应用程序负载均衡器后方的 EC2 实例上运行高可用的 Web 应用程序，使用 Amazon CloudWatch 指标。随着流量增加，一些 EC2 实例因大量未处理的请求而过载。CloudWatch 指标显示，与其他实例相比，部分实例处理的请求数量和接收响应的时间均有所增加。公司不希望将新请求转发给已过载的 EC2 实例。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 基于 RequestCountPerTarget 和 ActiveConnectionCount 这两个 CloudWatch 指标，使用轮询路由算法。<br>B<u>. 基于每个目标的请求数和活跃连接数，使用最少未完成请求算法 CloudWatch 指标。</u><br>C. 基于 RequestCount 和 TargetResponseTime CloudWatch 指标使用轮询路由算法。<br>D. 基于 RequestCount 和 TargetResponseTime CloudWatch 指标使用最少未完成请求算法。</p>
<p>最少未完成请求算法是 ALB 提供的动态负载均衡机制，能实时避免过载实例</p>
<ul>
<li>应用程序负载均衡器（ALB）支持两种负载均衡算法：<ul>
<li><strong>轮询（Round Robin）</strong>：按顺序分发请求，不考虑实例当前负载。</li>
<li><strong>最少未完成请求（Least outstanding requests）</strong>：将新请求发送给当前未完成请求数最少的实例，能动态避免过载实例。</li>
</ul>
</li>
<li>ALB 可基于 CloudWatch 指标监控目标健康状况，但算法本身不直接基于多个 CloudWatch 指标组合决策；不过题目可能意在要求根据实例负载指标<strong>选择合适算法</strong>。</li>
</ul>
<p><br>715 一家公司使用 EC2、Fargate 和 Lambda 运行多个工作负载，希望充分利用其计算节省计划，并希望在节省计划的覆盖率下降时收到通知。<br>哪种解决方案能以最高的运营效率满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>使用 AWS 预算为储蓄计划创建每日预算，为预算配置一个覆盖阈值，以向适当的电子邮件接收者发送通知。</u><br>B. 创建一个 Lambda 函数，针对节省计划生成覆盖率报告，使用 Amazon SES 将该报告通过电子邮件发送给相应的收件人。<br>C. 为节省计划预算创建一份 AWS 预算报告，将频率设置为每日。<br>D. 创建储蓄计划警报订阅，启用所有通知选项，输入接收通知的电子邮件地址。</p>
<ul>
<li><strong>AWS 预算（AWS Budgets）</strong> 支持设置节省计划预算，可配置“覆盖率”阈值并触发警报（如电子邮件、SNS）。</li>
<li>自定义 Lambda 函数可编程实现，但需要开发、部署和维护，运营效率较低。</li>
<li>节省计划本身在 AWS Cost Explorer 中有覆盖率报告，但实时通知需借助预算或自定义方案。</li>
</ul>
<p><br>716 一家公司在 AWS 上运行实时数据接入解决方案，包含最新版本的 Amazon MSK，部署在跨三个可用区的私有子网中的 VPC 内。需要重新设计数据接入解决方案，使其能通过互联网公开访问，同时传输中的数据也必须加密。<br>哪种解决方案能以最高的运营效率满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>在现有 VPC 中配置公共子网，在公共子网中部署 MSK 集群，更新 MSK 集群的安全设置以启用双向 TLS 认证。</u><br>B. 创建一个具有公有子网的新 VPC，在公有子网中部署一个 MSK 集群，更新 MSK 集群的安全设置以启用双向 TLS 认证。<br>C. 部署一个使用私有子网的应用程序负载均衡器（ALB），配置 ALB 安全组入站规则以允许来自 VPC CIDR 块的 HTTPS 协议入站流量。<br>D. 部署一个使用私有子网的网络负载均衡器（NLB），为通过互联网进行的 HTTPS 通信配置一个 NLB 监听器。</p>
<ul>
<li>MSK 本身设计用于私有网络访问，不建议直接暴露到互联网，因为：<ul>
<li>安全风险高，Kafka 协议复杂，直接暴露易受攻击。</li>
<li>AWS 推荐通过负载均衡器或 API 网关等中介公开 Kafka 服务。</li>
</ul>
</li>
<li>传输加密可通过 TLS 实现（MSK 支持 TLS 加密）。</li>
<li>但直接将 MSK 放在公有子网并启用双向 TLS（选项 A&#x2F;B）虽可加密，但<strong>将整个 Kafka 集群暴露在互联网</strong>是高风险且不符合最佳实践，运营效率未必高（需管理大量安全组规则、IP 白名单等）。</li>
<li>最高运营效率方案应利用托管服务或标准模式，如通过 NLB&#x2F;ALB 暴露，而不是重构集群部署。</li>
</ul>
<p><br>717 一家公司希望将本地遗留应用程序迁移到 AWS。该应用程序从本地企业资源规划（ERP）系统获取客户订单文件，然后将这些文件上传到 SFTP 服务器。应用程序使用一个定时任务，每小时检查一次订单文件。<br>公司已有一个能连接到本地网络的 AWS 账户。AWS 上的新应用程序必须支持与现有 ERP 系统的集成，必须安全且具备弹性，必须使用 SFTP 协议来即时处理来自 ERP 系统的订单。</p>
<p><strong>选项</strong>：<br>A. 在两个可用区中创建一个面向互联网的 AWS Transfer Family SFTP 服务器，使用 Amazon S3 存储。创建一个 Lambda 函数来处理订单文件，使用 S3 事件通知将 s3:ObjectCreated:* 事件发送到 Lambda 函数。<br>B. 在一个可用区中创建一个面向互联网的 AWS Transfer Family SFTP 服务器，使用 Amazon EFS 存储。创建一个 Lambda 函数来处理订单文件，使用 Transfer Family 托管工作流来调用该 Lambda 函数。<br>C. 在两个可用区中创建一个 AWS Transfer Family SFTP 内部服务器，使用 Amazon EFS 存储。创建一个 Step Functions 状态机来处理订单文件，使用 EventBridge Scheduler 调用该状态机，以定期检查 Amazon EFS 中的订单文件。<br>D. <u>在两个可用区中创建一个 AWS Transfer Family SFTP 内部服务器，使用 Amazon S3 存储。创建一个 Lambda 函数来处理订单文件，使用 Transfer Family 托管工作流来调用该 Lambda 函数。</u></p>
<ul>
<li>内部 SFTP 服务器通过 VPN&#x2F;Direct Connect 与本地 ERP 安全连接。</li>
<li>多可用区部署确保弹性。</li>
<li>S3 存储高耐久、低成本，且与托管工作流无缝集成。</li>
<li>Transfer Family 托管工作流可在文件上传完成后自动触发 Lambda，实现即时处理，无需轮询。</li>
</ul>
<p><br>718 一家公司的应用程序使用 Apache Hadoop 和 Apache Spark 在本地处理数据。现有基础设施不可扩展且管理复杂。解决方案架构师必须设计一个可扩展的解决方案以降低运营复杂性，但<strong>必须在本地进行数据处理</strong>。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用 AWS 站点到站点 VPN 访问本地 HDFS 的数据和应用程序，使用 Amazon EMR 集群来处理这些数据。<br>B. 使用 AWS DataSync 连接到本地的 HDFS 集群，创建一个 Amazon EMR 集群来处理数据。<br>C<u>. 将 Apache Hadoop 应用程序和 Apache Spark 应用程序迁移到 AWS Outposts 上的 Amazon EMR 集群，使用 EMR 集群来处理数据。</u><br>D. 使用 AWS Snowball 设备将数据迁移到 Amazon S3 存储桶，创建一个 Amazon EMR 集群来处理数据。</p>
<ul>
<li><p>“必须在本地进行数据处理”意味着计算和存储必须留在本地，不能将数据迁移到 AWS 公有云区域进行处理。</p>
</li>
<li><p>但可以借助 AWS 的混合云服务，将 AWS 的计算服务扩展到本地。</p>
</li>
<li><p><strong>AWS Outposts</strong> 是将 AWS 基础设施（计算、存储、数据库等）部署到本地数据中心的解决方案，可运行 Amazon EMR 等 AWS 托管服务，实现本地数据处理，同时享受 AWS 的管理和扩展性。</p>
</li>
<li><p>AWS Outposts 允许在本地运行 Amazon EMR 等 AWS 托管服务，实现数据不出本地，同时享受 AWS 的自动扩展、管理简化等优势。</p>
</li>
</ul>
<p><br>719 一家公司正将大量数据从本地存储迁移到 AWS。同一 AWS 区域内基于 Windows、Mac 和 Linux 的 Amazon EC2 实例将使用 <strong>SMB 和 NFS 存储协议</strong>访问这些数据。公司会定期访问部分数据，而其余数据则很少访问。<br>需要设计一个解决方案来托管这些数据，且运营开销最小。</p>
<p><strong>选项</strong>：<br>A. 创建一个使用 EFS 智能分层的 Amazon EFS 卷，使用 AWS DataSync 将数据迁移到该 EFS 卷。<br>B. <u>创建一个 Amazon FSx for ONTAP 实例，创建一个 FSx for ONTAP 文件系统，使其包含一个使用自动分层策略的根卷，将数据迁移到 FSx for ONTAP 卷中</u>。<br>C. 创建一个使用 S3 智能分层存储的 Amazon S3 存储桶，通过 AWS Storage Gateway Amazon S3 文件网关将数据迁移到该 S3 存储桶。<br>D. 创建一个 Amazon FSx for OpenZFS 文件系统，将数据迁移到新卷。</p>
<ul>
<li><p>FSx for ONTAP 原生支持多协议（SMB 和 NFS），适合混合操作系统环境。</p>
</li>
<li><p>自动分层策略可基于访问频率优化存储成本，符合数据访问模式。</p>
</li>
<li><p><strong>协议要求</strong>：SMB 和 NFS 同时支持 → 仅有部分 AWS 存储服务同时支持两者：</p>
<ul>
<li>Amazon EFS：仅支持 NFS。</li>
<li>Amazon S3：对象存储，不支持原生 SMB&#x2F;NFS（需通过网关转换）。</li>
<li>Amazon FSx for Windows File Server：支持 SMB，不支持 NFS。</li>
<li><strong>Amazon FSx for ONTAP</strong>：支持 SMB 和 NFS 协议，且提供高级存储特性（如自动分层、快照、压缩等）。</li>
</ul>
</li>
<li><p><strong>访问模式</strong>：数据有热有冷 → 需要智能分层功能，自动将不常访问的数据移到低成本层。</p>
</li>
</ul>
<p><br>720 一家制造公司在 AWS 上运行报告生成应用程序，生成每份报告大约需要 20 分钟。应用程序是单体应用，运行在单个 EC2 实例上，需要对其紧密耦合的模块进行频繁更新。每次为软件模块打补丁时，应用程序都会出现停机时间，报告生成在任何中断后都必须从头开始。公司希望重新设计应用程序，使其具有灵活性、可扩展性并能逐步改进，同时最大限度地减少应用程序的停机时间。</p>
<p><strong>选项</strong>：<br>A. 将应用程序作为单个函数在 AWS Lambda 上运行，并配置最大的预置并发量。<br>B. 采用 Spot 队列默认分配策略，在 Amazon EC2 Spot 实例上以微服务形式运行应用程序。<br>C. <u>在 Amazon Elastic Container Service（Amazon ECS）上以微服务形式运行应用程序，并启用服务自动扩展。</u><br>D. 在 AWS Elastic Beanstalk 上以单应用环境运行该应用程序，并采用一次性部署策略。</p>
<p>Spot 实例可能被中断，不适合长时间运行且需稳定性的报告生成任务</p>
<p> Elastic Beanstalk 上以单应用环境运行，一次性部署 → 仍是单体部署，更新时仍有停机时间</p>
<p><br>721 一家公司希望将大规模 Web 应用程序重构为无服务器微服务架构。应用程序目前使用 EC2 实例，用 Python 编写。公司选择了一个组件作为微服务进行测试，该组件每秒支持数百个请求。需要在支持 Python 的 AWS 解决方案上创建和测试该微服务，且必须能够自动扩展，需要最少的基础设施和最少的运营支持。</p>
<p><strong>选项</strong>：<br>A. 使用具有自动扩展功能的 Spot Fleet，其中包含运行最新 Amazon Linux 操作系统的 EC2 实例。<br>B. 使用配置了高可用性的 AWS Elastic Beanstalk Web 服务器环境。<br>C. 使用 Amazon EKS，启动自管理 EC2 实例的自动扩展组。<br>D. <u>使用运行自定义开发代码的 AWS Lambda 函数。</u></p>
<p><br>722 一家公司通过其本地位置与一个 AWS 账户建立了 AWS Direct Connect 连接。该 AWS 账户在同一 AWS 区域中有 30 个不同的 VPC。这些 VPC 使用私有虚拟接口（VIF）。每个 VPC 的 CIDR 块不重叠。<br>公司希望集中管理网络架构，同时仍允许每个 VPC 与所有其他 VPC 及本地网络进行通信。<br>哪种解决方案能满足这些要求且运营开销最少？</p>
<p><strong>选项</strong>：<br>A. <u>创建一个中转网关，并将 Direct Connect 连接与新的中转 VIF 相关联。开启中转网关的路由传输功能。</u><br>B. 创建一个 Direct Connect 网关，重新创建私有 VIF 以使用新网关，通过创建新的虚拟专用网关来关联每个 VPC。<br>C. 创建中转虚拟私有云，将直接连接到中转虚拟私有云，在该区域的所有其他虚拟私有云之间创建对等连接，更新路由表。<br>D. 从本地创建到每个 VPC 的 AWS 站点到站点 VPN 连接，确保每个连接的两个 VPN 隧道都处于 UP 状态，启用路由传播功能。</p>
<p>Transit Gateway 提供中心化、可扩展的互联解决方案。</p>
<ul>
<li><p>只需将每个 VPC 连接到 Transit Gateway，并配置一个 Transit VIF 连接本地网络，即可实现全互联，管理简单，运营开销最小。</p>
</li>
<li><p><strong>集中管理网络枢纽</strong>：AWS Transit Gateway（中转网关）是区域级网络枢纽，可连接多个 VPC 和本地网络（通过 Direct Connect 或 VPN）。</p>
</li>
<li><p><strong>Direct Connect 连接 Transit Gateway</strong>：需通过 <strong>Transit VIF</strong>（虚拟接口）将 Direct Connect 链路关联到 Transit Gateway，并在 Transit Gateway 上启用路由传播。</p>
</li>
<li><p><strong>VPC 间互通</strong>：通过将 VPC 连接到 Transit Gateway，并配置路由表，即可实现 VPC 间通信，无需 VPC 对等连接（对等连接数随 VPC 数呈指数增长，管理复杂）。</p>
</li>
</ul>
<p><br>723 一家公司有在 Amazon EC2 实例上运行的应用程序，这些 EC2 实例通过具有关联策略的 IAM 角色连接到 Amazon RDS 数据库。公司希望使用 AWS Systems Manager 为 EC2 实例打补丁，同时不中断正在运行的应用程序。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 创建一个新的 IAM 角色，将 AmazonSSMManagedInstanceCore 策略附加到新的 IAM 角色，将新的 IAM 角色附加到 EC2 实例和现有的 IAM 角色。<br>B. 创建一个 IAM 用户，将 AmazonSSMManagedInstanceCore 策略附加到该 IAM 用户，配置系统管理器以使用该 IAM 用户来管理 EC2 实例。<br>C. 在 Systems Manager 中启用默认主机配置管理以管理 EC2 实例。<br>D. <u>从现有的 IAM 角色中移除现有策略，将 AmazonSSMManagedInstanceCore 策略添加到现有的 IAM 角色中。</u></p>
<ul>
<li>Systems Manager 需要 EC2 实例关联的 IAM 角色包含 <strong>AmazonSSMManagedInstanceCore</strong> 托管策略（或等效权限），以便 SSM Agent 与 Systems Manager 服务通信。</li>
<li>现有 IAM 角色可能已有其他策略（如 RDS 访问），不能直接移除，否则会影响应用程序运行。</li>
<li>正确做法是<strong>在现有 IAM 角色上添加 AmazonSSMManagedInstanceCore 策略</strong>，而不是创建新角色替换（因为替换角色可能需要实例重启或应用程序重配置）</li>
</ul>
<p><br>724 一家公司使用 Amazon EKS 和 Kubernetes 水平 Pod 自动扩缩器（HPA）运行容器应用程序。一天中工作负载不稳定，当集群中现有节点达到最大容量时，节点数量不会自动扩容，导致性能问题。<br>哪种解决方案能以最少的管理开销解决此问题？</p>
<p><strong>选项</strong>：<br>A. 通过跟踪内存使用情况来扩展节点。<br>B. <u>使用 Kubernetes 集群自动扩缩器来管理集群中的节点数量。</u><br>C. 使用 AWS Lambda 函数自动调整 EKS 集群的大小。<br>D. 使用 Amazon EC2 自动扩展组来分配工作负载。</p>
<p><br>725 一家公司每月在 Amazon S3 标准存储中保持约 300 TB 的数据。每个 S3 对象大小通常在 50 GB 左右，并经常被其全球应用程序通过分片上传（multipart upload）来替换。S3 对象的数量和大小保持不变，但 S3 存储成本每月都在增加。<br>在这种情况下，解决方案架构师应如何降低成本？</p>
<p><strong>选项</strong>：<br>A. 从分片上传切换到 Amazon S3 传输加速。<br>B. <u>启用 S3 生命周期策略以删除不完整的分段上传。</u><br>C. 配置 S3 清单以防止对象过快归档。<br>D. 配置 Amazon CloudFront 以减少存储在 Amazon S3 中的对象数量。</p>
<p><br>726 一家公司已为移动设备部署了一款多人游戏，需要基于纬度和经度对玩家进行实时位置追踪。数据存储必须支持位置的快速更新和检索。<br>游戏使用带有只读副本的 Amazon RDS for PostgreSQL 数据库实例存储位置数据，但在使用高峰期无法维持读写更新所需的性能，且用户群正在迅速增长。<br>解决方案架构师应采取什么措施来提高数据层的性能？</p>
<p><strong>选项</strong>：<br>A. 对现有数据库实例进行快照，启用多可用区恢复快照。<br>B. 从 Amazon RDS 迁移到带有 OpenSearch Dashboards 的 Amazon OpenSearch Service。<br>C. 在现有数据库实例前部署 Amazon DynamoDB 加速器（DAX），修改游戏以使用 DAX。<br>D. <u>在现有数据库实例前部署一个 Amazon ElastiCache for Redis 集群，修改游戏以使用 Redis。</u></p>
<p>DAX 是 DynamoDB 的缓存层，但当前数据存储在 RDS PostgreSQL</p>
<p> OpenSearch 适合全文搜索和分析，但实时高频更新和低延迟点查询可能不是最佳选择</p>
<p><br>727 一家公司在其 AWS 账户的 Amazon DynamoDB 表中存储了关键数据。一名 IT 管理员意外删除了一个 DynamoDB 表，导致大量数据丢失并扰乱运营。公司希望在未来防止此类中断事件的发生。<br>哪种解决方案能以最少的运营开销满足这一要求？</p>
<p><strong>选项</strong>：<br>A. 在 AWS CloudTrail 中配置一条追踪记录，为删除操作创建一个 Amazon EventBridge 规则，创建一个 AWS Lambda 函数来自动恢复已删除的 DynamoDB 表。<br>B. 为 DynamoDB 表创建备份和恢复计划，手动恢复 DynamoDB 表。<br>C. <u>在 DynamoDB 表上配置删除保护。</u><br>D. 启用 DynamoDB 表的时间点恢复功能。</p>
<p><br>728 一家公司的本地数据中心存储容量即将耗尽，希望将其存储基础设施迁移到 AWS，同时最大限度地降低带宽成本。解决方案必须能够立即检索数据，且无需支付额外费用（指检索费用）。<br>如何满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 部署 Amazon S3 Glacier Vault 并启用快速检索，为工作负载启用预置检索容量。<br>B. <u>使用缓存卷部署 AWS 存储网关，使用存储网关将数据存储在 Amazon S3 中，同时保留频繁访问的数据子集的本地副本</u>。<br>C. 使用存储卷部署 AWS 存储网关以在本地存储数据，使用存储网关将数据的时间点快照异步备份到 Amazon S3。<br>D. 部署 AWS Direct Connect 以连接本地数据中心，配置 AWS Storage Gateway 以在本地存储数据，使用 Storage Gateway 将数据的时间点快照异步备份到 Amazon S3。</p>
<ul>
<li><p><strong>AWS Storage Gateway</strong> 提供混合存储方案：</p>
<ul>
<li><strong>文件网关</strong>：提供 SMB&#x2F;NFS 接口，后端存储在 S3，可缓存频繁访问的数据在本地，减少带宽使用。</li>
<li><strong>卷网关</strong>（缓存模式）：本地仅保留频繁访问数据的缓存，完整数据存储在 S3，减少本地存储占用。</li>
</ul>
</li>
<li><p><strong>立即检索 + 无额外检索费</strong> → 排除归档&#x2F;冷存储方案（如 S3 Glacier），因为 Glacier 检索有费用和延迟。</p>
</li>
<li><p><strong>降低带宽成本</strong> → 应尽量减少从 AWS 回拉数据到本地的流量，可通过本地缓存实现。</p>
</li>
</ul>
<p><br>729 一家公司在跨多个可用区的 VPC 中运行一个三层 Web 应用程序，EC2 实例在应用层的自动扩展组中运行。<br>公司需要制定一个自动扩容计划，该计划将分析每种资源的每日和每周历史工作负载趋势，配置必须根据预测和利用率的实时变化对资源进行适当扩容。<br>解决方案架构师应推荐哪种扩展策略来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 基于 EC2 实例的平均 CPU 利用率，通过步进式扩展实现动态扩展。<br>B. <u>启用预测性扩展以进行预测和扩展，通过目标跟踪配置动态扩展。</u><br>C. 根据 Web 应用程序的流量模式创建自动的定时扩展操作。<br>D. 制定简单的扩展策略，根据 EC2 实例的启动时间增加冷却时间。</p>
<ul>
<li>预测性扩展分析每日&#x2F;每周趋势并进行预测扩容。</li>
<li>目标跟踪动态扩展确保在实时利用率偏离预测时仍能及时调整。</li>
</ul>
<p><br>730 一家包裹递送公司的应用程序使用 EC2 实例和 Amazon Aurora MySQL 数据库集群。随着应用程序越来越受欢迎，EC2 实例使用量略有增加，而数据库集群使用量增长更快。公司添加了一个只读副本，短时间内降低了数据库集群的使用率，但负载仍在持续增加。导致数据库集群使用率上升的操作都是与交付详情相关的重复读取语句。需要减轻重复读取对数据库集群的影响，且要求最具成本效益。</p>
<p><strong>选项</strong>：<br>A. <u>在应用程序和数据库集群之间部署一个 Amazon ElastiCache for Redis 集群</u>。<br>B. 为数据库集群添加一个额外的只读副本。<br>C. 为 Aurora 只读副本配置 Aurora 自动扩展。<br>D. 修改数据库集群以拥有多个写入实例。</p>
<ul>
<li>缓存针对重复读取场景效果最显著，可极大降低数据库查询次数。</li>
</ul>
<p><br>731 一家公司有一个使用 Amazon DynamoDB 表进行存储的应用程序。解决方案架构师发现，对该表的许多请求没有返回最新数据。用户没有报告其他数据库性能问题，延迟处于可接受范围内。<br>解决方案架构师应该推荐哪种设计变更？</p>
<p><strong>选项</strong>：<br>A. 为表添加读取副本。<br>B. 使用全局二级索引（GSI）。<br>C. <u>请求对该表进行强一致性读取。</u><br>D. 请求对该表进行最终一致性读取。</p>
<p>DynamoDB 默认提供<strong>最终一致性读取</strong>（Eventually Consistent Reads），这意味着读取操作可能不反映最近完成的写入操作的结果，通常会在一秒内达成一致。</p>
<ul>
<li><strong>强一致性读取</strong>（Strongly Consistent Reads）返回反映所有先前写入操作结果的读取结果，但可能延迟稍高且成本更高。</li>
<li>如果应用程序要求总是读取最新数据，应将读取请求改为强一致性读取。</li>
</ul>
<p><br>732 一家公司已将其应用程序部署在 EC2 实例上，并使用 Amazon RDS 数据库。已采用最小权限原则配置了数据库访问凭证。安全团队希望保护应用程序和数据库免受 SQL 注入及其他基于网络的攻击。<br>哪种解决方案能以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用安全组和网络访问控制列表来保护数据库和                                                                                                                                              应用程序服务器。<br>B. <u>使用 AWS WAF 保护应用程序，使用 RDS 参数组配置安全设置。</u><br>C. 使用 AWS 网络防火墙保护应用程序和数据库。<br>D. 在应用程序代码中为不同功能使用不同的数据库账户，避免向数据库用户授予过多权限。</p>
<p><br>733 一家电子商务公司在 AWS Organizations 中的组织所属的 AWS 账户中运行应用程序，这些应用程序在所有账户的 Amazon Aurora PostgreSQL 数据库上运行。公司需要防止恶意活动，并且必须识别数据库上异常的失败和不完整登录尝试。<br>哪种解决方案能以最具运营效率的方式满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 将服务控制策略（SCPs）附加到组织的根目录，以识别失败的登录尝试。<br>B. <u>在 Amazon GuardDuty 中为组织的成员账户启用 Amazon RDS 保护功能</u>。<br>C. 将 Aurora 通用日志发布到 Amazon CloudWatch Logs 中的日志组，将日志数据导出到中央 Amazon S3 存储桶。<br>D. 将 AWS CloudTrail 中所有的 Aurora PostgreSQL 数据库事件发布到一个中央 Amazon S3 存储桶。</p>
<p>GuardDuty RDS 保护自动分析数据库日志（无需手动启用日志），检测异常登录活动，并通过 GuardDuty 控制台或 CloudWatch 事件告警，运营效率最高。</p>
<p><br>734 一家公司通过 AWS Direct Connect 连接将其企业数据中心与 us-east-1 区的 VPC 相连。最近收购了另一家企业，该企业拥有多个 VPC，并通过 Direct Connect 连接将其本地数据中心与 eu-west-2 区相连。两家公司的 VPC CIDR 块无重叠。需要实现两个区域与数据中心之间的连通性，需要一个具有可扩展性同时能减少运营开销的解决方案。</p>
<p><strong>选项</strong>：<br>A. 在 us-east-1 区域的 VPC 与 eu-west-2 区域的 VPC 之间建立跨区域 VPC 对等连接。<br>B. 从 us-east-1 区域的 Direct Connect 连接创建私有虚拟接口到 eu-west-2 区域的 VPC。<br>C. 在由 Amazon EC2 托管的全网格 VPN 网络中部署 VPN 设备，使用 AWS VPN CloudHub 在数据中心和每个 VPC 之间发送和接收数据。<br>D. <u>将现有的直连连接连接到直连网关，将每个区域中 VPC 的虚拟专用网关路由到 Direct Connect 网关。</u></p>
<ul>
<li>Direct Connect 网关支持跨区域路由，允许多个区域 VPC 通过同一网关与本地数据中心互通。</li>
<li>结合 VGW 或 Transit Gateway（隐含），可简化网络架构，提高可扩展性，降低管理负担。</li>
</ul>
<p><br>735 一家公司正在开发一款移动游戏，会将分数更新流式传输到后端处理器，然后将结果发布到排行榜上。解决方案架构师需要设计一个能够应对大规模流量峰值、按接收顺序处理移动游戏更新，并将处理后的更新存储在高可用数据库中的解决方案。公司还希望尽量减少维护该解决方案所需的管理开销。</p>
<p><strong>选项</strong>：<br>A. <u>将分数更新推送到 Amazon Kinesis Data Streams，使用 AWS Lambda 处理 Kinesis Data Streams 中的更新，将处理后的更新存储在 Amazon DynamoDB 中</u>。<br>B. 将分数更新推送到 Amazon Kinesis Data Streams，使用一组配置了自动扩展的 Amazon EC2 实例处理这些更新，将处理后的更新存储在 Amazon Redshift 中。<br>C. 将分数更新推送到 Amazon SNS 主题，订阅一个 AWS Lambda 函数到该 SNS 主题以处理这些更新，将处理后的更新存储在运行于 Amazon EC2 上的 SQL 数据库中。<br>D. 将分数更新推送到 Amazon SQS 队列，使用一组带有自动扩展功能的 Amazon EC2 实例来处理 SQS 队列中的更新，将处理后的更新存储在 Amazon RDS 多可用区数据库实例中</p>
<ul>
<li>Kinesis Data Streams 专为大规模有序流数据设计。</li>
<li>Lambda 提供无服务器处理，自动扩展，管理开销最小。</li>
<li>DynamoDB 满足高可用、低延迟存储需求，且适合排行榜场景。</li>
</ul>
<p><br>736 一家公司拥有多个 AWS 账户，应用程序部署在 us-west-2 区域，日志存储在每个账户的 Amazon S3 存储桶中。希望构建一个使用单个 S3 存储桶的集中式日志分析解决方案，日志不得离开 us-west-2 区域，且希望将运营开销降至最低，同时最具成本效益。</p>
<p><strong>选项</strong>：<br>A. 创建一个 S3 生命周期策略，将对象从其中一个应用程序 S3 存储桶复制到集中式 S3 存储桶。<br>B. <u>使用 S3 同区域复制将日志从 S3 存储桶复制到 us-west-2 中的另一个 S3 存储桶，使用此 S3 存储桶用于日志分析。</u><br>C. 编写一个脚本，每天使用 PutObject API 操作将存储桶的全部内容复制到位于 us-west-2 的另一个 S3 存储桶，将此 S3 存储桶用于日志分析。<br>D. 在这些账户中编写 AWS Lambda 函数，每当日志被投递到 S3 存储桶时（S3:ObjectCreated:* 事件）就触发，将日志复制到位于 us-west-2 的另一个 S3 存储桶，使用此 S3 存储桶进行日志分析。</p>
<ul>
<li>S3 同区域复制是托管功能，配置简单，自动处理新对象复制。</li>
</ul>
<p><br>737 一家公司拥有一款向全球学生提供按需培训视频的应用程序，也允许授权的内容开发者上传视频。数据存储在 us-east-2 的 Amazon S3 存储桶中。公司在 eu-west-2 和 ap-southeast-1 区域创建了新的 S3 存储桶，希望将数据复制到新存储桶中。需要为在 eu-west-2 和 ap-southeast-1 附近上传视频的开发人员以及流式传输视频的学生最大限度地减少延迟。<br>以下哪组步骤能满足这些要求，同时对应用程序的更改最少？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. 配置从 us-east-2 S3 存储桶到 eu-west-2 S3 存储桶的单向复制，配置从 us-east-2 S3 存储桶到 ap-southeast-1 S3 存储桶的单向复制。<br>B. 配置从 us-east-2 S3 存储桶到 eu-west-2 S3 存储桶的单向复制，配置从 eu-west-2 S3 存储桶到 ap-southeast-1 S3 存储桶的单向复制。<br>C. <u>在所有三个区域的 S3 存储桶之间配置双向复制。</u><br>D. 创建一个 S3 多区域访问点，修改应用程序使其使用多区域访问点的 ARN 进行视频流传输，不要修改用于视频上传的应用程序。<br>E. <u>创建一个 S3 多区域访问点，修改应用程序使其在视频流和上传时使用多区域访问点的 ARN。</u></p>
<p><br>738 一家公司推出了一款新的移动应用程序，用户在世界任何地方都能看到所选主题的本地新闻，还可以在应用内发布照片和视频。<br>用户通常在内容发布后的最初几分钟内访问内容，新内容迅速取代旧内容，然后旧内容就会消失。新闻的本地属性意味着用户消费的 90% 的内容都来自其上传所在的 AWS 区域。<br>哪种解决方案能通过为内容上传提供最低延迟来优化用户体验？</p>
<p><strong>选项</strong>：<br>A. 将内容上传并存储在 Amazon S3 中，使用 Amazon CloudFront 进行上传。<br>B. <u>将内容上传并存储在 Amazon S3 中，上传时使用 S3 传输加速。</u><br>C. 将内容上传到距离用户最近的区域中的 Amazon EC2 实例，将数据复制到 Amazon S3。<br>D. 在离用户最近的区域将内容上传并存储到 Amazon S3 中，使用多个 Amazon CloudFront 分发。</p>
<p>CloudFront 主要用于内容分发（下载），虽然也可用于上传（通过 PUT&#x2F;POST），但并非专为上传优化，且配置复杂</p>
<p><br>739 一家公司正在构建一个采用无服务器架构的新应用程序，包含 Amazon API Gateway REST API 和 AWS Lambda 函数。希望添加一项服务，能够将从 API Gateway REST API 接收到的消息发送到多个目标 Lambda 函数进行处理，且必须提供消息过滤功能，使目标 Lambda 函数能够只接收其所需的消息。要求以最小的运营开销满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 将来自 API Gateway REST API 的请求发送到 Amazon SNS 主题，订阅 Amazon SQS 队列到该 SNS 主题，配置目标 Lambda 函数以轮询不同的 SQS 队列。<br>B. <u>将来自 API Gateway REST API 的请求发送到 Amazon EventBridge，配置 EventBridge 以调用目标 Lambda 函数。</u><br>C. 将来自 API Gateway REST API 的请求发送到 Amazon MSK，配置 Amazon MSK 以将消息发布到目标 Lambda 函数。<br>D. 将来自 API Gateway REST API 的请求发送到多个 Amazon SQS 队列，配置目标 Lambda 函数以轮询不同的 SQS 队列。</p>
<ul>
<li>EventBridge 专为事件路由和过滤设计，支持复杂事件模式匹配。</li>
<li>可轻松将 API Gateway 请求作为事件发送到 EventBridge，再通过规则过滤并调用多个 Lambda 函数。</li>
</ul>
<p>SNS 可广播到多个 SQS 队列，并可配置筛选策略进行过滤，但需管理 SNS 和 SQS</p>
<p><br>740 一家公司将数百万个归档文件迁移到了 Amazon S3。解决方案架构师需要实施一个解决方案，使用客户提供的密钥对所有归档数据进行加密。解决方案必须对现有的未加密对象和未来的对象进行加密。</p>
<p><strong>选项</strong>：<br>A. <u>通过筛选 Amazon S3 清单报告创建未加密对象列表，配置 S3 批处理操作作业，使用客户提供的密钥进行服务器端加密（SSE-C）来加密列表中的对象，配置 S3 默认加密功能使用带有客户端提供密钥的服务器端加密（SSE-C）。</u><br>B. 使用 S3 Storage Lens 指标识别未加密的 S3 存储桶，配置 S3 默认加密功能，以使用带有 AWS KMS 密钥的服务器端加密（SSE-KMS）。<br>C. 通过筛选 Amazon S3 的 AWS 使用报告，创建未加密对象的列表，配置 AWS Batch 作业，使用带 AWS KMS 密钥的服务器端加密（SSE-KMS）对列表中的对象进行加密，配置 S3 默认加密功能，使其使用带 AWS KMS 密钥的服务器端加密（SSE-KMS）。<br>D. 通过筛选 Amazon S3 的 AWS 使用报告创建未加密对象列表，配置 S3 默认加密功能，使用客户提供的密钥进行服务器端加密（SSE-C）。</p>
<ul>
<li><p><strong>加密类型</strong>：SSE-C（Server-Side Encryption with Customer-Provided Keys）允许用户自己管理密钥，上传时提供密钥，S3 使用该密钥加密数据。</p>
</li>
<li><p><strong>现有对象加密</strong>：S3 不直接支持更改已有对象的加密方式，必须重新上传对象并指定加密。可通过 <strong>S3 批处理操作</strong>（S3 Batch Operations）复制对象并应用新加密设置（SSE-C）。</p>
</li>
<li><p><strong>未来对象加密</strong>：可通过 <strong>S3 默认加密</strong>（Bucket Default Encryption）设置，要求所有新上传对象使用 SSE-C（但需注意：SSE-C 要求每次上传都提供密钥，因此默认加密设置 SSE-C 仅适用于通过支持 SSE-C 的上传方式，且需应用端配合）。</p>
</li>
<li><p>S3 清单报告可列出对象及其加密状态，用于筛选未加密对象。</p>
</li>
<li><p>S3 批处理操作可大规模自动化重新加密现有对象为 SSE-C。</p>
</li>
<li><p>S3 默认加密设置 SSE-C 可确保新对象也加密（但需注意 SSE-C 需每次上传提供密钥，可能需客户端配合）。</p>
</li>
</ul>
<p><br>741 托管某公司域名记录的 DNS 提供商正遭遇中断，导致运行在 AWS 上的网站服务受到影响。公司需要迁移到更具弹性的托管 DNS 服务，并且希望该服务运行在 AWS 上。<br>解决方案架构师应如何快速迁移 DNS 托管服务？</p>
<p><strong>选项</strong>：<br>A. <u>为域名创建一个 Amazon Route 53 公共托管区域，导入包含由前提供商托管的域名记录的区域文件。</u><br>B. 为域名创建一个 Amazon Route 53 私有托管区域，导入包含由先前提供商托管的域名记录的区域文件。<br>C. 在 AWS 中创建一个简单的 AD 目录，为域记录启用 DNS 提供商与适用于 Microsoft Active Directory 的 AWS 目录服务之间的区域传输。<br>D. 在 VPC 中创建一个 Amazon Route 53 Resolver 入站端点，指定提供商的 DNS 将 DNS 查询转发到的 IP 地址，配置提供商的 DNS 将该域名的 DNS 查询转发到入站端点中指定的 IP 地址。</p>
<ul>
<li>Route 53 公共托管区域是 AWS 提供的权威 DNS 服务，高可用且弹性。</li>
<li>导入现有区域文件可快速迁移记录，最小化中断时间。</li>
</ul>
<p><br>742 一家公司正在 AWS 上构建一个连接到 Amazon RDS 数据库的应用程序。希望管理应用程序配置，并安全地存储和检索数据库及其他服务的凭据。<br>哪种解决方案能以最少的管理开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>使用 AWS AppConfig 存储和管理应用程序配置，使用 AWS Secrets Manager 存储和检索凭证。</u><br>B. 使用 AWS Lambda 存储和管理应用程序配置，使用 AWS Systems Manager Parameter Store 存储和检索凭证。<br>C. 使用加密的应用程序配置文件，将该文件存储在 Amazon S3 中用于应用程序配置，创建另一个 S3 文件来存储和检索凭据。<br>D. 使用 AWS AppConfig 存储和管理应用程序配置，使用 Amazon RDS 存储和检索凭证。</p>
<ul>
<li><strong>应用程序配置管理</strong>：AWS AppConfig 是专门用于管理应用程序配置的托管服务，支持版本控制、部署验证等。</li>
<li><strong>凭证管理</strong>：AWS Secrets Manager 是专门用于安全存储、轮换和管理凭据的托管服务（如 RDS 数据库密码），可自动轮换并集成 RDS 等。</li>
<li>Systems Manager Parameter Store 也可存储配置和凭据（支持 SecureString），但 Secrets Manager 更专注于凭据管理，且提供自动轮换等高级功能。</li>
</ul>
<p><br>743 为满足安全要求，一家公司需要在与 Amazon RDS MySQL 数据库实例通信时，对所有传输中的应用程序数据进行加密。最近的安全审计显示，已使用 AWS KMS 启用了静态数据加密，但未启用传输中数据的加密。<br>解决方案架构师应采取什么措施来满足安全要求？</p>
<p><strong>选项</strong>：<br>A. 在数据库上启用 IAM 数据库认证。<br>B. 提供自签名证书，在所有与 RDS 实例的连接中使用这些证书。<br>C. 为 RDS 实例创建快照，将快照恢复到启用了加密功能的新实例。<br>D. 下<u>载 AWS 提供的根证书，在与 RDS 实例的所有连接中提供这些证书。</u></p>
<ul>
<li>RDS MySQL 支持 SSL&#x2F;TLS 加密连接，需在客户端连接时使用 SSL 证书。</li>
<li>AWS 为每个区域提供了<strong>根证书</strong>（CA 证书），客户端需配置信任该证书以建立 SSL 连接。</li>
<li>启用传输加密不需要重新创建或恢复实例，只需配置客户端使用 SSL 连接，并确保 RDS 实例已配置为要求或支持 SSL（默认支持</li>
</ul>
<p><br>744 一家公司正在设计一项新的网络服务，将运行在弹性负载均衡器（ELB）后的 Amazon EC2 实例上。然而，许多网络服务客户端只能访问其防火墙授权的 IP 地址。<br>解决方案架构师应该推荐什么来满足客户的需求？</p>
<p><strong>选项</strong>：<br>A. <u>带有关联弹性 IP 地址的网络负载均衡器</u>。<br>B. 带有关联弹性 IP 地址的应用程序负载均衡器。<br>C. Amazon Route 53 托管区域中指向弹性 IP 地址的 A 记录。<br>D. 一个具有公共 IP 地址的 EC2 实例作为代理运行在负载均衡器前面。</p>
<ul>
<li><p>NLB 是第 4 层负载均衡器，支持分配弹性 IP 地址，提供稳定不变的入口 IP，适合防火墙白名单场景。</p>
</li>
<li><p>网络服务在 ELB 后的 EC2 实例上运行。</p>
</li>
<li><p>客户端防火墙只允许访问特定的<strong>授权 IP 地址</strong>（即需要固定的、可预测的入口 IP）。</p>
</li>
<li><p>传统 ELB（ALB&#x2F;NLB）的 IP 地址可能变化，不固定。</p>
</li>
</ul>
<p><br>745 一家公司新创建了一个 AWS 账户，默认设置未做任何更改。公司担心 AWS 账户根用户的安全性。<br>应该采取什么措施来保护根用户？</p>
<p><strong>选项</strong>：<br>A. 为日常管理任务创建 IAM 用户，禁用根用户。<br>B. <u>为日常管理任务创建 IAM 用户，为根用户启用多因素认证。</u><br>C. 为根用户生成访问密钥，使用访问密钥执行日常管理任务，而非 AWS 管理控制台。<br>D. 向最高级别的解决方案架构师提供根用户凭证，让解决方案架构师使用根用户执行日常管理任务。</p>
<p>AWS 安全最佳实践包括：</p>
<ol>
<li><strong>不要使用根用户进行日常操作</strong>，应创建 IAM 用户&#x2F;角色。</li>
<li><strong>为根用户启用多因素认证（MFA）</strong>，增加登录保护。</li>
<li>保存根用户凭证在安全的地方，仅用于必须使用根用户的少数任务（如修改账户设置、恢复 IAM 权限）。</li>
</ol>
<ul>
<li><strong>不能禁用根用户</strong>，因为某些关键账户操作必须使用根用户。</li>
</ul>
<p><br>746 一家公司正在部署一个可近实时处理流数据的应用程序，计划使用 Amazon EC2 实例来处理工作负载。网络架构必须可配置，以提供节点之间尽可能低的延迟。<br>哪种网络解决方案组合能够满足这些要求？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. <u>在每个 EC2 实例上启用并配置增强型联网。</u><br>B. 将 EC2 实例分组到不同的账户中。<br>C. <u>在集群放置组中运行 EC2 实例。</u><br>D. 为每个 EC2 实例附加多个弹性网络接口。<br>E. 使用亚马逊弹性块存储（Amazon EBS）优化的实例类型。</p>
<ul>
<li><strong>低延迟网络优化</strong>：<ul>
<li><strong>增强型联网（Enhanced Networking）</strong>：使用 SR-IOV 技术提高网络性能，降低延迟和抖动，增加吞吐量。</li>
<li><strong>集群放置组（Cluster Placement Group）</strong>：将实例放置在同一个可用区内的低延迟、高带宽网络中，适用于需要紧密节点间通信的应用程序（如 HPC、流处理）。</li>
</ul>
</li>
</ul>
<p><br>747 一家金融服务公司希望关闭两个数据中心，并将超过 100 TB 的数据迁移到 AWS。数据有复杂的目录结构，数百万个小文件存储在深层的子文件夹层级中，大部分数据是非结构化的，文件存储由来自多个供应商的基于 <strong>SMB 的存储类型</strong>构成。公司不希望在迁移后更改其访问数据的应用程序。<br>解决方案架构师应如何以最小的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用 AWS Direct Connect 将数据迁移到 Amazon S3。<br>B. 使用 AWS DataSync 将数据迁移到 Amazon FSx for Lustre。<br>C<u>. 使用 AWS DataSync 将数据迁移到适用于 Windows 文件服务器的 Amazon FSx。</u><br>D. 使用 AWS Direct Connect 将本地文件存储上的数据迁移到 AWS Storage Gateway 卷网关。</p>
<p>现有存储是基于 <strong>SMB</strong> 的多供应商存储（即 Windows 文件共享）</p>
<p><br>748 一家公司使用 AWS Organizations 中的组织来管理包含应用程序的 AWS 账户，并设置了一个专用的监控成员账户。希望通过 Amazon CloudWatch 跨账户查询和可视化可观测性数据。<br>哪种解决方案能够满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>为监控账户启用 CloudWatch 跨账户可观测性，部署一个 AWS CloudFormation 模板，由每个 AWS 账户中的监控账户提供，用于与监控账户共享数据。</u><br>B. 设置服务控制策略（SCP），以在组织根组织单位（OU）下的监控账户中提供对 CloudWatch 的访问权限。<br>C. 在监控账户中配置新的 IAM 用户，在每个 AWS 账户中配置 IAM 策略以使其能够访问、查询和可视化该账户中的 CloudWatch 数据，将新的 IAM 策略附加到新的 IAM 用户。<br>D. 在监控账户中创建一个新的 IAM 用户，在每个 AWS 账户中创建跨账户 IAM 策略，将这些 IAM 策略附加到新的 IAM 用户上。</p>
<ul>
<li>CloudWatch 跨账户可观测性是专门为此场景设计的托管功能，配置简单，管理方便，且与 Organizations 集成良好。</li>
</ul>
<p><br>749 一家公司的网站用于向公众销售产品，运行在 ALB 后的自动扩展组中的 EC2 实例上。有一个 CloudFront 分发，并使用 AWS WAF 防范 SQL 注入攻击。ALB 是 CloudFront 分发的源站。最近安全日志审查发现一个需要被阻止访问网站的外部恶意 IP。<br>解决方案架构师应采取什么措施来保护该应用程序？</p>
<p><strong>选项</strong>：<br>A. 修改 CloudFront 分发上的网络 ACL，为恶意 IP 地址添加一条拒绝规则。<br>B. <u>修改 AWS WAF 的配置，添加 IP 匹配条件以阻止恶意 IP 地址</u>。<br>C. 修改 ALB 后方目标组中 EC2 实例的网络 ACL，以拒绝恶意 IP 地址。<br>D. 修改 ALB 后面目标组中 EC2 实例的安全组，以拒绝恶意 IP 地址。</p>
<ul>
<li>AWS WAF 专为应用层防护设计，支持基于 IP 地址、地理位置、规则等条件阻止请求。</li>
<li>在 CloudFront 的 WAF Web ACL 中添加该恶意 IP 的阻止规则，可有效阻止其访问网站，且不影响合法流量。</li>
</ul>
<p><br>750 一家公司在 AWS Organizations 中设立了一个包含 10 个 AWS 账户的组织。解决方案架构师必须设计一个解决方案，为数千名员工提供这些账户的访问权限。公司拥有一个现有的身份提供商（IdP），并希望使用这个现有的 IdP 进行 AWS 的身份验证。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为所需 AWS 账户中的员工创建 IAM 用户，将 IAM 用户连接到现有的身份提供商，为 IAM 用户配置联合身份验证。<br>B. 使用从现有身份提供商同步的用户电子邮件地址和密码设置 AWS 账户根用户。<br>C. <u>配置 AWS IAM 身份中心（AWS 单点登录），将 IAM 身份中心连接到现有的 IdP，供应来自现有 IdP 的用户和组。</u><br>D. 使用 AWS 资源访问管理器（AWS RAM）与现有 IdP 中的用户共享对 AWS 账户的访问权限。</p>
<ul>
<li>为数千名员工逐个创建 IAM 用户不现实，且难以管理。</li>
<li>AWS IAM Identity Center（原 AWS Single Sign-On）是 AWS 托管的身份中心，支持与外部 IdP 集成（如 SAML 2.0），实现单点登录（SSO）到多个 AWS 账户。</li>
<li>IAM Identity Center 可从现有 IdP 同步用户和组，并允许跨账户分配权限集（基于角色），无需在每个账户单独创建用户。</li>
</ul>
<p><br>751 一位解决方案架构师正在为某公司的 AWS 账户设计 IAM 授权模型。公司已指定五名特定员工拥有对该 AWS 账户中 AWS 服务和资源的完全访问权限。<br>解决方案架构师为五名指定员工中的每一位创建了一个 IAM 用户，并创建了一个 IAM 用户组。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 将 AdministratorAccess 基于资源的策略附加到 IAM 用户组，将五个指定的员工 IAM 用户分别加入该 IAM 用户组。<br>B. 将基于 SystemAdministrator 身份的策略附加到 IAM 用户组，将五名指定员工的 IAM 用户分别加入该 IAM 用户组。<br>C. <u>将 AdministratorAccess 基于身份的策略附加到 IAM 用户组，放置五名指定员工中的每一位 IAM 用户组中的 IAM 用户。</u><br>D. 将基于 SystemAdministrator 资源的策略附加到 IAM 用户组，将五名指定员工的 IAM 用户分别加入该 IAM 用户组。</p>
<ul>
<li>AdministratorAccess 是 AWS 预定义的完全访问托管策略。</li>
<li>将其作为基于身份的策略附加到组，用户加入组后继承权限，管理简单</li>
</ul>
<p><br>752 一家公司拥有一个基于虚拟机（VM）的多层支付处理应用程序，各层之间通过第三方中间件解决方案进行异步通信，该解决方案可确保消息的恰好一次交付。<br>公司需要一种只需最少基础设施管理的解决方案，且必须保证应用程序消息传递的恰好一次交付。<br>哪些操作组合可以满足这些要求？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. <u>在架构的计算层使用 AWS Lambda。</u><br>B. 在架构的计算层使用 Amazon EC2 实例。<br>C. 使用 Amazon SNS 作为计算层之间的消息传递组件。<br><u>D. 使用 Amazon SQS 先进先出队列作为计算层之间的消息传递组件。</u><br>E. 在架构的计算层使用基于 Amazon EKS 的容器。</p>
<ul>
<li><ul>
<li><strong>Amazon SQS FIFO 队列</strong> 提供恰好一次处理和消息去重（通过 Content-Based Deduplication 或 Message Deduplication ID）。</li>
<li>Standard SQS 队列提供至少一次交付（可能重复）。</li>
<li>SNS 不保证恰好一次交付（标准主题是至少一次）。</li>
</ul>
</li>
<li><strong>计算层托管服务</strong>：<ul>
<li><strong>AWS Lambda</strong> 是无服务器计算，自动扩展，无需管理基础设施。</li>
<li>Lambda 可与 SQS FIFO 队列集成，支持恰好一次处理。</li>
<li>EC2 和 EKS 需要更多基础设施管理。</li>
</ul>
</li>
</ul>
<p><br>753 一家公司有一个夜间批处理程序，用于分析本地文件系统每天通过 SFTP 接收的报告文件。希望将此解决方案迁移到 AWS 云平台，解决方案必须具备高可用性和弹性，同时最大限度地减少运营工作。</p>
<p><strong>选项</strong>：<br>A. 部署用于 SFTP 的 AWS Transfer 以及用于存储的 Amazon EFS 文件系统，使用 Amazon 具有计划扩展策略以运行批处理操作的自动扩展组中的 EC2 实例。<br>B. 部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例，使用 Amazon EBS 卷进行存储，使用一个 Auto Scaling 组将最小实例数和期望实例数都设置为 1。<br>C. 部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例，使用 Amazon EFS 文件系统进行存储，使用一个自动扩展组将实例的最小数量和期望数量都设置为 1。<br>D. <u>部署用于 SFTP 的 AWS Transfer 以及用于存储的 Amazon S3 存储桶，修改应用程序将批处理文件从 Amazon S3 拉取到 Amazon EC2 实例进行处理，在具有计划扩展策略的自动扩展组中使用 EC2 实例来运行批处理操作。</u></p>
<ul>
<li><strong>SFTP 服务</strong>：<ul>
<li>AWS Transfer Family 是托管的 SFTP 服务，高可用，无需管理服务器。</li>
<li>自建 EC2 SFTP 服务器需管理可用性、补丁等，运营工作多。</li>
</ul>
</li>
<li><strong>存储</strong>：<ul>
<li>文件存储应持久、可共享（如果批处理在多实例运行）。</li>
<li>Amazon S3 是对象存储，适合存储文件，成本低，高可用，且与 AWS Transfer Family 原生集成。</li>
<li>EFS 是文件存储，也可用，但成本通常高于 S3，且对于批处理场景 S3 更常见。</li>
</ul>
</li>
<li><strong>批处理计算</strong>：<ul>
<li>使用 EC2 自动扩展组 + 计划扩展策略，可在夜间自动启动实例处理，完成后关闭，节省成本。</li>
<li>批处理程序可从 S3 读取文件，处理后将结果写回 S3。</li>
</ul>
</li>
</ul>
<p><br>754 公司有基于 HTTP 的应用程序部署在多个 AWS 区域的 EC2 实例上，要求提高应用程序的可用性与性能，防护常见 Web 攻击，且应用需要静态 IP 地址。</p>
<p><strong>A.</strong> 在每个区域 EC2 实例前放 NLB → NLB 上部署 AWS WAF → 使用 AWS Global Accelerator 创建加速器并将 NLB 注册为端点。<br><strong>B.</strong> <u>在每个区域 EC2 实例前放 ALB → ALB 上部署 AWS WAF → 使用 AWS Global Accelerator 创建加速器并将 ALB 注册为端点。</u><br><strong>C.</strong> 在每个区域 EC2 实例前放 NLB → NLB 上部署 AWS WAF → 创建 CloudFront 分发，源站用 Route 53 基于延迟路由到 NLB。<br><strong>D.</strong> 在每个区域 EC2 实例前放 ALB → 创建 CloudFront 分发，源站用 Route 53 基于延迟路由到 ALB → 在 CloudFront 分发上部署 AWS WAF。</p>
<ol>
<li><strong>应用类型与性能&#x2F;可用性要求</strong><ul>
<li>应用基于 HTTP → 适合 ALB（应用层负载均衡）或 CloudFront（CDN）。</li>
<li>需要<strong>静态 IP 地址</strong>：Global Accelerator 可提供静态 IP（Anycast IP），而 CloudFront 不提供静态 IP。</li>
</ul>
</li>
<li><strong>WAF 部署位置</strong><ul>
<li>AWS WAF 可部署在 CloudFront、ALB、API Gateway，<strong>但不能直接部署在 NLB</strong>（NLB 工作在第四层，不支持 WAF）。因此 A 和 C 中“在 NLB 上部署 AWS WAF”是<strong>错误</strong>的。</li>
</ul>
</li>
<li><strong>多区域流量分发</strong><ul>
<li>Global Accelerator 提供跨区域的流量负载均衡与静态 IP，且自动根据健康检查和延迟路由。</li>
<li>CloudFront + Route 53 基于延迟路由也可实现类似跨区域路由，但 CloudFront 是 CDN，用于缓存和边缘优化，不提供静态 IP 给源站访问。</li>
</ul>
</li>
</ol>
<p><br>755 当前架构：Aurora MySQL，多可用区、多只读副本、多数据库实例。</p>
<ul>
<li>问题：连接数过多错误；另外，希望故障转移时间缩短 20%（特指只读副本提升为写入器时的故障转移）。</li>
</ul>
<p><strong>选项：</strong><br>A. 从 Aurora 切换到采用多可用区集群部署的 Amazon RDS。<br>B<u>. 在 Aurora 数据库前使用 Amazon RDS Proxy。</u><br>C. 切换到 Amazon DynamoDB 并使用 DynamoDB 加速器（DAX）处理读取连接。<br>D. 切换到具有重定位功能的 Amazon Redshift。</p>
<p>RDS Proxy 是专门为 Aurora &#x2F; RDS 设计的连接池服务，能有效限制对数据库的连接数、复用连接，并且能在故障转移时保持客户端连接，从而减少故障转移时间。</p>
<p><br>756 文本文件存储在 S3，包含聊天消息、时间信息和客户 PII。</p>
<ul>
<li>需要给外部服务商提供随机样本（含最新对话）。</li>
<li>不能共享 PII。</li>
<li>可扩展（随对话数量增加）。</li>
<li>运营开销最小。</li>
</ul>
<p><strong>选项复述：</strong><br>A. <u>创建一个对象 Lambda 访问点，配一个 Lambda 函数在读取时编辑 PII。</u><br>B. 在 EC2 上做批处理，定期读取新文件、编辑 PII、写到另一个桶，让服务商访问这个桶。<br>C. 在 EC2 上建 Web 应用，展示文件列表、编辑 PII、允许服务商下载编辑后的文件。<br>D. 建 DynamoDB 表 + Lambda 函数（被 S3 触发），只提取非 PII 数据存到 DynamoDB，让服务商访问 DynamoDB。</p>
<p><br>757 有一个在 Amazon EC2 上运行的遗留系统。</p>
<ul>
<li>应用程序代码不能修改。</li>
<li>系统不能在多个实例上运行（即不支持分布式&#x2F;多实例负载均衡）。</li>
<li>目标：设计一个<strong>有弹性</strong>的解决方案，<strong>缩短系统的恢复时间</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 为 EC2 实例启用终止保护。<br>B. 为 EC2 实例配置多可用区部署。<br>C<u>. 创建一个 Amazon CloudWatch 告警，以便在发生故障时恢复 EC2 实例</u>。<br>D. 启动带有两个 EBS 卷并使用 RAID 配置以实现存储冗余的 EC2 实例</p>
<p><br>758  容器化应用工作负载。</p>
<ul>
<li>部署在跨三个可用区的 VPC。</li>
<li>需要高可用性（跨可用区）。</li>
<li>对应用程序改动要求最小。</li>
<li>运营开销最低。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>使用 Amazon ECS，配置 ECS 服务自动扩展（目标跟踪），最小容量&#x3D;3，任务放置策略设置为基于可用区属性的扩散策略。</u><br>B. 使用 Amazon EKS 自管理节点，配置应用程序自动扩展（目标跟踪），最小容量&#x3D;3。<br>C. 使用 Amazon EC2 预留实例，在分散放置组中启动三个 EC2 实例，配置自动扩展组（目标跟踪），最小容量&#x3D;3。<br>D. 使用 AWS Lambda 函数，连接到 VPC，配置应用程序自动扩展，将 Lambda 用作可扩展目标，最小容量&#x3D;3。</p>
<ul>
<li>ECS（尤其是 Fargate 启动类型）无需管理节点，任务跨 AZ 分布由服务调度完成，对应用几乎无修改。</li>
<li>选项 A 虽然没有明说 Fargate，但 ECS 可以搭配 Fargate 使用（默认可能 EC2 启动类型，但可以推断为 Fargate 以降低运营开销）。</li>
<li>EKS 自管理节点（B）需要管理节点组，运营开销高。</li>
<li>EC2 预留实例（C）需要自己管理一切，最高。</li>
<li>Lambda（D）虽然无服务器，但不适合直接部署容器化应用（除非应用已经改造成函数）。</li>
</ul>
<p><br>759 媒体公司，电影存储在 S3（每个电影一个视频文件，1–10 GB）。</p>
<ul>
<li>要求：用户购买后 5 分钟内能开始流媒体播放。</li>
<li>20 年内的电影需求高（较新），20 年以上的需求较低（较旧）。</li>
<li>目标：根据需求将托管服务成本降至最低。</li>
</ul>
<p><strong>选项：</strong><br>A. 所有媒体存 S3 标准，根据需求下降用生命周期策略移到低频访问层。<br>B. <u>新电影存 S3 标准，旧电影存 S3 标准不频繁访问（Standard-IA），用户订购旧电影时用标准检索。</u><br>C. 新电影存 S3 智能分层，旧电影存 S3 Glacier 灵活检索，订购旧电影时用加急检索。<br>D. 新电影存 S3 标准，旧电影存 S3 Glacier 灵活检索，订购旧电影时用批量检索。</p>
<ul>
<li>Standard-IA 适用于需要快速访问但不频繁访问的数据，取回无延迟，成本比 Standard 低。</li>
<li>Glacier 灵活检索虽然存储成本更低，但需要检索时间与费用，若每次旧电影播放都用加急检索则成本可能高于 Standard-IA。</li>
</ul>
<p><br>760 供应商提供的是 Docker 容器镜像。</p>
<ul>
<li>容器需要 50 GB 存储空间来存放临时文件。</li>
<li>基础设施必须是无服务器（serverless）。</li>
<li>运营开销最小。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 Lambda 函数，使用 Docker 容器镜像，挂载超过 50 GB 的 S3 卷。<br>B. 用 Lambda 函数，使用 Docker 容器镜像，挂载超过 50 GB 的 EBS 卷。<br>C. <u>创建使用 AWS Fargate 启动类型的 ECS 集群，为容器镜像创建一个任务定义，带有 Amazon EFS 卷，然后创建服务。</u><br>D. 创建使用 EC2 启动类型的 ECS 集群，配备 EBS 卷超过 50 GB，再创建任务定义和服务。</p>
<p>Fargate + EFS）：只需定义任务和服务，不需要管理节点，存储由 EFS 托管，完全无服务器。</p>
<p><br>761 公司需要用本地 LDAP 目录服务来<strong>对访问 AWS 管理控制台的用户进行身份验证</strong>。<br>LDAP 与 SAML <strong>不兼容</strong>。</p>
<p><strong>选项：</strong><br>A. <u>在 AWS 和本地 LDAP 之间启用 AWS IAM 身份中心（AWS 单点登录）</u>。<br>B. 创建一个使用 AWS 凭证的 IAM 策略，并将该策略集成到 LDAP 中。<br>C. 建立一个流程，在 LDAP 凭据更新时轮换 IAM 凭据。<br>D. 开发一个本地自定义身份代理应用程序或流程，使用 AWS STS 来获取短视频服务（原文疑为“获取短期凭证”的笔误）。</p>
<ul>
<li>AWS IAM 身份中心支持连接到外部身份源（如本地 AD 或 LDAP），通过 SCIM 同步用户&#x2F;组，并且支持为这些用户分配 AWS 账户访问权限。</li>
<li>但 IAM 身份中心的“外部身份源”连接方式中，LDAP 可以通过 AWS 提供的“内置身份源”连接（需要安装连接器代理在本地），从而实现用 LDAP 登录 AWS 管理控制台，这不需要 SAML。</li>
</ul>
<p><br>762 公司有多个 AMI 存储在<strong>一个 AWS 账户</strong>中，这些 AMI 含有关键数据和配置。需要一种方案，能够在 AMI 被意外删除时<strong>快速高效地恢复</strong>，且<strong>运营开销最少</strong>。</p>
<p><strong>选项：</strong><br>A. 创建 Amazon EBS 快照的 AMI，将快照存储在单独的 AWS 账户中。<br>B. 定期将所有 AMI 复制到另一个 AWS 账户。<br>C. <u>在回收站中创建保留规则。</u><br>D. 将 AMI 上传到具有跨区域复制功能的 Amazon S3 存储桶。</p>
<p><br>763 数据量：150 TB（150 太字节）</p>
<ul>
<li>时间要求：1 个月内迁移完成</li>
<li>当前网络：仅夜间可用，速度最高 100 Mbps（兆比特每秒）用于上传</li>
</ul>
<p><strong>选项：</strong><br>A. 使用 AWS Snowmobile<br>B. <u>订购多台 AWS Snowball</u><br>C. 启用 S3 传输加速并安全上传<br>D. 创建 S3 VPC 终端节点并建立 VPN 来上传</p>
<ul>
<li><strong>. Snowmobile</strong>：是 100 PB 级数据卡车，适合 EB 级，150 TB 虽然可用，但通常最小使用量更大，且成本可能高于 Snowball。</li>
<li><strong>B. Snowball</strong>：每台 Snowball Edge Storage Optimized 容量 80 TB 可用容量（实际设备容量更大但可用 80 TB），150 TB 需要至少 2 台（可能需要 3 台考虑冗余和效率），可以在一个月内寄送、拷贝、寄回，成本比 Snowmobile 更适合百 TB 级。</li>
</ul>
<p><br>764 三层应用（Web、应用、数据库）从本地迁移到 AWS。</p>
<ul>
<li>原来：Web 层和应用层运行在第三方虚拟机，数据库是 MySQL。</li>
<li>目标：迁移时<strong>尽可能少改变架构</strong>；</li>
<li>数据库需要<strong>能将数据恢复到特定时间点</strong>；</li>
<li>运营开销最少。</li>
</ul>
<p><strong>选项：</strong><br>A. Web 和 App 迁移到私有子网中的 EC2，数据库迁移到私有子网中的 RDS for MySQL。<br>B. <u>Web 层迁移到公共子网的 EC2，App 迁移到私有子网的 EC2，数据库迁移到私有子网中的 <strong>Aurora MySQL</strong>。</u><br>C. Web 层迁移到公共子网的 EC2，App 迁移到私有子网的 EC2，数据库迁移到私有子网中的 <strong>RDS for MySQL</strong>。<br>D. Web 和 App 迁移到公共子网的 EC2，数据库迁移到公共子网中的 Aurora MySQL。</p>
<p><strong>Aurora MySQL</strong> 作为 RDS 的增强版，性能更高，自动扩展存储，备份与恢复也方便，但可能比 RDS MySQL 稍微成本高些，但运营开销类似且更现代化</p>
<p><br>765 两个公司：开发团队（账户 A）和另一家公司（账户 B）。</p>
<ul>
<li>账户 B 需要访问账户 A 中的 SQS 队列（轮询）。</li>
<li>账户 B 不能放弃自身账户的权限（意思是账户 B 仍然使用自己的 IAM 身份，而不是账户 A 的 IAM 用户角色）。</li>
</ul>
<p><strong>选项</strong><br>A. 创建实例配置文件，为另一家公司提供对 SQS 队列的访问权限。<br>B. 创建 IAM 策略，为另一家公司提供对 SQS 队列的访问权限。<br>C. <u>创建 SQS 访问策略，为另一家公司提供对 SQS 队列的访问权限。</u><br>D. 创建 SNS 访问策略，为另一家公司提供对 SQS 队列的访问权限</p>
<p><strong>跨账户访问 SQS 队列</strong></p>
<ul>
<li>SQS 支持基于资源的策略（队列策略），允许其他 AWS 账户或 IAM 用户访问该队列。</li>
<li>这是在 SQS 队列本身上附加的策略（类似 S3 存储桶策略），而不是在对方账户创建 IAM 策略</li>
</ul>
<p><br>766 开发人员需要安全地 SSH 访问运行 Amazon Linux 的 EC2 实例。</p>
<ul>
<li>开发人员有时远程工作，有时在公司办公室。</li>
<li>EC2 实例在<strong>私有子网</strong>中，通过 NAT 网关访问互联网。</li>
<li>使用 AWS 服务作为解决方案的一部分。</li>
<li>要求<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 在与 EC2 实例相同的子网中创建堡垒主机，给开发人员 ec2:CreateVpnConnection 权限，安装 EC2 Instance Connect 供连接。<br>B. 建立公司网络与 VPC 之间的站点到站点 VPN，开发人员在公司时用此 VPN 访问，远程时另外再建一个 VPN 连接。<br>C. 在公有子网中创建堡垒主机，配置安全组和 SSH 密钥仅允许公司网络和远程网络的连接，开发人员通过堡垒主机 SSH 到 EC2 实例。<br>D. <u>将 AmazonSSMManagedInstanceCore IAM 策略附加到 EC2 实例的 IAM 角色，指示开发人员使用 AWS Systems Manager Session Manager 访问 EC2 实例。</u></p>
<ol>
<li><strong>安全与成本效益</strong><br>传统方案：堡垒主机（C）需要管理主机、安全组、密钥、暴露 SSH 到公网（虽然限制 IP），但远程工作时可能需要动态 IP 或额外 VPN，增加了管理复杂性和潜在安全风险。<br>站点到站点 VPN（B）需要管理 VPN 连接，且远程工作时还要另一个 VPN（如客户端 VPN），成本高且管理复杂。</li>
<li><strong>AWS 现代最佳实践</strong><br>AWS Systems Manager Session Manager 提供无堡垒主机、无需开放入站端口、通过 IAM 控制访问的 SSH&#x2F;RDP 替代方案，既安全又成本低（无需额外 EC2 实例做堡垒，只需 SSM Agent 和 IAM 策略）。<br>题目要求 EC2 实例是 Amazon Linux 最新版（已经内置 SSM Agent 或可轻松安装），且实例在私有子网但有 NAT 网关，可以连接到 SSM 服务端点（公有或通过 VPC 端点）。</li>
</ol>
<p><br>767 制药公司，新药研发。</p>
<ul>
<li>数据量指数增长，存在本地存储阵列。</li>
<li>需求：研究人员经常需要立即获取整个数据集的<strong>一个子集</strong>，延迟尽可能小（性能要求高）。</li>
<li>整个数据集不需要每天访问（说明大部分数据不常访问）。</li>
<li>公司希望减少持续的资本支出（CapEx），即想从本地存储转到云上运营支出（OpEx）。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 AWS DataSync 作为计划的 cron 作业，持续将数据迁移到 Amazon S3。<br>B. 部署 AWS 存储网关文件网关，目标存储为 S3，将数据迁移到存储网关设备。<br>C. <u>部署 AWS 存储网关卷网关（缓存卷），目标存储为 S3，将数据迁移到存储网关设备。</u><br>D. 配置站点到站点 VPN，将数据迁移到 Amazon EFS。</p>
<ul>
<li>文件网关：适合文件（NFS&#x2F;SMB）访问场景，缓存频繁访问数据。</li>
<li>卷网关缓存卷：适合需要保持完整卷语义的场景（如备份、灾难恢复），也可以缓存频繁读取的数据。</li>
</ul>
<p><br>768  应用运行在 EC2，数据存储在 DynamoDB 表。</p>
<ul>
<li>需要<strong>能将表恢复到过去 24 小时内的任何时间点</strong>。</li>
<li>要求<strong>运营开销最小</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>为该表配置时间点恢复（PITR）。</u><br>B. 为该表使用 AWS Backup。<br>C. 使用 Lambda 函数每小时对表进行按需备份。<br>D. 开启表上的流，捕获 24 小时内的更改日志，将流副本存到 S3</p>
<ul>
<li>DynamoDB 原生提供 PITR（时间点恢复），开启后可以恢复到过去 35 天内的任意一秒（满足 24 小时要求）。</li>
</ul>
<p>AWS Backup 可以实现计划备份，但 PITR 是自动持续备份，精度更高（秒级），恢复更快，且无需配置备份频率、保留策略等，更贴合“运营开销最小”</p>
<p><br>769 应用将文件上传到 S3。</p>
<ul>
<li>上传后需处理（提取元数据），处理时间 &lt; 5 秒。</li>
<li>上传数量和频率不定：有时每小时几个，有时数百个并发上传。</li>
<li>要求架构<strong>成本效益</strong>且符合需求。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 CloudTrail 记录 S3 API 调用，用 AWS AppSync 处理文件。<br>B. <u>在 S3 配置对象创建事件通知，调用 Lambda 函数处理文件。</u><br>C. 配置 Kinesis Data Streams 处理数据并发送到 S3，再调用 Lambda 处理。<br>D. 配置 SNS 主题来处理上传到 S3 的文件，调用 Lambda 处理</p>
<p><br>770 应用部署在 EC2 实例上，同时使用 Lambda（事件驱动部分）。</p>
<ul>
<li>有生产环境（一个 AWS 账户）和非生产开发环境（另一个账户）。</li>
<li>生产环境因为客户在多个时区，使用量稳定。</li>
<li>非生产环境仅工作日营业时间使用（周一至周五白天），周末不用。</li>
<li>目标：<strong>优化成本，最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 生产实例用按需实例；非生产实例仅在周末用专用主机（矛盾：非生产周末不用，怎么会用专用主机？不合理）。<br>B. 生产实例和非生产实例都用预留实例（RI），不使用时关闭非生产实例。<br>C<u>. 生产实例用计算节省计划；非生产实例用按需实例，不使用时关闭非生产实例。</u><br>D. 生产实例用专用主机；非生产实例用 EC2 实例节省计划。</p>
<p>计算节省计划（Compute Savings Plans）可以跨实例类型、区域（同一账户）灵活应用，适合生产稳定负载；非生产用按需 + 启停是最省钱的方式，因为只在需要时付费。</p>
<p><br>771 数据存储在本地 Oracle 关系数据库。</p>
<ul>
<li>需要在 Amazon Aurora PostgreSQL 中可用（用于分析）。</li>
<li>已有站点到站点 VPN 连接本地与 AWS。</li>
<li>要求：在迁移到 Aurora PostgreSQL 期间，<strong>捕获源数据库发生的变化</strong>（即迁移过程中新产生的变更也要同步到目标库，保证数据一致性）。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 AWS SCT 转换模式，用 AWS DMS 全量加载迁移任务迁移数据。<br>B. 用 AWS DataSync 迁移数据到 S3，再用 Aurora PostgreSQL 的 aws_s3 扩展导入。<br>C. <u>用 AWS SCT 转换模式，用 AWS DMS 迁移现有数据并复制持续的变更（变更数据捕获，CDC）。</u><br>D. 用 AWS Snowball 迁移数据到 S3，再用 aws_s3 扩展导入。</p>
<ul>
<li>需要将 Oracle 转为 PostgreSQL（模式转换） → SCT 可以实现。</li>
<li>需要在迁移过程中捕获源库的变化 → 需要 CDC（变更数据捕获）能力，否则迁移期间的新事务会丢失。</li>
</ul>
<p>DMS 支持从 Oracle 到 Aurora PostgreSQL 的 CDC 复制，且 SCT 可辅助转换不兼容的 schema 对象</p>
<p><br>772 应用程序用 Docker 容器构建，需要在 AWS 云中运行。</p>
<ul>
<li>希望用托管服务。</li>
<li>必须根据容器服务需求自动扩缩容。</li>
<li>不得导致额外的运营开销或需要管理的基础设施 → 这表示**无服务器（serverless）**方式。</li>
</ul>
<p><strong>选项（选两个）：</strong><br>A. <u>使用带有 AWS Fargate 的 Amazon ECS。</u><br><u>B. 使用带有 AWS Fargate 的 Amazon EKS</u>。<br>C. 配置 Amazon API Gateway + AWS Lambda 以运行容器。<br>D. 使用带有 Amazon EC2 工作节点的 Amazon ECS。<br>E. 使用带有 Amazon EC2 工作节点的 Amazon EKS。</p>
<p>Fargate 是 AWS 的无服务器容器计算引擎，可与 ECS 或 EKS 配合，无需管理节点，自动扩缩。</p>
<p><br>773 电子商务公司，季节性促销活动。</p>
<ul>
<li>网站部署在多可用区的 EC2 实例。</li>
<li>需要应对促销期间突增的流量。</li>
<li>要求：最具成本效益。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建一个足够大的 ASG 应对峰值负载，但<strong>停止一半实例</strong>，流量增加时用<strong>已停止的实例</strong>扩展。<br>B. 创建 ASG，最小规模就设为能处理高峰流量，无需横向扩展。<br>C. 使用 CloudFront + ElastiCache 缓存动态内容，ASG 做源，先启动实例填充缓存，填充后缩减。<br>D<u>. 配置 ASG 横向扩展，并创建启动模板来启动新实例</u>。</p>
<ul>
<li>D 是标准做法：配置 ASG 横向扩展 + 启动模板。按需求自动启动新实例，用完后自动缩减。</li>
<li>这是 AWS 推荐应对突发流量的方式，按使用付费，最具成本效益（无需预先保留过多容量）。</li>
</ul>
<p><br>774 合规政策：安全组不能包含允许从 <code>0.0.0.0/0</code> 进行 SSH（端口 22）的规则。</p>
<ul>
<li>如果有违规，公司需要收到通知。</li>
<li>需要尽快提供<strong>自动化</strong>解决方案，且<strong>运营开销最少</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>写一个 Lambda 脚本监控安全组是否有 0.0.0.0&#x2F;0 SSH 开放，每次发现时发送通知。</u><br><u>B. 启用 AWS Config 托管规则（受限 SSH），当创建不合规资源时生成 SNS 通知</u>。<br>C. 创建一个 IAM 角色（权限为全局开放安全组和网络 ACL 权限），并设置 SNS 主题，每当用户承担该角色时发送通知。<br>D. 配置服务控制策略（SCP）禁止非管理员创建或编辑安全组，用户请求管理员权限时在工单系统创建通知。</p>
<ul>
<li>AWS Config 持续监控资源配置变化和历史合规状态，当安全组规则违规时会触发通知。</li>
</ul>
<p><br>775 应用部署在<strong>一个 AWS 账户</strong>中，由运行在 Lambda 和 EKS 上的微服务组成。</p>
<ul>
<li>每个微服务由独立团队支持。</li>
<li>公司希望给每个团队一个<strong>专属账户</strong>来管理各自的微服务（意味着微服务将分布在多个账户）。</li>
<li>需要设计跨账户的服务间通信，且：<ul>
<li>通过 HTTPS（端口 443）通信。</li>
<li>提供<strong>服务发现和服务注册中心</strong>。</li>
</ul>
</li>
<li>目标：<strong>管理开销最小</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建检查 VPC + 网络防火墙 + 中转网关 + 防火墙规则仅允许 HTTPS。<br>B. <u>创建 VPC Lattice 服务网络，关联微服务，定义 HTTPS 监听器，将微服务计算资源注册为目标，将需要通信的 VPC 与服务网络关联。</u><br>C. 为每个微服务创建 NLB（HTTPS 监听器）和 PrivateLink 终端节点服务，在每个需要该微服务的 VPC 中创建接口终端节点。<br>D. 创建 VPC 对等连接，为每个服务创建前缀列表、路由表、安全组仅允许 HTTPS。</p>
<p>VPC Lattice 抽象了底层网络连接（跨账户、跨 VPC），自动处理服务发现，支持 HTTPS 监听器，并将服务注册到服务网络，团队只需将资源关联到服务网络即可通信，管理开销最小。</p>
<p><br>776 移动游戏，大部分元数据从 <strong>Amazon RDS 数据库实例</strong> 读取。</p>
<ul>
<li>游戏越来越受欢迎 → 元数据加载时间变慢（读取性能下降）。</li>
<li>单纯扩展数据库（指垂直&#x2F;水平扩展 RDS）没帮助。</li>
<li>要求探索<strong>所有选项</strong>，包括<strong>快照、复制和亚毫秒级响应时间</strong>功能的方案。</li>
</ul>
<p><strong>选项：</strong><br>A. 将数据库迁移到带有 Aurora 只读副本的 Amazon Aurora。<br>B. 将数据库迁移到带有全局表的 Amazon DynamoDB。<br>C. <u>在数据库前添加一个 Amazon ElastiCache for Redis 层。</u><br>D. 在数据库前添加一个 Amazon ElastiCache for Memcached 层。</p>
<ul>
<li>快照 → 缓存层（Redis&#x2F;Memcached）本身不支持快照（但 ElastiCache for Redis 支持备份&#x2F;快照）。</li>
<li>复制 → ElastiCache 支持副本（只读副本）。</li>
<li>亚毫秒级响应时间 → 内存缓存可以达到。</li>
</ul>
<p><br>777 AWS Organizations 多账户环境。</p>
<ul>
<li>安全 OU 拥有已批准的 AMI（通过 KMS 加密快照创建）。</li>
<li>需要与开发 OU 共享这些 AMI。</li>
</ul>
<p><strong>限制：</strong></p>
<ul>
<li>AMI 基于 KMS 加密的 EBS 快照。</li>
<li>要启动 AMI，需要两个权限：<ol>
<li>AMI 启动权限（允许账户使用 AMI）。</li>
<li>KMS 密钥使用权限（允许账户解密底层的加密快照）。</li>
</ol>
</li>
</ul>
<p><strong>选项（选两个）：</strong><br>A. 将开发团队 OU 的 ARN 添加到 AMI 的启动权限列表。<br>B. 将组织根 ARN 添加到 AMI 的启动权限列表。<br>C. 更新密钥策略，允许开发团队 OU 使用该 KMS 密钥解密。<br>D. <u>将开发团队账户的 ARN 添加到 AMI 的启动权限列表。</u><br><u>E. 重新创建 KMS 密钥，添加密钥策略允许组织根 ARN 使用 KMS 密钥。</u></p>
<p>但通常考题中，为了共享加密 AMI，正确做法是：</p>
<ol>
<li>将目标账户 ID 添加到 AMI 启动权限（D）。</li>
<li>在 KMS 密钥策略中允许目标账户使用该密钥（或在密钥策略中添加组织级条件允许组织内所有账户）</li>
</ol>
<p><br>778 80 个办事处。</p>
<ul>
<li>每个办事处存储 <strong>1 PB</strong> 数据。</li>
<li>每个办事处互联网带宽 1–2 Gbps（这里应指最大上传带宽，假定是 1 Gbps）。</li>
<li>需要将数据一次性迁移到 S3，<strong>4 周内完成</strong>（全量）。</li>
</ul>
<p>A. Direct Connect 10 Gbps → 虽然带宽高，但每个办事处新建立专线，成本极高，且 10 Gbps 传 1 PB 需要约 10 天（理论值），但实际可能受距离、安装时间限制（4 周内安装 80 条专线不现实），不具成本效益。 ❌</p>
<p>B. 使用多个 Snowball Edge 存储优化设备 → Snowball Edge Storage Optimized 容量 80 TB（可用），传 1 PB 需要约 13 台设备每个办事处。但可以分批寄送、拷贝、寄回，4 周内可能完成，成本比专线低，也比 Snowmobile 更适合百 PB 总量（80 PB 总量）。 ✅</p>
<p>C. Snowmobile → 每辆 100 PB，适合 EB 级，但 Snowmobile 需卡车到现场，80 个全球办事处意味着要派 80 辆 Snowmobile？不现实，成本高且物流复杂。 ❌</p>
<p>D. Storage Gateway 卷网关 → 本质还是网络传输，带宽不足，无法 4 周完成 1 PB&#x2F;办事处。 ❌</p>
<p><br>779 公司有 EFS 文件系统（参考数据集）。</p>
<ul>
<li>EC2 实例上的应用程序需要读取数据集，但<strong>不得能够更改数据集</strong>。</li>
<li>希望<strong>使用 IAM 访问控制</strong>来防止修改或删除数据集。</li>
</ul>
<p><strong>选项：</strong><br>A. 从 EC2 实例内部以只读模式挂载 EFS 文件系统。<br>B. <u>为 EFS 文件系统创建一个资源策略，该策略拒绝 IAM 角色执行 elasticfilesystem:ClientWrite 操作，这些 IAM 角色附加到 EC2 实例。</u><br>C. 为 EFS 文件系统创建一个身份策略，拒绝在该 EFS 文件系统上执行 elasticfilesystem:ClientWrite 操作。<br>D. 为每个应用程序创建一个 EFS 访问点，使用 POSIX 文件权限允许对根目录只读访问。</p>
<ol>
<li><p><strong>IAM 访问控制</strong><br>EFS 支持两种主要权限控制：</p>
<ul>
<li>POSIX 文件系统权限（基于用户&#x2F;组）。</li>
<li>IAM 策略（附加到 IAM 角色或资源策略用于 EFS 客户端挂载时的操作控制）。</li>
</ul>
<p>题目明确要求 <strong>使用 IAM 访问控制</strong> 来防止修改&#x2F;删除，所以应使用 IAM 策略而不是 POSIX 权限。</p>
</li>
</ol>
<p>EFS 资源策略允许你指定哪个 IAM 角色可以执行哪些客户端操作（如 ClientWrite, ClientRootAccess 等）。这是 EFS 特有的 IAM 集成功能，可以做到挂载时即使客户端以读写模式挂载，IAM 策略也会拒绝写操作。</p>
<p><br>780 公司有一个 AWS 账户。</p>
<ul>
<li>外部供应商在其自己的 AWS 账户中有自动化工具。</li>
<li>供应商没有对公司账户的 IAM 访问权限。</li>
<li>公司需要<strong>授予供应商对其 AWS 账户的访问权限</strong>。</li>
<li>要求：<strong>最安全</strong>的方式。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>在公司账户中创建一个 IAM 角色，以委派对供应商 IAM 角色的访问权限。附加适当的 IAM 策略以提供所需权限。</u><br>B. 在公司账户中创建 IAM 用户（密码符合复杂度要求），附加适当 IAM 策略。<br>C. 在公司账户中创建 IAM 组，将供应商账户的 IAM 用户添加到该组，为组附加适当策略。<br>D. 在公司账户中创建 IAM 用户，设置允许供应商账户访问的权限边界，为用户附加策略。</p>
<p> 在公司账户中创建 IAM 角色，信任策略设置为允许供应商账户的特定 IAM 角色&#x2F;用户代入，然后附加权限策略。这是 AWS 推荐的最安全跨账户访问方式，无需长期凭证，权限可随时撤销。</p>
<ul>
<li>供应商使用其自己账户的 IAM 实体（用户&#x2F;角色）通过 <code>AssumeRole</code> 获得临时凭证访问公司账户。</li>
<li>临时凭证自动过期，无需轮换，且可通过角色信任策略随时撤销访问。</li>
</ul>
<p><br>781 公司有实验性工作负载在 AWS 上运行，有云支出预算。</p>
<ul>
<li>首席财务官担心各部门的<strong>云支出责任</strong>（即需要知道哪个部门花了多少钱）。</li>
<li>需要在支出达到预算的 60% 时收到通知。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>在 AWS 资源上使用成本分配标签标记所有者，在 AWS 预算中创建使用预算，并添加警报阈值（60%）通知。</u><br>B. 使用 AWS 成本浏览器预测确定资源所有者，使用 AWS 成本异常检测创建 60% 警报。<br>C. 使用成本分配标签标记所有者，用 AWS Trusted Advisor &#x2F; AWS Support API 创建 60% 警报通知。<br>D. 用成本浏览器预测确定资源所有者，在 AWS 预算中创建使用预算并加警报阈值通知</p>
<ul>
<li>成本分配标签是 AWS 推荐的跟踪成本责任的方法。</li>
<li>AWS 预算是设置预算和警报的标准服务。</li>
</ul>
<p><br>782 公司要部署<strong>内部 Web 应用</strong>，仅能从<strong>公司办公室</strong>访问（即不开放到互联网）。</p>
<ul>
<li>Web 应用需要从互联网下载安全补丁（即实例需要出站互联网访问）。</li>
<li>已有 VPC + 站点到站点 VPN 连接到公司办公室。</li>
</ul>
<p><strong>选项：</strong><br>A. 在公共子网部署 EC2（在公共 ALB 后），ALB 安全组入站源 0.0.0.0&#x2F;0（等于允许全网访问），不符合仅公司办公室访问要求。 ❌</p>
<p>B. <u>在私有子网部署 EC2（在内部 ALB 后），ALB 安全组入站源设为公司办公网络的 CIDR 块（通过 VPN 连接访问），同时在公有子网部署 NAT 网关，允许 EC2 访问互联网下载补丁</u>。 ✅</p>
<p>C. 在公共子网部署 EC2（内部 ALB 后）——公共子网意味着 EC2 有公网 IP 或可通过互联网网关直接访问，这增加了暴露面，虽然安全组可以限制，但不是最佳；且说“将 ALB 安全组的出站目标设置为公司办公室网络的 CIDR 块”无关（入站访问才需控制），此选项描述混乱。 ❌</p>
<p>D. 在私有子网部署 EC2（公共 ALB 后）——公共 ALB 暴露在互联网（因在公有子网并绑定互联网网关），即使 ALB 安全组限制出站目标 0.0.0.0&#x2F;0 也没用，入站仍可能来自互联网，除非 ALB 安全组入站源限制为公司网络，但选项未提入站源设置，默认会暴露。 ❌</p>
<ul>
<li>私有子网 + 内部 ALB → 只能通过 VPN 访问。</li>
<li>ALB 安全组入站源为公司网络 CIDR → 仅公司办公室可访问。</li>
<li>NAT 网关在公有子网 + 互联网网关 → 私有子网实例可访问互联网下载补丁。</li>
</ul>
<p><br>783 会计记录存储在自定义应用程序（运行在 EC2 实例）。</p>
<ul>
<li>需要迁移到 <strong>AWS 托管服务</strong>，以便于“数据的开发和维护”。</li>
<li>要求：<strong>最少的运维支持</strong>。</li>
<li>要求：<strong>不可变且可通过密码验证的数据更改日志</strong>（即防篡改、可验证的审计日志）。</li>
</ul>
<p><strong>选项：</strong><br>A. 复制到 Amazon Redshift（数据仓库）。<br>B. 复制到 Amazon Neptune（图数据库）。<br>C. 复制到 Amazon Timestream（时序数据库）。<br>D. <u>复制到 Amazon QLDB（账本数据库）</u></p>
<p><br>784 营销数据从多个来源上传到 S3。</p>
<ul>
<li>有<strong>一系列数据准备作业</strong>，需要：<ol>
<li><strong>定期并行运行</strong>（大部分作业可并行）。</li>
<li><strong>少数作业需要按特定顺序运行</strong>。</li>
</ol>
</li>
<li>希望<strong>消除作业错误处理、重试逻辑和状态管理</strong>的运营开销。</li>
</ul>
<p><strong>选项：</strong><br>A. 数据上传到 S3 后，用 Lambda 处理；按固定时间隔调用其他 Lambda。<br>B. 用 Amazon Athena 处理数据，用 EventBridge Scheduler 定期调用 Athena。<br>C<u>. 用 AWS Glue DataBrew 处理数据，用 AWS Step Functions 状态机运行 DataBrew 数据准备作业。</u><br>D. 用 AWS Data Pipeline 处理数据，安排在午夜运行一次。</p>
<p>AWS Step Functions 专门用于编排多个 AWS 服务任务，支持并行执行和顺序执行，内置错误重试、状态管理，无需自己编写</p>
<p><br>785 支付处理应用程序运行在 <strong>Lambda</strong>（多个可用区私有子网中）。</p>
<ul>
<li>每天处理数百万笔交易。</li>
<li>要求：<strong>确保不会处理重复的付款</strong>（即消息&#x2F;付款指令不能重复执行）。</li>
</ul>
<p><strong>选项：</strong><br>A. Lambda 取到期付款 → 发布到 <strong>S3</strong> → S3 事件触发另一个 Lambda 处理。<br>B. Lambda 取到期付款 → 发布到 <strong>SQS 标准队列</strong> → 另一个 Lambda 轮询处理。<br>C. <u>Lambda 取到期付款 → 发布到 <strong>SQS FIFO 队列</strong> → 另一个 Lambda 轮询处理</u>。<br>D. Lambda 取到期付款 → 存储到 <strong>DynamoDB</strong> → DynamoDB 流触发另一个 Lambda 处理。</p>
<p> SQS FIFO 队列提供消息去重（基于消息去重 ID 或内容），配合 Lambda 可以确保每个付款只被处理一次。</p>
<p><br>786 公司本地数据中心有多个工作负载。</p>
<ul>
<li>数据中心扩展速度不够满足业务增长需求。</li>
<li>需要收集本地服务器和工作负载的使用情况、配置数据，以<strong>规划向 AWS 的迁移</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 在 AWS 迁移中心设置主区域，使用 <strong>AWS Systems Manager</strong> 收集本地服务器数据。<br>B. <u>在 AWS 迁移中心设置主区域，使用 <strong>AWS Application Discovery Service</strong> 收集本地服务器（已开启状态）的数据。</u><br>C. 用 AWS SCT 创建模板，用 AWS Trusted Advisor 收集本地服务器数据。<br>D. 用 AWS SCT 创建模板，用 AWS DMS 收集本地服务器数据。</p>
<p>AWS 提供 <strong>Application Discovery Service</strong> 来收集本地服务器配置、性能和使用数据（如 CPU、内存、网络连接、运行的应用程序等），用于迁移规划（如确定服务器大小、依赖关系）。</p>
<p><br>787 AWS Organizations 中已启用所有功能。</p>
<ul>
<li>必须审计<strong>任何现有或新 AWS 账户</strong>中的所有 <strong>API 调用</strong> 和 <strong>登录</strong>（即需要 CloudTrail 日志）。</li>
<li>需要<strong>托管解决方案</strong>，避免额外工作，成本最低。</li>
<li>需要知道任何 AWS 账户何时<strong>不符合 AWS 基础安全最佳实践（FSBP）</strong> 标准。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>在组织管理账户中部署 AWS Control Tower 环境，启用 AWS Security Hub 和 Control Tower 账户工厂。</u><br>B. 在专用的组织成员账户中部署 AWS Control Tower 环境，启用 Security Hub 和账户工厂。<br>C. 使用 AWS Managed Services (AMS) Accelerate 构建 MALZ（多账户登录区），提交 RFC 配置 Amazon GuardDuty。<br>D. 使用 AMS Accelerate 构建 MALZ，提交 RFC 配置 Security Hub。</p>
<p>Control Tower 自动启用 CloudTrail 组织跟踪，并可集成 Security Hub 进行 FSBP 合规检查，是满足审计与安全合规需求的一站式托管解决方案，运营开销最低。</p>
<p>Control Tower 环境通常部署在<strong>管理账户</strong>（payer account）中，而不是专用成员账户。因此 <strong>A</strong> 正确，B 不正确（虽然技术上可在成员账户部署，但不是最佳实践）</p>
<p><br>788 10 TB 日志文件存储在 S3，格式为 <strong>Apache Parquet</strong>。</p>
<ul>
<li>公司<strong>偶尔</strong>需要用 SQL 分析这些日志文件（即查询不是持续运行，而是按需偶尔查询）。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建 Aurora MySQL 数据库，用 DMS 迁移数据到 Aurora，然后对 Aurora 执行 SQL。<br>B. 创建 Redshift 集群，用 Redshift Spectrum 对 S3 数据运行 SQL。<br>C. <u>创建 AWS Glue 爬虫获取 S3 表元数据，用 Amazon Athena 直接对 S3 数据运行 SQL。</u><br>D. 创建 Amazon EMR 集群，用 Spark SQL 对 S3 数据运行 SQL。</p>
<p>Athena 专为直接查询 S3 中的结构化&#x2F;半结构化数据设计，支持 Parquet 格式，并可通过 Glue Data Catalog 管理元数据</p>
<p><br>789 防止 CloudFormation 堆栈部署包含：</p>
<ol>
<li>IAM 资源带有<strong>内联策略</strong> 或 策略语句中有 <code>&quot;*&quot;</code>（通配符权限过大）。</li>
<li>带有<strong>公共 IP 地址</strong>的 EC2 实例。</li>
</ol>
<ul>
<li>公司已在 AWS Organizations 中启用了 <strong>AWS Control Tower</strong>。</li>
<li>需要解决方案满足这些要求。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>使用 AWS Control Tower <strong>主动控制</strong>来阻止部署带公共 IP 的 EC2 实例以及带内联策略或 <code>&quot;*&quot;</code> 的 IAM 资源。</u><br>B. 使用 AWS Control Tower <strong>检测控制</strong>来阻止部署带公共 IP 的 EC2 实例以及带内联策略或 <code>&quot;*&quot;</code> 的 IAM 资源。<br>C. 使用 AWS Config 创建合规规则，当资源不合规时运行 Systems Manager Automation 删除资源。<br>D. 使用服务控制策略（SCP）在操作导致不合规时阻止针对 EC2 和 IAM 的操作。</p>
<ol>
<li><strong>Control Tower 的控制类型</strong><ul>
<li><strong>主动控制（Proactive Controls）</strong>：在资源创建之前进行策略检查（如 CloudFormation 预检），防止部署不合规资源。</li>
<li><strong>检测控制（Detective Controls）</strong>：在资源创建后评估合规性，不合规则发出警报或修复。</li>
</ul>
</li>
</ol>
<p><br>790 Web 应用程序运行在<strong>单个公共子网</strong>中的一台 <strong>EC2 实例</strong>上。</p>
<ul>
<li>无法满足增长的 Web 流量需求。</li>
<li>需要<strong>高可用性</strong>和<strong>可扩展性</strong>。</li>
<li>不能重写应用程序（即架构变化应限于基础设施层面）。</li>
</ul>
<p><strong>需要选两个步骤的组合。</strong></p>
<p><strong>选项：</strong><br>A. 将 EC2 实例替换为更大的计算优化型实例（垂直扩展）。<br>B. <u>在私有子网中配置具有多个可用区的 Amazon EC2 自动扩展组（横向扩展+多 AZ）。</u><br>C. 在公有子网中配置一个 NAT 网关来处理 Web 请求（NAT 网关用于出站流量，不处理入站 Web 请求，无关）。<br>D. 将 EC2 实例替换为更大的内存优化型实例（垂直扩展）。<br>E. <u>在公有子网中配置应用程序负载均衡器（ALB）以分发 Web 流量。</u></p>
<ul>
<li>垂直扩展（A 和 D）只能提升单实例容量，但存在上限且无高可用性（单点故障）。</li>
<li>横向扩展（自动扩展组）配合负载均衡器是 AWS 最佳实践，可根据流量自动增减实例，同时提高可用性</li>
</ul>
<p><br>791 公司有 AWS Lambda 函数，使用了<strong>环境变量</strong>。</p>
<ul>
<li>不希望开发人员以<strong>明文形式查看环境变量</strong>（即在 Lambda 控制台或代码中看到明文的敏感信息如密码、API 密钥等）。</li>
</ul>
<p><strong>选项：</strong><br>A. 将代码部署到 Amazon EC2 实例而不是 Lambda → 这不解决问题，EC2 的环境变量也可能被看到。 ❌</p>
<p>B. 在 Lambda 函数上配置 SSL 加密以使用 AWS CloudHSM 存储和加密环境变量 → CloudHSM 用于硬件密钥管理，但 SSL 加密与环境变量加密不同，且 Lambda 不直接支持用 CloudHSM 加密环境变量（可用 KMS）。此选项描述不准确。 ❌</p>
<p>C. 在 ACM 中创建证书，配置 Lambda 使用该证书对环境变量加密 → ACM 用于 TLS 证书，不用于加密环境变量。 ❌</p>
<p>D. <u>创建一个 AWS KMS 密钥，在 Lambda 函数上启用加密助手以使用该密钥来存储和加密环境变量 → Lambda 支持环境变量加密，使用 KMS 密钥加密，只有被授权的 Lambda 函数执行时才能解密，开发人员在控制台看到的是密文</u>。 ✅</p>
<p>Lambda 允许在创建或更新函数时为环境变量启用加密，指定一个 KMS 密钥。<br>加密后，环境变量在控制台和 API 响应中以密文显示，只有函数运行时 Lambda 服务才会用 KMS 解密。</p>
<p><br>792 分析公司使用 VPC 运行多层服务。</p>
<ul>
<li>希望使用 <strong>RESTful API</strong> 向<strong>数百万用户</strong>提供网络分析服务。</li>
<li>要求：用户必须通过<strong>身份验证服务</strong>验证后才能访问 API。</li>
<li>目标：<strong>最高的运营效率</strong>（即使用托管服务，减少运营负担）。</li>
</ul>
<p><strong>选项：</strong><br>A. <u>配置 Amazon Cognito <strong>用户池</strong>进行用户认证，通过 <strong>Cognito 授权器</strong>实现 Amazon API Gateway REST API。</u><br>B. 配置 Amazon Cognito <strong>身份池</strong>进行用户认证，使用 Cognito 授权器实现 Amazon API Gateway HTTP API。<br>C. 配置 Lambda 函数处理用户认证，使用 Lambda 授权器实现 API Gateway REST API。<br>D. 配置 IAM 用户处理用户认证，使用 IAM 授权器实现 API Gateway HTTP API。</p>
<ol>
<li><strong>数百万用户身份验证</strong><br>需要支持大规模外部用户（不是 AWS IAM 用户），最好用 Amazon Cognito（托管身份验证服务）。</li>
<li><strong>用户池 vs 身份池</strong><ul>
<li><strong>用户池（User Pool）</strong>：用于用户注册、登录（用户名&#x2F;密码、社交登录），管理用户身份。</li>
<li><strong>身份池（Identity Pool）</strong>：用于为用户提供 AWS 临时凭证以访问 AWS 资源（如 S3、DynamoDB）。<br>这里用户只需要访问 REST API，不要求直接访问 AWS 资源，所以用<strong>用户池</strong>进行身份验证即可。</li>
</ul>
</li>
<li><strong>API Gateway 认证集成</strong><br>API Gateway 支持 <strong>Cognito 用户池授权器</strong>，验证用户提供的 JWT 令牌，这是托管方案，运营效率最高。</li>
</ol>
<p><br>793 公司使用 AWS KMS 加密静态数据。</p>
<ul>
<li>需要<strong>防止 KMS 密钥被意外删除</strong>。</li>
<li>必须在<strong>用户尝试删除 KMS 密钥时</strong>通过 <strong>Amazon SNS</strong> 向管理员发送邮件通知。</li>
<li>要求：<strong>运营开销最小</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 创建 EventBridge 规则响应用户尝试删除 KMS 密钥，配置一个 AWS Config 规则来取消 KMS 密钥删除，将此 Config 规则添加为 EventBridge 目标，创建 SNS 主题通知管理员。<br>B. 创建自定义 Lambda 防止 KMS 密钥删除，创建 CloudWatch 警报在尝试删除时激活，创建 EventBridge 规则在 DeleteKey 操作时调用 Lambda，同时配置 SNS 通知。<br>C. 创建 EventBridge 规则响应 DeleteKey 操作，启动 Systems Manager 自动化运行手册取消删除，同时发布 SNS 消息通知管理员。<br>D. <u>创建 CloudTrail 跟踪投递日志到 CloudWatch Logs，创建指标筛选器和 CloudWatch 警报，当检测到 DeleteKey 操作时触发 SNS 通知</u>。</p>
<p>防止删除 KMS 密钥可以使用 <strong>KMS 密钥计划删除等待期（pending deletion period）</strong>，但题目似乎要求在尝试删除时就阻止并通知，而不是进入等待期。<br>但 AWS KMS 本身不提供“阻止删除”的 native 功能（除了密钥调度删除有 7–30 天等待期），要主动阻止删除需要额外的自动化机制。</p>
<p><br>794 移动应用使用情况分析报告生成程序。</p>
<ul>
<li>程序在<strong>每月的最后一周</strong>生成多份报告。</li>
<li>生成每份报告时间 <strong>&lt;10 分钟</strong>。</li>
<li>很少在每月最后一周之外生成报告。</li>
<li>要求在收到报告生成请求时<strong>能以最短时间完成</strong>（低延迟）。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 EC2 按需实例运行程序，EventBridge 规则在报告请求时启动实例，并在每月最后一周持续运行实例。<br>B. <u>在 Lambda 中运行程序，EventBridge 规则在报告生成时运行 Lambda 函数。</u><br>C. 在 ECS 中运行程序，安排 ECS 在报告被请求时运行程序。<br>D. 用 EC2 Spot 实例运行程序，EventBridge 规则在请求时启动实例，并在每月最后一周持续运行实例。</p>
<ul>
<li>报告生成程序可打包为 Lambda 函数（如果依赖多可以容器镜像支持）。</li>
<li>EventBridge 可定时触发或由 S3 事件等触发，Lambda 响应快。</li>
</ul>
<p><br>795 设计<strong>紧密耦合的高性能计算（HPC）</strong> 环境。</p>
<ul>
<li>需要<strong>优化网络和存储性能</strong>。</li>
</ul>
<p><strong>选项（选两个）：</strong><br>A. 在 AWS Global Accelerator 中创建加速器，配置自定义路由。<br>B. <u>创建 Amazon FSx for Lustre 文件系统，配置为临时存储</u>。<br>C. 创建 Amazon CloudFront 分发，配置查看器协议策略为 HTTP 和 HTTPS。<br>D. <u>启动 Amazon EC2 实例，为实例附加弹性结构适配器（EFA）。</u><br>E. 创建 AWS Elastic Beanstalk 部署来管理环境。</p>
<ul>
<li><strong>网络性能</strong>：紧密耦合 HPC（如 MPI 应用）需要低延迟、高带宽的节点间通信。AWS 提供 <strong>弹性结构适配器（EFA）</strong> 用于高性能网络（支持 OS-bypass）。</li>
<li><strong>存储性能</strong>：HPC 常需要并行文件系统，<strong>Amazon FSx for Lustre</strong> 是高性能、低延迟并行文件系统，适合 HPC 存储。</li>
</ul>
<p><br>796 需要防止包含<strong>不良内容</strong>的照片上传到公司 Web 应用程序。</p>
<ul>
<li><strong>不得涉及训练机器学习模型</strong>（即不能自己训练 ML 模型，应该用 AWS 预训练模型）。</li>
</ul>
<p><strong>选项：</strong><br>A. 使用 Amazon SageMaker Autopilot 创建并部署模型（这需要训练模型，违反“不得训练 ML 模型”要求）。 ❌<br>B. <u>创建使用 <strong>Amazon Rekognition</strong> 检测不良内容的 Lambda 函数，创建 Lambda 函数 URL 供 Web 应用调用。</u> ✅<br>C. 创建 Amazon CloudFront 函数，使用 <strong>Amazon Comprehend</strong> 检测不良内容 → Comprehend 是文本分析服务，不适合图像内容检测。 ❌<br>D. 创建使用 <strong>Amazon Rekognition Video</strong> 的 Lambda 函数检测不良内容 → Rekognition Video 用于视频分析，也可以检测图像，但 Rekognition Image 更直接；不过 Rekognition 整体包含内容安全检测（如不当内容检测），<strong>Video</strong> 也能用于图像，但通常考试中会直接选 Rekognition（Image API）。选项 B 是 Rekognition（一般指 Image API），D 是 Rekognition Video，对照片来说用 Image API 即可</p>
<ol>
<li><strong>AWS 预训练模型用于图像内容审核</strong><br>Amazon Rekognition 提供 <strong>Content Moderation</strong> 功能，可检测图片中的不当内容（如暴力、裸露等），无需训练模型，符合要求。</li>
<li><strong>实现方式</strong><br>可以创建 Lambda 函数调用 Rekognition API 检测上传图片，通过 Lambda 函数 URL 或 API Gateway 供 Web 应用调用。</li>
</ol>
<p><br>797 电子商务平台在 AWS 上运行，是关键业务。</p>
<ul>
<li>已为根用户账户配置了 <strong>MFA 设备</strong>。</li>
<li>担心 <strong>MFA 设备丢失</strong> 导致无法访问根用户账户。</li>
<li>需要解决方案确保不会失去根用户访问权限。</li>
</ul>
<p><strong>选项：</strong><br>A. 设置一个备用管理员账户，供公司在丢失 MFA 设备时登录使用。<br>B. <u>为根用户账户添加多个 MFA 设备，以应对灾难场景。</u><br>C. 当公司无法访问根账户时，创建一个新的管理员账户。<br>D. 当公司无法访问根账户时，将管理员策略附加到另一个 IAM 用户。</p>
<ol>
<li><strong>根用户 MFA 管理</strong><br>AWS 允许为根用户关联 <strong>多个 MFA 设备</strong>（例如虚拟 MFA 应用、硬件密钥等）。<br>如果主 MFA 设备丢失，可以使用备用 MFA 设备登录并移除丢失的设备，恢复访问。</li>
</ol>
<p><br>798 社交媒体公司有奖励计划网站。</p>
<ul>
<li>用户上传视频获得积分，用积分兑换合作商户的礼品&#x2F;折扣。</li>
<li>每个用户有唯一 ID，商户需要验证用户资格。</li>
<li><strong>当公司向用户发放积分时，合作伙伴希望通过 HTTP 端点接收用户 ID 通知。</strong></li>
<li>每天有数百个供应商可能成为合作伙伴。</li>
<li>要求：架构要能<strong>快速、可扩展地添加合作伙伴</strong>。</li>
<li>要求：<strong>最少的实施工作量</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 用 Amazon Timestream 存合作伙伴列表，Lambda 读取列表并给每个合作伙伴发通知。<br>B. <u>创建一个 Amazon SNS 主题，选择端点协议（如 HTTP），合作伙伴订阅该主题；当发放积分时，将用户 ID 发布到主题。</u><br>C. 创建 AWS Step Functions 状态机，为每个合作伙伴创建任务，发放积分时调用状态机。<br>D. 用 Kinesis Data Streams 存合作伙伴列表，实现生产者和消费者应用，发放积分时发送用户 ID。</p>
<p>Amazon SNS 是发布&#x2F;订阅服务，支持 HTTP&#x2F;S 端点订阅，可以动态添加订阅者（合作伙伴）。</p>
<p><br>799 公司有食谱记录的文本文件，存储在 Amazon S3 桶。</p>
<ul>
<li>需要从文本文件中提取<strong>食材名称</strong>（即文本实体提取）。</li>
<li>提取的食材名称将用于 Web 应用查询 DynamoDB 获取营养评分。</li>
<li>应用可以处理非食品记录和错误（即容错性要求不高）。</li>
<li><strong>公司没有任何具备机器学习知识的员工</strong>（所以不能用需要训练&#x2F;调优 ML 模型的方案）。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A<u>. S3 事件通知触发 Lambda → Lambda 使用 <strong>Amazon Comprehend</strong>（自然语言处理服务）提取实体 → 存到 DynamoDB。</u><br>B. S3 事件触发 Lambda → 使用 <strong>Amazon Forecast</strong>（时间序列预测服务）提取食材名称 → 错误（Forecast 不能做实体提取）。 ❌<br>C. S3 事件触发 Lambda → 使用 <strong>Amazon Polly</strong>（文本转语音）将食谱转音频 → 人工听音频提取食材名称 → 不自动，成本高效率低。 ❌<br>D. S3 事件触发 Lambda → 使用 <strong>Amazon SageMaker</strong> 分析对象提取食材名称 → 需要训练或部署自定义模型，不符合“无 ML 知识员工”要求。 ❌</p>
<p>Amazon Comprehend 提供预训练的实体识别功能（包括检测食品、材料等），无需 ML 知识，按使用量付费</p>
<p><br>800 公司主 AWS 账户有一个 VPC，其中运行 <strong>Lambda 函数</strong>。</p>
<ul>
<li>Lambda 函数需要访问 <strong>EFS 文件系统</strong>中的文件。</li>
<li>但 EFS 文件系统位于<strong>次级（另一个）AWS 账户</strong>中。</li>
<li>文件会不断添加，解决方案必须能<strong>扩展</strong>以满足需求。</li>
<li>要求：<strong>最具成本效益</strong>。</li>
</ul>
<p><strong>选项：</strong><br>A. 在主账户中创建新 EFS 文件系统，用 AWS DataSync 复制内容到新 EFS。<br>B. <u>在主账户和次账户的 VPC 之间创建 <strong>VPC 对等连接</strong>。</u><br>C. 在次账户中创建第二个 Lambda 函数（挂载 EFS），主账户 Lambda 调用次账户 Lambda。<br>D. 将文件系统内容移到 <strong>Lambda 层</strong>，配置权限允许次账户使用该层。</p>
<ol>
<li><p><strong>Lambda 访问跨账户 EFS</strong><br>Lambda 只能挂载与它在<strong>同一 VPC 和账户</strong>中的 EFS 文件系统。<br>要访问跨账户的 EFS，通常的做法是：</p>
<ul>
<li>将 EFS 通过 <strong>VPC 对等连接</strong> 共享到另一个账户的 VPC，然后在目标 VPC 中挂载。<br>但 Lambda 必须和 EFS 在同一账户吗？不，只要 EFS 在同一个 VPC 内并配置了正确的安全组&#x2F;NACL 即可，但 VPC 对等连接后，两个 VPC 可以跨账户互通，但 EFS 需要配置允许从对等 VPC 的客户端挂载（通过安全组或网络 ACL）。</li>
</ul>
</li>
</ol>
<ul>
<li>VPC 对等连接费用很低（仅跨 AZ 流量费），无数据复制成本。</li>
<li>EFS 本身具有弹性，随文件增加自动扩展。</li>
<li>Lambda 直接挂载 EFS 访问文件，延迟低，架构简单</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T700/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T700/" class="post-title-link" itemprop="url">AWS架构师T700</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T700"><a href="#AWS架构师T700" class="headerlink" title="AWS架构师T700"></a>AWS架构师T700</h1><p><br>601 一家公司在 <strong>Amazon RDS for PostgreSQL</strong> 数据库实例上运行关键数据库，希望以<strong>最少的停机时间和数据丢失</strong>迁移到 <strong>Amazon Aurora PostgreSQL</strong>。<br>要求：<strong>以最少的运营开销</strong>满足要求。</p>
<p>选项：<br>A. 为 RDS for PostgreSQL 实例创建<strong>数据库快照</strong>，以填充新的 Aurora PostgreSQL 数据库集群<br>B. <u>为 RDS for PostgreSQL 实例创建一个 <strong>Aurora 只读副本</strong>，将该只读副本提升为新的 Aurora PostgreSQL 数据库集群</u><br>C. 使用来自 <strong>Amazon S3 的数据导入</strong>将数据库迁移到 Aurora PostgreSQL 数据库集群<br>D. 使用 <strong>pg_dump</strong> 工具备份 RDS for PostgreSQL 数据库，将备份还原到新的 Aurora PostgreSQL 数据库集群</p>
<p><strong>创建 Aurora 只读副本并提升</strong> 是 AWS 推荐的从 RDS PostgreSQL 迁移到 Aurora PostgreSQL 的<strong>标准低停机方案</strong></p>
<p><br>602  一家公司的基础设施包含<strong>数百个使用 EBS 卷的 EC2 实例</strong>。<br>要求：确保<strong>每个 EC2 实例在灾难发生后都能恢复</strong>。<br>目标：以<strong>最少的工作量</strong>满足要求。</p>
<p>选项：<br>A. 为每个 EC2 实例所挂载的 EBS 存储创建快照，创建一个 AWS CloudFormation 模板从该 EBS 存储启动新的 EC2 实例<br>B. 为每个 EC2 实例所挂载的 EBS 存储创建快照，使用 AWS Elastic Beanstalk 根据 EC2 模板设置环境并挂载 EBS 存储<br>C. <u>使用 <strong>AWS Backup</strong> 为整个 EC2 实例组设置备份计划，使用 AWS Backup API 或 CLI 加快多个 EC2 实例的恢复过程</u><br>D. 创建一个 AWS Lambda 函数为每个 EC2 实例的 EBS 存储创建快照并复制 AMI，创建另一个 Lambda 函数使用复制的 AMI 执行恢复</p>
<p>AB，手动创建快照，D编写Lambda都是需要手动操作</p>
<p><br>603 一家公司迁移到 AWS，希望获得一个<strong>无服务器解决方案</strong>，用于对<strong>半结构化数据集</strong>进行<strong>大规模并行按需处理</strong>。<br>数据包括：日志、媒体文件、销售交易记录、物联网传感器数据，均存储在 <strong>Amazon S3</strong>。<br>要求：</p>
<ul>
<li>能够并行处理数据集中的<strong>数千个项目</strong></li>
<li>以<strong>最高的运营效率</strong>满足要求</li>
</ul>
<p>选项：<br>A. 使用 AWS Step Functions 的<strong>内联模式映射状态</strong>来并行处理数据<br>B. <u>使用<strong>分布式模式下的 AWS Step Functions Map 状态</strong>来并行处理数据</u><br>C. 使用 <strong>AWS Glue</strong> 并行处理数据<br>D. 使用<strong>多个 AWS Lambda 函数</strong>并行处理数据</p>
<p>Step Functions Map 状态有两种模式：</p>
<ul>
<li><p><strong>内联模式（Inline）</strong>：在状态机执行中直接处理，<strong>并行度有限</strong>（最大并发 40），适合小规模并行。</p>
</li>
<li><p><strong>分布式模式（Distributed）</strong> 使用 <strong>动态并行</strong>，为每个输入项启动<strong>独立子执行</strong>，可<strong>自动扩展至数千个并行任务</strong>，仅受账户限制限制（可申请提高）。</p>
</li>
</ul>
<p>Glue 是 ETL 服务，主要用于<strong>数据准备、转换和加载</strong>，虽然可并行处理（通过 Spark 作业），但更适用于<strong>批处理作业</strong>，而非“按需”处理</p>
<p><br>604 一家公司计划在 <strong>6 周内</strong> 迁移 <strong>10 PB 的数据</strong> 到 Amazon S3。<br>当前条件：</p>
<ul>
<li>数据中心有一条 <strong>500 Mbps 的互联网上行链路</strong></li>
<li>其他本地应用程序共享该上行链路</li>
<li>可用于迁移的带宽：<strong>80%</strong>（即 400 Mbps）</li>
</ul>
<p>问：哪种解决方案能够满足这些要求？</p>
<p>选项：<br>A. 配置 <strong>AWS DataSync</strong> 将数据迁移到 Amazon S3 并自动验证数据<br>B. 使用 <strong>rsync</strong> 将数据直接传输到 Amazon S3<br>C. 使用 <strong>AWS CLI</strong> 和多个复制进程将数据直接发送到 Amazon S3<br>D. <u>订购多台 <strong>AWS Snowball</strong> 设备，将数据复制到设备上，发送至 AWS 将数据复制到 Amazon S3</u></p>
<ul>
<li><strong>Snowball</strong> 是离线数据传输设备，每台 Snowball Edge Storage Optimized 容量为 <strong>80 TB</strong>（或更大型号）。</li>
</ul>
<p><br>605 一家公司有多台本地 <strong>iSCSI 网络存储服务器</strong>，希望通过迁移到 AWS 云来<strong>减少这些本地服务器的数量</strong>。<br>要求：</p>
<ol>
<li>提供对<strong>频繁使用数据的低延迟访问</strong></li>
<li><strong>最少的基础设施变更</strong></li>
<li>减少对本地服务器的依赖</li>
</ol>
<p>问：哪种解决方案能够满足这些要求？</p>
<p>选项：<br>A. 部署 <strong>Amazon S3 文件网关</strong><br>B. 部署带有备份到 Amazon S3 的 <strong>Amazon EBS 存储</strong><br>C. 部署一个配置有<strong>存储卷</strong>的 <strong>AWS Storage Gateway 卷网关</strong><br><u>D. 部署配置有<strong>缓存卷</strong>的 <strong>AWS Storage Gateway 卷网关</strong></u></p>
<p><strong>Storage Gateway 卷网关缓存卷模式</strong> 专为将本地 iSCSI 存储迁移到云而设计，它在本地保留缓存以提供低延迟访问，同时将主要数据存储在 AWS，可显著减少本地存储服务器数量。</p>
<p><br>606 解决方案架构师正在设计一个允许业务用户向 <strong>Amazon S3</strong> 上传对象的应用程序，要求：</p>
<ol>
<li><strong>最大限度地提高对象的耐久性</strong>（即数据不丢失）</li>
<li><strong>对象必须随时且在任何时间段内都能便捷获取</strong>（即低延迟访问）</li>
<li>使用模式：<ul>
<li>上传后 <strong>前 30 天内频繁访问</strong></li>
<li>超过 30 天<strong>访问可能性小</strong>（但仍需可访问）</li>
</ul>
</li>
<li>目标：<strong>最具成本效益</strong>的解决方案</li>
</ol>
<p>选项：<br>A. 将所有对象存储在 <strong>S3 标准存储</strong>，设置生命周期规则在 30 天后转换到 <strong>S3 Glacier</strong><br>B. <u>将所有对象存储在 <strong>S3 标准存储</strong>，设置生命周期规则在 30 天后转换到 <strong>S3 标准 - 不常访问（S3 Standard-IA）</strong></u><br>C. 将所有对象存储在 <strong>S3 标准存储</strong>，设置生命周期规则在 30 天后转换到 <strong>S3 单区域 - 不常访问（S3 One Zone-IA）</strong><br>D. 将所有对象存储在 <strong>S3 智能分层（S3 Intelligent-Tiering）</strong>，设置生命周期规则在 30 天后转换到 <strong>S3 标准不常访问（S3 Standard-IA）</strong></p>
<ul>
<li><p>Glacier 是归档存储，<strong>检索需要时间</strong>（标准检索需数小时），不满足“随时便捷获取”要求（超过30天的对象仍需快速访问）。</p>
</li>
<li><p>One Zone-IA 将数据存储在<strong>单个可用区</strong>，耐久性较低（99.999999999% 但单 AZ 风险高），不满足“耐久性最大化”要求。</p>
</li>
</ul>
<p><br>607 一家公司已将两层应用程序从本地迁移到 AWS：</p>
<ul>
<li>数据层：<strong>多可用区 Amazon RDS for Oracle</strong>，配备 <strong>12 TB 通用型 SSD EBS 存储</strong>。</li>
<li>应用特点：将<strong>文档作为 BLOB</strong> 存储在数据库中，平均大小 <strong>6 MB</strong>。<br>问题：</li>
<li>数据库规模不断扩大，<strong>降低性能并增加存储成本</strong>。<br>要求：</li>
</ul>
<ol>
<li><strong>提高数据库性能</strong></li>
<li><strong>高可用且具有弹性</strong>的解决方案</li>
<li><strong>最具成本效益</strong>的方式</li>
</ol>
<p>选项：<br>A. 减小 RDS 实例大小，增加存储到 24 TiB，将存储类型改为<strong>磁性存储</strong><br>B. 增大 RDS 实例大小，增加存储到 24 TiB，将存储类型改为<strong>预配置 IOPS</strong><br>C. <u>创建一个 <strong>Amazon S3 存储桶</strong>，更新应用程序将<strong>文档存储在 S3</strong>，将<strong>对象元数据存储在现有数据库</strong></u><br>D. 创建一个 <strong>Amazon DynamoDB 表</strong>，更新应用程序使用 DynamoDB，使用 <strong>AWS DMS</strong> 将数据从 Oracle 迁移到 DynamoDB</p>
<h3 id="1-问题根源分析"><a href="#1-问题根源分析" class="headerlink" title="1. 问题根源分析"></a>1. 问题根源分析</h3><ul>
<li>性能下降和存储成本上升的主要原因是：<strong>大 BLOB 文档直接存储在数据库</strong>（RDS for Oracle）。</li>
<li>数据库存储 BLOB 会：<ul>
<li>占用大量数据库存储（昂贵，尤其是 EBS）</li>
<li>增加备份&#x2F;恢复时间和成本</li>
<li>影响查询性能（因为 BLOB 数据使表体积膨胀）</li>
</ul>
</li>
</ul>
<h3 id="2-解决方案方向"><a href="#2-解决方案方向" class="headerlink" title="2. 解决方案方向"></a>2. 解决方案方向</h3><p>最佳实践是将<strong>大对象（如文档、图像）存储在对象存储（如 S3）</strong>，数据库中仅存储<strong>元数据（如文件名、路径、大小、S3 键）</strong>。<br>这称为 <strong>“BLOB 外部化”</strong> 或 <strong>“对象存储分离”</strong>。</p>
<p><br>608 一家公司的应用程序为全球 <strong>20,000 个零售店面</strong>的客户端提供服务。<br>架构：</p>
<ul>
<li>后端 Web 服务通过 <strong>HTTPS（端口 443）</strong> 公开</li>
<li>托管在 <strong>ALB 后</strong> 的 EC2 实例上</li>
<li>零售店面通过<strong>公共互联网</strong>与应用程序通信</li>
<li>每个零售店面注册其<strong>本地 ISP 分配的 IP 地址</strong></li>
</ul>
<p>安全要求：</p>
<ul>
<li><strong>将访问权限限制为仅零售店面注册的 IP 地址</strong></li>
<li>解决方案架构师应采取什么措施满足要求？</li>
</ul>
<p>选项：<br>A. <u>将 <strong>AWS WAF Web ACL</strong> 与 ALB 关联，在 ALB 上使用 <strong>IP 规则集</strong> 过滤流量，更新规则以包含已注册的 IP 地址</u><br>B. 部署 <strong>AWS 防火墙管理器</strong> 管理 ALB，配置防火墙规则限制流向 ALB 的流量，修改规则以包含已注册的 IP 地址<br>C. 将 IP 地址存储在 <strong>Amazon DynamoDB</strong> 表中，在 ALB 上配置 <strong>AWS Lambda 授权函数</strong>，验证传入请求来自已注册的 IP 地址<br>D. 在包含 ALB 公有接口的<strong>子网配置网络 ACL（NACL）</strong>，使用每个已注册 IP 地址的条目更新 NACL 上的入站规则</p>
<p><strong>AWS WAF</strong> 是 Web 应用程序防火墙，支持基于 <strong>IP 地址的匹配条件</strong>（IP 集）</p>
<ul>
<li>防火墙管理器用于<strong>集中管理</strong>多个账户和资源的 WAF、Shield Advanced、VPC 安全组策略等。</li>
<li>对于单个 ALB 的 IP 白名单，使用 WAF 直接关联即可，防火墙管理器增加不必要的复杂度（除非有多账户、跨区域集中管理需求）。</li>
</ul>
<p>NACL 是<strong>子网级别的无状态防火墙</strong>，规则数量有限（每 NACL 最多 20 条规则，可提高但仍有上限</p>
<p><br>609 一家公司正在利用 <strong>AWS Lake Formation</strong> 构建数据分析平台，数据来源包括 <strong>Amazon S3</strong> 和 <strong>Amazon RDS</strong>。<br>要求：</p>
<ul>
<li>需要一个<strong>安全解决方案</strong>，防止访问包含<strong>敏感信息的数据部分</strong></li>
<li>以<strong>运营开销最小</strong>的方式满足要求</li>
</ul>
<p>选项：<br>A. 创建一个包含访问 Lake Formation 表权限的 <strong>IAM 角色</strong><br>B. <u>创建<strong>数据过滤器</strong>以实施<strong>行级安全性和单元格级安全性</strong></u><br>C. 创建一个 <strong>AWS Lambda 函数</strong>，在 Lake Formation 摄入数据之前移除敏感信息<br>D. 创建一个 <strong>AWS Lambda 函数</strong>，定期查询并从 Lake Formation 表中移除敏感信息</p>
<p><br>610 一家公司部署了在 <strong>VPC 中运行的 EC2 实例</strong>，这些实例将源数据加载到 <strong>Amazon S3 存储桶</strong>，以便日后处理。<br>合规要求：<strong>数据不得通过公共互联网传输</strong>。<br>此外，<strong>本地数据中心的服务器</strong>将使用 EC2 实例上运行的应用程序所产生的输出（即需要从 S3 获取输出数据）。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 为 Amazon EC2 部署一个<strong>接口 VPC 终端节点</strong>，在公司和 VPC 之间创建 <strong>AWS 站点到站点 VPN 连接</strong><br>B. <u>为 Amazon S3 部署<strong>网关 VPC 终端节点</strong>，在本地环境和 VPC 之间建立 <strong>AWS Direct Connect 连接</strong></u><br>C. 从 VPC 建立一个 <strong>AWS Transit Gateway 连接到 S3 存储桶</strong>，在公司和 VPC 之间创建 <strong>站点到站点 VPN 连接</strong><br>D. 设置具有到 NAT 网关路由的<strong>代理 EC2 实例</strong>，配置代理 EC2 实例以获取 S3 数据并为应用程序实例提供数据</p>
<ol>
<li>为 S3 创建 <strong>网关 VPC 端点</strong>，确保 VPC 内 EC2 访问 S3 不走互联网。</li>
<li>使用 <strong>AWS Direct Connect</strong>（私有 VIF）连接本地数据中心与 VPC，使本地服务器通过 VPC 访问 S3（经网关端点）。</li>
</ol>
<p>接口端点适用于 EC2、SNS、SQS 等服务，但 <strong>S3 使用网关端点（Gateway Endpoint）或接口端点（Interface Endpoint）</strong></p>
<p>Transit Gateway 用于连接多个 VPC 和本地网络，但 <strong>S3 不支持通过 Transit Gateway 直接连接</strong>（S3 不是 VPC 资源）</p>
<p>代理 EC2 和 NAT 网关仍然可能通过互联网访问 S3（除非结合网关端点）。</p>
<p><br>611 一家公司有一个带有 <strong>REST 接口的应用程序</strong>，允许从第三方供应商<strong>近乎实时接收数据</strong>，随后处理并存储以进行分析。<br>当前：应用程序运行在 <strong>Amazon EC2 实例</strong>上。<br>问题：</p>
<ul>
<li>第三方供应商发送数据时收到 <strong>503 服务不可用错误</strong></li>
<li><strong>数据量激增时，计算能力达到最大限制</strong>，应用无法处理所有请求<br>目标：提供<strong>更具可扩展性的解决方案</strong>。</li>
</ul>
<p>选项：<br>A. <u>使用 <strong>Amazon Kinesis Data Streams</strong> 接入数据，使用 <strong>AWS Lambda</strong> 函数处理数据</u><br>B. 在现有应用程序之上使用 <strong>Amazon API Gateway</strong>，为第三方供应商创建一个带有配额限制的使用计划<br>C. 使用 <strong>Amazon SNS</strong> 来接收数据，将 EC2 实例放在 <strong>ALB 后的自动扩展组</strong>中<br>D. 将应用程序重新打包为容器，使用 <strong>EC2 启动类型 + 自动扩展组</strong> 通过 <strong>Amazon ECS</strong> 部署应用</p>
<p><strong>Kinesis Data Streams + Lambda</strong> 是 AWS 推荐的用于<strong>实时数据流处理</strong>的无服务器架构，<strong>Lambda</strong> 作为消费者处理数据，<strong>自动扩展</strong>并发处理多个分片的数据，无需管理服务器。</p>
<p><br>612 一家公司有一个在<strong>私有子网中的 EC2 实例</strong>上运行的应用程序，需要处理来自 <strong>Amazon S3 存储桶的敏感信息</strong>。<br>要求：<strong>应用程序不得使用互联网连接到 S3 存储桶</strong>。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 配置<strong>互联网网关</strong>，更新 S3 存储桶策略允许来自互联网网关的访问，更新应用程序使用互联网网关<br>B. 配置 <strong>VPN 连接</strong>，更新 S3 存储桶策略允许来自 VPN 连接的访问，更新应用程序使用 VPN 连接<br>C. 配置 <strong>NAT 网关</strong>，更新 S3 存储桶策略允许来自 NAT 网关的访问，更新应用程序使用 NAT 网关<br>D<u>. 配置一个 <strong>VPC 终端节点</strong>，更新 S3 存储桶策略允许来自 VPC 终端节点的访问，更新应用程序使用 VPC 终端节点</u></p>
<ul>
<li>VPN 连接用于连接本地数据中心与 VPC，不适用于访问 S3。即使通过 VPN，EC2 到 S3 的流量可能仍会经过互联网（除非配合 VPC 端点）。</li>
</ul>
<p><br>613 一家公司使用 <strong>Amazon EKS</strong> 运行容器应用程序，并在 <strong>Kubernetes Secret 对象</strong> 中存储敏感信息。<br>要求：<strong>确保这些信息得到加密</strong>。<br>目标：<strong>以最小的运营开销</strong>满足要求。</p>
<p>选项：<br>A. 使用容器应用程序通过 <strong>AWS KMS</strong> 对信息进行加密<br>B. <u>使用 <strong>AWS KMS 在 EKS 集群中启用密钥加密</strong></u><br>C. 实施一个 <strong>AWS Lambda 函数</strong>，使用 AWS KMS 对信息进行加密<br>D. 使用 <strong>AWS Systems Manager Parameter Store</strong> 通过 AWS KMS 对信息进行加密</p>
<h3 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h3><ul>
<li>敏感信息存储在 <strong>Kubernetes Secret</strong> 中（默认以 base64 编码，但未加密）。</li>
<li>要求：确保 Secret 数据<strong>静态加密</strong>（at-rest encryption）。</li>
<li>目标：<strong>最小运营开销</strong> → 优先使用 EKS 托管功能，避免自定义应用层加密逻辑。</li>
</ul>
<h3 id="2-EKS-的-Secret-加密选项"><a href="#2-EKS-的-Secret-加密选项" class="headerlink" title="2. EKS 的 Secret 加密选项"></a>2. EKS 的 Secret 加密选项</h3><p>EKS 支持使用 <strong>AWS KMS 密钥</strong> 对 Kubernetes Secret 进行<strong>静态加密</strong>（通过 <strong>EKS 集群加密配置</strong>）。</p>
<ul>
<li>在创建 EKS 集群时（或更新现有集群），可以启用 <strong>Secrets 加密</strong>，指定一个 AWS KMS 密钥。</li>
<li>此后，所有存储在 etcd 中的 Secret 数据都会由 EKS 使用该 KMS 密钥自动加密。</li>
<li>这是<strong>托管服务功能</strong>，无需在应用层进行加解密操作，运营开销最小。</li>
</ul>
<p><br>614 一家公司正在设计一个多层 Web 应用程序，包含：</p>
<ol>
<li><strong>Web 服务器和应用程序服务器</strong> 作为自动扩展组的一部分运行在 EC2 实例上</li>
<li><strong>Amazon RDS 数据库实例</strong> 用于数据存储</li>
</ol>
<p>要求：<strong>限制对应用服务器的访问，只有 Web 服务器能够访问它们</strong>。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 在应用服务器前部署 <strong>AWS PrivateLink</strong>，配置 <strong>网络 ACL</strong> 仅允许 Web 服务器访问<br>B. 在应用服务器前部署一个 <strong>VPC 终端节点</strong>，配置 <strong>安全组</strong> 只允许 Web 服务器访问<br>C. 部署一个 <strong>网络负载均衡器</strong>，目标组包含应用服务器的自动扩展组，配置 <strong>网络访问控制列表</strong> 仅允许 Web 服务器访问<br>D. <u>部署一个 <strong>应用程序负载均衡器</strong>，目标组包含应用服务器的自动扩展组，配置 <strong>安全组</strong> 仅允许 Web 服务器访问</u></p>
<p>在多层架构中，限制应用服务器仅允许 Web 服务器访问的最佳方法是：</p>
<ol>
<li>使用<strong>内部负载均衡器</strong>（ALB 或 NLB）进行流量分发（可选，但有助于扩展和管理）。</li>
<li>在<strong>应用服务器的安全组</strong>中设置规则，仅允许来自 <strong>Web 服务器安全组</strong> 的流量。<br>选项 D 提到了 ALB + 安全组配置，符合要求。</li>
</ol>
<p><br>615 一家公司在 <strong>Amazon EKS</strong> 上运行一个关键的、面向客户的应用程序（微服务架构）。<br>要求：<strong>在一个集中位置收集、聚合和汇总来自该应用程序的指标和日志</strong>。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 在现有的 EKS 集群中运行 <strong>Amazon CloudWatch 代理</strong>，在 CloudWatch 控制台中查看指标和日志<br>B. 在现有的 EKS 集群中运行 <strong>AWS App Mesh</strong>，在 App Mesh 控制台中查看指标和日志<br>C. 配置 <strong>AWS CloudTrail</strong> 以捕获数据事件，使用 <strong>Amazon OpenSearch Service</strong> 查询 CloudTrail<br>D. <u>在现有 EKS 集群中配置 <strong>Amazon CloudWatch 容器洞察</strong>，在 CloudWatch 控制台中查看指标和日志</u></p>
<ul>
<li><strong>CloudWatch 容器洞察</strong> 是 AWS 专门为 <strong>EKS、ECS 和 Kubernetes</strong> 设计的<strong>全托管监控解决方案</strong>。</li>
</ul>
<p><br>616 一家公司在 AWS 上部署了产品，架构包括：</p>
<ul>
<li>网络负载均衡器后的自动扩展组</li>
<li>产品的对象存储在 <strong>Amazon S3 存储桶</strong>中</li>
</ul>
<p>最近遭遇了<strong>恶意攻击</strong>，需要解决方案能够：</p>
<ol>
<li><strong>持续监控 AWS 账户、工作负载以及 S3 存储桶的访问模式中的恶意活动</strong></li>
<li><strong>报告可疑活动</strong></li>
<li><strong>在仪表板上显示相关信息</strong></li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 配置 <strong>Amazon Macie</strong> 以监控发现并向 <strong>AWS Config</strong> 报告<br>B. 配置 <strong>Amazon Inspector</strong> 以监控并向 <strong>AWS CloudTrail</strong> 报告发现的问题<br>C. <u>配置 <strong>Amazon GuardDuty</strong> 以监控并向 <strong>AWS Security Hub</strong> 报告发现结果</u><br>D. 配置 <strong>AWS Config</strong> 以监控并向 <strong>Amazon EventBridge</strong> 报告发现的问题</p>
<h4 id="Amazon-Macie"><a href="#Amazon-Macie" class="headerlink" title="Amazon Macie"></a><strong>Amazon Macie</strong></h4><ul>
<li>专注于 <strong>S3 中的数据安全与隐私</strong>（发现敏感数据、监控数据访问），但<strong>不是全面的账户和工作负载威胁检测服务</strong>。</li>
<li>不满足“监控 AWS 账户和工作负载”的广泛需求。</li>
</ul>
<h4 id="Amazon-Inspector"><a href="#Amazon-Inspector" class="headerlink" title="Amazon Inspector"></a><strong>Amazon Inspector</strong></h4><ul>
<li>用于 <strong>EC2 实例和容器镜像的漏洞评估</strong>（扫描软件漏洞、网络暴露），<strong>不是实时威胁检测服务</strong>。</li>
<li>不适用于持续监控恶意活动或 S3 访问模式。</li>
</ul>
<h4 id="Amazon-GuardDuty-✅"><a href="#Amazon-GuardDuty-✅" class="headerlink" title="Amazon GuardDuty ✅"></a><strong>Amazon GuardDuty</strong> ✅</h4><ul>
<li><strong>威胁检测服务</strong>，持续监控以下数据源：<ul>
<li><strong>AWS CloudTrail 事件</strong>（账户和工作负载的 API 调用）</li>
<li><strong>VPC 流日志</strong>（网络流量）</li>
<li><strong>DNS 查询日志</strong></li>
<li><strong>S3 数据事件日志</strong>（监控 S3 存储桶的访问模式）</li>
</ul>
</li>
<li>使用机器学习、异常检测和威胁情报识别恶意活动（如加密货币挖矿、数据泄露、凭证泄露等）。</li>
<li>可与 <strong>AWS Security Hub</strong> 集成，将发现结果发送到 Security Hub，提供<strong>集中安全仪表板</strong>，汇总和展示威胁警报。</li>
<li>完全符合需求：监控账户、工作负载、S3 访问 + 报告 + 仪表板。</li>
</ul>
<h4 id="AWS-Config"><a href="#AWS-Config" class="headerlink" title="AWS Config"></a><strong>AWS Config</strong></h4><ul>
<li>用于<strong>资源配置和合规性审计</strong>（跟踪资源变更、评估规则合规性），<strong>不是威胁检测服务</strong>。</li>
<li>不适用于实时监控恶意活动。</li>
</ul>
<p>617一家公司希望将本地数据中心迁移到 AWS，其中有一台<strong>存储服务器</strong>，使用 <strong>基于 NFS 的文件系统</strong> 存储数据。</p>
<ul>
<li>数据量：<strong>200 GB</strong></li>
<li>迁移要求：<ol>
<li><strong>不中断现有服务</strong>（即在线迁移，最小停机）</li>
<li><strong>AWS 中的多个资源必须能够通过 NFS 协议访问这些数据</strong>（即需要共享文件系统）</li>
</ol>
</li>
<li>目标：<strong>最具成本效益</strong> 的步骤组合（选择两项）</li>
</ul>
<p>选项：<br>A. 创建一个 <strong>Amazon FSx for Lustre</strong> 文件系统<br>B. <u>创建一个 <strong>Amazon Elastic File System（EFS）</strong> 文件系统</u><br>C. 创建一个 <strong>Amazon S3 存储桶</strong> 来接收数据<br>D. 手动使用操作系统复制命令将数据推送到 AWS 目标位置<br>E. <u>在本地数据中心安装 <strong>AWS DataSync 代理</strong>，在本地和 AWS 之间使用 <strong>DataSync 任务</strong></u></p>
<ul>
<li><strong>NFS 共享文件系统</strong> 在 AWS 中的选项：<ul>
<li><strong>Amazon EFS</strong>：全托管、跨可用区的 NFS 文件系统（支持 NFSv4）。</li>
<li><strong>Amazon FSx for Lustre</strong>：高性能并行文件系统（主要用于 HPC&#x2F;ML），支持 NFS 但非主要用例。</li>
<li><strong>FSx for ONTAP &#x2F; OpenZFS</strong>：也支持 NFS，但 EFS 是最常用且成本较低的通用 NFS 服务。</li>
</ul>
</li>
<li>对于通用 NFS 共享，<strong>EFS</strong> 是最具成本效益且易于管理的选择。</li>
</ul>
<p><br>618 一家公司希望为其 EC2 实例使用 <strong>Amazon FSx for Windows File Server</strong>，这些实例在 <strong>us-east-1</strong> 挂载 SMB 文件共享作为卷。<br>要求：</p>
<ol>
<li><strong>RPO &#x3D; 5 分钟</strong>（针对计划内维护或计划外中断）</li>
<li>需要将<strong>文件系统复制到 us-west-2</strong></li>
<li>复制的数据在 <strong>5 年内不得被任何用户删除</strong>（即防篡改、防删除的保留策略）</li>
</ol>
<p>问：哪种解决方案能够满足这些要求？</p>
<p>选项：<br>A. 在 us-east-1 创建 <strong>单可用区（Single-AZ）FSx 文件系统</strong>，使用 <strong>AWS Backup 每日备份计划</strong>，备份复制到 us-west-2，为目标备份库配置<strong>合规模式的 AWS Backup Vault Lock</strong>，最短期限 5 年<br>B. 在 us-east-1 创建 <strong>多可用区（Multi-AZ）FSx 文件系统</strong>，使用 AWS Backup 每日备份计划，备份复制到 us-west-2，为目标备份库配置<strong>治理模式的 AWS Backup Vault Lock</strong>，最短期限 5 年<br>C. <u>在 us-east-1 创建 <strong>多可用区 FSx 文件系统</strong>，使用 AWS Backup 每日备份计划，备份复制到 us-west-2，为目标备份库配置<strong>合规模式的 AWS Backup Vault Lock</strong>，最短期限 5 年</u><br>D. 在 us-east-1 创建 <strong>单可用区 FSx 文件系统</strong>，使用 AWS Backup 每日备份计划，备份复制到 us-west-2，为目标备份库配置<strong>治理模式的 AWS Backup Vault Lock</strong>，最短期限 5 年</p>
<ul>
<li><strong>FSx 部署类型</strong>：<ul>
<li><strong>单可用区（Single-AZ）</strong>：RPO 较高（依赖备份频率），不满足 5 分钟 RPO。</li>
<li><strong>多可用区（Multi-AZ）</strong>：提供<strong>自动故障转移和同步复制</strong>，RPO 接近 0，满足 5 分钟要求。</li>
</ul>
</li>
<li><strong>AWS Backup Vault Lock 模式</strong>：<ul>
<li><strong>治理模式（Governance mode）</strong>：允许特权用户（具有特定权限）在审计追踪后删除备份。</li>
<li><strong>合规模式（Compliance mode）</strong>：<strong>任何人（包括 root）都无法在保留期内删除备份</strong>，符合“5 年内不得被任何用户删除”的严格合规要求。</li>
</ul>
</li>
</ul>
<p><br>619 解决方案架构师正在设计安全解决方案，通过 <strong>AWS Organizations</strong> 为开发人员提供个人 AWS 账户，同时维持标准安全控制。</p>
<ul>
<li>开发人员个人拥有其账户的 <strong>根用户级别访问权限</strong>（即完全控制）。</li>
<li>要求：确保应用于新开发人员账户的<strong>强制性 AWS CloudTrail 配置不会被修改</strong>（即防止开发人员禁用或更改 CloudTrail 跟踪）。</li>
</ul>
<p>问：哪个操作符合这些要求？</p>
<p>选项：<br>A. 创建一个禁止修改 CloudTrail 的 <strong>IAM 策略</strong>，并将其附加到根用户<br>B. 在开发者账户中从 CloudTrail 创建新的跟踪，并启用<strong>组织跟踪选项</strong><br>C. <u>创建一个<strong>服务控制策略（SCP）</strong>，禁止对 CloudTrail 进行更改，并将其附加到开发者账户</u><br>D. 为 CloudTrail 创建一个<strong>服务关联角色</strong>，并设置一个策略条件，仅允许来自管理账户中的 ARN 的更改</p>
<p><strong>服务控制策略（SCP）</strong> 是 AWS Organizations 中唯一可<strong>限制成员账户根用户操作</strong>的机制，因此必须使用 SCP 来禁止对 CloudTrail 的修改。</p>
<p><br>620 一家公司计划在 AWS 云中部署一个<strong>业务关键型应用程序</strong>，要求：</p>
<ol>
<li><strong>持久性存储</strong></li>
<li><strong>一致且低延迟性能</strong></li>
</ol>
<p>问：解决方案架构师应推荐哪种类型的存储来满足这些要求？</p>
<p>选项：<br>A. 实例存储卷<br>B. Amazon ElastiCache for Memcached 集群<br>C. 预配置 IOPS SSD 驱动的弹性块存储（Amazon EBS）卷<br>D. 吞吐量优化型 HDD Amazon Elastic Block Store（Amazon EBS）卷</p>
<ul>
<li><p><strong>实例存储</strong>是<strong>临时性存储</strong>（实例终止或停止时数据丢失），<strong>不满足持久性要求</strong>。</p>
</li>
<li><p>ElastiCache 是<strong>内存缓存服务</strong>，不是持久性存储（数据可持久化但主要设计为缓存），且 Memcached 本身不提供数据持久化保证。</p>
</li>
<li><p>HDD  EBS适用于大吞吐量、顺序读写的工作负载（如大数据、日志处理），但<strong>随机访问延迟较高</strong></p>
</li>
<li><p><strong>EBS 卷</strong>是<strong>持久性块存储</strong>（数据独立于实例生命周期）。</p>
</li>
<li><p><strong>预配置 IOPS SSD（如 io1&#x2F;io2）</strong> 提供<strong>可预测的高性能</strong>：</p>
</li>
</ul>
<p><br>621 一家在线照片共享公司将照片存储在 <strong>us-west-1 的 S3 存储桶</strong>中。<br>要求：</p>
<ul>
<li>需要在 <strong>us-east-1 存储所有新照片的副本</strong></li>
<li>以<strong>最少的运营工作量</strong>满足要求</li>
</ul>
<p>选项：<br>A. <u>在 us-east-1 创建第二个 S3 存储桶，使用 <strong>S3 跨区域复制</strong> 将照片从现有桶复制到新桶</u><br>B. 为现有 S3 存储桶创建 <strong>跨域资源共享（CORS）配置</strong>，在 AllowedOrigin 元素中指定 us-east-1<br>C. 在 us-east-1 创建第二个 S3 存储桶，创建 <strong>S3 生命周期规则</strong> 将照片保存到第二个桶<br>D. 在 us-east-1 创建第二个 S3 存储桶，配置 <strong>S3 事件通知</strong> 调用 <strong>Lambda 函数</strong> 将照片复制到第二个桶</p>
<ul>
<li>CORS 用于控制跨域 HTTP 请求（如浏览器 JavaScript 访问不同域的 S3），与<strong>数据复制无关</strong>。</li>
</ul>
<p><br>622 一家公司正在为其订阅用户开发一个新的 Web 应用，包含：</p>
<ol>
<li><strong>静态单页</strong>（前端）</li>
<li><strong>持久化数据库层</strong>（后端）</li>
</ol>
<p>使用模式：</p>
<ul>
<li><strong>早上 4 小时</strong>：数百万用户（高峰）</li>
<li><strong>其他时间</strong>：几千名用户（低谷）</li>
</ul>
<p>要求：</p>
<ol>
<li><strong>能够快速改进数据库模式</strong>（即灵活的数据模型、易于变更）</li>
<li><strong>提供最高的可扩展性</strong>（应对高峰流量）</li>
</ol>
<p>问：哪些解决方案能满足要求并提供最高的可扩展性？（选择两项）</p>
<p>选项：<br>A. <u>部署 <strong>Amazon DynamoDB</strong> 作为数据库，按需提供容量</u><br>B. 部署 <strong>Amazon Aurora</strong> 作为数据库，选择无服务器数据库引擎模式<br>C. 部署 <strong>Amazon DynamoDB</strong> 作为数据库，确保启用了 DynamoDB 自动扩展<br>D<u>. 将静态内容部署到 <strong>Amazon S3 存储桶</strong>，配置以该 S3 存储桶为源站的 <strong>Amazon CloudFron</u>t 分发</strong><br>E. 在 Auto Scaling 组中的一组 <strong>EC2 实例</strong> 中为静态内容部署 Web 服务器，将实例配置为定期刷新 <strong>Amazon EFS</strong> 卷中的内容</p>
<ul>
<li><strong>DynamoDB 按需模式</strong> 自动适应工作负载，无需预置容量，可处理突增流量，<strong>可扩展性高</strong>。</li>
</ul>
<p><br>623 一家公司使用 Amazon API Gateway 管理其 REST API，供第三方服务提供商访问。<br>该公司必须保护该 REST API 免受 <strong>SQL 注入</strong> 和 <strong>跨站点脚本（XSS）</strong> 攻击。</p>
<p>选项如下：<br>A. 配置 AWS Shield<br>B. <u>配置 AWS WAF</u><br>C. 通过 Amazon CloudFront 发行版设置 API Gateway，并在 CloudFront 中配置 AWS Shield<br>D. 通过 Amazon CloudFront 发行版设置 API Gateway，并在 CloudFront 中配置 AWS WAF</p>
<p>AWS Shield 主要提供 DDoS 防护（网络层&#x2F;传输层），不针对 SQL 注入或 XSS 等应用层攻击。</p>
<p>AWS WAF 可直接关联到 API Gateway，对传入请求进行内容检查，有效防御 SQL 注入与 XSS，且 <strong>WAF 直接附加到 API Gateway 更简洁</strong>。</p>
<p><br>624 一家公司希望为用户提供对 AWS 资源的访问。公司有 1,500 名用户，目前通过公司网络上的 <strong>Active Directory（AD）用户组</strong>管理他们对本地资源的访问权限。<br>公司不希望用户再维护另一个身份来访问 AWS 资源。<br>解决方案架构师需要设计一个方案，既能管理用户对 AWS 资源的访问，又能保留他们对本地资源的现有访问方式（即继续使用 AD 登录本地系统）。</p>
<p>选项如下：<br>A. 为每个用户创建一个 IAM 用户，并为每个用户附加适当的策略<br>B. 使用 Amazon Cognito 与 Active Directory 用户池配合使用，创建附加了适当策略的角色<br>C. 定义跨账户角色，附加适当策略，将角色映射到 Active Directory 组<br>D. <u>配置基于 SAML 2.0 的联合身份验证，创建具有适当策略的角色，并将角色映射到 Active Directory 组</u></p>
<ul>
<li>这是 <strong>AWS 推荐的企业 AD 集成方案</strong>。通过 AD FS 或其他 SAML 2.0 身份提供商（IdP）将本地 AD 与 AWS 进行联合。</li>
<li>用户使用 AD 账户登录后，通过 SAML 断言获得 AWS 临时凭证，无需单独管理 IAM 用户。</li>
</ul>
<p><br>625 一家公司在多个应用程序负载均衡器（ALB）后托管一个网站。该公司在全球范围内对其内容拥有 <strong>不同的分发权限</strong>，需要确保向用户提供正确的内容，同时不违反这些权限。</p>
<p><strong>问题</strong>：解决方案架构师应选择哪种配置来满足此要求？</p>
<p>选项如下：<br>A. 使用 AWS WAF 配置 Amazon CloudFront<br>B. 配置带有 AWS WAF 的应用程序负载均衡器<br>C. <u>使用地理位置策略配置 Amazon Route 53</u><br>D. 使用地理邻近路由策略配置 Amazon Route 53</p>
<p>Route 53 的<strong>地理位置路由策略</strong>允许根据用户的地理位置（国家、区域）将 DNS 查询路由到不同的终端节点（例如不同区域的 ALB）</p>
<p>地理邻近路由策略是基于用户与资源物理距离的路由，可结合地理位置和延迟优化，但不直接强制执行基于分发权限的路由（更多是性能优化）</p>
<p><br>626 一家公司数据存储在本地，数据量增长已超出可用容量，希望将数据迁移到 Amazon S3。<br>要求：迁移解决方案需要能在<strong>传输后自动验证数据完整性</strong>。</p>
<p>选项如下：<br>A. 订购 AWS Snowball Edge 设备，配置该设备以执行向 S3 的在线数据传输<br>B. <u>在本地部署 AWS DataSync 代理，配置它以执行到 S3 的在线数据传输</u><br>C. 在本地创建 Amazon S3 文件网关，配置它以执行到 S3 存储桶的在线数据传输<br>D. 在本地的 Amazon S3 传输加速中配置一个加速器，用它执行向 S3 的在线数据传输</p>
<p><br>627 一家公司希望将两台本地 DNS 服务器迁移到 AWS，这两台服务器共托管约 <strong>200 个区域</strong>，平均每天接收 <strong>100 万个请求</strong>（约每秒 11-12 个请求，属于中等负载）。<br>公司希望<strong>最大化可用性</strong>，同时<strong>尽量减少与这两台服务器管理相关的运营开销</strong>。</p>
<p>选项如下：<br>A. <u>在 Amazon Route 53 控制台中创建 200 个新的托管区域，导入区域文件</u><br>B. 启动一个大型 Amazon EC2 实例来导入区域文件，配置 CloudWatch 告警和通知，以便在停机时发出警报<br>C. 使用 AWS Server Migration Service（SMS）将服务器迁移到 AWS，配置 CloudWatch 警报和通知<br>D. 在两个可用区的 Auto Scaling 组中启动一个 Amazon EC2 实例，导入区域文件，将期望容量设置为 1、最大容量设置为 3，配置基于 CPU 利用率的扩展警报</p>
<ul>
<li>Route 53 是 AWS 全托管的 DNS 服务，具有<strong>高可用性（99.99% SLA）</strong>，跨多个 AZ 分布，无需管理服务器。</li>
<li>可以批量创建托管区域并导入现有区域文件（支持导入功能）</li>
</ul>
<p><br>628 一家跨国公司在 AWS Organizations 中的多个 AWS 账户中运行应用程序。应用程序使用 <strong>分块上传（multipart upload）</strong> 将数据上传到多个区域的多个 Amazon S3 存储桶。<br>为了成本合规，公司希望<strong>报告未完成的分块上传情况</strong>（这些会占用存储空间并产生费用）。<br>要求：以<strong>最少的运营开销</strong>满足需求。</p>
<p>选项如下：<br>A. 配置 AWS Config 并设置规则，以报告不完整的分块上传对象数量<br>B. 创建服务控制策略（SCP）以报告不完整的分块上传对象数量<br>C. <u>配置 S3 Storage Lens 以报告不完整的分块上传对象计数</u><br>D. 创建一个 S3 多区域访问点来报告不完整的分块上传对象数量</p>
<ul>
<li>S3 Storage Lens 是专门为 S3 存储分析和成本优化设计的工具，可以直接报告<strong>分块上传计数</strong>。</li>
</ul>
<p><br>629 一家公司在 <strong>Amazon RDS for MySQL</strong> 上运行生产数据库，出于安全合规需要升级数据库版本。<br>要求：</p>
<ul>
<li>数据库包含关键数据，升级过程中不能丢失任何数据</li>
<li>需要<strong>快速升级并测试功能</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 创建一个 RDS 手动快照，升级到 Amazon RDS for MySQL 的新版本<br>B. 使用原生备份和恢复功能，将数据恢复到升级后的新版 Amazon RDS for MySQL<br>C. 使用 AWS DMS 将数据复制到升级后的新版本 Amazon RDS for MySQL<br>D. <u>使用 Amazon RDS 蓝绿部署来部署和测试生产变更</u></p>
<p>这是 RDS 标准升级流程之一，但直接对生产实例进行<strong>原地升级</strong>可能会造成较长时间不可用（取决于数据量）</p>
<p>手动执行备份、创建新版本实例、恢复数据，操作步骤多、耗时长，<strong>运营开销大</strong>，且测试过程需额外安排</p>
<p>DMS 可实现不停机迁移，但主要用于异构迁移或持续复制</p>
<p><br>630 解决方案架构师需要创建一个<strong>数据处理作业</strong>，要求如下：</p>
<ul>
<li>每天运行一次</li>
<li>最多可能需要 <strong>2 小时完成</strong></li>
<li>如果作业被中断，必须<strong>从头开始重新运行</strong></li>
<li>以<strong>最具成本效益的方式</strong>解决</li>
</ul>
<p>选项如下：<br>A. 创建一个在 Amazon EC2 预留实例上本地运行的脚本，由定时任务触发<br>B. 创建一个由 Amazon EventBridge 计划事件触发的 AWS Lambda 函数<br>C. <u>使用由 Amazon EventBridge 计划事件触发的 Amazon ECS Fargate 任务</u><br>D. 使用由 Amazon EventBridge 计划事件触发的、在 Amazon EC2 上运行的 Amazon ECS 任务</p>
<p>Lambda 最大超时时间为 <strong>15 分钟</strong>，无法运行长达 2 小时的作业，因此<strong>不满足需求</strong></p>
<p><strong>Fargate 是无服务器容器服务</strong>，按任务运行时间计费（vCPU 和内存使用量）</p>
<p><br>631 一家社交媒体公司希望将其<strong>用户资料、关系和互动</strong>的数据库存储在 AWS 云中，并需要满足以下功能：</p>
<ol>
<li>需要一个应用程序来监控数据库中的任何变化</li>
<li>此应用程序需要分析数据实体之间的关系</li>
<li>向用户提供建议</li>
</ol>
<p>要求：以<strong>最少的运营开销</strong>满足需求。</p>
<p>选项如下：<br>A. 使用 Amazon Neptune 存储信息，使用 Amazon Kinesis Data Streams 处理数据库中的变更<br>B. <u>使用 Amazon Neptune 存储信息，使用 Neptune Streams 处理数据库中的变更</u><br>C. 使用 Amazon QLDB 存储信息，使用 Amazon Kinesis Data Streams 处理数据库中的变更<br>D. 使用 Amazon QLDB 存储信息，使用 Neptune Streams 处理数据库中的变更</p>
<ul>
<li><p><strong>Neptune 是专门为图数据设计的数据库</strong>，适合存储和查询用户关系。</p>
</li>
<li><p><strong>Neptune Streams 提供原生的变更捕获</strong>，无需额外搭建流处理管道，减少了运营复杂性和开销。</p>
</li>
<li><p>QLDB 是账本数据库，专注于不可变、可验证的交易日志，<strong>不适合存储和查询复杂的图关系</strong>。</p>
</li>
<li><p>Kinesis Data Streams 可用于流式处理，但需要额外编写代码来捕获 Neptune 的变更并推送到 Kinesis，<strong>增加了架构复杂性和运营开销</strong>。</p>
</li>
</ul>
<p><br>632 一家公司正在开发一款新应用，该应用将存储大量数据，且满足以下条件：</p>
<ul>
<li>数据将<strong>每小时进行一次分析</strong></li>
<li>数据会被<strong>部署在多个可用区的多台 Amazon EC2 Linux 实例</strong>修改</li>
<li>未来 6 个月，所需存储空间将持续增长</li>
</ul>
<p>解决方案架构师应推荐哪种存储解决方案？</p>
<p>选项如下：<br>A. 将数据存储在 Amazon S3 Glacier 中，更新 S3 Glacier 存储库策略以允许应用程序实例访问<br>B. 将数据存储在 Amazon EBS 卷中，将 EBS 卷挂载到应用程序实例上<br>C. <u>将数据存储在 Amazon EFS 文件系统中，将该文件系统挂载到应用程序实例上</u><br>D. 将数据存储在应用程序实例之间共享的 Amazon EBS 预配置 IOPS 卷中</p>
<ul>
<li><p>Glacier 是<strong>归档存储服务</strong>，检索延迟高（分钟到小时），不适合被 EC2 实例频繁修改或每小时分析。</p>
</li>
<li><p>EBS 卷是<strong>块存储</strong>，只能挂载到<strong>同一可用区</strong>的单个 EC2 实例</p>
</li>
<li><p><strong>EFS 是托管网络文件系统（NFS）</strong>，支持<strong>跨多个可用区共享访问</strong>。</p>
</li>
<li><p>EBS 卷<strong>不支持多实例同时挂载读写</strong>（除非使用特定集群文件系统如 Lustre，但非原生支持，且需要额外配置）预配置 IOPS 卷是针对高性能单实例场景，不满足多可用区共享需求</p>
</li>
</ul>
<p><br>633 一家公司的应用使用 <strong>Amazon RDS for PostgreSQL 多可用区数据库实例</strong> 存储数据。<br>由于流量增加，出现性能问题，且确定 <strong>数据库查询是性能缓慢的主要原因</strong>。</p>
<p>问：解决方案架构师应采取什么措施来提升应用程序性能？</p>
<p>选项如下：<br>A. 从多可用区备用副本处理读取流量<br>B. 配置数据库实例以使用传输加速<br>C. <u>从源数据库实例创建一个只读副本，从该只读副本处理读取流量</u><br>D. 在应用程序和 Amazon RDS 之间使用 Amazon Kinesis Data Firehose，以提高数据库请求的并发量</p>
<p><br>634 一家公司每天收集 10GB 遥测数据，存储在 <strong>源数据账户</strong> 的 Amazon S3 存储桶中。<br>公司聘请了多家咨询机构，他们的分析师需要对数据拥有<strong>只读权限</strong>。<br>要求：共享数据给这些机构时，必须<strong>最大限度提高安全性和运营效率</strong>。</p>
<p>选项如下：<br>A. 为每个机构配置 S3 全局表以复制数据<br>B. 在有限时间内将 S3 存储桶设为公共，仅通知相关机构<br>C. <u>为 S3 存储桶配置跨账户访问权限，使其对各机构拥有的账户开放</u><br>D. 在源数据账户中为每位分析师创建一个 IAM 用户，授予每位用户对 S3 存储桶的访问权限</p>
<ul>
<li><strong>推荐做法</strong>：通过 S3 存储桶策略，授予其他 AWS 账户（机构账户）对该存储桶的只读访问权限（如 <code>s3:GetObject</code>）。</li>
<li><strong>安全性</strong>：权限仅限于指定账户，机构可自行管理其账户内的用户权限（通过 IAM 角色&#x2F;用户）</li>
</ul>
<p><br>635 一家公司在主要区域使用 <strong>Amazon FSx for NetApp ONTAP</strong> 提供 CIFS 和 NFS 文件共享，由 EC2 实例访问。<br>公司需要在次要区域部署<strong>存储灾难恢复（DR）解决方案</strong>，要求：</p>
<ul>
<li>次要区域复制的数据能够通过**与主要区域相同的协议（CIFS&#x2F;NFS）**访问</li>
<li>满足要求且<strong>运营开销最小</strong></li>
</ul>
<p>选项如下：<br>A. 创建 Lambda 函数将数据复制到 S3，将 S3 存储桶复制到次要区域<br>B. 使用 AWS Backup 为 FSx for ONTAP 卷创建备份，将卷复制到次要区域，从备份创建新的 FSx for ONTAP 实例<br>C. <u>在次要区域创建一个 FSx for ONTAP 实例，使用 NetApp SnapMirror 从主区域复制数据到次要区域</u><br>D. 创建一个 Amazon EFS 卷，迁移当前数据到该卷，复制卷到备用区域</p>
<ul>
<li><strong>FSx for ONTAP 原生集成 NetApp SnapMirror 技术</strong>，支持<strong>跨区域异步复制</strong>。</li>
<li>复制在存储层面自动持续进行，<strong>RPO 小</strong>。</li>
<li>目标区域同样是 FSx for ONTAP，<strong>支持相同协议（CIFS&#x2F;NFS）</strong></li>
</ul>
<p><br>636 一个开发团队正在创建基于事件的应用程序，使用 AWS Lambda 函数。</p>
<ul>
<li>事件源：文件添加到 Amazon S3 存储桶</li>
<li>当前配置：Amazon SNS 被配置为来自 S3 的事件目标</li>
<li>目标：需要<strong>以可扩展的方式处理来自 S3 的事件</strong></li>
</ul>
<p>选项如下：<br>A. 创建一个 SNS 订阅，在事件在 Lambda 中运行之前，先在 Amazon ECS 中处理该事件<br>B. 创建一个 SNS 订阅，在事件在 Lambda 中运行之前，先在 Amazon EKS 中处理该事件<br>C. <u>创建一个 SNS 订阅，将事件发送到 Amazon SQS，配置 SQS 队列以触发 Lambda 函数</u><br>D. 创建一个 SNS 订阅，将事件发送到 AWS SMS，配置 Lambda 函数以从 SMS 事件中进行轮询</p>
<ul>
<li>这是 AWS 推荐的 <strong>S3 事件处理可扩展模式</strong>（S3 → SNS → SQS → Lambda）。</li>
<li>通过 SQS 解耦，提高可靠性、扩展性和错误处理能力，符合“以可扩展的方式处理事件”的要求。</li>
</ul>
<p><br>637 一位解决方案架构师正在设计 <strong>Amazon API Gateway 背后的一项新服务</strong>，要求如下：</p>
<ul>
<li>请求模式<strong>不可预测</strong>，可能突然从 0 请求跃升至<strong>每秒超过 500 个请求</strong></li>
<li>数据需要<strong>在后端数据库持久化</strong>，目前总量小于 1GB，<strong>未来增长不可预测</strong></li>
<li>可以通过<strong>简单的键值请求</strong>来查询数据</li>
</ul>
<p>问：哪些 AWS 服务组合能够满足这些要求？（选择两项）</p>
<p>选项如下：<br>A. AWS Fargate<br><u>B. AWS Lambda</u><br><u>C. Amazon DynamoDB</u><br>D. 亚马逊 EC2 自动扩展<br>E. 兼容 MySQL 的 Amazon Aurora</p>
<p><strong>Amazon DynamoDB</strong>（键值存储，自动扩展，与 Lambda 集成良好）</p>
<p><br>638 一家公司收集研究数据并与<strong>全球各地的员工共享</strong>。要求：</p>
<ul>
<li>数据收集并存储在 <strong>Amazon S3 存储桶</strong> 中</li>
<li>在 AWS 云中处理数据</li>
<li>将数据与员工共享</li>
<li>需要一个 <strong>AWS 云中的安全解决方案</strong></li>
<li><strong>最大限度地减少运营开销</strong></li>
</ul>
<p>选项如下：<br>A. 使用 AWS Lambda 函数创建一个 S3 预签名 URL，指导员工使用该 URL<br>B. 为每位员工创建一个 IAM 用户，为每位员工创建一个 IAM 策略以允许 S3 访问，指导员工使用 AWS 管理控制台<br>C. <u>创建一个 S3 文件网关，创建一个用于上传的共享和一个用于下载的共享，允许员工挂载共享，指导他们在本地计算机上挂载共享以使用 S3 文件网关</u><br>D. 配置 AWS Transfer Family SFTP 端点，选择自定义身份提供商选项，使用 AWS Secrets Manager 管理用户凭证，指导员工使用 Transfer Family</p>
<p>Transfer Family 支持 SFTP 协议，适合文件传输，但需要为每个员工<strong>管理用户凭证</strong>（存储在 Secrets Manager 中）</p>
<ul>
<li>预签名 URL 有<strong>时效限制</strong>（通常几小时到几天），不适合长期共享和日常访问。</li>
</ul>
<p><br>639 一家公司正在构建新的家具库存应用程序，部署架构如下：</p>
<ul>
<li>多个可用区的一批 Amazon EC2 实例</li>
<li>EC2 实例在虚拟私有云（VPC）中的应用程序负载均衡器（ALB）后方运行</li>
<li>观察到的现象：<strong>传入流量似乎更倾向于某个 EC2 实例，导致部分请求出现延迟</strong></li>
</ul>
<p>问：解决方案架构师应采取什么措施来解决此问题？</p>
<p>选项如下：<br>A. <u>禁用应用程序负载均衡器上的会话亲和性（粘性会话）</u><br>B. 用网络负载均衡器替换应用程序负载均衡器<br>C. 增加每个可用区中的 EC2 实例数量<br>D. 调整应用程序负载均衡器目标组的健康检查频率</p>
<p><br>640 一家公司的应用工作流使用 AWS Lambda 函数从 Amazon S3 下载并解密文件。</p>
<ul>
<li>文件使用 <strong>AWS KMS 密钥</strong>加密</li>
<li>目标：设计解决方案，确保正确设置所需的权限</li>
</ul>
<p>问：哪些操作组合可以实现这一点？（选择两项）</p>
<p>选项如下：<br>A. 将 <code>kms:Decrypt</code> 权限附加到 Lambda 函数的资源策略<br>B. <u>在 KMS 密钥的策略中为 Lambda IAM 角色授予解密权限</u><br>C. 在 KMS 密钥的策略中为 Lambda 资源策略授予解密权限<br>D. 创建一个具有 <code>kms:Decrypt</code> 权限的新 IAM 策略，并将该策略附加到 Lambda 函数<br>E. <u>创建一个具有 <code>kms:Decrypt</code> 权限的新 IAM 角色，并将执行角色附加到 Lambda 函数</u></p>
<ul>
<li>文件在 S3 中使用 KMS 密钥加密，下载时需要 <strong>S3 的 <code>s3:GetObject</code> 权限</strong>（题目未提及，但隐含），解密时需要 <strong>KMS 的 <code>kms:Decrypt</code> 权限</strong>。</li>
<li>KMS 权限控制有两种主要方式：<ol>
<li><strong>KMS 密钥策略</strong>（Key Policy）</li>
<li><strong>IAM 策略</strong>（附加到 IAM 用户&#x2F;角色）</li>
</ol>
</li>
<li>Lambda 函数通过其 <strong>执行角色（IAM 角色）</strong> 获得权限，该角色需要被授权调用 <code>kms:Decrypt</code>。</li>
</ul>
<p><br>641 一家公司希望通过 AWS Organizations 监控所有成员账户的成本，用于财务审查。</p>
<ul>
<li>云运营团队在 <strong>管理账户（payer account）</strong> 中设计架构</li>
<li>需要查询<strong>所有成员账户</strong>的 AWS 成本和使用情况报告</li>
<li>必须<strong>每月运行一次查询</strong>，提供详细的账单分析</li>
<li>要求：<strong>最具可扩展性且最具成本效益的方式</strong></li>
</ul>
<p>选项如下：<br>A. 在管理账户中启用成本和使用情况报告，将报告交付到 Amazon Kinesis，使用 Amazon EMR 进行分析<br>B. <u>在管理账户中启用成本和使用情况报告，将报告交付到 Amazon S3，使用 Amazon Athena 进行分析</u><br>C. 为成员账户启用成本和使用情况报告，将报告交付到 Amazon S3，使用 Amazon Redshift 进行分析<br>D. 为成员账户启用成本和使用情况报告，将报告传输到 Amazon Kinesis，使用 Amazon QuickSight 进行分析</p>
<ul>
<li><strong>AWS 成本和使用情况报告（CUR）</strong> 可配置为每天生成报告文件到 S3（GZIP CSV 或 Parquet 格式）。</li>
<li><strong>S3</strong> 是低成本对象存储，适合存储历史账单数据。</li>
<li><strong>Athena</strong> 是无服务器查询服务，按扫描数据量收费，每月仅运行一次查询时成本极低。</li>
</ul>
<p><strong>EMR</strong> 是大数据集群，适用于复杂处理，但运维成本高</p>
<p><strong>Kinesis</strong> 是流数据处理服务，适用于实时数据摄取，<strong>不适合每月一次的批量分析</strong></p>
<p><strong>Redshift</strong> 是数据仓库，适合高频、复杂查询，但需要持续运行集群</p>
<p>QuickSight 是 BI 可视化工具，适合仪表板，但数据仍需先存储和处理</p>
<p><br>642 一家公司希望在 AWS 云中属于 <strong>Auto Scaling 组</strong> 的 Amazon EC2 实例上运行一款游戏应用程序。</p>
<ul>
<li>应用程序将使用 <strong>UDP 数据包</strong>传输数据</li>
<li>需要确保应用程序能够随着流量增减<strong>自动扩容和缩容</strong></li>
</ul>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p>选项如下：<br>A. <u>将网络负载均衡器附加到自动扩展组</u><br>B. 将应用程序负载均衡器附加到自动扩展组<br>C. 部署带有加权策略的 Amazon Route 53 记录集，以适当路由流量<br>D. 部署一个配置了端口转发到自动扩展组中 EC2 实例的 NAT 实例</p>
<ul>
<li><strong>网络负载均衡器（NLB）</strong> 工作在 <strong>第 4 层（TCP&#x2F;UDP）</strong>，支持 UDP 流量。</li>
<li>NLB 可以附加到 Auto Scaling 组，<strong>自动注册&#x2F;注销实例</strong>，实现流量分发和扩展。</li>
<li>适用于需要<strong>低延迟、高吞吐量</strong>的游戏服务器场景</li>
</ul>
<p><br>643 一家公司在 AWS 上为其不同品牌运营多个网站，要求如下：</p>
<ul>
<li>每个网站每天生成<strong>数十 GB 的网络流量日志</strong></li>
<li>需要设计<strong>可扩展的解决方案</strong>，让开发人员分析所有网站的流量模式</li>
<li>分析将在<strong>几个月内每周按需进行一次</strong></li>
<li>必须支持使用<strong>标准 SQL 进行查询</strong></li>
<li>要求<strong>最具成本效益</strong></li>
</ul>
<p>选项如下：<br>A. <u>将日志存储在 Amazon S3 中，使用 Amazon Athena 进行分析</u><br>B. 将日志存储在 Amazon RDS 中，使用数据库客户端进行分析<br>C. 将日志存储在 Amazon OpenSearch Service 中，使用 OpenSearch Service 进行分析<br>D. 将日志存储在 Amazon EMR 集群中，使用受支持的开源框架进行基于 SQL 的分析</p>
<p><br>644 一家国际公司为其开展业务的每个国家都设有一个子域名，格式为：</p>
<ul>
<li><code>example.com</code>（主域名）</li>
<li><code>country1.example.com</code></li>
<li><code>country2.example.com</code></li>
</ul>
<p>工作负载位于<strong>应用程序负载均衡器（ALB）</strong> 之后。<br>要求：<strong>对传输中的网站数据进行加密</strong>。</p>
<p>问：哪些步骤组合可以满足这些要求？（选择两项）</p>
<p>选项如下：<br>A. <u>使用 AWS Certificate Manager（ACM）控制台为顶级域名 <code>example.com</code> 申请公共证书，以及一个用于 <code>*.example.com</code> 的通配符证书</u><br>B. 使用 ACM 控制台为顶级域名 <code>example.com</code> 申请一个私有证书，并为 <code>*.example.com</code> 申请一个通配符证书<br>C. 使用 ACM 控制台为顶级域名 <code>example.com</code> 申请一个公共和私有证书<br>D. 通过电子邮件地址验证域名所有权，通过向 DNS 提供商添加所需的 DNS 记录，切换到 DNS 验证<br>E. <u>通过向 DNS 提供商添加所需的 DNS 记录来验证该域名的所有权</u></p>
<ul>
<li>需要为以下域名提供 HTTPS 加密：<ul>
<li><code>example.com</code></li>
<li><code>country1.example.com</code></li>
<li><code>country2.example.com</code>（以及其他国家子域名）</li>
</ul>
</li>
<li>工作负载在 ALB 后 → 可以使用 <strong>ACM 公共证书</strong> 附加到 ALB 以实现 TLS 终止</li>
<li>需要支持<strong>主域名和所有子域名</strong> → 最简便的方式是申请<strong>通配符证书</strong> <code>*.example.com</code>，该证书可以覆盖所有同级子域</li>
</ul>
<p><br>645 一家公司需要在其<strong>本地密钥管理器</strong>中使用加密密钥，且该密钥管理器位于 <strong>AWS 云之外</strong>（出于法规和合规要求）。<br>要求：</p>
<ul>
<li>使用<strong>保留在 AWS 云之外的加密密钥</strong>来管理加密和解密</li>
<li>支持<strong>来自不同供应商的多种外部密钥管理器</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 使用由 CloudHSM 集群支持的 AWS CloudHSM 密钥存储<br>B. <u>使用由外部密钥管理器支持的 AWS KMS 外部密钥存储</u><br>C. 使用默认的 AWS KMS 托管密钥存储<br>D. 使用由 AWS CloudHSM 集群支持的自定义密钥存储</p>
<ul>
<li><strong>KMS 外部密钥存储</strong> 是 AWS KMS 的一个功能，允许将<strong>加密密钥保留在外部密钥管理器</strong>（如本地 HSM 或第三方密钥管理服务）中。</li>
</ul>
<p><br>646 解决方案架构师需要在 AWS 云中托管一个 <strong>高性能计算（HPC）工作负载</strong>，要求如下：</p>
<ul>
<li>在<strong>数百个 Amazon EC2 实例</strong>上运行</li>
<li>需要对<strong>共享文件系统</strong>进行并行访问，以实现大型数据集的分布式处理</li>
<li>数据集将<strong>同时被多个实例访问</strong></li>
<li><strong>访问延迟在 1 毫秒以内</strong></li>
<li>处理完成后，工程师需要访问该数据集进行<strong>手动后处理</strong></li>
</ul>
<p>选项如下：<br>A. 将 Amazon EFS 用作共享文件系统，从 EFS 访问数据集<br>B. 挂载一个 Amazon S3 存储桶作为共享文件系统，直接从该 S3 存储桶执行后处理操作<br>C. <u>使用 Amazon FSx for Lustre 作为共享文件系统，将该文件系统链接到 Amazon S3 存储桶以进行后处理</u><br>D. 配置 AWS RAM 以共享 Amazon S3 存储桶，使其能够挂载到所有实例以进行处理和后处理</p>
<p><br>647 一家游戏公司正在开发具备 <strong>IP 语音功能</strong>的应用程序，要求如下：</p>
<ul>
<li>为<strong>全球用户</strong>提供服务</li>
<li>需要<strong>高可用性</strong>，并能在 <strong>AWS 区域间实现自动故障转移</strong></li>
<li>希望<strong>最大限度地降低用户延迟</strong></li>
<li>不依赖用户设备上的 <strong>IP 地址缓存</strong></li>
</ul>
<p>问：解决方案架构师应如何做才能满足这些要求？</p>
<p>选项如下：<br>A. <u>使用带有健康检查的 AWS Global Accelerator</u><br>B. 使用带有地理位置路由策略的 Amazon Route 53<br>C. 创建一个包含多个源站的 Amazon CloudFront 分发<br>D. 创建一个使用基于路径路由的应用程序负载均衡器</p>
<ul>
<li>CloudFront 是 CDN，主要用于缓存和加速 HTTP(S) 内容，<strong>不支持 UDP</strong>（IP 语音通常使用 UDP），不适合实时语音流量。</li>
</ul>
<p><br>648 一家天气预报公司需要处理数百千兆字节的数据，要求如下：</p>
<ul>
<li><strong>亚毫秒级延迟</strong></li>
<li>需要<strong>高可用的云存储解决方案</strong></li>
<li>能够处理<strong>大量的持续吞吐量</strong></li>
<li>存储的文件应能被<strong>数千个计算实例同时访问和处理</strong>整个数据集</li>
</ul>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p>选项如下：<br>A. 使用适用于 Lustre 的 Amazon FSx 临时文件系统<br>B. <u>将 Amazon FSx 用于 Lustre 持久文件系统</u><br>C. 使用具有突发吞吐量模式的 Amazon EFS<br>D. 使用具有预置吞吐量模式的 Amazon EFS</p>
<ul>
<li><p><strong>FSx for Lustre</strong> 有<strong>临时</strong>（Scratch）和<strong>持久</strong>（Persistent）两种类型。</p>
</li>
<li><p><strong>临时文件系统</strong>为高性能设计，但<strong>不提供高可用性</strong>（数据不持久，实例故障可能导致数据丢失），不符合“高可用”要求。</p>
</li>
<li><p>EFS 是 NFS 文件系统，<strong>延迟在毫秒级</strong>，无法满足亚毫秒要求。</p>
</li>
</ul>
<p><br>649 一家电子商务公司在本地运行 PostgreSQL 数据库，目前使用高 IOPS Amazon EBS 块存储（非 AWS），每日峰值 I&#x2F;O 事务<strong>不超过 15,000 IOPS</strong>。<br>公司希望将数据库迁移到 <strong>Amazon RDS for PostgreSQL</strong>，并要求：</p>
<ul>
<li>提供<strong>独立于磁盘存储容量的磁盘 IOPS 性能</strong></li>
<li>选择<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项如下：<br>A. 配置通用 SSD (gp2) EBS 卷存储类型并配置 15,000 IOPS<br>B. 配置预配 IOPS SSD (io1) EBS 卷存储类型并预配 15,000 IOPS<br>C. <u>配置通用 SSD (gp3) EBS 卷存储类型并预置 15,000 IOPS</u><br>D. 配置 EBS 磁性（magnetic）卷类型以实现最大 IOPS</p>
<ul>
<li><strong>gp3 允许独立调整 IOPS</strong>（最高 16,000），不受存储容量限制。</li>
</ul>
<ol>
<li><strong>需求分析</strong><ul>
<li>迁移到 <strong>RDS for PostgreSQL</strong></li>
<li>峰值 IOPS：<strong>15,000</strong></li>
<li><strong>独立于磁盘存储容量的 IOPS</strong> → 需要能够<strong>独立配置 IOPS</strong>的 EBS 类型，而不受存储容量大小限制</li>
<li><strong>最具成本效益</strong> → 在满足性能要求的前提下，选择成本最低的选项</li>
</ul>
</li>
<li><strong>各 EBS 类型对比</strong><ul>
<li><strong>gp2（通用 SSD）</strong>：IOPS 与卷容量绑定（每 GB 3 IOPS，最大 16,000 IOPS，但需相应容量）。若要达到 15,000 IOPS，需要至少 5,000 GB 存储（即使不需要这么多容量），<strong>不满足“独立于容量”要求，且成本可能较高</strong>。</li>
<li><strong>io1（预配置 IOPS SSD）</strong>：可独立配置 IOPS（最高 64,000），但<strong>价格较高</strong>，通常用于需要稳定高性能的场景。</li>
<li><strong>gp3（新一代通用 SSD）</strong>：<strong>IOPS 和吞吐量可独立于容量配置</strong>（基础性能 3,000 IOPS + 125 MB&#x2F;s，可额外按需增加 IOPS 和吞吐量，最高 16,000 IOPS）。<strong>成本低于 io1</strong>，且满足独立配置要求。</li>
<li><strong>Magnetic（磁性）</strong>：性能极低（最大几百 IOPS），不满足 15,000 IOPS 需求。</li>
</ul>
</li>
</ol>
<p><br>650 一家公司希望将其本地 <strong>Microsoft SQL Server Enterprise 版</strong> 数据库迁移到 AWS，要求如下：</p>
<ul>
<li>在线应用程序使用该数据库处理<strong>事务</strong></li>
<li>数据分析团队使用<strong>相同的生产数据库</strong>运行报告进行分析处理</li>
<li>希望通过尽可能迁移到<strong>托管服务</strong>来<strong>减少运营开销</strong></li>
</ul>
<p>问：哪种解决方案能以最少的运营开销满足这些要求？</p>
<p>选项如下：<br>A. 迁<u>移到适用于 Microsoft SQL Server 的 Amazon RDS，将读取副本用于报告目的</u><br>B. 迁移到 Amazon EC2 上的 Microsoft SQL Server，使用 Always On 读取副本进行报告<br>C. 迁移到 Amazon DynamoDB，使用 DynamoDB 按需副本进行报告用途<br>D. 迁移到 Amazon Aurora MySQL，使用 Aurora 读取副本进行报告</p>
<p><br>651 一家公司在 Amazon S3 存储桶中存储大量图像文件，访问模式和存储要求如下：</p>
<ol>
<li><strong>最初 180 天</strong>：需要随时可用（高频率访问） → 使用 <strong>S3 标准存储</strong></li>
<li><strong>第 181–360 天</strong>：访问频率较低</li>
<li><strong>第 361 天–5 年</strong>：需要归档，但必须能在请求时<strong>立即获取</strong>（检索时间 ≤ 分钟级）</li>
<li><strong>5 年后</strong>：只有审计人员可以访问，检索时间可在 <strong>12 小时内</strong></li>
<li><strong>整个过程中图像不能丢失</strong></li>
</ol>
<p>开发人员将在前 180 天使用 S3 标准存储，需要配置 <strong>S3 生命周期规则</strong>。<br>目标：以 <strong>最具成本效益</strong> 的方式满足要求。</p>
<p>选项如下：<br>A. 180 天后转换为 S3 单区域-IA，360 天后转换为 S3 Glacier 即时检索，5 年后转换为 S3 Glacier 深度归档<br>B. 180 天后转换为 S3 单区域-IA，360 天后转换为 S3 Glacier 灵活检索，5 年后转换为 S3 Glacier 深度归档<br>C. <u>180 天后转换为 S3 标准-IA，360 天后转换为 S3 Glacier 即时检索，5 年后转换为 S3 Glacier 深度归档</u><br>D. 180 天后转换为 S3 标准-IA，360 天后转换为 S3 Glacier 灵活检索，5 年后转换为 S3 Glacier 深度归档</p>
<ul>
<li><strong>标准-IA</strong> 在低访问阶段提供多 AZ 持久性，更可靠。</li>
<li><strong>Glacier 即时检索</strong> 在归档阶段满足“立即获取”要求。</li>
<li><strong>Glacier 深度归档</strong> 在 5 年后满足低成本、12 小时内检索的审计需求。</li>
</ul>
<p><br>652 一家公司有一个<strong>大数据工作负载</strong>，要求如下：</p>
<ul>
<li>每天运行 <strong>6 小时</strong></li>
<li>在流程运行时<strong>不能丢失任何数据</strong></li>
<li>设计 <strong>Amazon EMR 集群配置</strong> 来支持这个关键工作负载</li>
<li>要求<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项如下：<br>A. 配置一个<strong>长期运行的集群</strong>，在按需实例上运行主节点和核心节点，在抢占式实例（Spot 实例）上运行任务节点<br>B. <u>配置一个<strong>临时集群</strong>，在按需实例上运行主节点和核心节点，在竞价型实例上运行任务节点</u><br>C. 配置一个<strong>临时集群</strong>，在按需实例上运行主节点，在竞价型实例上运行核心节点和任务节点<br>D. 配置一个<strong>长期运行的集群</strong>，其中主节点运行在按需实例上，核心节点运行在 Spot 实例上，任务节点运行在 Spot 实例上</p>
<ul>
<li><p><strong>临时集群</strong>：按需启动和终止，适合每天 6 小时的运行模式。</p>
</li>
<li><p><strong>任务节点使用 Spot 实例</strong>：降低成本，即使中断也不影响数据完整性。</p>
</li>
</ul>
<p><br>653 一家公司维护一个 <strong>Amazon RDS 数据库</strong>，存储<strong>用户到成本中心的映射</strong>。</p>
<ul>
<li>该公司在 <strong>AWS Organizations</strong> 中的一个组织内拥有多个账户</li>
<li>需要标记在<strong>组织中特定 AWS 账户</strong>中创建的所有资源</li>
<li>要求：用<strong>创建资源的用户的成本中心 ID</strong> 标记每个资源</li>
</ul>
<p>问：哪种解决方案能够满足这些要求？</p>
<p>选项如下：<br>A. 从管理账户将特定账户移至新的组织单元（OU），创建服务控制策略（SCP），要求所有资源在创建前必须带有正确的成本中心标签，将 SCP 应用于新的 OU<br>B. <u>创建 AWS Lambda 函数，在 Lambda 函数从 RDS 数据库中查找适当的成本中心后标记资源，配置响应 AWS CloudTrail 事件的 Amazon EventBridge 规则以调用 Lambda 函数</u><br>C. 创建 AWS CloudFormation 堆栈来部署 Lambda 函数，配置该 Lambda 函数从 RDS 数据库中查找成本中心并为资源添加标签，创建一个 Amazon EventBridge 计划规则来调用该 CloudFormation 堆栈<br>D. 创建 AWS Lambda 函数用默认值为资源添加标签，配置一个 Amazon EventBridge 规则响应 CloudTrail 事件，在资源缺少成本中心标签时调用 Lambda 函数</p>
<ul>
<li><p><strong>SCP 是权限策略</strong>，可用于<strong>强制要求标签</strong>（通过 IAM 条件键），但<strong>不能自动添加标签</strong>，只能拒绝不带标签的资源创建请求。</p>
</li>
<li><p><strong>CloudTrail</strong> 记录 AWS API 调用（包括资源创建事件）。</p>
</li>
<li><p><strong>EventBridge</strong> 可监听 CloudTrail 事件，触发 <strong>Lambda 函数</strong>。</p>
</li>
</ul>
<p><br>654 一家公司最近将其 Web 应用程序迁移到 AWS 云，当前架构：</p>
<ul>
<li>使用 <strong>Amazon EC2 实例</strong> 运行多个进程</li>
<li>包括 <strong>Apache Web 服务器</strong>（提供静态内容）</li>
<li>Apache 向 <strong>PHP 应用程序</strong> 发出请求</li>
<li>PHP 应用程序使用<strong>本地 Redis 服务器</strong>进行用户会话</li>
</ul>
<p>公司希望<strong>重新设计架构以实现高可用性并使用 AWS 托管解决方案</strong>。</p>
<p>选项如下：<br>A. 使用 AWS Elastic Beanstalk 托管静态内容和 PHP 应用程序，配置 Elastic Beanstalk 将其 EC2 实例部署到公共子网，分配公共 IP 地址<br>B. 使用 AWS Lambda 托管静态内容和 PHP 应用程序，使用 Amazon API Gateway REST API 将请求代理到 Lambda 函数，设置 CORS 配置，配置 Amazon ElastiCache for Redis 处理会话<br>C. 将后端代码保留在 EC2 实例上，创建启用多可用区的 Amazon ElastiCache for Redis 集群（集群模式），将前端资源复制到 Amazon S3，配置后端代码以引用 EC2 实例<br>D. <u>配置 CloudFront 分发指向 S3（托管静态内容），配置应用程序负载均衡器指向运行在 ECS Fargate 上的 PHP 应用程序，配置 PHP 应用程序使用在多个可用区中运行的 Amazon ElastiCache for Redis</u></p>
<ul>
<li><strong>静态内容</strong>：S3 + CloudFront（全球加速、高可用、低成本）</li>
<li><strong>PHP 应用</strong>：ECS Fargate（无服务器容器托管，自动扩展，多可用区部署，高可用）</li>
<li><strong>会话存储</strong>：ElastiCache Redis 多可用区（高可用、托管）</li>
<li><strong>负载均衡</strong>：ALB 分发流量到 ECS 服务，支持健康检查和自动扩展</li>
</ul>
<p><br>655 一家公司在 <strong>Auto Scaling 组中的 Amazon EC2 实例</strong> 上运行 Web 应用程序，要求如下：</p>
<ul>
<li>应用程序设计为使用 <strong>会话亲和性（粘性会话）</strong> 以获得更好的用户体验</li>
<li>应用程序必须作为 <strong>端点在 Internet 上公开可用</strong></li>
<li>必须将 <strong>WAF 应用于端点</strong> 以获得额外的安全性</li>
<li>必须在端点上配置 <strong>会话亲和性（粘性会话）</strong></li>
</ul>
<p>问：哪些步骤组合将满足这些要求？（选择两项）</p>
<p>选项如下：<br>A. 创建一个公共网络负载均衡器，指定应用程序目标组<br>B. 创建网关负载均衡器，指定应用程序目标组<br>C. <u>创建公共应用型负载均衡器，指定应用程序目标组</u><br>D. 创建第二个目标组，将弹性 IP 地址添加到 EC2 实例<br>E. <u>在 AWS WAF 中创建 Web ACL，将 Web ACL 与端点相关联</u></p>
<ul>
<li>需要 <strong>C（公共 ALB）</strong> 来实现负载均衡、Internet 公开和粘性会话。</li>
<li>需要 <strong>E（创建 Web ACL 并关联到 ALB）</strong> 来应用 WAF 安全防护。</li>
</ul>
<p><br>656 一家公司运营一个存储<strong>历史事件图像</strong>的网站，要求如下：</p>
<ul>
<li>用户需要能够根据事件发生的年份<strong>搜索和查看图像</strong></li>
<li>平均每年每张图像的请求只有 <strong>1 到 2 次</strong>（访问频率<strong>极低</strong>）</li>
<li>需要<strong>高可用性</strong>解决方案来存储图像并向用户交付</li>
<li>要求<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项如下：<br>A. 将图像存储在 Amazon EBS 中，使用在 EC2 上运行的 Web 服务器<br>B. 将图像存储在 Amazon EFS 中，使用在 EC2 上运行的 Web 服务器<br>C. 在 Amazon S3 Standard 中存储图像，使用 S3 Standard 通过静态网站直接传递图像<br>D. <u>将图像存储在 Amazon S3 标准不频繁访问（S3 Standard-IA）中，使用 S3 Standard-IA 通过静态网站直接交付图像</u></p>
<p><br>657 一家公司在 AWS Organizations 的一个组织中拥有多个 AWS 账户（不同业务部门使用），全球多个办事处。<br>要求：</p>
<ul>
<li>需要更新安全组规则，以允许新的办事处 CIDR 范围或移除旧的 CIDR 范围</li>
<li>希望<strong>集中管理安全组规则</strong>，以<strong>最小化更新 CIDR 范围所需的管理开销</strong></li>
<li>要求<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项如下：<br>A. 在组织的管理账户中创建 VPC 安全组，当需要 CIDR 范围更新时更新安全组<br>B. <u>创建一个包含 CIDR 列表的 VPC 客户管理前缀列表，使用 AWS RAM 在整个组织内共享该前缀列表，在整个组织的安全组中使用该前缀列表</u><br>C. 创建一个 AWS 托管前缀列表，使用 AWS Security Hub 策略在整个组织内强制实施安全组更新，当 CIDR 范围变化时，使用 Lambda 函数自动更新前缀列表<br>D. 在中央管理的 AWS 账户中创建安全组，为整个组织创建 AWS 防火墙管理器通用安全组策略，在该策略中选择先前创建的安全组作为主要组</p>
<ul>
<li><strong>安全组不能跨账户共享</strong>（即使在同一 VPC 内跨账户引用也有限制），无法直接应用到其他账户。</li>
</ul>
<p><br>658 一家公司使用本地 NAS 系统为其 <strong>高性能计算（HPC）工作负载</strong> 提供文件共享，希望将其<strong>对延迟敏感的 HPC 工作负载及其存储迁移到 AWS 云</strong>，要求如下：</p>
<ul>
<li>必须能够通过文件系统提供 <strong>NFS 和 SMB 多协议访问</strong></li>
<li>要求以<strong>最低的延迟</strong>满足需求</li>
<li>需要选择 <strong>两项</strong> 解决方案</li>
</ul>
<p>选项如下：<br><u>A. 将计算优化型 EC2 实例部署到<strong>集群放置组</strong>中</u><br>B. 将计算优化型 EC2 实例部署到<strong>分区放置组</strong>中<br>C. 将 EC2 实例附加到 Amazon FSx for Lustre 文件系统<br>D. 将 EC2 实例附加到 Amazon FSx for OpenZFS 文件系统<br>E. <u>将 EC2 实例附加到 Amazon FSx for NetApp ONTAP 文件系统</u></p>
<ul>
<li><p><strong>ONTAP</strong> 支持 <strong>NFS 和 SMB 多协议</strong>，并且可以通过 <strong>FSx for ONTAP</strong> 的<strong>高性能 SSD 存储类型</strong>提供低延迟访问（亚毫秒级）。</p>
</li>
<li><p><strong>OpenZFS</strong> 支持 NFS（v3、v4）和 SMB，但<strong>延迟通常高于 Lustre</strong>，不是专为 HPC 设计的低延迟文件系统。</p>
</li>
<li><p><strong>Lustre 是并行文件系统</strong>，专为 HPC 设计，提供<strong>亚毫秒延迟和高吞吐</strong>，但<strong>不支持 SMB 协议</strong>（仅支持 POSIX&#x2F;NFSv3），不满足“NFS 和 SMB 多协议”要求。</p>
</li>
</ul>
<p><br>659 一家公司正在迁移数据中心，需要在<strong>两周内</strong>将 <strong>50 TB（大字节 &#x3D; TB）</strong> 的数据<strong>安全传输到 AWS</strong>。</p>
<ul>
<li>现有数据中心与 AWS 之间有一个<strong>站点到站点 VPN 连接</strong>，其<strong>利用率为 90%</strong>（即带宽已接近饱和）</li>
<li>问：解决方案架构师应使用哪种 AWS 服务来满足这些要求？</li>
</ul>
<p>选项如下：<br>A. 带有 VPC 终端节点的 AWS DataSync<br>B. AWS Direct Connect<br>C<u>. AWS Snowball Edge 存储优化型</u><br>D. AWS 存储网关</p>
<p><br>660 一家公司在 <strong>Auto Scaling 组的 Amazon EC2 按需实例</strong> 上托管一个应用程序，现象如下：</p>
<ul>
<li>高峰时段每天在同一时间出现</li>
<li>用户反馈：<strong>高峰时段开始时应用程序性能缓慢</strong>，2–3 小时后恢复正常</li>
<li>公司希望确保应用程序在<strong>高峰时段开始时就能正常运行</strong></li>
</ul>
<p>选项如下：<br>A. 配置应用程序负载均衡器，以将流量正确分配到实例<br>B. 为自动扩展组配置动态扩展策略，以根据内存利用率启动新实例<br>C. 为自动扩展组配置动态扩展策略，以基于 CPU 利用率启动新实例<br>D. <u>为自动扩展组配置一个定时扩展策略，以便在高峰时段前启动新实例</u></p>
<p><br>661 一家公司在 AWS 上运行连接到其 <strong>Amazon RDS 数据库</strong> 的应用程序，这些应用程序在<strong>周末和一年中的高峰期会进行扩展</strong>。<br>要求：</p>
<ul>
<li>希望为连接到数据库的应用程序<strong>更有效地扩展数据库</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 将 Amazon DynamoDB 与带有数据库目标组配置的连接池结合使用，修改应用程序以使用 DynamoDB 端点<br>B. <u>将 Amazon RDS Proxy 与数据库的目标组一起使用，更改应用程序以使用 RDS Proxy 端点</u><br>C. 使用在 Amazon EC2 上运行的自定义代理作为数据库的中介，更改应用程序以使用自定义代理端点<br>D. 使用 AWS Lambda 函数通过数据库的目标组配置提供连接池，修改应用程序以使用该 Lambda 函数</p>
<ul>
<li><strong>RDS Proxy</strong> 是 AWS 托管的<strong>数据库连接池代理</strong>，专门用于管理 RDS 数据库连接。</li>
</ul>
<p><br>662 一家公司使用 <strong>AWS 成本资源管理器</strong> 监控 AWS 成本，发现 <strong>Amazon EBS 的存储和快照成本每月都在增加</strong>，但<strong>并未每月购买额外的 EBS 存储</strong>。<br>要求：</p>
<ul>
<li>针对当前的存储使用情况<strong>优化月度成本</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 使用 Amazon CloudWatch Logs 中的日志监控 Amazon EBS 的存储利用率，使用 Amazon EBS 弹性卷来减少 EBS 卷的大小<br>B. 使用自定义脚本来监控空间使用情况，使用 Amazon EBS 弹性卷来减少 EBS 卷的大小<br>C. 删除所有过期和未使用的快照以降低快照成本<br>D. <u>删除所有非必要的快照，使用 Amazon Data Lifecycle Manager 来创建和管理快照，根据公司的快照政策要求</u></p>
<ul>
<li><strong>Data Lifecycle Manager（DLM）</strong> 是 <strong>AWS 托管服务</strong>，可自动创建、保留和删除 EBS 快照。</li>
</ul>
<p><br>663 一家公司正在 AWS 上开发新应用，包含以下组件：</p>
<ul>
<li><strong>Amazon ECS 集群</strong></li>
<li><strong>Amazon S3 存储桶</strong>（包含应用资产）</li>
<li><strong>Amazon RDS for MySQL 数据库</strong>（包含敏感数据集）</li>
</ul>
<p>要求：</p>
<ul>
<li>确保<strong>只有 ECS 集群</strong>能够访问 RDS 数据库中的数据和 S3 存储桶中的数据</li>
</ul>
<p>问：哪种解决方案能够满足这些要求？</p>
<p>选项如下：<br>A. 创建一个新的 AWS KMS 客户托管密钥，用于加密 S3 存储桶和 RDS 数据库，确保 KMS 密钥策略包含 ECS 任务执行角色的加密和解密权限<br>B. 创建一个 AWS KMS AWS 托管密钥，用于加密 S3 存储桶和 RDS 数据库，确保 S3 存储桶策略将 ECS 任务执行角色指定为用户<br>C. 创建一个 S3 存储桶策略限制仅允许 ECS 任务执行角色访问，为 RDS 创建 VPC 端点，更新 RDS 安全组仅允许来自 ECS 任务子网的访问<br>D. <u>为 RDS 创建 VPC 端点并更新安全组仅允许来自 ECS 任务子网的访问，<strong>为 S3 创建 VPC 端点</strong>并更新 S3 存储桶策略仅允许来自 S3 VPC 端点的访问</u></p>
<ul>
<li>KMS 密钥用于<strong>加密静态数据</strong>，但<strong>不控制访问权限</strong>（即即使能解密，仍需 S3&#x2F;RDS 的访问权限）。</li>
</ul>
<p><br>664 一家公司有一个在本地运行的 Web 应用程序，问题如下：</p>
<ul>
<li>每月发生两次高峰时段，出现<strong>延迟问题</strong></li>
<li>延迟出现时，应用程序的 <strong>CPU 利用率立即增加到正常水平的 10 倍</strong></li>
</ul>
<p>公司希望：</p>
<ul>
<li>将应用程序迁移到 AWS 以<strong>降低延迟</strong></li>
<li>在应用程序需求增加时<strong>自动扩展</strong></li>
<li>使用 <strong>AWS Elastic Beanstalk</strong> 进行应用程序部署</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. <u>配置 Elastic Beanstalk 环境，使其在<strong>无限制模式下使用可突增性能实例</strong>，配置<strong>根据请求扩展环境</strong></u><br>B. 配置 Elastic Beanstalk 环境以使用<strong>计算优化型实例</strong>，配置该环境以<strong>基于请求进行扩展</strong><br>C. 配置 Elastic Beanstalk 环境以使用<strong>计算优化型实例</strong>，将该环境配置为<strong>按计划进行扩展</strong><br>D. 配置 Elastic Beanstalk 环境，使其在<strong>无限制模式下使用可突增性能实例</strong>，配置该环境以<strong>基于预测指标进行扩展</strong></p>
<ul>
<li><strong>成本效益</strong>：T 实例在无限制模式下以较低成本应对突发 CPU 需求。</li>
<li><strong>扩展及时</strong>：基于请求的自动扩展可快速响应流量增长，避免延迟。</li>
<li><strong>符合场景</strong>：突发性、不可预测（或半可预测）的高峰，适合此组合。</li>
</ul>
<p><br>665 一家公司客户遍布全球，要求：</p>
<ul>
<li>借助<strong>自动化</strong>来保护其系统和网络基础设施的安全</li>
<li>安全团队必须能够<strong>追踪并审计基础设施的所有增量变更</strong></li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. 使用 <strong>AWS Organizations</strong> 来设置基础设施，使用 <strong>AWS Config</strong> 来跟踪变更<br>B. <u>使用 <strong>AWS CloudFormation</strong> 来设置基础设施，使用 <strong>AWS Config</strong> 来跟踪变更</u><br>C. 使用 <strong>AWS Organizations</strong> 来设置基础设施，使用 <strong>AWS Service Catalog</strong> 来跟踪变更<br>D. 使用 <strong>AWS CloudFormation</strong> 来设置基础设施，使用 <strong>AWS Service Catalog</strong> 来跟踪变更</p>
<ul>
<li><p><strong>自动化部署</strong>：CloudFormation 提供可重复、版本控制的 IaC 部署，确保基础设施安全基线。</p>
</li>
<li><p><strong>全面审计</strong>：AWS Config 持续监控资源，记录所有配置变更（无论变更来源），满足安全团队追踪和审计增量变更的需求。</p>
</li>
<li><p><strong>Organizations</strong> 用于多账户管理、策略控制，但<strong>不是自动化设置基础设施的工具</strong>（不直接部署资源）。</p>
</li>
</ul>
<p><br>666 一家初创公司在 <strong>单个 Amazon EC2 实例</strong> 上托管一个网站，包含：</p>
<ul>
<li>无状态 Python 应用程序</li>
<li>MySQL 数据库</li>
<li>网站访问量很小</li>
<li>公司担心实例可靠性，需要<strong>迁移到高可用架构</strong></li>
<li><strong>无法修改应用程序代码</strong></li>
</ul>
<p>问：解决方案架构师应采取哪两种操作组合来实现网站的高可用性？（选择两项）</p>
<p>选项如下：<br>A. 在每个正在使用的可用区中配置一个互联网网关<br>B. <u>将数据库迁移到 Amazon RDS for MySQL 多可用区数据库实例</u><br>C. 将数据库迁移到 Amazon DynamoDB，并启用 DynamoDB 自动扩展<br>D. 使用 AWS DataSync 在多个 EC2 实例之间同步数据库数据<br>E. <u>创建一个应用程序负载均衡器，将流量分发到分布在两个可用区的 EC2 实例的自动扩展组</u></p>
<ul>
<li><strong>B</strong>：数据库层高可用 → RDS Multi-AZ MySQL</li>
<li><strong>E</strong>：应用层高可用 → ALB + Auto Scaling 跨可用区</li>
</ul>
<p><br>667 一家公司正在将其数据和应用程序迁移到 AWS，要求：</p>
<ul>
<li>从其 <strong>AWS 区域</strong> 和 <strong>本地位置</strong> 安全地访问 Amazon S3 上的数据</li>
<li>数据<strong>不得通过互联网传输</strong></li>
<li>公司已在其区域和本地位置之间建立了 <strong>AWS Direct Connect</strong> 连接</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. <u>为 Amazon S3 创建<strong>网关终端节点</strong>，使用网关终端节点从该区域和本地位置安全访问数据</u><br>B. 在 AWS Transit Gateway 中创建一个网关，以便从该区域和本地位置安全访问 Amazon S3<br>C. 为 Amazon S3 创建<strong>接口端点</strong>，使用这些接口端点从该区域和本地位置安全地访问数据<br>D. 使用 AWS KMS 密钥从该区域和本地位置安全访问数据</p>
<ul>
<li><strong>网关端点（Gateway Endpoint）</strong>：仅支持 <strong>S3 和 DynamoDB</strong>，在 VPC 路由表中添加指向 S3 的路由，<strong>免费</strong>。</li>
<li><strong>接口端点（Interface Endpoint）</strong>：基于 PrivateLink，为服务提供私有 IP 地址，支持更多服务，<strong>按用量收费</strong>。</li>
<li>对于 <strong>S3</strong>，通常推荐 <strong>网关端点</strong>（免费、高效），但需注意访问来源是否在 <strong>同一 VPC</strong> 或 <strong>通过 VPC 对等&#x2F;传输网关可达</strong>。</li>
</ul>
<p>Transit Gateway 用于连接多个 VPC 和本地网络，但本身不是 S3 访问端点</p>
<p><br>668 一家公司在 AWS Organizations 中创建了新组织，为开发团队设有多个账户。</p>
<ul>
<li>开发团队成员使用 <strong>AWS IAM Identity Center（原 SSO）</strong> 访问这些账户</li>
<li>对于每个应用程序，开发团队必须使用<strong>预定义的应用程序名称</strong>来标记所创建的资源</li>
<li>要求：设计一个解决方案，使开发团队<strong>仅在应用程序名称标签具有获批值的情况下才能创建资源</strong></li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. 创建一个具有条件允许策略的 IAM 组，该策略要求在创建资源时指定应用程序名称标签<br>B. 创建一个跨账户角色，该角色对任何带有应用程序名称标签的资源具有拒绝策略<br>C. 在 AWS 资源组中创建一个资源组，以验证标签是否已应用于所有账户中的所有资源<br>D. <u>在 Organizations 中创建一个标签策略，其中包含允许的应用程序名称列表</u></p>
<ul>
<li><strong>AWS Organizations 标签策略</strong> 是专门用于<strong>跨账户统一管理标签合规性</strong>的功能。</li>
<li>可定义<strong>标签键的允许值列表</strong>（如 application-name 只能为 [“app1”, “app2”, …]）。</li>
<li>当用户尝试创建资源时，如果标签值不在允许列表中，操作将被拒绝</li>
</ul>
<p><br>669 一家公司在 <strong>Amazon RDS for PostgreSQL</strong> 上运行数据库，要求：</p>
<ul>
<li>获得一个<strong>安全的解决方案</strong>，通过<strong>每 30 天轮换一次密码</strong>来管理主用户密码</li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 使用 Amazon EventBridge 安排自定义 AWS Lambda 函数，每 30 天轮换一次密码<br>B. 使用 AWS CLI 中的 <code>modify-db-instance</code> 命令来更改密码<br>C. <u>将 AWS Secrets Manager 与 Amazon RDS for PostgreSQL 集成，以实现密码轮换的自动化</u><br>D. 将 AWS Systems Manager 参数存储与 Amazon RDS for PostgreSQL 集成，以实现密码轮换自动化</p>
<p><strong>Parameter Store</strong> 可存储密码，但<strong>不支持自动轮换功能</strong>（仅存储）</p>
<p><br>670 一家公司对使用 <strong>Amazon DynamoDB 表</strong> 的应用程序进行测试，要求如下：</p>
<ul>
<li>测试<strong>每周运行一次</strong>，<strong>每次持续 4 小时</strong></li>
<li>公司知道测试期间应用程序每秒对表执行的<strong>读写操作次数</strong>（即可预测的吞吐量需求）</li>
<li>目前 DynamoDB 仅用于此测试，<strong>无其他用途</strong></li>
<li>需要<strong>优化该表的成本</strong></li>
</ul>
<p>选项如下：<br>A. 选择<strong>按需模式</strong>，适当更新读写容量单位<br>B. <u>选择<strong>预置模式</strong>，适当地更新读写容量单位</u><br>C. 购买为期 <strong>1 年</strong> 的 DynamoDB 预留容量<br>D. 购买为期 <strong>3 年</strong> 的 DynamoDB 预留容量</p>
<ul>
<li>相比按需模式，预置模式的每小时单价更低，整体成本更优。</li>
</ul>
<p><br>671 一家公司在 Amazon EC2 实例上运行其应用程序，要求：</p>
<ul>
<li>定期进行财务评估，<strong>发现异常支出</strong></li>
<li>需要一个解决方案来<strong>防止异常支出</strong></li>
<li>解决方案必须<strong>监控成本</strong>，并在出现异常支出时<strong>通知相关负责人</strong></li>
</ul>
<p>选项如下：<br>A. 使用 AWS 预算模板创建零支出预算<br>B. <u>在 AWS 计费和成本管理控制台中创建一个 AWS 成本异常检测监控器</u><br>C. 为当前运行的工作负载定价详情创建 AWS 定价计算器估算<br>D. 使用 Amazon CloudWatch 监控成本并识别异常支出</p>
<p>CloudWatch 主要监控资源性能指标（如 CPU、内存），<strong>不能直接监控成本异常</strong></p>
<p><br>672 一家营销公司从营销活动收到大量新的点击流数据，存储在 <strong>Amazon S3</strong> 上。<br>要求：</p>
<ul>
<li>需要<strong>快速分析</strong> S3 中的点击流数据</li>
<li>然后<strong>确定是否在数据管道中对这些数据进行进一步处理</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. 在 Spark 目录中创建外部表，在 AWS Glue 中配置作业以查询数据<br>B. <u>配置 AWS Glue 爬虫来爬取数据，配置 Amazon Athena 以查询数据</u><br>C. 在 Hive 元存储中创建外部表，在 Amazon EMR 中配置 Spark 作业以查询数据<br>D. 配置 AWS Glue 爬虫来爬取数据，配置 Amazon Kinesis Data Analytics 以使用 SQL 查询数据</p>
<p><br>673 一家公司在其数据中心运行一台 <strong>SMB 文件服务器</strong>，存储公司创建的大型文件，访问模式如下：</p>
<ul>
<li>文件创建后的 <strong>7 天内</strong> 被<strong>频繁访问</strong></li>
<li>7 天后，公司仍需能够访问这些文件，但<strong>最长检索时间为 24 小时</strong></li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. 使用 AWS DataSync 将 SMB 文件服务器中超过 7 天的数据复制到 AWS<br>B. <u>创建一个 <strong>Amazon S3 文件网关</strong> 以增加公司的存储空间，创建一个 <strong>S3 生命周期策略</strong> 来转换 7 天后将数据转换到 S3 Glacier Deep Archive</u><br>C. 创建一个 <strong>Amazon FSx 文件网关</strong> 以增加公司的存储空间，创建一个 <strong>Amazon S3 生命周期策略</strong>，用于在 7 天后转换数据<br>D. 为每个用户配置对 Amazon S3 的访问权限，创建一个 S3 生命周期策略，将数据在 7 天后转换到 S3 Glacier Flexible Retrieval</p>
<ul>
<li><p><strong>S3 文件网关</strong> 提供 <strong>SMB&#x2F;NFS 接口</strong>，可部署在本地作为缓存，后端存储为 <strong>Amazon S3</strong>。</p>
</li>
<li><p><strong>生命周期策略</strong>：可配置 <strong>7 天后将 S3 对象转为 Glacier Deep Archive</strong>（检索时间 ≤ 12 小时，满足 24 小时要求）。</p>
</li>
<li><p><strong>FSx 文件网关</strong> 用于将本地缓存与 <strong>Amazon FSx for Windows File Server</strong> 集成，不是 S3 + 生命周期策略的架构，且成本较高，不适合归档场景。</p>
</li>
</ul>
<p><br>674 一家公司在 <strong>Auto Scaling 组的 EC2 实例</strong> 上运行 Web 应用程序，后端使用 <strong>Amazon RDS for PostgreSQL</strong> 数据库实例。<br>问题：</p>
<ul>
<li>当流量增加时，应用程序运行缓慢</li>
<li>高流量期间，数据库承受着<strong>沉重的读取负载</strong></li>
</ul>
<p>问：解决方案架构师应采取哪些措施来解决这些性能问题？（选择两项）</p>
<p>选项如下：<br>A. 为数据库实例开启自动扩展<br>B. <u>为数据库实例创建一个只读副本，配置应用程序将读取流量发送到该只读副本</u><br>C. 将数据库实例转换为多可用区数据库实例部署，配置应用程序将读取流量发送到备用数据库实例<br>D. <u>创建一个 Amazon ElastiCache 集群，配置应用程序以在 ElastiCache 集群中缓存查询结果</u><br>E. 配置自动扩展组子网，以确保 EC2 实例与数据库实例部署在同一可用区中</p>
<ul>
<li><strong>ElastiCache</strong>（如 Redis 或 Memcached）可作为内存缓存，缓存频繁读取的查询结果。</li>
</ul>
<p><br>675 一家公司使用 <strong>Amazon EC2 实例</strong> 和 <strong>Amazon EBS 卷</strong> 运行应用程序。<br>要求：</p>
<ul>
<li>每天为每个 EBS 卷创建快照，以满足合规要求</li>
<li>希望实施一种架构，<strong>防止 EBS 卷快照被意外删除</strong></li>
<li><strong>不得更改存储管理员用户的管理权限</strong></li>
<li>以 <strong>最少的管理工作量</strong> 满足要求</li>
</ul>
<p>选项如下：<br>A. 创建一个具有删除快照权限的 IAM 角色，将该角色附加到新的 EC2 实例，通过新 EC2 实例中的 AWS CLI 来删除快照<br>B. 创建一个拒绝删除快照的 IAM 策略，将该策略附加到存储管理员用户<br>C. 为快照添加标签，在回收站中为带有这些标签的 EBS 快照创建保留规则<br>D. <u>锁定 EBS 快照以防止删除</u></p>
<p><br>676 一家公司的应用程序使用 <strong>网络负载均衡器、Auto Scaling 组、EC2 实例</strong> 以及部署在 <strong>Amazon VPC 中的数据库</strong>。<br>要求：</p>
<ul>
<li><strong>近乎实时地捕获其 VPC 中网络接口的进出流量信息</strong></li>
<li>将这些信息发送到 <strong>Amazon OpenSearch Service</strong> 进行分析</li>
</ul>
<p>选项如下：<br>A. 在 Amazon CloudWatch Logs 中创建一个日志组，配置 VPC 流日志将日志数据发送到该日志组，使用 <strong>Amazon Kinesis Data Streams</strong> 将日志从日志组流式传输到 OpenSearch Service<br>B. <u>在 Amazon CloudWatch Logs 中创建一个日志组，配置 VPC 流日志将日志数据发送到该日志组，使用 <strong>Amazon Kinesis Data Firehose</strong> 将日志从日志组流式传输到 OpenSearch Service</u><br>C. 在 AWS CloudTrail 中创建一条跟踪记录，配置 VPC 流日志将日志数据发送到该跟踪记录，使用 Amazon Kinesis Data Streams 将跟踪记录中的日志流式传输到 OpenSearch Service<br>D. 在 AWS CloudTrail 中创建一条跟踪记录，配置 VPC 流日志将日志数据发送到该跟踪记录，使用 Amazon Kinesis Data Firehose 将跟踪记录中的日志流式传输到 OpenSearch Service</p>
<p><strong>Amazon OpenSearch Service</strong>（用于分析和可视化）</p>
<p>VPC 流日志可以发送到 <strong>CloudWatch Logs</strong> 或 <strong>S3</strong>，但不能直接发送到 CloudTrail（CloudTrail 用于 API 调用审计，不是网络流量日志）</p>
<p><strong>Kinesis Data Streams</strong> 是流处理服务，但<strong>不能直接订阅 CloudWatch Logs 并自动传输到 OpenSearch</strong></p>
<p><strong>Kinesis Data Firehose</strong> 是 <strong>托管的数据传输服务</strong>，可<strong>直接订阅 CloudWatch Logs 日志流</strong>，并自动将数据加载到 OpenSearch Service</p>
<p><br>677 一家公司正在开发一款将在 <strong>生产环境的 Amazon EKS 集群</strong> 上运行的应用程序（生产集群使用按需实例的托管节点组）。<br>公司需要一个<strong>专用的 EKS 集群用于开发工作</strong>，要求：</p>
<ul>
<li>将<strong>不常使用</strong>这个开发集群来测试应用程序的弹性</li>
<li><strong>EKS 集群必须管理所有节点</strong>（即使用<strong>托管节点组</strong>）</li>
<li>需要<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项如下：<br>A. <u>创建仅包含 Spot 实例的托管节点组</u><br>B. 创建两个托管节点组：一个包含按需实例，第二个包含 Spot 实例<br>C. 创建一个具有使用 Spot 实例的启动配置的自动扩展组，配置用户数据以将节点添加到 EKS 集群<br>D. 创建仅包含按需实例的托管节点组</p>
<p>对于不常使用的开发集群，<strong>Spot 实例</strong> 成本最低（比按需便宜 60–90%）</p>
<ul>
<li><strong>适合场景</strong>：开发集群不常使用，可容忍 Spot 中断，且测试弹性时 Spot 回收本身可视为一种故障模拟。</li>
</ul>
<p><br>678 一家公司在 <strong>Amazon S3</strong> 中存储敏感数据，需要创建一个加密解决方案，要求：</p>
<ul>
<li>公司需要<strong>完全掌控</strong>用户<strong>创建、轮换和禁用加密密钥</strong>的权限</li>
<li>尽可能减少对所有必须加密的数据所做的操作（即<strong>简化加密流程</strong>）</li>
</ul>
<p>选项如下：<br>A. 使用带有<strong>亚马逊 S3 托管加密密钥（SSE-S3）</strong> 的默认服务器端加密来存储敏感数据<br>B. <u>使用 <strong>AWS KMS 创建一个客户管理的密钥</strong>，使用新密钥对 S3 进行加密，使用 <strong>AWS KMS 密钥（SSE-KMS）</strong> 通过服务器端加密来加密 S3 对象</u><br>C. 使用 <strong>AWS KMS 创建一个 AWS 托管密钥</strong>，使用新密钥通过 <strong>AWS KMS 密钥进行服务器端加密（SSE-KMS）</strong> 来加密 S3 对象<br>D. 将 S3 对象下载到 Amazon EC2 实例，使用客户管理的密钥对这些对象进行加密，将加密后的对象重新上传到 Amazon S3</p>
<ul>
<li><strong>完全掌控密钥</strong>：包括密钥的创建、轮换、禁用权限 → 必须使用 <strong>客户管理的密钥（CMK）</strong>，而不是 AWS 托管密钥。</li>
</ul>
<p><strong>减少操作</strong>：希望简化加密流程 → 应使用 <strong>服务器端加密（SSE）</strong>，而非客户端加密（避免下载、加密、上传的复杂流程）</p>
<p><br>679 一家公司希望将其本地虚拟机备份到 AWS，备份解决方案将备份作为对象导出到 <strong>Amazon S3 存储桶</strong>，要求：</p>
<ul>
<li>备份必须<strong>保留 30 天</strong></li>
<li>必须在 <strong>30 天后自动删除</strong></li>
</ul>
<p>问：哪些步骤组合可以满足这些要求？（选择三项）</p>
<p>选项如下：<br>A. 创建一个启用了 <strong>S3 对象锁定</strong> 的 S3 存储桶<br>B. <u>创建一个启用了 <strong>对象版本控制</strong> 的 S3 存储桶</u><br>C. 为对象配置 <strong>30 天的默认保留期</strong><br>D. 配置 <strong>S3 生命周期策略</strong> 以保护对象 30 天<br>E<u>. 配置 <strong>S3 生命周期策略</strong>，使对象在 30 天后过期</u><br>F. <u>配置备份解决方案，为对象添加 <strong>30 天保留期的标签</strong></u></p>
<p><strong>（为对象添加保留期标签）</strong>：通过标签控制不同对象的保留策略，更灵活。</p>
<p><br>680 一位解决方案架构师需要将文件从一个 <strong>Amazon S3 存储桶</strong> 复制到：</p>
<ol>
<li>一个 <strong>Amazon EFS 文件系统</strong></li>
<li>另一个 <strong>S3 存储桶</strong></li>
</ol>
<p>要求：</p>
<ul>
<li>文件必须<strong>持续复制</strong>（新文件不断添加到源 S3 存储桶）</li>
<li>只有当源文件发生更改时，复制的文件才应被覆盖（即<strong>增量复制</strong>）</li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. <u>为目标 S3 存储桶和 EFS 文件系统创建一个 <strong>AWS DataSync 位置</strong>，为其创建一个任务，将传输模式设置为<strong>仅传输已更改的数据</strong></u><br>B. 创建一个 <strong>AWS Lambda 函数</strong>，将文件系统挂载到该函数，设置 <strong>S3 事件通知</strong> 在创建和更改文件时调用该函数，配置函数以将文件复制到文件系统和目标 S3 存储桶<br>C. 为目标 S3 存储桶和 EFS 文件系统创建一个 <strong>AWS DataSync 位置</strong>，为其创建一个任务，将传输模式设置为<strong>传输所有数据</strong><br>D. 在与文件系统相同的 VPC 中启动一个 <strong>Amazon EC2 实例</strong>，挂载文件系统，创建一个脚本定期将源 S3 存储桶中所有已更改的对象同步到目标 S3 存储桶和已挂载的文件系统</p>
<p><br>681 一家公司使用 <strong>Amazon EC2 实例</strong>，并将数据存储在 <strong>Amazon EBS 卷</strong> 上，要求：</p>
<ul>
<li>确保所有数据在<strong>静态时通过 AWS KMS 进行加密</strong></li>
<li>必须能够<strong>控制加密密钥的轮换</strong></li>
<li>以<strong>最少的运营开销</strong>满足要求</li>
</ul>
<p>选项如下：<br>A. <u>创建一个<strong>客户管理的密钥</strong>，使用该密钥对 EBS 卷进行加密</u><br>B. 使用 <strong>AWS 托管密钥</strong> 对 EBS 卷进行加密，使用该密钥配置自动密钥轮换<br>C. 创建一个带有<strong>导入密钥材料的外部 KMS 密钥</strong>，使用该密钥对 EBS 卷进行加密<br>D. 使用 <strong>AWS 自有密钥</strong> 对 EBS 卷进行加密</p>
<ol>
<li><strong>需求分析</strong><ul>
<li><strong>静态加密</strong>：EBS 卷使用 <strong>KMS 密钥</strong> 加密（SSE）</li>
<li><strong>控制密钥轮换</strong>：用户需能<strong>主动管理密钥轮换</strong>（启用、禁用、轮换周期等）</li>
<li><strong>最少运营开销</strong>：尽量使用托管功能，减少手动操作</li>
</ul>
</li>
<li><strong>KMS 密钥类型对比</strong><ul>
<li><strong>AWS 托管密钥</strong>：由 AWS 自动创建和管理，用户<strong>只能启用&#x2F;禁用自动轮换（每年一次）</strong>，不能手动触发轮换或控制轮换细节。</li>
<li><strong>客户管理密钥（CMK）</strong>：由用户创建和管理，可<strong>手动轮换或启用自动轮换（可自定义周期）</strong>，且可控制密钥策略和权限。</li>
<li><strong>外部密钥</strong>：密钥材料由用户外部提供，管理复杂，开销大。</li>
<li><strong>AWS 自有密钥</strong>：一般不直接使用，通常指 AWS 服务的默认加密密钥（如 SSE-S3），不提供用户控制。</li>
</ul>
</li>
</ol>
<p><br>682 一家公司需要一个解决方案，以在 <strong>Amazon EC2 实例上实施静态数据加密</strong>，要求：</p>
<ul>
<li>必须能<strong>自动识别不合规的资源</strong>（即未加密的 EBS 卷）</li>
<li>根据发现的问题<strong>执行合规政策</strong>（即自动修复）</li>
<li>满足要求且<strong>管理开销最小</strong></li>
</ul>
<p>选项如下：<br>A. <u>使用 <strong>IAM 策略</strong> 仅允许创建加密的 EBS 卷，使用 <strong>AWS Config 和 AWS Systems Manager</strong> 自动检测和修复未加密的 EBS 卷</u><br>B. 使用 <strong>AWS KMS</strong> 管理对加密 EBS 卷的访问，使用 <strong>AWS Lambda 和 Amazon EventBridge</strong> 自动检测和修复未加密的 EBS 卷<br>C. 使用 <strong>Amazon Macie</strong> 检测未加密的 EBS 卷，使用 <strong>AWS Systems Manager 自动化规则</strong> 自动加密现有和新的 EBS 卷<br>D. 使用 <strong>Amazon Inspector</strong> 检测未加密的 EBS 卷，使用 <strong>AWS Systems Manager 自动化规则</strong> 自动加密现有和新的 EBS 卷</p>
<p><strong>Macie</strong> 用于 <strong>发现和保护敏感数据</strong>（如 PII），主要针对 S3，<strong>不用于检测 EBS 卷加密状态</strong></p>
<p><strong>Inspector</strong> 用于 <strong>评估 EC2 实例的安全漏洞和网络暴露</strong>，<strong>不用于检测 EBS 加密状态</strong></p>
<ul>
<li><strong>IAM 策略</strong>：通过权限控制，<strong>阻止创建未加密 EBS 卷</strong>（预防性控制）。</li>
<li><strong>AWS Config</strong>：持续监控资源配置，通过 <strong>Config 规则</strong> 检测未加密 EBS 卷（检测性控制）。</li>
<li><strong>Systems Manager 自动化</strong>：当 Config 标记资源不合规时，可触发 <strong>SSM 自动化执行手册</strong> 自动加密卷（修复性控制）。</li>
</ul>
<p><br>683 一家公司正将其 <strong>多层本地应用程序</strong> 迁移到 AWS，应用程序包含：</p>
<ul>
<li><strong>单节点 MySQL 数据库</strong></li>
<li><strong>多节点 Web 层</strong></li>
</ul>
<p>要求：</p>
<ul>
<li>在迁移过程中<strong>尽量减少对应用程序的更改</strong></li>
<li>迁移后<strong>提高应用程序的弹性</strong></li>
</ul>
<p>问：哪些步骤组合能够满足这些要求？（选择两项）</p>
<p>选项如下：<br>A. <u>将 Web 层迁移到<strong>应用程序负载均衡器后的 Auto Scaling 组中的 Amazon EC2 实例</strong></u><br>B. 将数据库迁移到<strong>网络负载均衡器后的自动扩展组中的 Amazon EC2 实例</strong><br>C. <u>将数据库迁移到 <strong>Amazon RDS 多可用区部署</strong></u><br>D. 将 Web 层迁移到 <strong>AWS Lambda 函数</strong><br>E. 将数据库迁移到 <strong>Amazon DynamoDB 表</strong></p>
<p><br>684 一家公司希望将其 Web 应用程序从本地迁移到 AWS，背景与要求：</p>
<ul>
<li>公司位于 <strong>eu-central-1 区域附近</strong>（用户靠近该区域）</li>
<li><strong>法规限制</strong>：无法在 eu-central-1 区域部署其<strong>部分应用程序</strong>（可能指某些组件或数据必须留在特定地域）</li>
<li>希望实现<strong>个位数毫秒级的延迟</strong>（极低延迟）</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项如下：<br>A. 在 eu-central-1 部署应用程序，将公司的 VPC 从 eu-central-1 扩展到 <strong>Amazon CloudFront 中的边缘位置</strong><br>B. <u>通过将公司的 VPC 从 eu-central-1 扩展到选定的<strong>本地区域</strong>，在 <strong>AWS 本地区域</strong>部署应用程序</u><br>C. 在 eu-central-1 中部署应用程序，将公司的 VPC 从 eu-central-1 扩展到 <strong>Amazon CloudFront 中的区域边缘缓存</strong><br>D. 通过将公司的 VPC 从 eu-central-1 扩展到选定的 <strong>Wavelength 区域</strong>，在 <strong>AWS Wavelength 区域</strong>部署应用程序</p>
<ul>
<li><p><strong>loudFront 边缘位置不能运行应用程序</strong>，只能缓存内容</p>
</li>
<li><p><strong>Local Zones</strong> 专为<strong>极低延迟</strong>设计（个位数毫秒），且<strong>位于大都市附近</strong>（例如可能有 Local Zone 靠近法兰克福或欧洲其他城市）。</p>
</li>
<li><p><strong>Wavelength</strong> 针对 <strong>5G 移动设备超低延迟</strong>，通常需要与电信运营商结合，且用户需通过特定移动网络访问。</p>
</li>
</ul>
<p><br>685 一家公司的电子商务网站流量不稳定，其使用 AWS Lambda 函数直接访问一个私有的 Amazon RDS for PostgreSQL 数据库实例。该公司希望保持可预测的数据库性能，并确保 Lambda 调用不会因过多连接而使数据库过载。<br>解决方案架构师应采取什么措施来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 将客户端驱动指向 RDS 自定义端点。在 VPC 内部署 Lambda 函数。<br>B. <u>将客户端驱动程序指向 RDS 代理端点。在 VPC 内部署 Lambda 函数</u>。<br>C. 将客户端驱动程序指向 RDS 自定义端点。在 VPC 外部部署 Lambda 函数。<br>D. 将客户端驱动程序指向 RDS 代理端点。在 VPC 外部部署 Lambda 函数。</p>
<ul>
<li><strong>RDS Proxy</strong>：专门用于管理数据库连接池，复用连接，避免因 Lambda 快速创建&#x2F;销毁连接导致的数据库连接爆炸，从而稳定数据库性能。</li>
<li><strong>Lambda 部署位置</strong>：因为 RDS 实例是私有的（在 VPC 内），Lambda 必须部署在 VPC 内（配置 VPC 子网和安全组）才能直接访问私有 RDS 或通过 RDS Proxy 访问。</li>
</ul>
<p><br>686 一家公司正在开发一款应用程序，将测试数据存储在多个本地位置。需要将本地位置连接到 AWS 云中某个 AWS 区域的虚拟私有云（VPC）。未来一年，账户和 VPC 的数量将会增加。网络架构必须简化新连接的管理，并且具备扩展能力。<br>哪种解决方案能以最少的管理开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在虚拟私有云（VPC）之间创建对等连接。在虚拟私有云（VPC）与本地位置之间创建虚拟专用网络（VPN）连接。<br>B. 启动一个 Amazon EC2 实例。在该实例上安装 VPN 软件来连接所有 VPC 和本地位置。<br>C. <u>创建中转网关。为 VPC 连接创建 VPC 附件。为本地连接创建 VPN 附件。</u><br>D. 在本地位置和中央 VPC 之间创建 AWS Direct Connect 连接。通过对等连接将中央 VPC 与其他 VPC 相连。</p>
<ul>
<li><strong>可扩展的连接管理</strong>：VPC 数量增加时，如果使用 VPC 对等连接，则连接数为 n×(n−1)&#x2F;2<em>n</em>×(<em>n</em>−1)&#x2F;2，管理复杂，不可扩展。</li>
<li><strong>集中化的网络枢纽</strong>：AWS Transit Gateway（中转网关）是一个区域级的网络枢纽，可以连接多个 VPC 和本地网络（通过 VPN 或 Direct Connect），简化管理和扩展。</li>
<li><strong>VPN 附件</strong>：Transit Gateway 支持创建 VPN 附件，用于与本地站点建立 IPsec VPN 连接。</li>
</ul>
<p><br>687 一家使用 AWS 的公司需要一个解决方案来预测每月制造流程所需的资源。该解决方案必须使用当前存储在 Amazon S3 存储桶中的历史数据。这家公司没有机器学习（ML）经验，希望使用托管服务来进行训练和预测。</p>
<p>哪些步骤组合可以满足这些要求？（选择两项。）</p>
<p><strong>选项</strong>：<br>A. 部署 Amazon SageMaker 模型。创建一个 SageMaker 端点进行推理。<br>B. 使用 Amazon SageMaker，利用 S3 存储桶中的历史数据来训练模型。<br>C. 配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon SageMaker 端点根据输入创建预测。<br>D. <u>配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon Forecast 预测器根据输入创建预测。</u><br>E. <u>使用 S3 存储桶中的历史数据训练 Amazon Forecast 预测器。</u></p>
<ul>
<li>Amazon Forecast 是 AWS 完全托管的<strong>时间序列预测</strong>服务，无需 ML 经验，适合基于历史数据做资源需求预测。</li>
<li>Amazon SageMaker 是通用 ML 平台，需要更多 ML 知识来构建和训练模型</li>
</ul>
<p><br>688 一家公司在 AWS Organizations 中管理 AWS 账户，已配置 IAM Identity Center（AWS 单点登录）和 AWS Control Tower。公司希望跨所有账户管理多个用户权限，权限由多个 IAM 用户使用，需要在开发团队和管理员团队之间分配不同权限。新招聘的用户也要被包含在内。<br>哪种解决方案能以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在 IAM Identity Center 中为每个账户创建单独的用户。在 IAM Identity Center 中创建独立的开发人员组和管理员组。将用户分配到相应的组中。为每个组创建自定义 IAM 策略，以设置细粒度权限。<br>B. 在 IAM Identity Center 中为每个账户创建单独的用户。在 IAM Identity Center 中创建独立的开发人员组和管理员组。将用户分配到相应的组中。根据细粒度权限的需要，为每个用户附加 AWS 托管的 IAM 策略。<br>C. <u>在 IAM Identity Center 中创建个人用户。在 IAM Identity Center 中创建新的开发人员组和管理员组。创建新的权限集，其中包含每个组适用的 IAM 策略。将新组分配到相应的账户。将新的权限集分配给新组。当新员工入职时，将他们添加到适当的组。</u><br>D. 在 IAM Identity Center 中创建个人用户。创建新的权限集，其中包含每个用户相应的 IAM 策略。将用户分配到相应的账户。从特定账户内为用户授予额外的 IAM 权限。当新员工入职时，将他们添加到 IAM Identity Center 并分配到各个账户。</p>
<p><br>689 一家公司希望标准化其 Amazon EBS 卷加密策略，同时希望最大限度地降低运行卷加密检查所需的成本和配置工作。<br>哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 编写 API 调用来描述 EBS 卷并确认这些 EBS 卷已加密。使用 Amazon EventBridge 来调度 AWS Lambda 函数以运行这些 API 调用。<br>B. 编写 API 调用以描述 EBS 卷并确认 EBS 卷已加密。在 AWS Fargate 任务上运行这些 API 调用。<br>C. 创建一个 AWS IAM 策略，该策略要求在 EBS 卷上使用标签。使用 AWS 版本探索器显示未正确标记的资源。手动加密未标记的资源。<br>D. <u>为 Amazon EBS 创建一条 AWS Config 规则，以评估卷是否已加密，并在未加密时标记该卷已加密。</u></p>
<p>AWS Config 提供预定义的托管规则 <code>ebs-encryption-by-default</code> 或自定义规则，可自动检查 EBS 卷是否加密</p>
<p><br>690 一家公司定期将 GB 大小的文件上传到 Amazon S3。上传后，使用一组 Amazon EC2 Spot 实例转码文件格式。公司需要在上传（从本地数据中心到 S3）和下载（从 S3 到 EC2 实例）时扩展吞吐量。<br>哪些解决方案将满足这些要求？（选择两个。）</p>
<p><strong>选项</strong>：<br>A. 使用 S3 存储桶访问点而不是直接访问 S3 存储桶。<br>B. 将文件上传到多个 S3 存储桶中。<br>C. <u>使用 S3 多部分上传。</u><br><u>D. 并行获取对象的多个字节范围。</u><br>E. 上传文件时为每个对象添加一个随机前缀。</p>
<ul>
<li>上传时提高吞吐量 → 多部分上传（C）。</li>
<li>下载时提高吞吐量 → 并行获取多个字节范围（D）</li>
</ul>
<p>为每个对象添加随机前缀 → 这是为了优化 S3 的键（key）分布，避免热前缀影响性能，但主要用于高并发请求场景（每秒数千次请求）</p>
<p>S3 存储桶访问点（Bucket Access Points）主要用于简化大规模数据访问的权限管理，不直接提升吞吐量</p>
<p><br>691 解决方案架构师为部署在多个可用区的 Web 应用程序设计共享存储解决方案。Web 应用在 Auto Scaling 组的 EC2 实例上运行。公司计划频繁更改内容。解决方案必须在更改发生后立即返回新内容时具有强一致性。<br>哪些解决方案满足这些要求？（选择两个。）</p>
<p><strong>选项</strong>：<br>A. 使用安装到各个 EC2 实例的 AWS Storage Gateway Volume Gateway iSCSI 块存储。<br>B. <u>创建 Amazon EFS 文件系统。将 EFS 文件系统挂载到单个 EC2 实例</u>。<br>C. 创建共享的 Amazon EBS 卷。将 EBS 卷挂载到各个 EC2 实例上。<br>D. 使用 AWS DataSync 在 Auto Scaling 组中的 EC2 主机之间执行数据的连续同步。<br>E. <u>创建 Amazon S3 存储桶来存储 Web 内容。将 Cache-Control 标头的元数据设置为无缓存。使用 Amazon CloudFront 交付内容</u></p>
<ul>
<li><strong>创建 Amazon EFS 文件系统并挂载到各个 EC2 实例</strong>（强一致性、多 AZ 共享）。</li>
<li><strong>使用 S3 + CloudFront（无缓存）</strong> 作为内容分发，S3 具有强一致性，CloudFront 通过无缓存设置确保立即获取新内容。</li>
</ul>
<p><br>692 一家公司正在使用应用型负载均衡在三个 AWS 区域部署应用程序。Amazon Route 53 用于在这些区域之间分配流量。<br>解决方案架构师应该使用哪种 Route 53 配置来提供最高性能体验？</p>
<p><strong>选项</strong>：<br>A. <u>使用延迟策略创建</u> A 记录。<br>B. 使用地理位置策略创建 A 记录。<br>C. 使用故障转移策略创建 CNAME 记录。<br>D. 使用地理邻近策略创建 CNAME 记录。</p>
<ul>
<li>延迟策略（Latency-based routing）是 Route 53 专门用于优化性能的路由方式，它会根据 Amazon 的延迟测量数据，将用户 DNS 查询解析到延迟最低的区域端点。</li>
</ul>
<p><br>693 一家公司的 Web 应用程序包含嵌入式非关系型数据库，运行在 ALB 后的 EC2 实例上，这些实例在单个可用区的 Auto Scaling 组中。<br>流量增加要求应用程序具有高可用性，并使数据库最终保持一致。<br>哪种解决方案将以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 用网络负载均衡器替换 ALB。使用 EC2 实例上的复制服务维护嵌入式非关系型数据库。<br>B. 用网络负载均衡器替换 ALB。使用 AWS DMS 将嵌入式非关系型数据库迁移到 Amazon DynamoDB。<br>C. 修改 Auto Scaling 组以跨三个可用区使用 EC2 实例。维护嵌入式非关系型数据库及其在 EC2 实例上的复制服务。<br>D. <u>修改 Auto Scaling 组以跨三个可用区使用 EC2 实例。使用 AWS DMS 将嵌入式非关系型数据库迁移到 Amazon DynamoDB。</u></p>
<ul>
<li>扩展 Auto Scaling 组到多 AZ 实现应用层高可用。</li>
<li>将嵌入式数据库迁移到 DynamoDB，利用其内置的多 AZ 耐久性、自动扩展和最终一致&#x2F;强一致读取能力，大大减少数据库管理负担。</li>
<li>DMS 可用于一次性迁移，之后由 DynamoDB 全托管，符合“最少运营开销”要求。</li>
</ul>
<p><br>694 一家公司正在 AWS 上构建购物应用程序，提供每月更改一次的曲库，需要随流量扩展，且延迟尽可能低。每个用户的购物车数据需要高度可用，即使用户断开并重连，会话数据也必须可用。<br>解决方案架构师应该做些什么来确保购物车数据始终得到保存？</p>
<p><strong>选项</strong>：<br>A. 配置应用型负载均衡以启用粘性会话功能（会话亲和性）以访问 Amazon Aurora 中的曲库。<br>B<u>. 为 Redis 配置 Amazon ElastiCache 以缓存来自 Amazon DynamoDB 的曲库数据和来自用户会话。</u><br>C. 配置 Amazon OpenSearch Service 以缓存来自 Amazon DynamoDB 的曲库数据和来自用户会话的购物车数据。<br>D. 为曲库和购物车配置带有 Amazon EBS 的 Amazon EC2 实例。配置自动快照。</p>
<ul>
<li>ElastiCache Redis 是常见的外部会话存储方案，支持数据持久化、多可用区部署，保证购物车数据高可用和持久性。</li>
<li>配合 DynamoDB 作为曲库持久存储，Redis 缓存曲库降低读取延迟。</li>
<li>用户断开重连后，会话仍可从 Redis 恢复，满足要求。</li>
</ul>
<p><br>695 一家公司正在构建一个基于微服务的应用程序，将部署在 Amazon EKS 上。微服务会相互交互。公司希望确保应用程序是可观察的，以识别未来的性能问题。<br>哪种解决方案将满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 将应用程序配置为使用 Amazon ElastiCache 来减少发送到微服务的请求数量。<br>B. <u>配置 Amazon CloudWatch Container Insights 以从 EKS 集群收集指标。配置 AWS X-Ray 以跟踪微服务之间的请求。</u><br>C. 配置 AWS CloudTrail 以查看 API 调用。构建一个 Amazon QuickSight 仪表板来观察微服务交互。<br>D. 使用 AWS Trusted Advisor 了解应用程序的性能。</p>
<ul>
<li>Container Insights 自动收集容器化应用的基础设施和性能指标。</li>
<li>X-Ray 是 AWS 的分布式追踪服务，专门用于跟踪微服务架构中的请求流，帮助识别延迟和错误。</li>
</ul>
<p>CloudTrail 记录 API 调用（用于审计和安全），QuickSight 用于可视化分析 → CloudTrail 不适用于性能监控，QuickSight 虽可建仪表板但数据来源不合适，无法有效追踪微服务性能。</p>
<p>Trusted Advisor 提供成本、安全、性能等建议，但并非实时可观察性工具，不适用于持续识别微服务性能问题。</p>
<p><br>696 公司需要为客户提供对其数据的安全访问。公司处理客户数据并将结果存储在 Amazon S3 存储桶中。所有数据都受严格的法规和安全要求约束，数据必须静态加密。每个客户只能从他们的 AWS 账户访问他们的数据，公司员工不得访问这些数据。<br>哪种解决方案将满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为每个客户提供 AWS 证书管理器（ACM）证书。加密数据客户端。在私有证书策略中，拒绝所有主体访问证书，客户提供的 IAM 角色除外。<br>B. 为每个客户提供单独的 AWS KMS 密钥。加密数据服务器端。在 S3 存储桶策略中，拒绝解密除客户提供的 IAM 角色之外的所有主体的数据。<br>C. <u>为每个客户提供单独的 AWS KMS 密钥。加密数据服务器端。在每个 KMS 密钥策略中，拒绝解密除客户提供的 IAM 角色之外的所有主体的数据</u>。<br>D. 为每个客户提供 AWS 证书管理器（ACM）证书。加密数据客户端。在公共证书策略中，拒绝所有主体访问证书，客户提供的 IAM 角色除外</p>
<ul>
<li>KMS 密钥策略直接控制谁可以使用密钥进行加解密操作。</li>
<li>每个客户拥有独立密钥，实现逻辑隔离。</li>
<li>在密钥策略中明确拒绝公司员工访问，符合“员工不得访问数据”的要求。</li>
<li>S3 服务器端加密使用 KMS（SSE-KMS）可满足静态加密要求。</li>
</ul>
<p><br>697 解决方案架构师创建了包含两个公共子网和两个私有子网的 VPC。安全要求所有 EC2 实例必须启动在私有子网中。但私有子网中运行在端口 80 和 443 上的 Web 服务器无法接收外部 Internet 流量。<br>解决方案架构师应该如何解决此问题？</p>
<p><strong>选项</strong>：<br>A. 将 EC2 实例附加到私有子网中的 Auto Scaling 组。确保网站的 DNS 记录解析为 Auto Scaling 组标识符。<br>B. <u>在公共子网中配置面向 Internet 的应用型负载均衡（ALB）。将 EC2 实例添加到目标组，将 ALB 与 EC2 关联。将网站的 DNS 记录解析为 ALB。</u><br>C. 在私有子网中启动 NAT 网关。更新私有子网的路由表以添加到 NAT 网关的默认路由。将公共弹性 IP 地址附加到 NAT 网关。<br>D. 确保附加到 EC2 实例的安全组允许端口 80 和 443 流量。确保网站的 DNS 记录解析为 EC2 实例的公共 IP 地址。</p>
<p>在私有子网启动 NAT 网关并附加 EIP → NAT 网关用于<strong>出站</strong> Internet 访问，不是用于入站流量，无法解决外部用户访问 Web 服务器的问题。</p>
<p><br>698 一家公司正在使用 AWS Fargate 集群向 Amazon EKS 部署新应用程序。应用程序需要一个存储解决方案来实现数据持久性，必须具有高可用性、容错性，并能在多个应用程序容器之间共享。<br>哪种解决方案将以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在放置 EKS 工作节点的相同可用区中创建 Amazon EBS 卷。在 EKS 集群上的 StorageClass 对象中注册卷。使用 EBS Multi-attach 在容器之间共享数据。<br>B. <u>创建 Amazon Elastic File System（Amazon EFS）文件系统。在 StorageClass 对象中注册文件系统到 EKS 集群。对所有容器使用相同的文件系统。</u><br>C. 创建 Amazon EBS 卷。在 EKS 集群上的 StorageClass 对象中注册该卷。对所有容器使用相同的卷。<br>D. 在放置 EKS 工作节点的相同可用区中创建 Amazon EFS 文件系统。在 EKS 集群上的 StorageClass 对象中注册文件系统。创建 AWS Lambda 函数以同步文件系统之间的数据。</p>
<p>EFS 是 AWS 托管的共享文件存储，天生跨 AZ 部署，提供高可用和容错。</p>
<p>EKS 有 CSI 驱动程序支持 EFS，配置简单，适合 Fargate 容器共享存储。</p>
<p><br>699 一家公司有一个在其本地数据中心使用 Docker 容器的应用程序。容器在主机上运行，将持久数据存储在主机上的卷中。容器实例使用这些持久数据。<br>公司希望将应用程序迁移到完全托管的服务，因为不想管理任何服务器或存储基础设施。<br>哪种解决方案将满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用 Amazon EKS 与自我管理的节点。创建附加到 EC2 实例的 EBS 卷，并将 EBS 卷用作容器挂载的持久卷。<br>B. <u>使用具有 AWS Fargate 启动类型的 Amazon ECS。创建一个 Amazon EFS 卷，并将 EFS 卷添加为容器中挂载的持久存储卷。</u><br>C. 使用具有 AWS Fargate 启动类型的 Amazon ECS。创建一个 Amazon S3 存储桶，并将 S3 存储桶映射为容器中挂载的持久存储卷。<br>D. 使用具有 Amazon EC2 启动类型的 Amazon ECS。创建一个 Amazon EFS 卷，并将 EFS 卷添加为容器中挂载的持久存储卷。</p>
<ul>
<li>Fargate 提供无服务器容器运行环境，无需管理节点。</li>
<li>EFS 是托共享文件系统，支持多容器挂载，数据持久且跨 AZ 高可用</li>
</ul>
<p><br>700 一家游戏公司希望在多个 AWS 区域推出一款新的面向互联网的应用程序，使用 TCP 和 UDP 协议进行通信。需要为全球用户提供高可用性和最小延迟。<br>解决方案架构师应该采取哪些行动组合来满足这些要求？（选择两个。）</p>
<p><strong>选项</strong>：<br>A. <u>在每个区域的应用程序前面创建内部网络负载均衡器。</u><br>B. 在每个区域的应用程序前面创建外部应用程序负载均衡器。<br>C. <u>创建一个 AWS Global Accelerator 加速器，将流量路由到每个区域的负载均衡器。</u><br>D. 将 Amazon Route 53 配置为使用地理位置路由策略来分配流量。<br>E. 配置 Amazon CloudFront 以处理对每个区域中应用程序的流量和路由请求。</p>
<ul>
<li><strong>在每个区域的应用程序前面创建外部网络负载均衡器</strong>（选项 A 写的是“内部”，但可能题意实为外部，这里需结合推理）。</li>
<li><strong>使用 Global Accelerator 做全局路由</strong>（C）。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T600/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T600/" class="post-title-link" itemprop="url">AWS架构师T600</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T600"><a href="#AWS架构师T600" class="headerlink" title="AWS架构师T600"></a>AWS架构师T600</h1><p><br>501 一家公司希望将客户支付数据导入其位于 Amazon S3 中的数据湖。</p>
<ul>
<li>平均每分钟接收一次支付数据</li>
<li>希望对这些支付数据进行实时分析，然后再将数据导入数据湖<br>要求：以最高的运营效率满足这些要求。</li>
</ul>
<p><strong>选项</strong>：<br>A. 使用 Amazon Kinesis Data Streams 接入数据。使用 AWS Lambda 进行实时数据分析。<br>B. 使用 AWS Glue 获取数据。使用 Amazon Kinesis Data Analytics 进行实时数据分析。<br>C. <u>使用 Amazon Kinesis Data Firehose 接入数据。使用 Amazon Kinesis Data Analytics 进行实时数据分析。</u><br>D. 使用 Amazon API Gateway 接入数据。使用 AWS Lambda 实时分析数据。</p>
<p>AWS Glue 主要用于 ETL（批处理&#x2F;微批处理），不适合实时数据接入（每分钟一次虽不算高频，但 Glue 不是为实时流设计的）。Kinesis Data Analytics 适合实时分析，但搭配 Glue 不合理</p>
<p><strong>Kinesis Data Firehose + Kinesis Data Analytics</strong> 是 AWS 专门为实时分析并存入数据湖设计的托管解决方案</p>
<p>502一家公司运营一个网站，使用内容管理系统（CMS）部署在 Amazon EC2 上。</p>
<ul>
<li>CMS 运行在单个 EC2 实例上</li>
<li>数据层使用 Amazon Aurora MySQL 多可用区数据库实例</li>
<li>网站图像存储在挂载于 EC2 实例内部的 Amazon EBS 卷上</li>
</ul>
<p>要求：提高网站的性能和弹性（选两项措施）。</p>
<p><strong>选项</strong>：<br>A. 将网站图像移至每个 EC2 实例上挂载的 Amazon S3 存储桶中<br>B. 通过使用主 EC2 实例的 NFS 共享来共享网站图像。在其他 EC2 实例上挂载此共享<br>C. <u>将网站图像迁移到每个 EC2 实例都挂载的 Amazon Elastic File System（Amazon EFS）文件系统上</u><br>D. 从现有的 EC2 实例创建一个亚马逊机器镜像（AMI）。使用该 AMI 在应用程序负载均衡器后方配置新实例，作为自动扩展组的一部分。将自动扩展组配置为至少维持两个实例。在 AWS Global Accelerator 中为该网站配置一个加速器<br>E. <u>从现有的 EC2 实例创建一个亚马逊机器镜像（AMI）。使用该 AMI 在应用程序负载均衡器后方配置新实例，作为自动扩展组的一部分。将自动扩展组配置为至少维持两个实例。为网站配置一个亚马逊 CloudFront 分发</u></p>
<ul>
<li>静态资源（图像）存储到 S3</li>
<li>通过 CloudFront 分发（提升性能）</li>
<li>计算层用 ASG+ELB（提升弹性）</li>
</ul>
<p><br>503 一家公司运营基础设施监控服务，正在开发新功能以监控客户 AWS 账户中的数据。<br>该功能需要调用客户账户中的 AWS API，描述 Amazon EC2 实例并读取 CloudWatch 指标。<br>问：公司应以最安全的方式获得访问客户账户的权限，应采取什么措施？</p>
<p><strong>选项</strong>：<br>A. <u>确保客户在其账户中创建一个具有只读 EC2 和 CloudWatch 权限的 IAM 角色，并且信任策略应用于公司的账户。</u><br>B. 创建一个无服务器 API，实现令牌自动售货机，为具有只读 EC2 和 CloudWatch 权限的角色提供临时 AWS 凭证。<br>C. 确保客户在其账户中创建一个具有 EC2 和 CloudWatch 只读权限的 IAM 用户。在密钥管理系统中加密并存储客户的访问密钥和密钥。<br>D. 确保客户在其账户中创建一个 Amazon Cognito 用户，以使用具有 EC2 和 CloudWatch 只读权限的 IAM 角色。在密钥管理系统中加密并存储 Amazon Cognito 用户和密码。</p>
<ul>
<li>跨账户访问的最佳安全实践是使用 <strong>IAM 角色</strong> 和 <strong>假设角色（AssumeRole）</strong>，而不是长期凭证（如 IAM 用户的访问密钥）。</li>
<li>客户账户创建 IAM 角色，并配置信任策略（Trust Policy）允许公司账户中的特定实体（如 IAM 用户或角色）担任该角色。</li>
<li>公司账户中的应用程序使用安全令牌服务（STS）AssumeRole 获取临时安全凭证，以访问客户账户。</li>
</ul>
<p><br>504 一家公司需要连接美国东部（弗吉尼亚北部）区域内跨越数百个 AWS 账户的多个 VPC。网络团队拥有自己的 AWS 账户来管理云网络。<br>问：连接这些 VPC 的操作效率最高的解决方案是什么？</p>
<p><strong>选项</strong>：<br>A. 在每个 VPC 之间建立 VPC 对等连接。更新每个相关联子网的路由表<br>B. 在每个 VPC 中配置一个 NAT 网关和一个互联网网关，以通过互联网连接各个 VPC<br>C. <u>在网络团队的 AWS 账户中创建一个 AWS Transit Gateway。配置来自每个 VPC 的静态路由</u><br>D. 在每个 VPC 中部署 VPN 网关。在网络团队的 AWS 账户中创建一个中转 VPC，以连接到每个 VPC</p>
<ul>
<li><strong>需求</strong>：连接数百个账户中的多个 VPC，操作效率最高（即易于管理、扩展、维护）。</li>
<li><strong>VPC 对等连接</strong>（选项 A）是点对点连接，对于数百个 VPC，需要建立 n*(n-1)&#x2F;2 个对等连接，管理复杂，不具可扩展性。</li>
<li><strong>通过互联网连接</strong>（选项 B）不安全且依赖公网，不是推荐的内部 VPC 互联方案，且配置繁琐。</li>
<li><strong>Transit Gateway</strong>（选项 C）是 AWS 托管的中转网络中心，可以连接数千个 VPC（跨账户），通过资源共享，只需将每个 VPC 连接到 Transit Gateway，然后通过路由表控制流量，管理简单，操作效率最高。</li>
<li><strong>VPN 网关 + 中转 VPC</strong>（选项 D）是传统方案（Transit VPC），但需要部署和管理 VPN 连接、维护 EC2 实例等，比 Transit Gateway 复杂，效率低。</li>
</ul>
<p><br>505 一家公司有运行夜间批处理作业的 Amazon EC2 实例，实例在使用按需计费的自动扩展组中运行。<br>如果作业在一个实例上失败，另一个实例会重新处理该作业。<br>批处理作业每天在本地时间 00:00 到 06:00 之间运行。<br>问：哪种解决方案能以最具成本效益的方式提供 EC2 实例来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为亚马逊 EC2 购买一份 1 年期储蓄计划，该计划需涵盖批处理作业所使用的自动扩展组的实例系列。<br>B. 为批处理作业所使用的自动扩展组中的实例，购买特定实例类型和操作系统的 1 年期预留实例。<br>C. <u>为自动扩展组创建新的启动模板。将实例设置为 Spot 实例。设置扩展策略基于 CPU 使用率</u>。<br>D. 为自动扩展组创建新的启动模板。增大实例大小。设置基于 CPU 使用率的扩展策略。</p>
<p>将自动扩展组实例改为 <strong>Spot 实例</strong>。Spot 实例比按需便宜很多（通常 70–90% 折扣），且作业可以容忍中断（如果 Spot 被回收，另一实例会重新处理作业），非常适合此场景，最具成本效益。</p>
<p><br>506 一家社交媒体公司正在开发一项功能，允许用户上传照片。预计大型活动期间需求大幅增加，必须确保网站能处理用户的上传流量。<br>问：哪种解决方案能满足这些要求且具有最高的可扩展性？</p>
<p><strong>选项</strong>：<br>A. 从用户的浏览器向应用服务器上传文件，然后将文件传输至亚马逊 S3 存储桶<br>B. 配置一个 AWS 存储网关文件网关，直接从用户的浏览器将文件上传到该文件网关<br>C. <u>在应用程序中生成亚马逊 S3 预签名 URL，直接将文件从用户的浏览器上传到 S3 存储桶中</u><br>D. 配置一个 Amazon Elastic File System（Amazon EFS）文件系统，直接从用户的浏览器将文件上传到该文件系统</p>
<ul>
<li><strong>S3 预签名 URL</strong> 允许客户端直接上传文件到 S3，无需经过应用服务器，这样<strong>卸载了上传流量</strong>，应用服务器只需生成预签名 URL。S3 本身可以无限扩展，处理海量并发上传。</li>
</ul>
<p><br>507 一家公司拥有旅游票务网络应用程序，目前数据库在北美单一数据中心。公司希望扩展到多个 AWS 区域服务全球用户。<br>要求：</p>
<ul>
<li>在多个区域部署 Web 平台</li>
<li>维护单一的主预订数据库，且保持全球一致性</li>
<li>预订数据库更新的平均延迟必须低于 1 秒</li>
</ul>
<p>问：解决方案架构师应推荐哪种解决方案来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>将应用程序转换为使用 Amazon DynamoDB。为中心预订表使用全局表。在每个区域部署中使用正确的区域端点</u>。<br>B. 将数据库迁移到 Amazon Aurora MySQL 数据库。在每个区域部署 Aurora 只读副本。在每个区域部署中使用正确的区域端点来访问数据库。<br>C. 将数据库迁移到 Amazon RDS for MySQL 数据库。在每个区域部署 MySQL 只读副本。在每个区域部署中使用正确的区域终端节点来访问数据库。<br>D. 将应用程序迁移到 Amazon Aurora 无服务器数据库。在每个区域部署数据库实例。在每个区域部署中使用正确的区域端点访问数据库。使用 AWS Lambda 函数处理每个区域中的事件流以同步数据库。</p>
<ul>
<li><strong>A</strong>：DynamoDB 全局表是<strong>多主</strong>架构，所有区域都可写，最终一致性（不满足“单一主数据库”和“全球一致性”要求）。虽然可以提供低延迟，但无法保证强一致性（全局表是最终一致性）。</li>
<li><strong>B</strong>：Aurora MySQL 支持跨区域只读副本，但<strong>只读副本是异步复制</strong>，读取副本时可能有延迟，不满足全球一致性（读取可能过时）。写入必须去主区域，可能导致跨区域写入延迟可能超过 1 秒（如果用户远离主区域）。</li>
<li><strong>C</strong>：RDS for MySQL 只读副本同样异步复制，不满足全球一致性。</li>
<li><strong>D</strong>：每个区域部署 Aurora 无服务器实例，使用 Lambda 同步 → 这相当于多主异步同步，很难保证强一致性且复杂。</li>
</ul>
<p><br>508 一家公司将多个 Windows Server 工作负载迁移到 us-west-1 区域的 Amazon EC2 实例。目前手动备份创建镜像。<br>如果 us-west-1 发生自然灾害，希望在 us-west-2 区域快速恢复工作负载。<br>要求：</p>
<ul>
<li>数据丢失不超过 24 小时（RPO ≤ 24h）</li>
<li>EC2 实例的所有备份自动化</li>
<li>最少的管理工作量</li>
</ul>
<p>问：哪些解决方案能以最少的管理工作量满足这些要求？（选两项）</p>
<p><strong>选项</strong>：<br>A. 创建一个基于 Amazon EC2 的 Amazon Machine Image (AMI) 生命周期策略，以基于标签创建备份。将备份计划为每天运行两次。<strong>按需复制镜像</strong>。<br>B. <u>创建一个基于 Amazon EC2 的 Amazon Machine Image (AMI) 生命周期策略，以基于标签创建备份。将备份计划设置为每天运行两次。将副本配置到 us-west-2 区域。</u><br>C. 使用 AWS Backup 在 us-west-1 和 us-west-2 创建备份库。基于标签值为 EC2 实例创建备份计划。创建一个 AWS Lambda 函数作为定时任务运行，以将备份数据复制到 us-west-2。<br>D. <u>使用 AWS Backup 创建备份库。使用 AWS Backup 基于标签值为 EC2 实例创建备份计划。将副本的目标位置定义为 us-west-2。指定备份计划为每天运行两次。</u><br>E. 使用 AWS Backup 创建备份库。使用 AWS Backup 基于标签值为 EC2 实例创建备份计划。指定备份计划为每天运行两次。<strong>按需复制</strong>到 us-west-2。</p>
<p><strong>按需复制镜像</strong>意味着需要手动或另外配置跨区域复制，不是全自动，管理工作量较大。</p>
<p><br>509 一家公司运行一个用于图像处理的两层应用程序，部署在两个可用区，每个可用区有一个公有子网和一个私有子网。</p>
<ul>
<li>应用负载均衡器（ALB）位于公有子网（Web层）</li>
<li>应用层 EC2 实例位于私有子网</li>
</ul>
<p>用户报告应用程序运行速度比预期慢。安全审计显示应用程序正收到来自少数 IP 地址的数百万个非法请求。<br>要求：在寻找永久解决方案的同时，解决方案架构师需要紧急解决此性能问题。</p>
<p><strong>选项</strong>：<br>A. 修改 Web 层的入站安全组。为消耗资源的 IP 地址添加一条拒绝规则。<br>B. <u>修改 Web 层子网的网络 ACL。为正在消耗资源的 IP 地址添加一条入站拒绝规则。</u><br>C. 修改应用层的入站安全组。为消耗资源的 IP 地址添加一条拒绝规则。<br>D. 修改应用层子网的网络 ACL。为消耗资源的 IP 地址添加一条入站拒绝规则。</p>
<ul>
<li><p><strong>攻击流量路径</strong>：用户请求 → ALB（在公有子网） → 应用层 EC2（私有子网）。</p>
</li>
<li><p>非法请求的目标是应用程序，因此流量已经通过 ALB 到达应用层 EC2 实例。</p>
</li>
<li><p><strong>安全组（Security Group）</strong> 是有状态、作用于实例级别（ENI），修改后立即生效，但因为是允许列表（默认拒绝），无法显式拒绝特定 IP（只能通过限制允许的 IP 来间接拒绝）。要直接“拒绝”某些 IP，安全组不支持显式拒绝规则，只能通过移除允许规则或添加拒绝规则？实际上安全组<strong>不支持“拒绝”规则</strong>，只支持“允许”规则。因此 A 和 C 不可行（安全组不能添加拒绝规则）。</p>
</li>
<li><p><strong>网络 ACL（Network ACL）</strong> 是无状态、作用于子网级别，支持显式的允许&#x2F;拒绝规则，且可以快速添加拒绝规则阻止特定 IP 的流量。</p>
<ul>
<li>由于攻击流量通过 ALB 进入，而 ALB 在公有子网，流量从 ALB 到应用层 EC2 时，会经过应用层 EC2 所在的<strong>私有子网</strong>。因此，在私有子网的网络 ACL 添加入站拒绝规则可以阻止这些 IP 的流量到达应用层 EC2 实例。</li>
<li>但注意：ALB 作为客户端，源 IP 是 ALB 的私有 IP（因为 ALB 在公有子网，但转发请求到后端时，源 IP 会保留客户端 IP？实际上 ALB 默认将客户端 IP 通过 X-Forwarded-For 传递，但网络层源 IP 是 ALB 的私有 IP）。因此，如果在私有子网的网络 ACL 中基于原始攻击者 IP 拒绝，可能无效，因为网络 ACL 看到的是 ALB 的私有 IP。</li>
</ul>
</li>
<li><p>更有效的紧急阻断是在 <strong>ALB 所在的公有子网网络 ACL</strong> 添加入站拒绝规则（因为攻击流量首先到达 ALB，源 IP 是攻击者 IP），这样可以阻止攻击流量进入 VPC。<br>因此，最佳紧急措施是修改 <strong>Web 层子网（公有子网）的网络 ACL</strong>，添加入站拒绝规则，阻止攻击者 IP。</p>
</li>
</ul>
<p><br>510 一家全球营销公司的应用程序在 eu-west-1 区域的 VPC 中运行，需要与 ap-southeast-2 区域的 VPC 中运行的数据库安全通信。<br>问：哪种网络设计能够满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在 eu-west-1 VPC 和 ap-southeast-2 VPC 之间创建一个 VPC 对等连接。在 eu-west-1 应用程序安全组中创建一条入站规则，允许来自 ap-southeast-2 安全组中数据库服务器 IP 地址的流量。<br>B. <u>在 ap-southeast-2 VPC 和 eu-west-1 VPC 之间配置 VPC 对等连接。更新子网路由表。在 ap-southeast-2 数据库安全组中创建一条入站规则，该规则引用 eu-west-1 中应用服务器的安全组 ID。</u><br>C. 在 ap-southeast-2 VPC 和 eu-west-1 VPC 之间配置 VPC 对等连接。更新子网路由表。在 ap-southeast-2 数据库安全组中创建一条入站规则，允许来自 eu-west-1 应用服务器 IP 地址的流量。<br>D. 创建一个中转网关，并在 eu-west-1 VPC 和 ap-southeast-2 VPC 之间建立对等连接。当中转网关正确对等且路由配置完成后，在数据库安全组中创建一条入站规则，该规则引用 eu-west-1 中应用服务器的安全组 ID。</p>
<ul>
<li><p><strong>A</strong>：对等连接方向正确，但在应用程序安全组中允许来自数据库 IP 的流量（方向反了，应该是数据库安全组允许应用程序流量）。且使用 IP 地址而不是安全组引用，不够灵活。</p>
</li>
<li><p><strong>B</strong>：配置对等连接，更新路由表，在数据库安全组中引用应用程序安全组 ID → 这是安全且符合最佳实践的方式（使用安全组引用，跨 VPC 安全组引用在 peered VPC 中支持）。</p>
</li>
<li><p><strong>C</strong>：同样配置对等连接，但数据库安全组中允许来自应用服务器 IP 地址（固定 IP），不够灵活（IP 可能变化）。</p>
</li>
<li><p><strong>D</strong>：使用中转网关（Transit Gateway）跨区域连接，但 Transit Gateway 本身支持跨区域对等，不是 VPC 对等连接。虽然可行，但比简单的跨区域 VPC 对更复杂，且题目只涉及两个 VPC 之间连接，不需要中转网关（除非已有中心网络架构）。</p>
</li>
<li><p><strong>VPC 对等连接</strong>可以在不同区域的 VPC 之间建立连接（跨区域 VPC 对等）。</p>
</li>
<li><p><strong>安全通信</strong>：除了网络可达，还需要通过安全组控制访问。</p>
</li>
<li><p>最佳实践：</p>
<ol>
<li>建立跨区域 VPC 对等连接（需要指定哪个 VPC 发起请求）。</li>
<li>更新两端的子网路由表，使流量通过对等连接路由。</li>
<li>在数据库安全组中，允许来自应用程序安全组的流量（使用安全组引用，而不是固定 IP，因为 IP 可能变化）。</li>
</ol>
</li>
</ul>
<p><br>511 一家公司正在开发使用 PostgreSQL 数据库模式的软件，需要为开发人员配置多个开发环境和数据库。<br>平均每个开发环境在 8 小时工作日中被使用一半的时间（即每天约 4 小时）。<br>问：哪种解决方案最具成本效益地满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为每个开发环境配置其自己的 Amazon Aurora PostgreSQL 数据库<br>B. 为每个开发环境配置各自的 Amazon RDS for PostgreSQL 单可用区数据库实例<br>C. <u>为每个开发环境配置其自己的 Amazon Aurora 按需付费 PostgreSQL 兼容数据库</u><br>D. 通过使用 Amazon S3 对象选择功能，为每个开发环境配置其专属的 Amazon S3 存储桶</p>
<p>开发环境间歇使用，最具成本效益的是 Aurora Serverless（选项 C 隐含）。</p>
<p><br>512 一家公司使用 AWS Organizations，资源按账户进行标记（tagging）。同时使用 AWS Backup 备份 AWS 基础设施资源。<br>要求：备份所有 AWS 资源。<br>问：哪种解决方案能以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>使用 AWS Config 识别所有未标记的资源。通过编程方式为已识别的资源添加标签。在中使用标签备份计划。</u><br>B. 使用 AWS Config 识别所有未运行的资源。将这些资源添加到备份库中。<br>C. 要求所有 AWS 账户所有者检查其资源，以确定需要备份的资源。<br>D. 使用 Amazon Inspector 识别所有不合规的资源。</p>
<ul>
<li><strong>AWS Backup 支持基于标签（tag）自动备份资源</strong>。因此，如果所有资源都有统一的标签，可以通过标签备份计划一次性覆盖。</li>
<li>但可能存在未标记的资源，导致它们不会被备份</li>
</ul>
<p>Amazon Inspector 用于安全漏洞评估，与备份无关</p>
<p><br>513 一家社交媒体公司希望允许用户上传图片，应用程序托管在 AWS 云中。<br>要求：</p>
<ol>
<li>自动调整图片大小，以适应多种设备类型</li>
<li>一天中遇到不可预测的流量模式</li>
<li>高可用性</li>
<li>最大限度提升可扩展性</li>
</ol>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>创建一个托管在 Amazon S3 中的静态网站，该网站调用 AWS Lambda 函数来调整图像大小并进行存储存储在 Amazon S3 存储桶中的图像。</u><br>B. 创建一个托管在 Amazon CloudFront 中的静态网站，该网站调用 AWS Step Functions 来调整图像大小，并将图像存储在 Amazon RDS 数据库中。<br>C. 创建一个托管在运行于 Amazon EC2 实例上的 Web 服务器中的动态网站。配置一个在 EC2 实例上运行的进程，用于调整图像大小并将图像存储在 Amazon S3 存储桶中。<br>D. 创建一个动态网站，托管在自动扩展的 Amazon Elastic Container Service（Amazon ECS）集群上，该集群在 Amazon Simple Queue Service（Amazon SQS）中创建一个调整大小的任务。设置一个在 Amazon EC2 实例上运行的图像调整程序，以处理这些调整大小的任务。</p>
<p><br>514 一家公司在 Amazon EC2 上运行微服务应用，希望迁移到 Amazon EKS 集群以实现可扩展性。<br>安全合规要求：</p>
<ul>
<li>EKS 控制平面配置为：端点私有访问设为 true，端点公共访问设为 false</li>
<li>数据平面（节点）放置在私有子网中</li>
</ul>
<p>问题：节点无法加入集群。<br>问：哪种解决方案将允许节点加入集群？</p>
<p><strong>选项</strong>：<br>A. 在 AWS 身份和访问管理（IAM）中向 AmazonEKSNodeRole IAM 角色授予所需权限<br>B. <u>创建接口 VPC 终端节点，以允许节点访问控制平面</u><br>C. 在公共子网中重新创建节点。限制 EC2 节点的安全组<br>D. 允许节点安全组中的出站流量</p>
<ul>
<li><strong>EKS 控制平面端点配置</strong>：<ul>
<li>私有访问（true）：控制平面端点只能从 VPC 内访问（通过私有 IP）</li>
<li>公共访问（false）：控制平面不能从互联网访问</li>
</ul>
</li>
<li><strong>数据平面节点在私有子网</strong>：没有公网 IP，无法直接访问互联网。</li>
<li><strong>节点加入集群</strong>需要与 EKS 控制平面通信（Kubernetes API 服务器）。<br>当控制平面只有私有端点时，节点必须通过 VPC 内部网络访问 API 服务器。<br>但是，EKS 控制平面的私有端点实际上是通过 <strong>接口 VPC 端点（Interface VPC Endpoint）</strong> 实现的（AWS PrivateLink）。</li>
</ul>
<p><strong>根本原因</strong>：如果私有子网中的节点没有路由到达控制平面的接口 VPC 端点，或者接口端点未正确创建&#x2F;配置，节点无法加入集群。</p>
<p><br>515 一家公司正将本地应用程序迁移到 AWS，希望使用 Amazon Redshift 作为解决方案。<br>问：哪些用例适合 Amazon Redshift？（选三项）</p>
<p><strong>选项</strong>：<br>A. 支持数据 API，以便传统应用程序、容器化应用程序和事件驱动型应用程序访问数据<br><u>B. 支持客户端和服务端加密</u><br><u>C. 在指定时段以及应用程序未活跃时构建分析工作负载</u><br>D. 缓存数据以减轻后端数据库的压力<br>E. 全球扩展以支持 PB 级数据和每分钟数千万次请求<br>F. <u>使用 AWS 管理控制台创建集群的次要副本</u></p>
<p><strong>解析</strong>：</p>
<p><strong>Amazon Redshift 是云数据仓库</strong>，主要用于：</p>
<ul>
<li>大规模数据分析（OLAP）</li>
<li>处理 PB 级数据</li>
<li>支持复杂查询和聚合</li>
<li>支持加密（传输中和静态）</li>
<li>可以按需或预留实例运行，适合定时分析工作负载</li>
<li>支持跨区域快照和只读副本（次要副本）用于灾备或读取扩展</li>
</ul>
<p><br>516 一家公司向客户提供 API 接口，用于获取财务信息。预计在一年中的使用高峰期会收到更多请求。<br>要求：</p>
<ul>
<li>API 以低延迟持续响应</li>
<li>为该 API 提供一个计算主机</li>
<li>以最少的运营开销满足要求</li>
</ul>
<p>问：哪种解决方案能以最少的运营开销满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用应用程序负载均衡器和亚马逊弹性容器服务（Amazon ECS）<br>B. <u>使用 Amazon API Gateway 和具有预置并发的 AWS Lambda 函数</u><br>C. 使用应用程序负载均衡器和 Amazon Elastic Kubernetes Service（Amazon EKS）集群<br>D. 使用具有预留并发的 Amazon API Gateway 和 AWS Lambda 函数</p>
<ul>
<li><p><strong>B 和 D</strong>：使用 API Gateway + Lambda 是无服务器架构，API Gateway 托管 API 前端，Lambda 提供计算，无需管理服务器。</p>
<ul>
<li><strong>预置并发（Provisioned Concurrency）</strong>：Lambda 可以配置预置并发，保持一定数量的函数实例预热，以避免冷启动，保证低延迟。</li>
<li><strong>预留并发（Reserved Concurrency）</strong>：是限制函数的最大并发数，不是用于降低延迟的主要手段。</li>
</ul>
</li>
<li><p><strong>A 和 C</strong>：使用应用负载均衡器 + ECS&#x2F;EKS 需要管理容器集群、节点、自动扩展等，有一定运营开销。</p>
</li>
</ul>
<p><br>517 一家公司希望将所有 AWS Systems Manager Session Manager 日志发送到 Amazon S3 存储桶进行存档。<br>要求：以最高的运营效率满足这一要求。</p>
<p><strong>选项</strong>：<br>A. <u>在 Systems Manager 控制台中启用 S3 日志记录。选择一个 S3 存储桶来发送会话数据。</u><br>B. 安装 Amazon CloudWatch 代理。将所有日志推送到 CloudWatch 日志组。出于存档目的，将日志从组导出到 S3 存储桶。<br>C. 创建 Systems Manager 文档以将所有服务器日志上传到中央 S3 存储桶。使用 Amazon EventBridge 每天针对帐户中的所有服务器运行 Systems Manager 文档。<br>D. 安装 Amazon CloudWatch 代理。将所有日志推送到 CloudWatch 日志组。创建 CloudWatch 日志订阅，将任何传入的日志事件推送到 Amazon Kinesis Data Firehose 传输流。将 Amazon S3 设置为目的地。</p>
<p>在 Systems Manager 控制台直接启用 S3 日志记录，选择 S3 存储桶，这是最直接、最简单的方式，无需额外代理或复杂流程。运营效率最高。</p>
<p><br>518 一个应用程序使用 Amazon RDS MySQL 数据库实例，磁盘空间即将不足。<br>解决方案架构师希望在不中断服务的情况下增加磁盘空间。<br>要求：以最少的工作量满足这些要求。</p>
<p><strong>选项</strong>：<br><u>A. 在 RDS 中启用存储自动扩展</u><br>B. 增加 RDS 数据库实例大小<br>C. 将 RDS 数据库实例的存储类型更改为预配置 IOPS<br>D. 备份 RDS 数据库，增加存储容量，恢复数据库，并停止之前的实例</p>
<ul>
<li><strong>RDS 存储自动扩展（Storage Auto Scaling）</strong> 功能可以自动增加存储容量，当可用存储空间低于阈值时触发，无需手动干预，且不中断服务。</li>
<li><strong>其他选项</strong>：<ul>
<li><strong>B</strong>：增加数据库实例大小（实例类型）不会增加存储空间，且可能需要重启。</li>
<li><strong>C</strong>：更改存储类型（如从 gp2 改为 io1）不影响容量，且可能涉及停机。</li>
<li><strong>D</strong>：手动备份、增加存储、恢复，工作量大且可能导致停机。</li>
</ul>
</li>
</ul>
<p><br>519 一家咨询公司为全球客户提供专业服务，为客户提供解决方案和工具，以加快在 AWS 上收集和分析数据的速度。<br>需要集中管理和部署一套通用的解决方案和工具，供客户用于自助服务。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为客户创建 AWS CloudFormation 模板<br>B. <u>为客户创建 AWS 服务目录产品</u><br>C. 为客户创建 AWS Systems Manager 模板<br>D. 为客户创建 AWS Config 项目</p>
<p><strong>AWS 服务目录（Service Catalog）</strong> 允许组织集中管理和部署预先批准的 AWS 产品（包括 CloudFormation 模板、AMI、Marketplace 产品等），并让最终用户（客户）通过自助服务门户按需部署，同时保持治理和合规性</p>
<p><br>520 一家公司设计一款运行在 Amazon EC2 上的新 Web 应用程序，使用 Amazon DynamoDB 作为后端数据存储。</p>
<ul>
<li>流量不可预测</li>
<li>预计对数据库的读写吞吐量处于中等至较高水平</li>
<li>需要根据应用程序的流量进行扩展</li>
</ul>
<p>问：哪种 DynamoDB 表配置能最具成本效益地满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用 DynamoDB 标准表类配置具有预配置读写能力的 DynamoDB。将 DynamoDB 自动扩展设置为最大定义容量。<br>B. <u>使用 DynamoDB 标准表类别，将 DynamoDB 配置为按需模式。</u><br>C. 使用 DynamoDB 标准低频访问（DynamoDB Standard-IA）表类别配置具有预置读写能力的 DynamoDB。将 DynamoDB 自动扩展设置为定义的最大容量。<br>D. 使用 DynamoDB 标准不频繁访问（DynamoDB Standard-IA）表类别，将 DynamoDB 配置为按需模式。</p>
<ul>
<li><strong>DynamoDB 计费模式</strong>：<ul>
<li><strong>预置容量（Provisioned）</strong>：预先设置读写容量单位（RCU&#x2F;WCU），按小时收费，适合可预测的稳定流量；结合自动扩展可以根据流量调整容量，但需要设置最小&#x2F;最大容量范围。</li>
<li><strong>按需容量（On-Demand）</strong>：按实际读写请求次数收费，无需预置容量，自动扩展，适合不可预测或突发流量。</li>
</ul>
</li>
<li><strong>表类别</strong>：<ul>
<li>标准表（Standard）适用于经常访问的数据</li>
<li>标准低频访问（Standard-IA）适用于不常访问的数据，存储成本更低但读写成本更高，且仅支持按需模式（某些场景也支持预置？实际上 Standard-IA 是存储类别，主要用于降低存储成本，但可以配合按需或预置容量模式）</li>
</ul>
</li>
</ul>
<p><br>521 一家零售公司有多项业务，每个 IT 团队管理自己的 AWS 账户，所有账户是 AWS Organizations 的一部分。<br>每个团队在其账户的 Amazon DynamoDB 表中监控产品库存水平。<br>现在，公司正在一个共享 AWS 账户中部署中央库存报告应用，该应用必须能从所有团队的 DynamoDB 表中读取数据项。<br>问：哪种身份验证选项能最安全地满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在库存应用账户中将 DynamoDB 与 AWS Secrets Manager 集成。配置应用程序，使其使用 Secrets Manager 中的正确密钥进行身份验证并读取 DynamoDB 表。安排每 30 天进行一次密钥轮换。<br>B. 在每个业务账户中，创建一个具有编程访问权限的 IAM 用户。配置应用程序，使其使用正确的 IAM 用户访问密钥 ID 和秘密访问密钥来进行身份验证并读取 DynamoDB 表。每 30 天手动轮换一次 IAM 访问密钥。<br>C. <u>在每个业务账户中，创建一个名为 BU_ROLE 的 IAM 角色，该角色附带一个策略，授予其对 DynamoDB 表的访问权限，以及一个信任策略，用于信任库存应用账户中的特定角色。在库存账户中，创建一个名为 APP_ROLE 的角色，该角色允许访问 STS AssumeRole API 操作。将应用配置为使用 APP_ROLE，并承担跨账户角色 BU_ROLE 以读取 DynamoDB 表。</u><br>D. 将 DynamoDB 与 AWS 证书管理器（ACM）集成。生成身份证书以对 DynamoDB 进行身份验证。配置应用程序以使用正确的证书来验证和读取 DynamoDB 表。</p>
<ul>
<li><strong>最安全</strong>：应避免使用长期凭证（如 IAM 用户访问密钥），优先使用 <strong>IAM 角色跨账户访问</strong>。</li>
<li>跨账户访问 DynamoDB 的最佳实践：<ol>
<li>在每个业务账户中创建 IAM 角色（如 BU_ROLE），授予对 DynamoDB 表的读取权限，并设置信任策略允许库存应用账户中的特定 IAM 角色担任该角色。</li>
<li>在库存应用账户中创建 IAM 角色（如 APP_ROLE），允许应用程序调用 STS AssumeRole 以获取临时凭证访问其他账户。</li>
<li>应用程序使用 APP_ROLE 的临时凭证，通过 STS AssumeRole 获取每个业务账户 BU_ROLE 的临时凭证，从而读取 DynamoDB 表。</li>
</ol>
</li>
</ul>
<p><br>522 一家公司使用 Amazon EKS 运行容器应用程序，工作负载在一天中并不稳定。<br>希望 Amazon EKS 能够根据工作负载进行扩缩容。<br>要求：以最小的运营开销满足这些要求（选两项）。</p>
<p><strong>选项</strong>：<br>A. 使用 AWS Lambda 函数来调整 EKS 集群的大小。<br>B. <u>使用 Kubernetes 指标服务器激活水平 Pod 自动扩缩容（Horizontal Pod Autoscaler, HPA）</u>。<br>C. <u>使用 Kubernetes 集群自动扩缩器（Cluster Autoscaler）来管理集群中的节点数量。</u><br>D. 使用 Amazon API Gateway 并将其连接到 Amazon EKS。<br>E. 使用 AWS App Mesh 观察网络活动。</p>
<ul>
<li><strong>EKS 扩缩容</strong>包含两个层面：<ol>
<li><strong>Pod 级别</strong>：水平 Pod 自动扩缩容（HPA），根据 CPU、内存等指标调整 Pod 副本数。</li>
<li><strong>节点级别</strong>：集群自动扩缩器（Cluster Autoscaler），根据 Pod 调度需求自动调整节点数量（即调整节点组大小）。</li>
</ol>
</li>
<li><strong>最小运营开销</strong>：使用 Kubernetes 原生自动化工具（HPA 和 Cluster Autoscaler），无需自定义脚本或额外服务。</li>
</ul>
<p><br>523 一家公司运行基于微服务的无服务器 Web 应用程序，需要从多个 Amazon DynamoDB 表中检索数据。<br>要求：</p>
<ul>
<li>让应用程序具备检索数据的能力</li>
<li>不影响应用程序的基准性能</li>
<li>以最高的运营效率满足这些要求</li>
</ul>
<p><strong>选项</strong>：<br>A. AWS AppSync 管道解析器<br>B. 带有 Lambda@Edge 函数的 Amazon CloudFront<br>C. 边缘优化的 Amazon API Gateway 与 AWS Lambda 函数<br>D. <u>带有 DynamoDB 连接器的 Amazon Athena 联合查询</u></p>
<p><br>524 一家公司希望分析和排查与 IAM 权限相关的“访问被拒绝”错误和“未授权”错误。已经启用 AWS CloudTrail。<br>要求：以最小的工作量满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 使用 AWS Glue 并编写自定义脚本来查询 CloudTrail 日志中的错误<br>B. 使用 AWS Batch 并编写自定义脚本来查询 CloudTrail 日志中的错误<br>C. <u>使用 Amazon Athena 查询搜索 CloudTrail 日志以识别错误</u><br>D. 使用 Amazon QuickSight 搜索 CloudTrail 日志。创建一个仪表板来识别错误</p>
<ul>
<li><strong>CloudTrail 日志</strong> 存储在 S3 中，格式为 JSON。</li>
<li><strong>最小工作量</strong>：使用托管服务直接查询，无需编写和管理自定义脚本或作业。</li>
<li><strong>Amazon Athena</strong> 支持直接对 S3 中的 CloudTrail 日志进行 SQL 查询，快速识别错误事件，无需数据加载或转换，且按查询量付费，操作简单</li>
</ul>
<p><br>525 一家公司希望将其现有的 AWS 使用成本添加到运营成本仪表盘中。<br>要求：</p>
<ul>
<li>通过编程方式获取使用成本</li>
<li>能够访问本年度的成本数据</li>
<li>能够预测未来 12 个月的成本</li>
<li>以最少的运营开销满足这些要求</li>
</ul>
<p><strong>选项</strong>：<br>A. <u>使用带有分页功能的 AWS Cost Explorer API 访问与使用成本相关的数据</u><br>B. 通过可下载的 AWS Cost Explorer 报告 .csv 文件访问与使用成本相关的数据<br>C. 配置 AWS 预算操作，通过 FTP 将使用成本数据发送给公司<br>D. 创建 AWS 预算报告以获取使用成本数据。通过 SMTP 将数据发送给公司</p>
<ul>
<li><strong>A</strong>：AWS Cost Explorer API 可以直接通过编程方式获取成本和使用数据，包括历史成本和预测数据，支持分页获取大量数据，且是托管 API，运营开销最小。</li>
<li><strong>B</strong>：可下载的 .csv 报告需要手动下载或通过脚本触发下载，不是实时的编程接口，且预测功能不如 API 灵活。</li>
<li><strong>C 和 D</strong>：AWS 预算（Budgets）用于设置成本阈值和警报，可以通过操作发送通知，但不是用于完整成本数据获取和预测的主要工具，且通过 FTP&#x2F;SMTP 发送增加了额外配置开销。</li>
</ul>
<p>526一位解决方案架构师正在评估应用程序的弹性。注意到数据库管理员最近在扩展操作中对 Amazon Aurora PostgreSQL 数据库写入实例执行了故障转移，导致应用程序中断 3 分钟。<br>要求：以最小的运营开销减少扩展操作的停机时间。</p>
<p><strong>选项</strong>：<br>A. 在集群中创建更多的 Aurora PostgreSQL 只读副本，以处理故障转移期间的负载<br>B. 在同一 AWS 区域中设置一个备用 Aurora PostgreSQL 集群。在故障转移期间，更新应用程序以使用备用集群的写入器端点<br>C. 创建一个 Amazon ElastiCache for Memcached 集群，以在故障转移期间处理负载<br>D. 为<u>数据库设置 Amazon RDS 代理。更新应用程序以使用代理端点</u></p>
<ul>
<li><strong>问题</strong>：Aurora 故障转移期间应用程序中断 3 分钟，原因可能是应用程序连接在故障转移后需要重新建立，或者 DNS 端点更新延迟。</li>
<li><strong>最小运营开销</strong>：希望使用托管服务，无需复杂架构变更。</li>
<li><strong>Amazon RDS Proxy</strong> 可以管理数据库连接池，并在故障转移时保持应用程序连接，自动将流量路由到新的写入器实例，从而显著减少故障转移期间的应用程序中断时间。设置 RDS Proxy 相对简单（托管服务），只需更新应用程序的连接端点为代理端点即可。</li>
<li>其他选项：<ul>
<li><strong>A</strong>：增加只读副本不能解决写入故障转移的中断问题。</li>
<li><strong>B</strong>：设置备用集群并手动更新应用程序端点，运营开销大，且不是自动故障转移。</li>
<li><strong>C</strong>：ElastiCache 用于缓存，不能解决数据库故障转移的连接中断问题。</li>
</ul>
</li>
</ul>
<p><br>527 一家公司拥有基于订阅的区域性流媒体服务，在单个 AWS 区域运行。架构包括：</p>
<ul>
<li>Web 服务器和应用服务器运行在 EC2 实例上，位于弹性负载均衡器后的自动扩展组中</li>
<li>Amazon Aurora 全局数据库集群跨多个可用区扩展</li>
</ul>
<p>公司希望进行全球扩张，并确保应用程序的停机时间最短。<br>问：哪种解决方案将提供最高的容错能力？</p>
<p><strong>选项</strong>：<br>A. 扩展 Web 层和应用层的自动扩展组，以便在第二个区域的可用区中部署实例。使用 Aurora 全局数据库在主区域和第二个区域部署数据库。使用 Amazon Route 53 健康检查以及到第二个区域的故障转移路由策略。<br>B. 将 Web 层和应用层部署到第二个区域。在第二个区域中添加一个 Aurora PostgreSQL 跨区域 Aurora 只读副本。使用 Amazon Route 53 健康检查和故障转移路由策略指向第二个区域。根据需要将备用副本提升为主副本。<br>C. 将 Web 层和应用层部署到第二个区域。在第二个区域创建一个 Aurora PostgreSQL 数据库。使用 AWS 数据库迁移服务（AWS DMS）将主数据库复制到第二个区域。使用 Amazon Route 53 健康检查和故障转移路由策略指向第二个区域。<br>D. <u>将 Web 层和应用层部署到第二个区域。使用 Amazon Aurora 全局数据库在主区域和第二个区域部署数据库。将 Amazon Route 53 健康检查与故障转移路由策略配合使用</u></p>
<p><strong>Aurora 全局数据库 + 多区域应用部署 + Route 53 故障转移</strong> 是 AWS 推荐的高容错全球扩展方案。</p>
<p><br>528 一家数据分析公司希望将其批处理系统迁移到 AWS。<br>现状：</p>
<ul>
<li>白天通过 FTP 定期接收数千个小型数据文件</li>
<li>本地批处理作业在夜间处理这些文件，耗时数小时</li>
</ul>
<p>要求：</p>
<ul>
<li>AWS 解决方案应尽快处理传入的数据文件</li>
<li>对 FTP 客户端的改动尽可能小</li>
<li>文件成功处理后删除传入的数据文件</li>
<li>每个文件的处理时间需要 3 到 8 分钟</li>
<li>以最具运营效率的方式满足要求</li>
</ul>
<p><strong>选项</strong>：<br>A. 使用运行 FTP 服务器的 Amazon EC2 实例，将传入的文件作为对象存储在 Amazon S3 Glacier Flexible Retrieval 中。在 AWS Batch 中配置作业队列。使用 Amazon EventBridge 规则，每晚从 S3 Glacier Flexible Retrieval 调用作业来处理这些对象。作业处理完对象后，删除这些对象。<br>B. 使用运行 FTP 服务器的 Amazon EC2 实例，将传入的文件存储在 Amazon Elastic Block Store（Amazon EBS）卷上。在 AWS Batch 中配置作业队列。使用 Amazon EventBridge 规则调用作业，每晚从 EBS 卷处理文件。作业处理完文件后删除这些文件。<br>C. 使用 AWS Transfer Family 创建一个 FTP 服务器，将传入的文件存储在 Amazon Elastic Block Store（Amazon EBS）卷上。在 AWS Batch 中配置一个作业队列。当每个文件到达时，使用 Amazon S3 事件通知来调用 AWS Batch 中的作业。作业处理完文件后，删除这些文件。<br>D. <u>使用 AWS Transfer Family 创建一个 FTP 服务器，将传入的文件存储在 Amazon S3 标准存储中。创建一个 AWS Lambda 函数来处理这些文件，并在处理完成后删除它们。当文件到达时，使用 S3 事件通知来调用该 Lambda 函数。</u></p>
<ul>
<li><strong>对 FTP 客户端改动小</strong>：继续使用 FTP 协议，可以使用 <strong>AWS Transfer Family</strong>（托管 FTP&#x2F;SFTP 服务），无需自管 EC2 FTP 服务器。</li>
<li><strong>尽快处理文件</strong>：不再夜间批处理，改为文件到达后立即处理（事件驱动）。</li>
<li><strong>文件处理时间 3–8 分钟</strong>：超出 Lambda 最大执行时间（15 分钟），因此 Lambda 可以处理（但需注意 Lambda 最大 15 分钟，可以满足）。但考虑数千个文件，可能并行处理，Lambda 适合。</li>
<li><strong>运营效率</strong>：使用托管服务（Transfer Family、S3、Lambda）自动化处理，无需管理服务器。</li>
</ul>
<p><br>529 一家公司正将其工作负载迁移到 AWS。数据库中包含交易数据和敏感数据。<br>要求：</p>
<ul>
<li>使用 AWS 云解决方案提高安全性</li>
<li>减少数据库的运营开销</li>
</ul>
<p><strong>选项</strong>：<br>A. 将数据库迁移到 Amazon EC2。使用 AWS 密钥管理服务（AWS KMS）的 AWS 托管密钥进行加密。<br>B<u>. 将数据库迁移到 Amazon RDS。配置静态加密。</u><br>C. 将数据迁移到 Amazon S3。使用 Amazon Macie 进行数据安全和保护<br>D. 将数据库迁移到 Amazon RDS。使用 Amazon CloudWatch Logs 保障数据安全和保护。</p>
<ul>
<li><strong>减少运营开销</strong>：应使用托管数据库服务（如 Amazon RDS），而不是自管理 EC2 上的数据库。</li>
<li><strong>提高安全性</strong>：RDS 支持静态加密（使用 KMS 密钥），以及传输加密、IAM 集成、安全组等。</li>
</ul>
<p><br>530 一家公司拥有具备 TCP 和 UDP 多人游戏功能的在线游戏应用程序。使用 Amazon Route 53 将应用程序流量导向不同 AWS 区域中的多个网络负载均衡器（NLB）。<br>为应对用户增长，需要提升在线游戏的应用性能并降低延迟。</p>
<p><strong>选项</strong>：<br>A. 在网络负载均衡器（NLB）前添加一个 Amazon CloudFront 分发。增加 Cache-Control 的 max-age 参数。<br>B. 用应用程序负载均衡器（ALB）替换网络负载均衡器（NLB）。配置 Route 53 使用基于延迟的路由。<br>C. <u>在网络负载均衡器（NLB）前添加 AWS Global Accelerator。配置一个 Global Accelerator 端点以使用正确的监听器端口。</u><br>D. 在网络负载均衡器（NLB）后添加一个亚马逊 API 网关端点。启用 API 缓存。为不同的阶段覆盖方法缓存。</p>
<p>CloudFront 是 CDN，主要用于缓存和加速 HTTP&#x2F;HTTPS 内容，不支持 TCP&#x2F;UDP 游戏流量。</p>
<p>ALB 仅支持 HTTP&#x2F;HTTPS，不支持 UDP，不适合 TCP&#x2F;UDP 游戏</p>
<p>AWS Global Accelerator 提供静态任播 IP，通过 AWS 全球网络将用户流量路由到最近区域的 NLB，减少延迟和抖动，支持 TCP&#x2F;UDP，非常适合全球分布的实时游戏应用。</p>
<p>API Gateway 用于 REST&#x2F;WebSocket API，支持 HTTP，不适用于原始 TCP&#x2F;UDP 游戏流量。</p>
<p><br>531 一家公司需要与第三方数据馈送集成。当有新数据时，第三方会发送一个 webhook 通知外部服务。<br>开发人员编写了一个 AWS Lambda 函数，在收到 webhook 回调时检索数据。<br>要求：让第三方能够调用这个 Lambda 函数，并以最高的运营效率满足要求。</p>
<p><strong>选项</strong>：<br>A. <u>为 Lambda 函数创建一个函数 URL。将该 Lambda 函数 URL 提供给第三方用于 webhook</u><br>B. 在 Lambda 函数前部署应用程序负载均衡器（ALB）。向第三方提供该 ALB 的 URL 以用于 webhook<br>C. 创建一个亚马逊简单通知服务（Amazon SNS）主题。将该主题附加到 Lambda 函数。向第三方提供 SNS 主题的公共主机名以用于 Webhook<br>D. 创建一个 Amazon Simple Queue Service（Amazon SQS）队列。将该队列附加到 Lambda 函数。向第三方提供 SQS 队列的公共主机名以用于 webhook</p>
<p><strong>Lambda 函数 URL</strong> 是 Lambda 的一项功能，可以为一个函数创建唯一的 HTTPS 端点，无需配置 API Gateway 或其他服务，直接通过 URL 调用函数</p>
<p>532一家公司在某个 AWS 区域有一项工作负载，客户通过 Amazon API Gateway REST API 访问。使用 Amazon Route 53 作为 DNS 提供商。<br>要求：为所有客户提供独立且安全的 URL。<br>问：哪些步骤组合能以最高的运营效率满足这些要求？（选三项）</p>
<p><strong>选项</strong>：<br>A. <u>在注册商处注册所需域名。在 Route 53 托管区域中创建一个通配符自定义域名，然后在该区域中创建指向 API Gateway 端点的记录</u>。<br>B. 在另一个区域的 AWS 证书管理器（ACM）中请求一个与这些域名匹配的通配符证书。<br>C. 根据 Route 53 中的要求为每个客户创建托管区域。创建指向 API 网关端点的区域记录。<br>D. <u>在相同的 AWS 证书管理器（ACM）中请求一个与自定义域名匹配的通配符证书地区。</u><br>E. 在 API 网关中为每个客户创建多个 API 端点。<br>F. <u>在 API 网关中为 REST API 创建自定义域名。从 AWS 证书管理器（ACM）导入证书</u>。</p>
<ul>
<li><strong>要求</strong>：为所有客户提供独立且安全的 URL，即每个客户有不同子域名（如 <a target="_blank" rel="noopener" href="https://client1.example.com/">client1.example.com</a>, <a target="_blank" rel="noopener" href="https://client2.example.com/">client2.example.com</a>）指向同一 API Gateway，且需要 HTTPS。</li>
<li><strong>最高运营效率</strong>：使用通配符证书和通配符自定义域名，避免为每个客户单独配置。</li>
</ul>
<p>步骤组合应为：</p>
<ol>
<li><strong>注册域名</strong>（在注册商处注册，并在 Route 53 中创建托管区域）—— 选项 A 包含此步骤。</li>
<li><strong>获取通配符 SSL 证书</strong>（通过 ACM，且必须在 <strong>同一区域</strong> 因为 API Gateway 自定义域名需要证书与 API Gateway 同区域）—— 选项 D 正确（相同区域的 ACM 通配符证书）。</li>
<li><strong>在 API Gateway 中创建自定义域名</strong>，导入 ACM 证书，并配置映射到 API 阶段 —— 选项 F 正确。</li>
</ol>
<p><br>533 一家公司将数据存储在 Amazon S3 中，规定数据不得包含个人身份信息（PII）。<br>最近发现一些 S3 对象包含 PII。<br>要求：自动检测 S3 存储桶中的 PII，并通知公司的安全团队。</p>
<p><strong>选项</strong>：<br>A. <u>使用 Amazon Macie。创建一个 Amazon EventBridge 规则，用于从 Macie 的发现结果中过滤 SensitiveData 事件类型，并向安全团队发送一条亚马逊简单通知服务（Amazon SNS）通知。</u><br>B. 使用 Amazon GuardDuty。创建一个 Amazon EventBridge 规则，从 GuardDuty 的检测结果中筛选出 CRITICAL 事件类型，并向安全团队发送 Amazon Simple Notification Service（Amazon SNS）通知。<br>C. 使用 Amazon Macie。创建一个 Amazon EventBridge 规则，用于从 Macie 的发现结果中筛选出 SensitiveData:S3Object&#x2F;Personal 事件类型，并向安全团队发送 Amazon Simple Queue Service（Amazon SQS）通知。<br>D. 使用 Amazon GuardDuty。创建一个 Amazon EventBridge 规则，从 GuardDuty 的检测结果中筛选出 CRITICAL 事件类型，并向安全团队发送 Amazon Simple Queue Service（Amazon SQS）通知。</p>
<p>GuardDuty 是威胁检测服务（如异常 API 调用、潜在攻击），不是专门用于扫描 S3 内容中的 PII。</p>
<p><br>534 一家公司希望为其多个 AWS 账户构建日志解决方案，将所有账户的日志集中存储在一个账户的 S3 存储桶中。<br>日志包括 VPC 流量日志和 CloudTrail 日志。<br>要求：</p>
<ul>
<li>所有日志在 <strong>30 天内</strong> 必须具备高可用性以用于频繁分析</li>
<li>额外保留 <strong>60 天</strong> 作为备份（即总保留 90 天）</li>
<li>创建 <strong>90 天后</strong> 删除</li>
</ul>
<p>问：哪种解决方案能最具成本效益地满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在创建后 30 天将对象转换到 S3 标准存储类别。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。<br>B. 在创建后 30 天，将对象转换为 S3 标准不常访问（S3 Standard-IA）存储类别。90 天后，将所有对象移至 S3 Glacier 灵活检索存储类别。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。<br>C. <u>在对象创建 30 天后，将其转换为 S3 Glacier 灵活检索存储类别。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。</u><br>D. 在创建后 30 天，将对象转换为 S3 单区域 - 不常访问（S3 One Zone-IA）存储类别。90 天后，将所有对象移至 S3 Glacier 灵活检索存储类别。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。</p>
<ul>
<li><strong>A</strong>：30 天后转换到 <strong>S3 Standard</strong>（依然是标准存储），成本没有降低，不适合低频访问，不具成本效益。</li>
<li><strong>B</strong>：30 天后转换到 <strong>S3 Standard-IA</strong>（标准不常访问），适合低频访问，成本低于标准存储；但 <strong>90 天后移动到 Glacier</strong> 没有意义，因为 90 天后就删除了，额外移动操作可能增加费用且无必要。</li>
<li><strong>C</strong>：30 天后转换到 <strong>S3 Glacier Flexible Retrieval</strong>（原 S3 Glacier）。Glacier 适合归档，但访问需要检索（几分钟到几小时），不符合“额外保留 60 天作为备份”可能偶尔需要访问的情况？虽然备份可能不需要实时访问，但 Glacier 检索有成本和延迟，不如 Standard-IA 平衡。但题目说“备份”，可能允许归档存储。然而，在 30 天高可用期后立即转到 Glacier 可能成本更低，但需考虑检索成本。</li>
<li><strong>D</strong>：30 天后转换到 <strong>S3 One Zone-IA</strong>（单区域低频访问），成本更低但只有单个可用区，备份数据可能不需要多 AZ 冗余；90 天后移到 Glacier 仍多余。</li>
</ul>
<p><br>535 一家公司正在为其工作负载构建一个 Amazon Elastic Kubernetes Service（Amazon EKS）集群。<br>要求：所有存储在 Amazon EKS 中的密钥（secrets）都必须在 Kubernetes etcd 键值存储中进行加密。<br>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 创建一个新的 AWS KMS 密钥。使用 AWS Secrets Manager 来管理、轮换和存储 Amazon EKS 中的所有密钥。<br>B. <u>创建一个新的 AWS KMS 密钥。在其上启用 Amazon EKS KMS 密钥加密 Amazon EKS 集群</u>。<br>C. 使用默认选项创建 Amazon EKS 集群。使用 Amazon EBS 容器存储接口（CSI）驱动程序作为附加组件。<br>D. 使用别名 &#x2F;aws&#x2F;ebs 创建一个新的 AWS KMS 密钥。为该账户启用默认的 Amazon EBS 卷加密功能。</p>
<ul>
<li><strong>EKS 集群的 etcd 加密</strong>：EKS 支持使用 AWS KMS 密钥对 etcd 数据进行加密（包括 Kubernetes secrets）。</li>
<li>创建 EKS 集群时，可以指定一个 KMS 密钥用于加密 etcd 存储。这需要：<ol>
<li>创建一个 KMS 密钥（或使用现有密钥）</li>
<li>在创建集群时启用加密，并指定该 KMS 密钥</li>
</ol>
</li>
</ul>
<p><br>536 一家公司希望为数据科学家提供对生产环境中 Amazon RDS for PostgreSQL 数据库的近实时只读访问权限。</p>
<ul>
<li>当前数据库配置为单可用区</li>
<li>数据科学家使用的复杂查询不能影响生产数据库</li>
<li>需要一个高可用的解决方案</li>
<li>要求：以最具成本效益的方式满足这些要求</li>
</ul>
<p><strong>选项</strong>：<br>A. 在维护窗口期扩展现有的生产数据库，为数据科学家提供足够的算力。<br>B. 将设置从单可用区更改为具有更大的次要备用实例的多可用区实例部署。为数据科学家提供对次要实例的访问权限。<br>C. 将设置从单可用区部署更改为多可用区实例部署。为数据科学家额外提供两个只读副本。<br>D. <u>将设置从单可用区更改为具有两个可读备用实例的多可用区集群部署。为数据科学家提供读取端点。</u></p>
<ul>
<li>只读副本可以提供只读访问，但多可用区主备部署增加了成本（备用不可读），可能不是最成本效益。</li>
<li>改为<strong>具有两个可读备用实例的多可用区集群部署</strong>——这描述的是 -  - —–<strong>Amazon Aurora PostgreSQL</strong> 的多可用区集群（一个主实例和最多 15 个 Aurora 副本，副本可读）。Aurora 副本与主实例共享存储，复制延迟低（近实时），且副本可读，提供读取端点，高可用，且按实际使用量计费（存储和计算分离），可能更具成本效益</li>
</ul>
<p><br>537 一家公司在 AWS 云中运行跨三个可用区的三层 Web 应用程序。架构包括：</p>
<ul>
<li>应用程序负载均衡器</li>
<li>托管用户会话状态的 Amazon EC2 Web 服务器</li>
<li>在 EC2 实例上运行的 MySQL 数据库</li>
</ul>
<p>预计应用程序流量会突然增加，需要能够扩展以满足未来容量需求，并确保在所有三个可用区都具有高可用性。<br>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>将 MySQL 数据库迁移到采用多可用区数据库集群部署的 Amazon RDS for MySQL。使用具有高可用性的 Amazon ElastiCache for Redis 来存储会话数据和缓存读取内容。将 Web 服务器迁移到自动扩展组位于三个可用区。</u><br>B. 将 MySQL 数据库迁移到采用多可用区数据库集群部署的 Amazon RDS for MySQL。使用具有高可用性的 Amazon ElastiCache for Memcached 来存储会话数据和缓存读取内容。将 Web 服务器迁移到位于三个可用区的自动扩展组中。<br>C. 将 MySQL 数据库迁移到 Amazon DynamoDB。使用 DynamoDB 加速器（DAX）缓存读取内容。将会话数据存储在 DynamoDB 中。将 Web 服务器迁移到位于三个可用区的自动扩展组。<br>D. 将 MySQL 数据库迁移到单一可用区中的 Amazon RDS for MySQL。使用具有高可用性的 Amazon ElastiCache for Redis 来存储会话数据和缓存读取内容。将 Web 服务器迁移到位于三个可用区中的自动扩展组。</p>
<p><strong>解决方案关键点</strong>：</p>
<ul>
<li><strong>数据库高可用</strong>：迁移到多可用区 RDS for MySQL（或 Aurora）</li>
<li><strong>会话状态外部化</strong>：使用 ElastiCache for Redis（支持高可用、持久化）存储会话数据，使 Web 服务器无状态</li>
<li><strong>Web 层扩展</strong>：将 Web 服务器迁移到跨三个可用区的自动扩展组，通过负载均衡器分发流量</li>
</ul>
<p>迁移到 DynamoDB（NoSQL），可能不适合原有关系型数据模型（需要重构），且 DynamoDB 虽然可扩展，但迁移成本高</p>
<p><br>538 一家全球视频流媒体公司使用 Amazon CloudFront 作为 CDN。希望分阶段在多个国家推出内容。<br>要求：确保在推出内容的国家以外的观众无法观看这些内容。</p>
<p><strong>选项</strong>：<br>A. <u>通过使用允许列表为 CloudFront 中的内容添加地理限制。设置自定义错误消息。</u><br>B. 为受限内容设置新的 URL。通过使用签名 URL 和 Cookie 来授权访问。设置自定义错误消息。<br>C. 对公司分发的内容数据进行加密。设置自定义错误消息。<br>D. 为受限内容创建新的 URL。为签名 URL 设置时间限制访问策略。</p>
<p><br>539 一家公司希望使用 AWS 改进其本地灾难恢复（DR）配置。核心生产业务应用程序使用运行在虚拟机上的 Microsoft SQL Server Standard。<br>要求：</p>
<ul>
<li>恢复点目标（RPO）为 30 秒或更短</li>
<li>恢复时间目标（RTO）为 60 分钟</li>
<li>灾难恢复解决方案需要尽可能降低成本</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用带有 Always On 可用性组的 Microsoft SQL Server Enterprise，在本地服务器和 AWS 之间配置多站点活动&#x2F;活动设置。<br>B. <u>在 AWS 上配置 SQL Server 数据库的 Amazon RDS 热备用。配置 AWS 数据库迁移服务（AWS DMS）使用变更数据捕获（CDC）</u>。<br>C. 使用 AWS Elastic Disaster Recovery，将其配置为以试点模式向 AWS 复制磁盘更改。<br>D. 使用第三方备份软件每晚捕获备份。将备用备份集存储在 Amazon S3 中。</p>
<p>在 AWS 上配置 RDS for SQL Server 热备用，使用 AWS DMS 变更数据捕获（CDC）实时复制数据。DMS CDC 可以持续复制更改，RPO 可达秒级；RDS 热备用可以快速提升为主实例，满足 RTO 要求。这是托管服务，相对成本较低。</p>
<p><br>540 一家公司拥有本地 Oracle 数据库服务器，用于处理和存储客户信息。<br>希望使用 AWS 数据库服务实现：</p>
<ol>
<li>提高可用性</li>
<li>改善应用程序性能</li>
<li>减轻主数据库系统的报告负载</li>
</ol>
<p>要求：以最高的运营效率满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 使用 AWS 数据库迁移服务（AWS DMS）在多个 AWS 区域中创建 Amazon RDS 数据库实例。将报告功能指向与主数据库实例分开的另一个数据库实例。<br>B. 在单可用区部署中使用 Amazon RDS 创建一个 Oracle 数据库。在与主数据库实例相同的可用区中创建一个只读副本。将报表功能指向该只读副本。<br>C. 使用部署在多可用区集群部署中的 Amazon RDS 创建 Oracle 数据库。将报告功能定向为使用集群部署中的读取器实例。<br>D. <u>使用部署在多可用区实例部署中的 Amazon RDS 创建 Amazon Aurora 数据库。指导报告功能指向读取器实例。</u></p>
<p>从 <strong>运营效率</strong> 和 <strong>AWS 推荐</strong> 来看，<strong>迁移到 Amazon Aurora</strong>（如果应用允许）可以获得更好的性能、可用性和成本效益，且 Aurora 自动管理复制和故障转移。</p>
<p>RDS for Oracle 的多可用区集群部署可能成本较高</p>
<p><br>541 一家公司希望在 AWS 上构建一个 Web 应用程序。<br>特点：</p>
<ul>
<li>客户端访问请求无法预测，可能会长时间处于空闲状态</li>
<li>只有支付订阅费的客户才能登录并使用 Web 应用程序</li>
</ul>
<p>要求：哪些步骤组合能最具成本效益地满足这些要求？（选三项）</p>
<p><strong>选项</strong>：<br>A. <u>创建一个 AWS Lambda 函数以从 Amazon DynamoDB 检索用户信息。创建一个 Amazon API Gateway 端点以接受 RESTful API。将 API 调用发送到 Lambda 函数。</u><br>B. 在应用程序负载均衡器后创建一个 Amazon Elastic Container Service（Amazon ECS）服务，用于从 Amazon RDS 检索用户信息。创建一个 Amazon API Gateway 端点以接收 RESTful API。将 API 调用发送到 Lambda 函数。<br>C. <u>创建一个 Amazon Cognito 用户池来对用户进行身份验证</u>。<br>D. 创建一个 Amazon Cognito 身份池来验证用户身份。<br>E. 使用 AWS Amplify 通过 HTML、CSS 和 JS 来提供前端网页内容。使用集成的 Amazon CloudFront 分发<br>F. <u>使用带有 PHP、CSS 和 JS 的 Amazon S3 静态网站托管。使用 Amazon CloudFront 来提供前端网页内容</u>。</p>
<p>AWS Amplify 是完整的前端开发平台，可以托管前端并集成 CloudFront，但可能比简单 S3 + CloudFront 成本高（有额外特性）</p>
<p><br>542 一家媒体公司使用 Amazon CloudFront 分发通过互联网交付内容。<br>要求：</p>
<ul>
<li>只有高级客户才能访问媒体流和文件内容</li>
<li>所有内容存储在 Amazon S3 存储桶中</li>
<li>还会为特定目的（如电影租赁或音乐下载）向客户按需交付内容</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为高级客户生成并提供 S3 签名 Cookie<br>B. <u>为高级客户生成并提供 CloudFront 签名 URL</u><br>C. 使用源站访问控制（OAC）来限制非付费客户的访问<br>D. 生成并激活字段级加密以阻止非高级客户</p>
<p>签名 URL 可以设置过期时间，适用于租赁或下载场景；签名 Cookie 适合提供对一组内容（如整个高级目录）的访问</p>
<p><br>543 一家公司在多个独立结算的 AWS 账户中运行着 Amazon EC2 实例。公司最近购买了一份 Savings Plan（节省计划）。由于业务变化，停用了大量 EC2 实例。<br>希望将其 Savings Plan 折扣应用到其他 AWS 账户上。<br>问：哪些步骤组合可以满足这些要求？（选两项）</p>
<p><strong>选项</strong>：<br>A. <u>在管理账户的 AWS 账户管理控制台中，从账单偏好设置部分开启折扣共享功能。</u><br>B. 在购买了现有节省计划的账户的 AWS 账户管理控制台中，从账单偏好设置部分开启折扣共享包含所有账户。<br>C. 在 AWS Organizations 管理账户中，使用 AWS 资源访问管理器（AWS RAM）与其他账户共享节省计划。<br>D. <u>在新的付款人账户中通过 AWS Organizations 创建一个组织。邀请其他 AWS 账户加入该组织。从管理账户加入组织。</u><br>E. 在现有的 AWS 账户中，利用现有的 EC2 实例和节省计划在 AWS Organizations 中创建一个组织。从管理账户邀请其他 AWS 账户加入该组织。</p>
<p>在购买节省计划的账户（可能是成员账户）中开启折扣共享，但折扣共享必须在 <strong>管理账户</strong> 中设置，而不是购买账户（除非购买账户也是管理账户）</p>
<p>使用 AWS RAM 共享节省计划 —— 不正确，AWS RAM 用于共享 VPC、子网等资源，不用于共享节省计划折扣</p>
<p><br>544 一家零售公司为其公共 REST API 使用区域性的 Amazon API Gateway API。API Gateway 端点是一个指向 Amazon Route 53 别名记录的自定义域名。<br>解决方案架构师需要创建一个对客户影响最小且数据丢失最少的解决方案，以发布 API 的新版本。</p>
<p><strong>选项</strong>：<br>A. <u>为 API 网关创建金丝雀发布部署阶段。部署最新的 API 版本。将适当比例的流量导向金丝雀阶段。API 验证后，将金丝雀阶段提升为生产阶段</u>。<br>B. 以 OpenAPI YAML 文件格式创建具有新版本 API 的新 API 网关端点。在 API 网关中使用合并模式下的导入更新操作来处理该 API。将 API 的新版本部署到生产阶段。<br>C. 以 OpenAPI JSON 文件格式创建一个带有新版本 API 的新 API 网关端点。在 API 网关中使用覆盖模式的导入更新操作到该 API。将 API 的新版本部署到生产阶段。<br>D. 使用新版本的 API 定义创建一个新的 API 网关端点。为新的 API 网关 API 创建一个自定义域名。将 Route 53 别名记录指向新的 API 网关 API 自定义域名</p>
<ul>
<li><strong>B 和 C</strong>：使用导入更新操作（合并或覆盖）直接更新现有 API，可能导致全量立即切换，若有问题影响大。</li>
<li><strong>D</strong>：创建全新 API 和自定义域名，通过 Route 53 切换，会导致所有流量立即切换到新版本，不是渐进式发布。</li>
</ul>
<p><br>545 一家公司希望在其主网站不可用时，将用户引导至备用的静态错误页面。<br>主网站的 DNS 记录托管在 Amazon Route 53 中，域名指向一个应用程序负载均衡器（ALB）。<br>要求：解决方案能最大限度减少变更和基础设施开销。</p>
<p><strong>选项</strong>：<br>A. 更新 Route 53 记录以使用延迟路由策略。向记录添加一个托管在 Amazon S3 存储桶中的静态错误页面，以便将流量发送到响应最快的端点。<br>B. <u>设置 Route 53 的主备故障转移配置。当 Route 53 健康检查判定 ALB 端点不健康时，将流量导向托管在 Amazon S3 存储桶中的静态错误页面。</u><br>C. 使用应用负载均衡器（ALB）和托管静态错误页面的 Amazon EC2 实例作为端点，设置 Route 53 的双活配置。配置 Route 53，仅当应用负载均衡器的健康检查失败时，才将请求发送到该实例。<br>D. 更新 Route 53 记录以使用多值答案路由策略。创建健康检查。如果健康检查通过，将流量导向网站。如果健康检查未通过，将流量导向托管在 Amazon S3 中的静态错误页面。</p>
<p><br>546 最近对一家公司 IT 支出的分析强调需要降低备份成本。首席信息官希望简化本地备份基础设施，并通过停止使用物理备份磁带来降低成本。<br>同时，必须保留在本地备份应用程序和工作流程方面的现有投资。<br>问：解决方案架构师应该推荐什么？</p>
<p><strong>选项</strong>：<br>A. 设置 AWS Storage Gateway，通过 NFS 接口与备份应用程序连接。<br>B. 设置一个 Amazon EFS 文件系统，通过 NFS 接口与备份应用程序相连。<br>C. 设置一个 Amazon EFS 文件系统，通过 iSCSI 接口与备份应用程序相连。<br>D. <u>设置 AWS 存储网关，以使用 iSCSI 虚拟磁带库（VTL）接口与备份应用程序连接。</u></p>
<ul>
<li><strong>AWS Storage Gateway 虚拟磁带库（VTL）</strong> 可以将本地备份应用程序通过 iSCSI 接口连接到云中的虚拟磁带，备份数据存储在 Amazon S3 和 Glacier 中，从而替代物理磁带，降低成本，且无需更改备份应用程序。</li>
</ul>
<p><br>547 一家公司在不同地点设有数据收集传感器，向公司传输大量数据。<br>希望在 AWS 上设计一个平台，用于接收和处理海量流数据。<br>要求：</p>
<ul>
<li>具备可扩展性</li>
<li>支持近实时的数据收集</li>
<li>必须将数据存储在 Amazon S3 中，以便未来进行报告</li>
<li>运营开销最小</li>
</ul>
<p><strong>选项</strong>：<br>A. <u>使用 Amazon Kinesis Data Firehose 将流数据传输到 Amazon S3</u>。<br>B. 使用 AWS Glue 将流数据传输到 Amazon S3。<br>C. 使用 AWS Lambda 传输流数据并将数据存储到 Amazon S3。<br>D. 使用 AWS 数据库迁移服务（AWS DMS）将流数据传输到 Amazon S3。</p>
<ul>
<li><strong>A</strong>：Amazon Kinesis Data Firehose 是专门用于实时流数据摄取、转换并加载到 S3 等存储服务的全托管服务，可扩展、近实时，且运营开销最小。</li>
<li><strong>B</strong>：AWS Glue 主要用于 ETL（批处理或微批处理），不是为实时流数据摄取设计的。</li>
<li><strong>C</strong>：Lambda 可以处理流数据（如来自 Kinesis Data Streams），但需要编写代码和管理事件源映射，不如 Firehose 直接简单，运营开销较大。</li>
<li><strong>D</strong>：DMS 主要用于数据库迁移和持续复制，不适用于传感器流数据摄取</li>
</ul>
<p><br>548 一家公司为财务、数据分析和开发部门分别设立了独立的 AWS 账户。<br>出于成本和安全考虑，希望控制每个 AWS 账户可以使用的服务。<br>要求：以最小的运营开销满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 使用 AWS Systems Manager 模板来控制每个部门可以使用哪些 AWS 服务。<br>B. <u>在 AWS Organizations 中为每个部门创建组织单位（OU）。将服务控制策略（SCP）附加到组织单位。</u><br>C. 使用 AWS CloudFormation 自动配置每个部门可以使用 AWS 服务。<br>D. 在 AWS 账户的 AWS 服务目录中设置产品列表，以管理和控制特定 AWS 服务的使用。</p>
<p><br>549 一家公司为其电子商务网站创建了一个多层应用程序：</p>
<ul>
<li>应用程序负载均衡器位于公共子网</li>
<li>Web 层位于公共子网</li>
<li>MySQL 集群托管在私有子网的 EC2 实例上</li>
</ul>
<p>MySQL 数据库需要从互联网上的第三方提供商获取产品目录和定价信息。<br>要求：制定一种策略，在不增加运营开销的情况下最大限度地提高安全性。</p>
<p><strong>选项</strong>：<br>A. 在 VPC 中部署一个 NAT 实例。通过该 NAT 实例路由所有基于互联网的流量。<br>B. 在<u>公有子网中部署一个 NAT 网关。修改私有子网路由表，将所有发往互联网的流量定向到 NAT 网关</u>。<br>C. 配置互联网网关并将其附加到虚拟私有云。修改私有子网路由表，将发往互联网的流量定向到互联网网关。<br>D. 配置虚拟专用网关并将其附加到 VPC。修改私有子网路由表，将出站互联网流量定向到虚拟专用网关。</p>
<ul>
<li><p><strong>NAT 网关</strong>（托管服务）允许私有子网实例通过公有子网的 NAT 网关访问互联网，而互联网无法直接发起连接回私有实例，提高了安全性。</p>
</li>
<li><p><strong>A</strong>：NAT 实例需要自行管理（打补丁、监控、高可用），运营开销大。</p>
</li>
<li><p><strong>C</strong>：互联网网关允许有公网 IP 的实例直接访问互联网，但私有子网实例若无公网 IP 仍无法出站；如果给私有实例分配公网 IP 或 EIP，则暴露到互联网，降低安全性。</p>
</li>
<li><p><strong>D</strong>：虚拟专用网关用于连接到本地网络或 VPN，不用于访问互联网。</p>
</li>
</ul>
<p><br>550 一家公司正在使用 AWS KMS 密钥对 AWS Lambda 环境变量进行加密。<br>解决方案架构师需要确保具备解密和使用这些环境变量所需的权限。<br>问：解决方案架构师必须采取哪些步骤来实施正确的权限？（选两项）</p>
<p><strong>选项</strong>：<br>A. 在 Lambda 资源策略中添加 AWS KMS 权限。<br>B. <u>在 Lambda 执行角色中添加 AWS KMS 权限。</u><br>C. 在 Lambda 函数策略中添加 AWS KMS 权限。<br>D. <u>在 AWS KMS 密钥策略中允许 Lambda 执行角色</u>。<br>E. 在 AWS KMS 密钥策略中允许 Lambda 资源策略。</p>
<ul>
<li><strong>Lambda 环境变量加密</strong>：使用 KMS 密钥加密环境变量，Lambda 在运行时需要解密环境变量。</li>
<li><strong>权限需求</strong>：<ol>
<li><strong>Lambda 执行角色</strong> 需要 <code>kms:Decrypt</code> 权限（针对该 KMS 密钥），以便 Lambda 服务代表执行角色解密环境变量。</li>
<li><strong>KMS 密钥策略</strong> 必须允许 Lambda 执行角色使用该密钥（即授权执行角色可以调用解密操作）。</li>
</ol>
</li>
</ul>
<p><br>551 一家公司有一个生成报告的财务应用程序，报告平均大小为 50 KB，存储在 Amazon S3 中。<br>报告在生成后的第一周内会被频繁访问，且必须存储数年。这些报告必须能在 6 小时内检索到。<br>问：哪种解决方案最具成本效益地满足这些要求？</p>
<p><strong>选项</strong>：<br>A. <u>使用 S3 标准存储。使用 S3 生命周期规则在 7 天后将报告转换为 S3 Glacier</u>。<br>B. 使用 S3 标准存储。使用 S3 生命周期规则，在 7 天后将报告转换为 S3 标准 - 不常访问（S3 Standard-IA）存储。<br>C. 使用 S3 智能分层存储。配置 S3 智能分层存储，将报告转换到 S3 标准不常访问存储（S3 Standard-IA）和 S3 冰川存储。<br>D. 使用 S3 标准存储。使用 S3 生命周期规则在 7 天后将报告转换为 S3 Glacier 深度归档。</p>
<ul>
<li><strong>A</strong>：7 天后转 <strong>S3 Glacier</strong>（现 Glacier Flexible Retrieval），检索时间通常为 1–5 分钟（加急）或 3–5 小时（标准），满足 6 小时内检索要求，且 Glacier 存储成本低，适合长期存储。</li>
<li><strong>B</strong>：7 天后转 <strong>S3 Standard-IA</strong>，存储成本比标准低，但比 Glacier 高；检索时间即时，但长期存储成本较高。</li>
<li><strong>C</strong>：使用 <strong>S3 智能分层</strong> 自动在 Standard、Standard-IA、Glacier 之间移动，但智能分层有监控和自动化费用，且对于明确访问模式（第一周频繁后长期低频）而言，生命周期规则更经济。</li>
<li><strong>D</strong>：7 天后转 <strong>S3 Glacier Deep Archive</strong>，检索时间至少 12 小时，不满足 6 小时内检索要求。</li>
</ul>
<p><br>552 一家公司需要优化其 Amazon EC2 实例的成本，同时每 2–3 个月需要更换一次 EC2 实例的类型和系列。<br>问：公司应该做些什么来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 购买为期 3 年的部分预付预留实例。<br>B. <u>购买为期 1 年的无预付计算节省计划。</u><br>C. 购买 1 年期的全部预付预留实例。<br>D. 购买 1 年期的全额预付 EC2 实例节省计划。</p>
<ul>
<li><strong>预留实例（RI）</strong> 提供折扣，但锁定实例类型、系列、区域等，灵活性差，不适合频繁更换实例类型。</li>
<li><strong>计算节省计划（Compute Savings Plans）</strong> 提供最大的灵活性，可以自动应用于任何 EC2 实例类型、系列、区域（包括 Fargate、Lambda），只要使用量在承诺范围内即可享受折扣，适合需要频繁更换实例类型的场景。</li>
</ul>
<p><br>553 一位解决方案架构师需要检查公司的 Amazon S3 存储桶，以发现个人身份信息（PII）。<br>公司 PII 数据存储在美国东部 1 区和美国西部 2 区。<br>要求：以最低的运营开销满足这些要求。</p>
<p><strong>选项</strong>：<br>A. <u>在每个区域配置 Amazon Macie。创建一个作业来分析 Amazon S3 中的数据</u>。<br>B. 为所有区域配置 AWS Security Hub。创建一条 AWS Config 规则来分析 Amazon S3 中的数据。<br>C. 配置 Amazon Inspector 以分析 Amazon S3 中的数据。<br>D. 配置 Amazon GuardDuty 以分析 Amazon S3 中的数据。</p>
<ul>
<li><strong>A</strong>：配置 Amazon Macie 在每个区域，创建数据发现作业分析 S3 数据，这是最直接且开销最低的方案。</li>
<li><strong>B</strong>：Security Hub 是安全态势管理服务，可以聚合来自多个服务（包括 Macie）的发现，但本身不直接发现 PII；AWS Config 用于合规审计，不能主动扫描 S3 内容中的 PII。</li>
<li><strong>C</strong>：Amazon Inspector 用于评估 EC2 实例和容器镜像的安全漏洞，不用于 S3 数据内容分析。</li>
<li><strong>D</strong>：Amazon GuardDuty 是威胁检测服务（异常 API 调用、潜在攻击），不用于扫描 S3 内容中的 PII。</li>
</ul>
<p><br>554 一家公司的 SAP 应用程序在本地环境中有一个后端 SQL Server 数据库。<br>希望将本地应用程序和数据库服务器迁移到 AWS。<br>要求：</p>
<ul>
<li>需要满足 SAP 数据库高需求的实例类型</li>
<li>本地性能数据显示，SAP 应用程序和数据库的内存利用率都很高</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 为应用程序使用计算优化的实例系列。为数据库使用内存优化的实例系列。<br>B. 对应用程序和数据库均使用存储优化型实例系列。<br>C. <u>为应用程序和数据库均使用内存优化实例系列。</u><br>D. 为应用程序使用高性能计算（HPC）优化的实例系列。为数据库使用内存优化的实例系列。</p>
<ul>
<li><strong>SAP 应用程序和数据库内存利用率高</strong>：说明两者都需要大内存，因此应选择 <strong>内存优化实例系列</strong>（如 R5、R6i、X2gd 等）。</li>
<li>SAP 应用服务器（如 SAP NetWeaver）和 SAP 数据库（如 SQL Server for SAP）通常都推荐使用内存优化实例以获得最佳性能。</li>
</ul>
<p><br>555 一家公司在包含公有子网和私有子网的 VPC 中运行应用程序，VPC 跨多个可用区。<br>应用程序在私有子网的 EC2 实例上运行，并使用 Amazon SQS 队列。<br>解决方案架构师需要设计一个安全的解决方案，以建立 EC2 实例和 SQS 队列之间的连接。</p>
<p><strong>选项</strong>：<br>A. <u>为 Amazon SQS 实现一个接口 VPC 终端节点。将该终端节点配置为使用私有子网。向终端节点添加一个安全组，该安全组具有入站访问规则，允许来自处于私有状态的 EC2 实例的流量。</u><br>B. 为 Amazon SQS 实现一个接口 VPC 终端节点。将该终端节点配置为使用公有子网。为该接口终端节点附加一个 VPC 终端节点策略，允许来自私有子网中的 EC2 实例的访问。<br>C. 为 Amazon SQS 实现一个接口 VPC 终端节点。将该终端节点配置为使用公有子网。为该接口 VPC 终端节点附加一个 Amazon SQS 访问策略，该策略仅允许来自指定 VPC 终端节点的请求。<br>D. 为 Amazon SQS 实现一个网关端点。在私有子网中添加一个 NAT 网关。为 EC2 实例附加一个允许访问 SQS 队列的 IAM 角色。</p>
<ul>
<li><strong>目标</strong>：私有子网中的 EC2 实例安全地连接 SQS 队列，最好不经过互联网。</li>
<li><strong>SQS 支持接口 VPC 端点（Interface VPC Endpoint）</strong> 通过 AWS PrivateLink 实现，允许从 VPC 内私有访问 SQS，无需经过互联网。</li>
<li>接口端点需要部署在子网中（通常选择私有子网），并分配安全组控制入站流量。</li>
</ul>
<p><br>556 一位解决方案架构师正在使用 AWS CloudFormation 模板部署一个三层 Web 应用程序。</p>
<ul>
<li>Web 层和应用层托管在 Amazon EC2 实例上</li>
<li>应用层在 Amazon DynamoDB 表中存储和检索用户数据</li>
<li>数据库层不公开可访问</li>
<li>应用程序 EC2 实例需要访问 DynamoDB 表</li>
<li>不能在模板中暴露 API 凭证</li>
</ul>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 创建一个 IAM 角色来读取 DynamoDB 表。通过引用实例配置文件，将该角色与应用程序实例相关联。<br>B. <u>创建一个具有从 DynamoDB 表读写所需权限的 IAM 角色。将该角色添加到 EC2 实例配置文件，并将该实例配置文件与应用程序实例相关联。</u><br>C. 使用 AWS CloudFormation 模板中的参数部分，让用户输入已创建的 IAM 用户的访问密钥和秘密密钥，该用户需具备从 DynamoDB 表进行读写的必要权限。<br>D. 在 AWS CloudFormation 模板中创建一个 IAM 用户，该用户拥有从 DynamoDB 表进行读写所需的权限。使用 GetAtt 函数检索访问密钥和秘密密钥，并通过用户数据将它们传递给应用程序实例。</p>
<ul>
<li><strong>安全访问 DynamoDB</strong>：EC2 实例应使用 <strong>IAM 角色</strong> 而不是长期凭证（访问密钥）。</li>
<li><strong>IAM 角色通过实例配置文件（Instance Profile）与 EC2 实例关联</strong>，实例会自动获取临时安全凭证，无需在模板中暴露任何密钥。</li>
<li><strong>CloudFormation 实现</strong>：在模板中创建 IAM 角色和实例配置文件，并将实例配置文件关联到 EC2 实例。</li>
</ul>
<p><br>557 一位解决方案架构师负责管理一个分析应用程序，该应用程序在 Amazon S3 存储桶中存储了大量半结构化数据。<br>需求：</p>
<ol>
<li>使用并行数据处理来更快地处理这些数据</li>
<li>利用存储在 Amazon Redshift 数据库中的信息来丰富这些数据</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 使用 Amazon Athena 处理 S3 数据。使用 AWS Glue 和 Amazon Redshift 数据来丰富 S3 数据。<br>B. <u>使用 Amazon EMR 处理 S3 数据。使用 Amazon EMR 和 Amazon Redshift 数据来丰富 S3 数据。</u><br>C. 使用 Amazon EMR 处理 S3 数据。使用 Amazon Kinesis Data Streams 将 S3 数据移至 Amazon Redshift，以便对数据进行扩充。<br>D. 使用 AWS Glue 处理 S3 数据。将 AWS Lake Formation 与 Amazon Redshift 数据结合使用，以丰富 S3 数据。</p>
<ul>
<li><strong>并行数据处理</strong>：需要能够大规模并行处理 S3 中的半结构化数据（如 JSON、Parquet、CSV 等）。</li>
<li><strong>丰富数据</strong>：需要结合 S3 数据和 Redshift 中的数据（可能通过连接或查询）。</li>
</ul>
<p><br>558 一家公司在同一 AWS 账户内的 us-west-2 区域有两个 VPC。需要允许这些 VPC 之间的网络流量。<br>每月大约有 500 GB 的数据将在这些 VPC 之间传输。<br>问：连接这些 VPC 的最具成本效益的解决方案是什么？</p>
<p><strong>选项</strong>：<br>A. 部署 AWS Transit Gateway 以连接各 VPC。更新每个 VPC 的路由表，使 VPC 间通信通过中转网关进行。<br>B. 在 VPC 之间实现 AWS 站点到站点 VPN 隧道。更新每个 VPC 的路由表，以使用 VPN 隧道进行 VPC 间通信。<br>C. <u>在 VPC 之间建立 VPC 对等连接。更新每个 VPC 的路由表以使用 VPC 对等连接用于 VPC 间通信。</u><br>D. 在 VPC 之间建立 1 GB 的 AWS Direct Connect 连接。更新每个 VPC 的路由表，以使用 Direct Connect 连接进行 VPC 间通信。</p>
<ul>
<li><strong>A</strong>：Transit Gateway 可以连接多个 VPC，但每个 VPC 连接每小时收费，且数据传输也收费（跨 VPC 流量每 GB 收费）。对于只有两个 VPC 的场景，Transit Gateway 可能成本较高。</li>
<li><strong>B</strong>：站点到站点 VPN 需要 VPN 网关和 VPN 连接小时费，且跨 VPC 流量通过 VPN 隧道（本质上是经过公网但加密），有 VPN 连接费和可能的跨可用区数据传输费，不经济。</li>
<li><strong>C</strong>：VPC 对等连接（VPC Peering）在同一区域内的两个 VPC 之间建立直接连接，<strong>不收费</strong>（仅标准数据传输费，但同一区域内跨 VPC 数据传输不收费？注意：同一区域、同一账户的 VPC 对等流量不收费）。因此是最具成本效益的方案。</li>
<li><strong>D</strong>：Direct Connect 用于连接本地数据中心到 AWS，不用于 VPC 间连接，且费用高昂。</li>
</ul>
<p><br>559 一家公司在 AWS 上为不同产品线托管了多个应用程序，使用不同的计算资源（EC2 实例、应用程序负载均衡器等）。<br>这些应用程序在 AWS Organizations 中同一组织下的不同 AWS 账户中运行，涉及多个 AWS 区域。<br>每个产品线的团队都在各自的账户中为每个计算资源添加了标签。<br>公司希望从组织中的合并计费功能获取每个产品线的更多成本细节。<br>问：哪些步骤组合可以满足这些要求？（选两项）</p>
<p><strong>选项</strong>：<br>A. 在 AWS 计费控制台中选择特定的 AWS 生成标签。<br>B<u>. 在 AWS 账单控制台中选择特定的用户定义标签。</u><br>C. 在 AWS 资源组控制台中选择特定的用户定义标签。<br>D. 从每个 AWS 账户激活所选标签。<br>E. <u>从组织管理账户激活所选标签。</u></p>
<ol>
<li>在 <strong>组织管理账户的 AWS 账单控制台</strong> 中启用 <strong>成本分配标签（Cost Allocation Tags）</strong>，特别是 <strong>用户定义标签</strong>，以便在成本报告中包含这些标签。</li>
<li>启用后，可以在成本报告中按这些标签进行筛选和分组，获取每个产品线的成本细节。</li>
</ol>
<p><br>560 一家公司的解决方案架构师正在设计一个使用 AWS Organizations 的多账户解决方案，并将账户组织到组织单元（OU）中。<br>要求是：</p>
<ol>
<li>能够识别 OU 层级结构的任何变更</li>
<li>将变更通知给运营团队</li>
<li>以最少的运营开销满足要求</li>
</ol>
<p><strong>A</strong> 使用 AWS Control Tower 配置 AWS 账户，使用账户漂移通知来识别对 OU 层级结构的更改。<br><strong>B</strong> <u>使用 AWS Control Tower 配置 AWS 账户，使用 AWS Config 聚合规则识别 OU 层级结构的变更</u>。<br><strong>C</strong> 使用 AWS 服务目录在组织中创建账户，使用 AWS CloudTrail 组织跟踪来识别对 OU 层次结构的更改。<br><strong>D</strong> 使用 AWS CloudFormation 模板在组织中创建账户，使用堆栈上的漂移检测操作来识别对 OU 层级结构的更改。</p>
<ul>
<li><p>AWS Config 支持 <strong>AWS Organizations 资源类型</strong>（<code>AWS::Organizations::Organization</code>、<code>AWS::Organizations::OrganizationalUnit</code> 等），可以通过 Config 规则监控 OU 变更。</p>
</li>
<li><p>Control Tower 可以集中管理多账户，而 Config 可以聚合多账户的配置变更。</p>
</li>
<li><p>Config 可以自动发送变更通知到 SNS（配合 EventBridge 或直接规则通知），从而通知运营团队。</p>
</li>
<li><p>这是 AWS 推荐的管理方法，能直接满足需求，且运营开销较低（托管服务）</p>
</li>
<li><p>CloudFormation 漂移检测用于检测资源实际配置与模板的差异，<strong>不适用于检测 OU 层级结构变化</strong>，因为 OU 层级不是 CloudFormation 堆栈的一部分（除非用 CF 管理 Organizations 资源，但漂移检测不针对 OU 结构自动报警）。</p>
</li>
</ul>
<p><br>561 一家公司的网站每天处理数百万次请求且持续增长，解决方案架构师需要提高 Web 应用的响应时间，并<strong>减少从 DynamoDB 表中检索产品详情时的延迟</strong>。<br>要求：<strong>以最少的运营开销</strong>满足需求。</p>
<p>选项：</p>
<p><strong>A</strong> <u>设置一个 DynamoDB 加速器（DAX）集群，通过 DAX 路由所有读取请求。</u><br><strong>B</strong> 在 DynamoDB 表和 Web 应用之间设置 Amazon ElastiCache for Redis，将所有读取请求通过 Redis 路由。<br><strong>C</strong> 在 DynamoDB 表和 Web 应用之间设置 Amazon ElastiCache for Memcached，通过 Memcached 路由所有读取请求。<br><strong>D</strong> 在表上设置 Amazon DynamoDB Streams，让 AWS Lambda 从该表读取数据并填充 Amazon ElastiCache，将所有读取请求通过 ElastiCache 路由。</p>
<ul>
<li>DAX 是 <strong>为 DynamoDB 专门设计的完全托管的内存缓存服务</strong>。</li>
<li>它与 DynamoDB API 兼容，只需在应用中更改终结点即可，无需重写数据访问逻辑</li>
</ul>
<p><br>562 一名解决方案架构师需要确保从 VPC 内的 EC2 实例对 DynamoDB 的 API 调用<strong>不经过互联网</strong>。<br>需要选择<strong>两个步骤</strong>的组合来满足此要求。</p>
<p>选项：<br>A. <u>为端点创建路由表条目</u><br>B. <u>为 DynamoDB 创建一个网关端点</u><br>C. 为 Amazon EC2 创建一个接口端点<br>D. 在 VPC 的每个子网中为终端节点创建一个弹性网络接口<br>E. 在端点的安全组中创建一个安全组条目以提供访问权限</p>
<ol>
<li><strong>创建网关端点</strong>（对应选项 B）。</li>
<li>创建网关端点时，需<strong>关联到 VPC 和路由表</strong>，并<strong>自动在指定路由表中添加路由</strong>（对应选项 A）。<ul>
<li>如果没有将路由表指向该端点，流量仍可能走互联网网关，所以路由表条目是必要的。</li>
</ul>
</li>
</ol>
<h3 id="VPC-端点类型"><a href="#VPC-端点类型" class="headerlink" title=". VPC 端点类型"></a>. VPC 端点类型</h3><ul>
<li><strong>网关端点</strong>（Gateway Endpoint）：<br>适用于 S3 和 DynamoDB。<br>工作原理：在 VPC 路由表中添加一条指向该网关端点的路由（目标前缀列表 → 端点）。<br>流量通过 AWS 内部网络直达服务，不经互联网。</li>
<li><strong>接口端点</strong>（Interface Endpoint）：<br>适用于其他大多数 AWS 服务（通过 PrivateLink）。<br>在每个子网中创建弹性网络接口（ENI），需要安全组控制访问。</li>
</ul>
<p><br>563 一家公司同时在 <strong>Amazon EKS 集群</strong> 和 <strong>本地 Kubernetes 集群</strong> 上运行应用程序，希望从<strong>一个中央位置</strong>查看所有集群和工作负载。<br>要求：<strong>以最少的运营开销</strong>满足需求。</p>
<p>选项：<br>A. 使用 Amazon CloudWatch 容器洞察来收集和分组集群信息。<br>B. <u>使用 Amazon EKS Connector 注册并连接所有 Kubernetes 集群</u>。<br>C. 使用 AWS Systems Manager 收集和查看集群信息。<br>D. 将 Amazon EKS Anywhere 用作主集群，以使用原生 Kubernetes 命令查看其他集群。</p>
<ul>
<li><strong>EKS Connector</strong> 是 AWS 提供的功能，允许将<strong>外部 Kubernetes 集群（包括本地集群）注册到 AWS 控制台的 EKS 页面</strong>。</li>
</ul>
<p><br>564 一家公司正在构建电子商务应用程序，需要存储敏感的客户信息，要求：</p>
<ol>
<li>客户可以在网站上完成购买交易。</li>
<li>确保敏感客户数据得到保护，<strong>即使是数据库管理员也无法获取</strong>（即对内部人员也保密）。</li>
</ol>
<p>选项：<br>A. 将敏感数据存储在 Amazon EBS 卷中，使用 EBS 加密，使用 IAM 实例角色限制访问。<br>B. <u>将敏感数据存储在适用于 MySQL 的 Amazon RDS 中，使用 <strong>AWS KMS 客户端加密</strong>来加密数据。</u><br>C. 将敏感数据存储在 Amazon S3 中，使用 AWS KMS 服务端加密，使用 S3 存储桶策略限制访问。<br>D. 将敏感数据存储在适用于 Windows Server 的 Amazon FSx 中，在应用服务器上挂载文件共享，使用 Windows 文件权限限制访问。</p>
<ul>
<li><strong>客户端加密</strong>指的是<strong>数据在发送到数据库之前，在应用层就用 KMS 密钥加密</strong>。</li>
<li>加密后的密文存入数据库，数据库管理员只能看到密文，无法解密（除非拥有 KMS 密钥访问权）。</li>
<li>这样即使 DBA 有数据库访问权限，也无法获取明文敏感数据。</li>
</ul>
<p><br>565 一家公司正在将本地 MySQL 数据库迁移到 AWS 云平台。<br>要求：</p>
<ol>
<li>迁移后的数据库必须<strong>与现有应用程序保持兼容性</strong>（即应用无需或极少修改代码）。</li>
<li>在需求增加期间必须能够<strong>自动扩展</strong>（存储、计算或读写能力能自动增长以应对负载）。</li>
</ol>
<p>选项：<br>A. 使用原生 MySQL 工具将数据库迁移到 Amazon RDS for MySQL，配置弹性存储扩展。<br>B. 使用 mysqldump 将数据库迁移到 Amazon Redshift，为 Redshift 集群开启自动扩展。<br>C. <u>使用 AWS DMS 将数据库迁移到 Amazon Aurora，开启 Aurora 自动扩展</u>。<br>D. 使用 AWS DMS 将数据库迁移到 Amazon DynamoDB，配置自动扩展策略。</p>
<ul>
<li>Aurora MySQL 完全兼容 MySQL 5.6&#x2F;5.7&#x2F;8.0，应用程序可无缝迁移。</li>
<li>Aurora 支持<strong>自动扩展</strong>功能：<ul>
<li><strong>存储自动扩展</strong>（最大 128 TB，无需预分配）</li>
<li><strong>读取副本自动扩展</strong>（Aurora Auto Scaling 可基于负载自动增加或减少 Aurora 副本数量）</li>
</ul>
</li>
</ul>
<p><br>566 一家公司在两个可用区的 VPC 中运行多个 EC2 Linux 实例，应用特点：</p>
<ol>
<li>使用<strong>分层目录结构</strong></li>
<li>需要<strong>共享存储</strong></li>
<li>需要<strong>快速且并发的读写操作</strong></li>
</ol>
<p>问：解决方案架构师应如何满足这些要求？</p>
<p>选项：<br>A. 创建一个 Amazon S3 存储桶，允许来自 VPC 中所有 EC2 实例的访问。<br>B. <u>创建一个 Amazon EFS，从每个 EC2 实例挂载该 EFS 文件系统。</u><br>C. 在预配置 IOPS SSD (io2) EBS 卷上创建文件系统，将该 EBS 卷附加到所有 EC2 实例。<br>D. 在附加到每个 EC2 实例的 EBS 卷上创建文件系统，在不同的 EC2 实例之间同步 EBS 卷。</p>
<p>Amazon EFS 是 AWS 为多实例共享文件系统设计的服务，完全符合：</p>
<ul>
<li>分层目录结构（POSIX 文件系统）</li>
<li>跨可用区共享</li>
<li>快速并发读写</li>
<li>托管服务，无需运维同步逻辑</li>
</ul>
<p><br>567 一个解决方案架构师正在设计工作负载，用于存储建筑物内商业用户<strong>每小时的能源消耗数据</strong>。</p>
<ul>
<li>传感器通过 HTTP 请求向数据库传输数据，请求会累加每个租户的使用量。</li>
<li><strong>必须尽可能使用托管服务</strong>。</li>
<li>未来该工作负载将添加更多独立组件（需要可扩展性和模块化）。</li>
<li>要求：<strong>以最小的运营开销</strong>满足需求。</li>
</ul>
<p>选项：<br>A. <u>使用 Amazon API Gateway 和 AWS Lambda 函数接收并处理数据，存储到 Amazon DynamoDB 表中。</u><br>B. 使用 ELB + EC2 自动扩展组接收和处理数据，处理后的数据存储到 Amazon S3。<br>C. 使用 API Gateway + Lambda 接收处理数据，存储到 EC2 上的 Microsoft SQL Server Express 数据库。<br>D. 使用 ELB + EC2 自动扩展组接收和处理数据，处理后的数据存储到 Amazon EFS。</p>
<p><br>568 解决方案架构师正在为存储和查看<strong>工程图纸</strong>的 Web 应用程序设计存储架构，所有组件部署在 AWS。<br>要求：</p>
<ol>
<li><strong>支持缓存</strong>，以最小化用户等待图纸加载的时间。</li>
<li>能够存储 <strong>PB 级数据</strong>。</li>
</ol>
<p>问：应使用哪种存储和缓存组合？</p>
<p>选项：<br>A. <u>Amazon S3 + Amazon CloudFront</u><br>B. Amazon S3 Glacier + Amazon ElastiCache<br>C. Amazon EBS + Amazon CloudFront<br>D. AWS Storage Gateway + Amazon ElastiCache</p>
<p><br>569 一条 <strong>Amazon EventBridge 规则</strong> 以<strong>第三方 API</strong>为目标，但该第三方 API 没有收到任何传入流量。<br>解决方案架构师需要确定：</p>
<ol>
<li><strong>规则条件是否得到满足</strong>（即规则是否被触发）</li>
<li><strong>规则的目标是否被调用</strong></li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. <u>在 AWS&#x2F;Events 命名空间中查看 Amazon CloudWatch 中的指标。</u><br>B. 查看 Amazon SQS 死信队列中的事件。<br>C. 在 Amazon CloudWatch 日志中检查事件。<br>D. 在 AWS CloudTrail 中检查 EventBridge 事件的轨迹。</p>
<p>EventBridge 直接向 CloudWatch 发送指标，其中：</p>
<ul>
<li><code>MatchedEvents</code> 表示规则匹配的事件数（条件满足）</li>
<li><code>Invocations</code> 表示规则触发的目标调用次数</li>
<li><code>FailedInvocations</code> 表示目标调用失败的次数<br>通过查看 <strong>CloudWatch 指标（AWS&#x2F;Events 命名空间）</strong>，可以快速判断规则是否被触发以及目标是否被调用（及是否失败）。</li>
</ul>
<p><br>570 一家公司有大型工作负载，<strong>每周五晚上运行</strong>，平时运行不超过两个 EC2 实例，但<strong>每周五需要扩展到六个实例</strong>以应对定期重复出现的工作负载增长。<br>要求：<strong>以最少的运营开销</strong>满足需求。</p>
<p>选项：<br>A. 在 Amazon EventBridge 中创建一个提醒以扩展实例。<br>B. <u>创建一个具有计划操作的自动扩展组。</u><br>C. 创建一个使用手动扩展的自动扩展组。<br>D. 创建一个使用自动扩展的自动扩展组。</p>
<ul>
<li><strong>Auto Scaling 组（ASG）支持“计划操作”（Scheduled Actions）</strong>，允许提前设置扩展计划（如每周五特定时间将期望容量改为6，之后改回2）。</li>
</ul>
<p><br>571 一家公司正在创建 REST API，要求：</p>
<ol>
<li>API 端点必须使用 <strong>TLSv1.3</strong>。</li>
<li>TLS 证书必须由<strong>特定的公共第三方证书颁发机构（CA）</strong> 签发（不是由 AWS ACM 默认的 Amazon 受信任的 CA 签发）。</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. <u>在本地机器创建第三方 CA 签名的证书，导入 ACM，在 Amazon API Gateway 创建自定义域名的 HTTP API，配置使用该证书。</u><br>B. 在 AWS Certificate Manager（ACM）中创建由第三方 CA 签名的证书，在 Amazon API Gateway 创建自定义域名的 HTTP API，配置使用该证书。<br>C. 使用 ACM 创建第三方 CA 签名的证书，将该证书导入 ACM（重复表述），创建带有 Lambda 函数 URL 的 Lambda 函数，配置 Lambda 函数 URL 使用该证书。<br>D. 在 ACM 中创建第三方 CA 签名的证书，创建带有 Lambda 函数 URL 的 Lambda 函数，配置 Lambda 函数 URL 使用该证书。</p>
<h3 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h3><ul>
<li><strong>TLSv1.3 支持</strong>：需要服务端支持 TLSv1.3，API Gateway 和 Lambda 函数 URL 均支持 TLSv1.3。</li>
<li><strong>特定第三方 CA 签名证书</strong>：不能使用 ACM 默认提供的由 Amazon Trust Services 签发的证书，必须是由指定的第三方公共 CA（如 DigiCert、GlobalSign、Let’s Encrypt 等）签发的证书。</li>
</ul>
<h3 id="2-AWS-证书管理相关事实"><a href="#2-AWS-证书管理相关事实" class="headerlink" title="2. AWS 证书管理相关事实"></a>2. AWS 证书管理相关事实</h3><ul>
<li><strong>ACM 默认只颁发由 Amazon Trust Services（Amazon 的 CA）签名的证书</strong>，不支持直接从第三方 CA 购买或签发证书。</li>
<li>若需要使用第三方 CA 签名的证书，必须<strong>自行从第三方 CA 获取证书，然后导入到 ACM</strong>（Import Certificate），或者直接将证书部署到服务上（如果服务支持上传自定义证书）。</li>
<li>API Gateway 自定义域名支持使用 ACM 中的证书（无论 ACM 签发还是导入的）。</li>
<li>Lambda 函数 URL 也支持使用 ACM 证书，但同样只能使用 ACM 中的证书（签发或导入）。</li>
</ul>
<p><br>572 一家公司在 AWS 上运行应用程序，特点：</p>
<ul>
<li>使用量不稳定</li>
<li>当前通过 AWS Direct Connect 连接到<strong>本地兼容 MySQL 的数据源</strong></li>
<li>本地数据库<strong>至少使用 2 GiB 内存</strong></li>
</ul>
<p>公司希望：</p>
<ol>
<li>将本地数据库迁移到 <strong>AWS 托管服务</strong></li>
<li>利用<strong>自动扩展</strong>功能应对意外的工作负载增长</li>
<li><strong>管理开销最小</strong></li>
</ol>
<p>选项：<br>A. 配置一个 Amazon DynamoDB 数据库，使用默认的读写容量设置<br>B. 配置一个 Amazon Aurora 数据库，最小容量为 1 个 Aurora 容量单位（ACU）<br>C. 配置一个 Amazon Aurora Serverless v2 数据库，最小容量为 1 个 Aurora 容量单位（ACU）<br>D. <u>配置一个内存为 2 GiB 的 Amazon RDS for MySQL 数据库</u></p>
<p><strong>Aurora Serverless v2</strong> 是 AWS 提供的支持自动扩缩容的托管关系数据库服务，完美匹配：</p>
<ul>
<li>MySQL 兼容性</li>
<li>自动扩展应对不稳定负载</li>
<li>完全托管，管理开销最小</li>
</ul>
<p><br>573 一家公司希望在 AWS Lambda 中使用事件驱动的编程模型，函数运行在 <strong>Java 11</strong> 上。<br>目标：<strong>减少 Lambda 函数的启动延迟</strong>（特别是扩容时的冷启动和异常延迟）。<br>约束：</p>
<ul>
<li>应用没有严格的延迟要求</li>
<li>希望以 <strong>最具成本效益的方式</strong> 满足要求</li>
</ul>
<p>选项：<br>A. 配置 Lambda 预置并发（Provisioned Concurrency）<br>B. 增加 Lambda 函数的超时时间<br>C. 增加 Lambda 函数的内存<br>D. <u>配置 Lambda SnapStart</u></p>
<ul>
<li><strong>问题</strong>：Java 11 Lambda 函数启动延迟较长（JVM 冷启动问题），尤其在函数扩容（新实例初始化）时。</li>
</ul>
<p><strong>SnapStart</strong> 是 AWS 提供的专为减少冷启动延迟而设计的原生功能，且不需要像预置并发那样持续付费，因此<strong>最具成本效益</strong>。</p>
<p><strong>预置并发会持续收费</strong>（按配置的并发数和时长），即使没有请求也会产生费用。</p>
<p>增加内存会提高 CPU 和网络性能，<strong>可能略微减少初始化时间</strong>，但效果有限，且<strong>会增加每次执行的成本</strong></p>
<p><br>574 一家金融服务公司推出新应用，使用 <strong>Amazon RDS for MySQL</strong> 数据库追踪股市趋势。<br>特点：</p>
<ul>
<li><strong>只需在每周结束时运行该应用 2 小时</strong>（即数据库每周仅需运行约 2 小时）</li>
<li>需要<strong>优化数据库的运行成本</strong></li>
<li>问：哪种解决方案能<strong>最具成本效益</strong>地满足要求？</li>
</ul>
<p>选项：<br>A. <u>将现有的 RDS for MySQL 迁移到 Aurora Serverless v2 MySQL 数据库集群</u><br>B. 将现有的 RDS for MySQL 迁移到 Aurora MySQL 数据库集群<br>C. 迁移到运行 MySQL 的 Amazon EC2 实例，为该 EC2 实例购买实例预留<br>D. 迁移到使用 MySQL 容器镜像的 Amazon ECS 集群运行任务</p>
<p><strong>Aurora Serverless v2</strong> 是 AWS 提供的无服务器数据库服务，专为<strong>间歇性、不可预测的工作负载</strong>设计，支持自动暂停和按实际使用计费，非常适合每周仅运行 2 小时的场景，能够<strong>最大程度节省成本</strong>，同时保持完全托管和 MySQL 兼容性</p>
<p><br>575 一家公司的应用部署在 <strong>EKS</strong> 上，前面有 <strong>ALB</strong>，应用使用 <strong>PostgreSQL 数据库引擎</strong>。<br>要求：</p>
<ol>
<li>数据库数据<strong>高可用性</strong></li>
<li>提高<strong>读取工作负载</strong>的处理能力</li>
<li>以<strong>最高的运营效率</strong>满足要求</li>
</ol>
<p>选项：<br>A. 创建配置了全局表的 Amazon DynamoDB 数据库表<br>B. 创建具有多可用区部署的 Amazon RDS 数据库<br>C. <u>创建采用多可用区数据库集群部署的 Amazon RDS 数据库</u><br>D. 创建配置了跨区域只读副本的 Amazon RDS 数据库</p>
<p><strong>RDS Multi-AZ DB Cluster</strong>（选项 C）专为 PostgreSQL&#x2F;MySQL 设计，在单个区域内提供<strong>同步多副本高可用，且所有副本均可处理读取请求</strong>，同时保持完全托管和自动化运维，符合：</p>
<ul>
<li>高可用性</li>
<li>读取扩展</li>
<li>最高运营效率</li>
</ul>
<p><br>576 一家公司使用 <strong>API Gateway + AWS Lambda</strong> 构建无服务器 Web 应用程序（RESTful API）。<br>用户<strong>分布在不同地理位置</strong>，公司希望<strong>减少用户的 API 请求延迟</strong>。</p>
<p>问：解决方案架构师应使用哪种类型的 API Gateway 端点来满足这些要求？</p>
<p>选项：<br>A. 私有端点（Private endpoint）<br>B. 区域端点（Regional endpoint）<br>C. 接口 VPC 终端节点（Interface VPC endpoint）<br>D. <u>边缘优化端点（Edge-optimized endpoint）</u></p>
<p>API Gateway 的<strong>边缘优化端点</strong>使用 <strong>Amazon CloudFront 全球边缘网络</strong></p>
<p>VPC 端点（VPC Endpoint），用于让 VPC 内资源安全访问 AWS 服务（如 API Gateway），与 API Gateway 端点类型无关，不用于公开 API</p>
<p><strong>区域端点</strong> - API 部署在<strong>特定 AWS 区域</strong>，用户直接访问该区域的 API Gateway</p>
<p><strong>私有端点</strong>- 仅可通过 VPC 内部访问，不公开到互联网，适用于内部服务调用</p>
<p><br>577 一家公司使用 <strong>Amazon CloudFront</strong> 分发内容为其网站提供服务。<br>要求：</p>
<ol>
<li>客户访问网站时<strong>使用 TLS 证书</strong>（即 HTTPS 访问）。</li>
<li>希望<strong>自动化 TLS 证书的创建和续订</strong>。</li>
<li>以<strong>最高的运营效率</strong>满足要求。</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 使用 CloudFront 安全策略创建证书<br>B. 使用 CloudFront 源站访问控制（OAC）创建证书<br><u>C. 使用 AWS Certificate Manager（ACM）创建证书，对域名使用 <strong>DNS 验证</strong></u><br>D. 使用 AWS Certificate Manager（ACM）创建证书，对域名使用 <strong>电子邮件验证</strong></p>
<p><strong>AWS ACM + DNS 验证</strong> 是实现 TLS 证书<strong>全生命周期自动化管理</strong>的最佳实践：</p>
<ul>
<li>ACM 自动处理证书申请、验证、续订</li>
<li>DNS 验证（尤其配合 Route 53）完全自动化</li>
<li>CloudFront 无缝集成 ACM 证书</li>
</ul>
<p><br>578 一家公司部署了一个使用 <strong>Amazon DynamoDB</strong> 作为数据库层的<strong>无服务器应用程序</strong>。</p>
<ul>
<li>用户数量大幅增加</li>
<li>目标：<ol>
<li>将<strong>数据库响应时间从毫秒级提升至微秒级</strong></li>
<li>对<strong>数据库请求进行缓存</strong></li>
</ol>
</li>
<li>要求：<strong>以最少的运营开销</strong>满足要求</li>
</ul>
<p>选项：<br>A. <u>使用 DynamoDB 加速器（DAX）</u><br>B. 将数据库迁移到 Amazon Redshift<br>C. 将数据库迁移到 Amazon RDS<br>D. 使用 Amazon ElastiCache for Redis</p>
<p><br>579 一家公司运行一个使用 <strong>Amazon RDS for PostgreSQL</strong> 的应用程序。<br>特点：</p>
<ul>
<li><strong>仅在工作日的工作时间接收流量</strong>（非工作时间无流量）。<br>公司希望：</li>
</ul>
<ol>
<li><strong>优化成本</strong></li>
<li><strong>减少运营开销</strong></li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. <u>使用 <strong>AWS 上的实例调度器配置启动和停止计划</strong></u><br>B. 关闭自动备份，每周创建数据库的手动快照<br>C. 创建自定义 AWS Lambda 函数，根据最低 CPU 利用率来启动和停止数据库<br>D. 购买全部预付的预留数据库实例</p>
<p>对于<strong>固定时间运行</strong>的 RDS 实例，使用 <strong>AWS Instance Scheduler</strong> 配置启动&#x2F;停止计划是最佳实践</p>
<p><br>580 一家公司使用<strong>本地直连存储</strong>运行一个<strong>延迟敏感的应用程序</strong>，现正使用 <strong>“直接迁移”（lift and shift）</strong> 方法将应用程序移至 AWS 云。<br>要求：</p>
<ul>
<li><strong>不希望更改应用程序架构</strong></li>
<li>需要<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项：<br>A. 使用 Amazon EC2 实例配置一个自动扩展组，使用 <strong>Amazon FSx for Lustre</strong> 文件系统运行应用程序<br>B. 在 Amazon EC2 实例上托管应用程序，使用 <strong>Amazon EBS GP2 卷</strong> 运行应用程序<br>C. 使用 Amazon EC2 实例配置一个自动扩展组，使用 <strong>Amazon FSx for OpenZFS</strong> 文件系统运行应用程序<br>D. <u>在 Amazon EC2 实例上托管应用程序，使用 <strong>Amazon EBS GP3 卷</strong> 运行应用程</u>序</p>
<p>对于延迟敏感、原使用本地直连存储的直接迁移场景，<strong>EBS GP3 卷</strong> 提供了最佳的成本效益平衡：</p>
<ul>
<li>保持块存储架构不变</li>
<li>性能可调以满足延迟要求</li>
<li>相比 GP2 和文件系统服务（如 FSx）更经济</li>
</ul>
<p><br>581 一家公司在 <strong>Amazon EC2 实例</strong>上运行<strong>有状态的生产应用程序</strong>，要求：</p>
<ul>
<li><strong>至少有两个 EC2 实例始终处于运行状态</strong></li>
<li>需要设计一个<strong>高可用且容错</strong>的架构</li>
</ul>
<p>解决方案架构师已创建了一个 <strong>EC2 实例的自动扩展组（Auto Scaling Group，ASG）</strong>，需要选择<strong>额外步骤</strong>来满足要求。</p>
<p>选项：<br>A. 将 ASG 最小容量设为 2，在一个可用区部署一个按需实例，在第二个可用区部署一个按需实例<br>B. <u>将 ASG 最小容量设为 4，在一个可用区部署两个按需实例，在第二个可用区部署两个按需实例</u><br>C. 将 ASG 最小容量设为 2，在一个可用区部署 4 个 Spot 实例<br>D. 将 ASG 最小容量设为 4，在一个可用区部署两个按需实例，在第二个可用区部署两个 Spot 实例</p>
<h3 id="1-需求分析-1"><a href="#1-需求分析-1" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h3><ul>
<li>应用类型：<strong>有状态生产应用</strong>（意味着实例可能承载状态，需考虑故障转移和状态管理）。</li>
<li>高可用和容错：需要<strong>跨多个可用区（AZ）</strong> 部署，以抵御单可用区故障。</li>
<li>最低实例数：<strong>至少两个实例始终运行</strong> → 但高可用要求应确保即使一个可用区故障，仍有足够实例运行（至少两个）。</li>
</ul>
<h3 id="2-关键点"><a href="#2-关键点" class="headerlink" title="2. 关键点"></a>2. 关键点</h3><ul>
<li>如果只部署两个实例（每个 AZ 一个），当一个 AZ 故障时，只剩一个实例，可能违反“至少两个实例运行”的要求（取决于应用是否能单实例运行）。</li>
<li>更稳健的做法是：<strong>每个可用区至少部署两个实例</strong>，这样单 AZ 故障后，另一 AZ 仍有两个实例，满足最低要求。</li>
</ul>
<p>582一家电子商务公司使用 <strong>Amazon Route 53</strong> 作为 DNS 提供商，其网站部署在：</p>
<ol>
<li><strong>本地数据中心</strong>（靠近美国西部俄勒冈区域 us-west-1）</li>
<li><strong>AWS 欧洲中部法兰克福区域（eu-central-1）</strong></li>
</ol>
<p>要求：</p>
<ul>
<li><strong>尽可能缩短网站的加载时间</strong></li>
</ul>
<p>问：哪种 Route 53 路由策略能满足此要求？</p>
<p>选项：<br>A. <u>设置<strong>地理位置路由策略</strong>：将靠近 us-west-1 的流量发送到本地数据中心，靠近 eu-central-1 的流量发送到 eu-central-1</u><br>B. 设置一个<strong>简单的路由策略</strong>（应为简单路由策略，即默认轮询或故障转移），将所有靠近 eu-central-1 的流量路由到 eu-central-1，将所有靠近本地数据中心的流量路由到本地数据中心<br>C. 设置<strong>延迟路由策略</strong>，将该策略与 us-west-1 关联<br>D. 设置<strong>加权路由策略</strong>，在 eu-central-1 和本地数据中心之间平均分配流量</p>
<p><br>583 一家公司有 <strong>5 PB 的归档数据</strong> 在物理磁带上，合规要求需<strong>再保存 10 年</strong>。</p>
<ul>
<li>希望在 <strong>6 个月内</strong> 迁移到 AWS</li>
<li>本地数据中心有 <strong>1 Gbps 上行互联网连接</strong></li>
<li>目标：<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项：<br>A. 在本地从磁带读取数据，暂存到本地 NFS 存储，使用 AWS DataSync 迁移到 <strong>Amazon S3 Glacier Flexible Retrieval</strong><br>B. 使用本地备份应用程序从磁带读取数据，直接写入 <strong>Amazon S3 Glacier Deep Archive</strong><br>C. <u>订购多台带有磁带网关的 <strong>AWS Snowball</strong> 设备，将物理磁带复制到 Snowball 中的虚拟磁带，运送 Snowball 到 AWS，创建生命周期策略将磁带迁移到 <strong>Amazon S3 Glacier Deep Archive</strong></u><br>D. 配置本地磁带网关，在 AWS 云中创建虚拟磁带，使用备份软件将物理磁带复制到虚拟磁带</p>
<p><br>584 一家公司正在部署一个<strong>可并行处理大量数据的应用程序</strong>，计划使用 <strong>Amazon EC2 实例</strong>处理工作负载。<br>网络架构要求：</p>
<ul>
<li><strong>必须可配置，以防止节点组共享相同的底层硬件</strong><br>（即需要<strong>物理隔离</strong>，避免不同节点组（如不同实例）在同一台物理服务器上，以减少资源争用和故障影响范围）</li>
</ul>
<p>问：哪种网络解决方案能满足这些要求？</p>
<p>选项：<br><u>A. 在<strong>分散放置组件</strong>运行 EC2 实例</u><br>B. 将 EC2 实例分组到不同的账户中<br>C. 为 EC2 实例配置<strong>专属租户</strong><br>D. 为 EC2 实例配置<strong>共享租户</strong></p>
<p><br>585 解决方案架构师正在设计灾难恢复（DR）策略，需要在<strong>故障转移的 AWS 区域</strong>中提供 <strong>Amazon EC2 容量</strong>。<br>业务需求：</p>
<ul>
<li>DR 策略<strong>必须满足故障转移区域的容量要求</strong>（即确保在故障转移时有足够的 EC2 容量可用）</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 在故障转移区域购买<strong>按需实例</strong><br>B. 在故障转移区域购买 <strong>EC2 节省计划</strong><br>C. 在故障转移区域购买<strong>区域性预留实例</strong><br>D. <u>在故障转移区域购买<strong>容量预留</strong></u></p>
<p>对于灾难恢复场景，要<strong>确保故障转移区域有足够的 EC2 容量</strong>，必须使用 <strong>Capacity Reservation（容量预留）</strong>，它提供确定性的容量保证，而其他选项（按需实例、节省计划、区域性预留实例）均不能提供同等保证</p>
<p><br>586 一家公司在 AWS Organizations 中有五个组织单元（OU），分别对应五个业务部门。<br>现在，<strong>研发（R&amp;D）业务部门</strong> 将从公司分离出去，需要<strong>拥有自己的组织</strong>。<br>解决方案架构师已为研发部门创建了一个<strong>单独的新的管理账户</strong>。<br>问：在新的管理账户中，接下来应该做什么？</p>
<p>选项：<br>A. 让研发 AWS 账户在过渡期间同时属于两个组织<br>B. <u>在研发 AWS 账户离开先前的组织后，邀请该账户加入新组织</u><br>C. 在新组织中创建一个新的研发 AWS 账户，将资源从之前的研发 AWS 账户迁移到新的研发 AWS 账户<br>D. 让研发 AWS 账户加入新组织，让新的管理账户成为先前组织的成员</p>
<p><br>587 一家公司需要设计解决方案以<strong>捕获不同 Web 应用程序中的客户活动</strong>，用于分析和预测。<br>特点：</p>
<ul>
<li>客户活动<strong>不可预测</strong>，可能<strong>突然增加</strong>（需要高可扩展性）</li>
<li>需要能与其他 Web 应用程序<strong>集成</strong>（即通过标准接口如 API）</li>
<li>出于安全考虑，必须<strong>包含授权步骤</strong></li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 配置<strong>网关负载均衡器（GWLB）</strong> 前置 Amazon ECS 容器实例，信息存储在 <strong>Amazon EFS</strong> 中，授权在 GWLB 处解决<br>B. 配置 <strong>Amazon API Gateway</strong> 端点前置 <strong>Amazon Kinesis 数据流</strong>，数据存储在 <strong>Amazon S3</strong> 中，使用 <strong>AWS Lambda</strong> 函数解决授权<br>C. <u>配置 <strong>Amazon API Gateway</strong> 端点前置 <strong>Amazon Kinesis Data Firehose</strong>，数据存储在 <strong>Amazon S3</strong> 中，使用 <strong>API Gateway Lambda 授权器</strong> 解决授权</u><br>D. 配置 <strong>GWLB</strong> 前置 <strong>Amazon ECS</strong> 容器实例，数据存储在 <strong>Amazon EFS</strong> 中，使用 <strong>AWS Lambda</strong> 函数解决授权</p>
<ul>
<li><strong>捕获客户活动</strong>：实时或近实时数据流，用于分析和预测 → 适合使用<strong>流式数据服务</strong>（如 Kinesis）。</li>
<li><strong>不可预测的突发流量</strong>：需要<strong>自动扩展</strong>以应对峰值 → 无服务器架构（如 API Gateway、Kinesis、Lambda）更合适。</li>
<li><strong>与其他 Web 应用集成</strong>：标准方式是通过 <strong>REST API</strong>（如 API Gateway 端点）。</li>
<li><strong>包含授权步骤</strong>：需要在接收请求时进行身份验证和授权。</li>
</ul>
<p><br>588 一家电子商务公司运行 <strong>Microsoft SQL Server 企业版的 Amazon RDS 数据库实例</strong>，需要提供灾难恢复（DR）解决方案。<br>当前要求：</p>
<ul>
<li><strong>RPO（恢复点目标）&#x3D; 24 小时</strong></li>
<li><strong>RTO（恢复时间目标）&#x3D; 24 小时</strong></li>
<li>需要以<strong>最具成本效益</strong>的方式满足要求</li>
</ul>
<p>选项：<br>A. 创建跨区域只读副本，并将该只读副本提升为主要实例<br>B. 使用 AWS DMS 创建 RDS 跨区域复制<br>C. 每 24 小时使用跨区域复制将原生备份复制到 Amazon S3 存储桶<br>D. <u>每 24 小时将自动快照复制到另一个区域</u></p>
<p>对于 RPO&#x2F;RTO 均为 24 小时的灾难恢复场景，使用 <strong>RDS 自动快照跨区域复制</strong> 是最简单、成本最低的方案</p>
<p><br>589 一家公司在<strong>启用粘性会话的 ALB 后</strong>的自动扩展组（ASG）中的 EC2 实例上运行 Web 应用程序。<br>当前：<strong>Web 服务器本地托管用户会话状态</strong>。<br>问题：希望在<strong>确保高可用性</strong>的同时，<strong>避免在 Web 服务器故障时丢失用户会话状态</strong>。</p>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. 使用 <strong>Amazon ElastiCache for Memcached</strong> 存储会话数据，更新应用使用它存储会话状态<br>B. <u>使用 <strong>Amazon ElastiCache for Redis</strong> 存储会话状态，更新应用使用它存储会话状态</u><br>C. 使用 <strong>AWS Storage Gateway 缓存卷</strong> 存储会话数据，更新应用使用它存储会话状态<br>D. 使用 <strong>Amazon RDS</strong> 存储会话状态，更新应用使用 RDS 存储会话状态</p>
<p><br>590 一家公司将 MySQL 数据库从本地迁移到 <strong>Amazon RDS for MySQL</strong>，实例规模已满足<strong>平均每日工作负载</strong>。<br>问题：<strong>每月一次运行报表查询时，数据库运行缓慢</strong>。<br>目标：</p>
<ul>
<li>能够运行报表</li>
<li>同时<strong>保持日常工作负载的性能</strong>（即报表查询不影响日常 OLTP 操作）</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. <u>创建数据库的<strong>只读副本</strong>，将查询定向到只读副本</u><br>B. 创建数据库备份，将备份恢复到另一个数据库实例，将查询指向新数据库<br>C. 将数据导出到 <strong>Amazon S3</strong>，使用 <strong>Amazon Athena</strong> 查询 S3 存储桶<br>D. 调整数据库实例大小以适应额外的工作负载</p>
<p><br>591 一家公司使用 <strong>Amazon EKS</strong> 运行容器应用程序，包含多个微服务（如管理客户、处理订单）。<br>需求：</p>
<ul>
<li>需要将<strong>传入的请求路由到相应的微服务</strong></li>
<li>以<strong>最具成本效益的方式</strong>满足要求</li>
</ul>
<p>选项：<br>A. 使用 AWS 负载均衡器控制器配置<strong>网络负载均衡器（NLB）</strong><br>B. <u>使用 AWS 负载均衡器控制器配置<strong>应用程序负载均衡器（ALB）</strong></u><br>C. 使用 <strong>AWS Lambda</strong> 函数将请求连接到 Amazon EKS<br>D. 使用 <strong>Amazon API Gateway</strong> 将请求连接到 Amazon EKS</p>
<ul>
<li><strong>网络负载均衡器</strong> 工作在 OSI 第 4 层（TCP&#x2F;UDP），支持高性能、低延迟流量分发。</li>
<li>但 NLB <strong>不支持基于内容的路由</strong>（如路径、主机头），只能基于端口和协议转发流量</li>
</ul>
<p><br>592 一家公司销售<strong>受版权保护的图像的访问权限</strong>，要求：</p>
<ol>
<li>全球客户群需要<strong>快速访问</strong>图像（低延迟）</li>
<li><strong>必须拒绝来自特定国家的用户</strong>的访问（地理限制）</li>
<li>希望<strong>尽可能降低成本</strong></li>
</ol>
<p>选项：<br>A. 使用 <strong>Amazon S3</strong> 存储图像，开启 MFA 和公共存储桶访问，向客户提供 S3 存储桶链接<br>B. 使用 <strong>Amazon S3</strong> 存储图像，为每个客户创建 IAM 用户，将用户加入有权访问 S3 存储桶的组<br>C. 使用 <strong>ALB 后的 EC2 实例</strong>存储图像，仅在提供服务的国家部署实例，为客户提供其所在国家实例的 ALB 链接<br>D. <u>使用 <strong>Amazon S3</strong> 存储图像，使用 <strong>Amazon CloudFront</strong> 分发并配置<strong>地理限制</strong>，为每位客户提供<strong>签名 URL</strong> 访问 CloudFront 数据</u></p>
<p><strong>Amazon S3 + CloudFront + 地理限制 + 签名 URL</strong> 是 AWS 推荐用于全球安全分发私有内容的架构，同时满足性能、安全和成本要求。</p>
<p><br>593 解决方案架构师正在设计基于 <strong>Amazon ElastiCache for Redis</strong> 的高可用性解决方案，要求：</p>
<ol>
<li>确保故障不会导致<strong>本地和 AWS 区域内</strong>的性能下降或数据丢失</li>
<li>需要在<strong>节点级别</strong>和<strong>区域级别</strong>提供高可用性</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>选项：<br>A. <u>使用包含<strong>多个节点的分片</strong>的<strong>多可用区 Redis 复制组</strong></u><br>B. 使用包含多个节点的 Redis 分片，并开启 <strong>Redis 追加文件（AOF）</strong><br>C. 使用<strong>多可用区 Redis 集群</strong>，且复制组中包含多个只读副本<br>D. 使用包含多个节点且开启自动扩展的 Redis 分片</p>
<h3 id="ElastiCache-for-Redis-高可用架构"><a href="#ElastiCache-for-Redis-高可用架构" class="headerlink" title="ElastiCache for Redis 高可用架构"></a>ElastiCache for Redis 高可用架构</h3><ul>
<li><strong>Redis（非集群模式）</strong>：通过<strong>多可用区复制组</strong>实现高可用，包含一个主节点（在一个 AZ）和最多 5 个只读副本（可在不同 AZ）。<ul>
<li>主节点故障时，自动将副本提升为主节点。</li>
<li>但<strong>分片（Sharding）</strong> 用于扩展数据量和吞吐量，通常与<strong>Redis Cluster</strong>模式相关。</li>
</ul>
</li>
<li><strong>Redis Cluster（集群模式）</strong>：<ul>
<li>数据分片到多个分片（Shard），每个分片是一个复制组（主节点 + 副本）。</li>
<li>支持<strong>多可用区部署</strong>，每个分片的主节点和副本可分布在不同 AZ。</li>
<li>提供节点级别和 AZ 级别高可用，且支持自动故障转移。</li>
</ul>
</li>
</ul>
<p>在实际 AWS 文档中，ElastiCache for Redis 集群模式的高可用方案就是<strong>多可用区集群部署</strong>，每个分片跨 AZ</p>
<p><br>594 一家公司计划迁移到 AWS，使用 <strong>Amazon EC2 按需实例</strong> 运行应用程序。<br>在迁移测试阶段发现：<strong>应用程序启动和加载内存以达到完全可用状态需要很长时间</strong>。<br>问题：在接下来的测试阶段，哪种解决方案可以减少应用程序的启动时间？</p>
<p>选项：<br>A. 启动两个或更多 EC2 按需实例，开启自动扩展功能，使 EC2 按需实例在下一个测试阶段可用<br>B. 启动 EC2 Spot 实例以支持应用程序并扩展应用程序，使其在下一个测试阶段可用<br>C. <u>启动开启休眠功能的 EC2 按需实例，在此期间配置 EC2 自动扩展预热池，在下一个测试阶段使用</u><br>D. 使用容量预留启动 EC2 按需实例，在下一个测试阶段启动额外的 EC2 实例</p>
<ul>
<li><strong>EC2 休眠</strong>：将实例内存状态保存到 EBS 卷，重启时从磁盘加载内存状态，恢复应用程序到之前状态，跳过应用初始化过程。</li>
<li><strong>Auto Scaling 预热池</strong>：维护一组预初始化实例（可处于停止或休眠状态），在需要时快速投入服务。</li>
</ul>
<p><br>595 一家公司的应用程序在<strong>自动扩展组（ASG）中的 EC2 实例</strong>上运行。</p>
<ul>
<li>观察到应用程序<strong>在一周中的随机几天会遭遇突发的流量增长</strong>（即不可预测的突发流量）</li>
<li>目标：在流量突然增加时<strong>保持应用程序性能</strong></li>
<li>要求：<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项：<br>A. 使用<strong>手动扩展</strong>来更改自动扩展组的大小<br>B. <u>使用<strong>预测扩展</strong>来更改自动扩展组的大小</u><br>C. 使用<strong>动态扩展</strong>来更改自动扩展组的大小<br>D. 使用<strong>计划扩展</strong>来更改自动扩展组的大小</p>
<p><br>596 一个电子商务应用程序使用运行在 <strong>Amazon EC2 实例上的 PostgreSQL 数据库</strong>。<br>问题：</p>
<ul>
<li>在<strong>每月的促销活动期间</strong>，数据库使用率上升，导致<strong>数据库连接问题</strong></li>
<li>后续每月促销活动的<strong>流量不可预测</strong>，影响销售预测</li>
<li>目标：在流量不可预测增长时<strong>保持性能稳定</strong></li>
<li>要求：<strong>最具成本效益</strong>的解决方案</li>
</ul>
<p>选项：<br>A. <u>将 PostgreSQL 数据库迁移到 <strong>Amazon Aurora Serverless v2</strong></u><br>B. 为 EC2 实例上的 PostgreSQL 数据库<strong>启用自动扩展</strong>以适应增加的使用量<br>C. 将 PostgreSQL 数据库迁移到<strong>具有更大实例类型的 Amazon RDS for PostgreSQL</strong><br>D. 将 PostgreSQL 数据库迁移到 <strong>Amazon Redshift</strong> 以适应增加的使用量</p>
<p><strong>Aurora Serverless v2</strong> 专为<strong>不可预测工作负载</strong>设计，提供自动扩展的计算和连接能力，按使用量付费，是应对每月不可预测促销流量的<strong>最具成本效益</strong>且稳定的解决方案</p>
<p><br>597 一家公司通过 <strong>Amazon API Gateway + AWS Lambda</strong> 托管一个<strong>内部无服务器应用程序</strong>。<br>问题：<strong>员工每天开始使用应用程序时会遇到高延迟</strong>（冷启动问题）。<br>目标：<strong>降低延迟</strong>。</p>
<p>选项：<br>A. 提高 API Gateway 的限流阈值<br>B. <u>设置定时扩展，在员工开始使用应用程序之前增加 <strong>Lambda 预置并发数</strong> 每天</u><br>C. 创建一个 Amazon CloudWatch 警报，在每天开始时将 Lambda 函数作为警报目标启动<br>D. 增加 Lambda 函数内存</p>
<p>对于<strong>可预测的每日开始时段冷启动延迟</strong>，最佳实践是使用 <strong>Lambda 预置并发并按计划调整</strong>（在需要前增加，之后减少），确保实例已预热，消除冷启动</p>
<p><br>598 一家研究公司使用本地设备生成数据（.csv 文件），并支持将数据写入 <strong>SMB 文件共享</strong>。<br>要求：</p>
<ol>
<li>使用 AWS 云分析数据</li>
<li>分析师必须能够使用 <strong>SQL 命令</strong> 查询数据</li>
<li>分析师将在一天中定期运行查询</li>
<li>需要<strong>最具成本效益</strong>的解决方案</li>
</ol>
<p>问：哪些步骤组合能最具成本效益地满足要求？（选择三项）</p>
<p>选项：<br>A. <u>在本地以 <strong>Amazon S3 文件网关模式</strong> 部署 AWS Storage Gateway</u><br>B. 在本地部署 AWS Storage Gateway，采用 <strong>Amazon FSx 文件网关模式</strong><br>C. <u>设置一个 <strong>AWS Glue 爬虫</strong>，基于 Amazon S3 中的数据创建一个表</u><br>D. 使用 <strong>EMRFS</strong> 设置 Amazon EMR 集群，以查询 Amazon S3 中的数据，为分析师提供访问权限<br>E. 设置一个 <strong>Amazon Redshift 集群</strong> 来查询 Amazon S3 中的数据，为分析师提供访问权限<br>F. <u>设置 <strong>Amazon Athena</strong> 来查询 Amazon S3 中的数据，为分析师提供访问权限</u></p>
<ol>
<li><strong>A</strong>：通过 S3 File Gateway 将本地 SMB 数据自动上传至 S3（低成本、自动化）。</li>
<li><strong>C</strong>：使用 Glue 爬虫创建元数据表（低成本、自动化）。</li>
<li><strong>F</strong>：使用 Athena 提供 SQL 查询能力（按查询付费，无服务器）。</li>
</ol>
<p><br>599 一家公司希望使用 <strong>Amazon ECS 集群 + Amazon RDS 数据库</strong> 构建和运行一个支付处理应用程序，但<strong>出于合规要求</strong>必须在<strong>本地数据中心</strong>运行此应用程序。<br>解决方案架构师计划使用 <strong>AWS Outposts</strong> 作为解决方案的一部分。<br>问：在该方案中，<strong>公司运营团队负责哪些活动</strong>？（选择三项）</p>
<p>选项：<br>A. <u>为 Outposts 机架提供弹性电源和网络连接</u><br>B. 管理虚拟化管理程序、存储系统以及在 Outposts 上运行的 AWS 服务<br>C. <u>数据中心环境的物理安全和访问控制</u><br>D. 前哨基地基础设施的可用性，包括前哨基地机架内的电源、服务器和网络设备<br>E. 前哨站组件的物理维护<br>F. <u>为 Amazon ECS 集群提供额外容量，以缓解服务器故障和维护事件</u></p>
<p><br>600 一家公司计划将一个<strong>基于 TCP 的应用程序</strong>迁移到 VPC 中。<br>当前：该应用程序通过公司数据中心的硬件设备在<strong>非标准 TCP 端口上可公开访问</strong>，性能要求：</p>
<ul>
<li>每秒最多处理 <strong>300 万请求</strong></li>
<li><strong>延迟较低</strong><br>要求：在 AWS 中的新公共端点达到<strong>相同的性能水平</strong>。</li>
</ul>
<p>问：解决方案架构师应推荐什么来满足这一要求？</p>
<p>选项：<br>A. <u>部署<strong>网络负载均衡器（NLB）</strong>，将 NLB 配置为可通过应用程序所需的 TCP 端口公开访问</u><br>B. 部署<strong>应用程序负载均衡器（ALB）</strong>，将 ALB 配置为可通过应用程序所需的 TCP 端口公开访问<br>C. 部署一个 <strong>Amazon CloudFront 分发</strong>，监听应用程序所需的 TCP 端口，使用 ALB 作为源站<br>D. 部署一个配置了应用程序所需 TCP 端口的 <strong>Amazon API Gateway API</strong>，为 AWS Lambda 函数配置预置并发以处理请求</p>
<p>对于<strong>基于 TCP、高吞吐、低延迟</strong>的公开端点，<strong>网络负载均衡器（NLB）</strong> 是 AWS 推荐的服务：</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T500/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T500/" class="post-title-link" itemprop="url">AWS架构师T500</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T500"><a href="#AWS架构师T500" class="headerlink" title="AWS架构师T500"></a>AWS架构师T500</h1><p><br>401 一家公司希望使用 AWS 云服务提高现有应用程序的<strong>高可用性和弹性</strong>。</p>
<ul>
<li>当前应用程序位于本地数据中心。</li>
<li>最近因意外断电导致数据库服务器崩溃，<strong>数据丢失</strong>。</li>
<li>要求：<ol>
<li>解决方案<strong>必须避免任何单点故障</strong>。</li>
<li>应用程序必须能<strong>根据用户需求进行扩展</strong>。</li>
</ol>
</li>
</ul>
<p>A. <u>通过在多个可用区的自动扩展组中使用 Amazon EC2 实例来部署应用服务器区域。在多可用区配置中使用 Amazon RDS 数据库实例。</u></p>
<p>B. 在单个可用区内的自动扩展组中使用 Amazon EC2 实例部署应用程序服务器。在 EC2 实例上部署数据库。启用 EC2 自动恢复功能。</p>
<p>C. 通过在多个可用区的 Auto Scaling 组中使用 Amazon EC2 实例来部署应用服务器。在单个可用区中使用带有只读副本的 Amazon RDS 数据库实例。如果主数据库实例发生故障，将只读副本提升为新的主数据库实例。</p>
<p>D. 在多个可用区的 Auto Scaling 组中使用 Amazon EC2 实例部署应用程序服务器。在多个可用区的 EC2 实例上部署主数据库服务器和备用数据库服务器。使用 Amazon Elastic Block Store (Amazon EBS) 多挂载功能在实例之间创建共享存储。</p>
<ul>
<li><strong>RDS 多可用区（Multi-AZ）</strong>：<ul>
<li>自动同步复制到备用实例（不同 AZ）。</li>
<li>主实例故障时自动故障转移，数据不丢失（同步复制）。</li>
<li>完全托管，备份、补丁自动化。</li>
</ul>
</li>
<li><strong>自建数据库跨可用区</strong>：<ul>
<li>需要自行配置复制、故障转移、备份，复杂性高，容易出错。</li>
</ul>
</li>
<li><strong>单可用区数据库</strong>：<ul>
<li>存在单点故障，不满足“避免任何单点故障”。</li>
</ul>
</li>
</ul>
<p><br>402 一家公司需要摄入并处理应用程序生成的大量流数据：</p>
<ul>
<li>应用程序在 <strong>Amazon EC2 实例</strong>上运行，数据发送到采用<strong>默认设置配置的 Amazon Kinesis Data Streams</strong>。</li>
<li>每隔一天，应用程序消费这些数据并写入 <strong>Amazon S3</strong> 存储桶，用于商业智能（BI）处理。</li>
<li>问题：<strong>Amazon S3 并未接收到应用程序发送到 Kinesis Data Streams 的所有数据</strong>。</li>
</ul>
<p>问：解决方案架构师应如何解决此问题？</p>
<p>A. <u>通过修改数据保留期来更新 Kinesis Data Streams 的默认设置。</u></p>
<p>B. 更新应用程序以使用 Kinesis Producer Library（KPL）将数据发送到 Kinesis Data Streams。</p>
<p>C. 更新 Kinesis 分片的数量，以处理发送到 Kinesis Data Streams 的数据吞吐量。</p>
<p>D. 在 S3 存储桶中启用 S3 版本控制，以保留摄入到该 S3 存储桶中的每个对象的所有版本。</p>
<p>Kinesis Data Streams 默认<strong>数据保留期</strong>为 <strong>24 小时</strong>。<br>题目描述：<strong>每隔一天</strong>（即每 48 小时）消费数据并写入 S3。<br>因此，若保留期为默认的 24 小时，则消费应用程序在 48 小时后来拉取数据时，部分数据可能因超过保留期而被自动删除，导致 S3 接收不全。</p>
<p>保留期（Retention Period）：Kinesis 流中数据可供消费的最长时间，默认 24 小时，最大可延长至 365 天</p>
<p><br>403 一名开发人员拥有一个应用程序，使用 <strong>AWS Lambda 函数</strong>将文件上传到 <strong>Amazon S3</strong>。<br>开发人员已经拥有一个 <strong>IAM 用户</strong>，具备 Amazon S3 所需的有效 IAM 凭证。<br>问：解决方案架构师应如何授予这些权限？</p>
<p>A. 在 Lambda 函数的资源策略中添加所需的 IAM 权限。</p>
<p>B. 使用 Lambda 函数中现有的 IAM 凭证创建一个签名请求。</p>
<p>C. 创建一个新的 IAM 用户，并在 Lambda 函数中使用现有的 IAM 凭证。</p>
<p>D. <u>创建具有所需权限的 IAM 执行角色，并将该 IAM 角色附加到 Lambda 函数。</u></p>
<h3 id="Lambda-权限模型"><a href="#Lambda-权限模型" class="headerlink" title="Lambda 权限模型"></a>Lambda 权限模型</h3><ul>
<li>Lambda 函数在执行时需要访问 AWS 资源（如 S3），必须通过 <strong>IAM 执行角色（Execution Role）</strong> 获得权限。</li>
<li><strong>IAM 执行角色</strong> 是一个 IAM 角色，附加到 Lambda 函数，函数在运行时代入该角色，获得角色关联的策略所定义的权限。</li>
<li><strong>IAM 用户凭证</strong>（访问密钥&#x2F;秘密密钥）<strong>不应该</strong>直接嵌入 Lambda 函数代码或环境变量中（不安全且难以轮换）。</li>
</ul>
<h3 id="2-现有-IAM-用户的凭证不应用于-Lambda"><a href="#2-现有-IAM-用户的凭证不应用于-Lambda" class="headerlink" title="2. 现有 IAM 用户的凭证不应用于 Lambda"></a>2. 现有 IAM 用户的凭证不应用于 Lambda</h3><ul>
<li>虽然开发人员已有具备 S3 权限的 IAM 用户，但<strong>最佳实践是 Lambda 使用 IAM 角色</strong>，而不是硬编码用户凭证。</li>
<li>硬编码凭证会带来安全风险（泄露、轮换困难）且不符合 AWS 的安全设计。</li>
</ul>
<p><br>404 一家公司部署了无服务器应用程序：</p>
<ul>
<li>当新文档上传到 <strong>Amazon S3 存储桶</strong>时，触发 <strong>AWS Lambda 函数</strong> 处理文档。</li>
<li>最近一次营销活动后，发现<strong>应用程序没有处理许多文档</strong>。</li>
</ul>
<p>问：解决方案架构师应如何改进此应用程序的架构？</p>
<p>A. 将 Lambda 函数的运行时超时值设置为 15 分钟。</p>
<p>B. 配置 S3 存储桶复制策略。将文档暂存到 S3 存储桶中，以备后续处理。</p>
<p>C. 部署一个额外的 Lambda 函数。在这两个 Lambda 函数之间对文档处理进行负载均衡。</p>
<p>D. <u>创建一个 Amazon Simple Queue Service（Amazon SQS）队列。将请求发送到该队列。将队列配置为 Lambda 的事件源。</u></p>
<p><br>405 一位解决方案架构师正在为<strong>软件演示环境</strong>设计架构：</p>
<ul>
<li>环境在 <strong>应用程序负载均衡器（ALB）</strong> 后的 <strong>自动扩展组中的 EC2 实例</strong> 上运行。</li>
<li>系统<strong>在工作时间流量显著增长</strong>，但<strong>周末无需运行</strong>。</li>
<li>要求：确保系统能够<strong>扩展以满足需求</strong>。</li>
<li>需选择<strong>两项</strong>正确的行动组合。</li>
</ul>
<p>A. 使用 AWS 自动扩展根据请求速率调整 ALB 容量。</p>
<p>B. 使用 AWS Auto Scaling 来扩展 VPC 互联网网关的容量。</p>
<p>C. 在多个 AWS 区域中启动 EC2 实例，以在各区域间分配负载。</p>
<p><u>D. 使用目标跟踪扩展策略，基于实例的 CPU 利用率来扩展自动扩展组。</u></p>
<p><u>E. 使用定时伸缩将自动伸缩组的最小、最大和期望容量在周末调整为零。每周开始时恢复默认值。</u></p>
<ol>
<li><strong>动态扩展</strong>：基于指标（如 CPU）自动调整实例数 → <strong>D</strong>。</li>
<li><strong>定时扩展</strong>：根据已知时间表（周末关闭）调整容量 → <strong>E</strong>。</li>
</ol>
<p><br>406 一名解决方案架构师正在设计包含两层架构的 VPC：</p>
<ul>
<li><strong>公共子网</strong>：Web 服务器必须对互联网开放 <strong>443 端口</strong>。</li>
<li><strong>数据库子网</strong>：Amazon RDS for MySQL 实例必须仅允许 Web 服务器通过 <strong>3306 端口</strong>访问。</li>
</ul>
<p>问：解决方案架构师应采取哪些步骤组合来满足这些要求？<strong>（选两项）</strong></p>
<p>A. 为公有子网创建网络访问控制列表。添加一条规则，拒绝在 3306 端口向 <code>0.0.0.0/0</code> 的出站流量。</p>
<p>B. 为数据库实例创建一个安全组。添加一条规则，允许来自公共子网 CIDR 块的流量通过 3306 端口。</p>
<p><u>C. 为公有子网中的 Web 服务器创建一个安全组。添加一条规则，允许来自 <code>0.0.0.0/0</code>、端口为 443 的流量。</u></p>
<p><u>D. 为数据库实例创建一个安全组。添加一条规则，允许来自 Web 服务器安全组的流量通过 3306 端口。</u></p>
<p>E. 为数据库实例创建一个安全组。添加一条规则，拒绝所有流量，只允许来自 Web 服务器安全组且通过 3306 端口的流量。</p>
<ul>
<li><p><strong>Web 服务器安全组</strong>：需要允许来自互联网的任何 IP（<code>0.0.0.0/0</code>）的 HTTPS（443）入站。</p>
</li>
<li><p><strong>数据库安全组</strong>：需要仅允许来自 <strong>Web 服务器安全组</strong> 的 MySQL（3306）入站。</p>
</li>
<li><p><strong>安全组</strong>（Security Group）是实例级别的有状态防火墙，常用于精细访问控制。</p>
</li>
<li><p><strong>网络 ACL</strong>（Network ACL）是子网级别的无状态防火墙，用于粗粒度控制，但通常<strong>不建议</strong>用于此类精细控制（尤其是动态 IP 或弹性场景）。</p>
</li>
</ul>
<p><br>407 一家公司为托管在 AWS 云中的游戏应用程序实施<strong>共享存储解决方案</strong>。<br>要求：</p>
<ol>
<li>能够使用 <strong>Lustre 客户端</strong> 访问数据。</li>
<li>解决方案必须是 <strong>完全托管</strong> 的。</li>
</ol>
<p>问：哪种解决方案满足这些要求？</p>
<p>A. 创建一个 AWS DataSync 任务，将数据作为可挂载的文件系统共享。将该文件系统挂载到应用服务器。</p>
<p>B. 创建一个 AWS Storage Gateway 文件网关。创建一个使用所需客户端协议的文件共享。将应用服务器连接到该文件共享。</p>
<p>C. 创建一个 Amazon Elastic File System（Amazon EFS）文件系统，并将其配置为支持 Lustre。将该文件系统附加到源服务器。将应用服务器连接到该文件系统。</p>
<p>D. <u>创建一个 Amazon FSx for Lustre 文件系统。将该文件系统附加到源服务器。将应用服务器连接到该文件系统。</u></p>
<ul>
<li><strong>Amazon FSx for Lustre</strong>：AWS 完全托管的 Lustre 文件系统，原生支持 Lustre 客户端协议，专为高性能计算工作负载设计。</li>
<li><strong>Amazon EFS</strong>：托管的 NFS 文件系统，<strong>不支持 Lustre 协议</strong>。</li>
<li><strong>AWS Storage Gateway 文件网关</strong>：提供 SMB&#x2F;NFS 协议，不支持 Lustre。</li>
<li><strong>AWS DataSync</strong>：用于数据迁移和同步，不提供共享文件系统挂载点（虽有缓存位置，但不是常规共享文件系统）。</li>
</ul>
<p><br>408 一家公司运行一个应用程序，接收来自<strong>数千个地理位置分散、使用 UDP 协议</strong>的远程设备的数据。<br>特点：</p>
<ul>
<li>数据<strong>立即处理</strong>，必要时向设备发回消息。</li>
<li><strong>不存储任何数据</strong>。</li>
<li>需求：<ol>
<li><strong>最小化设备数据传输的延迟</strong>。</li>
<li><strong>能够快速故障转移到另一个 AWS 区域</strong>。</li>
</ol>
</li>
</ul>
<p>A. 配置 Amazon Route 53 故障转移路由策略。在两个区域中各创建一个网络负载均衡器（NLB）。配置 NLB 以调用 AWS Lambda 函数来处理数据。</p>
<p>B. <u>使用 AWS Global Accelerator。在两个区域中各创建一个网络负载均衡器（NLB）作为端点。创建一个采用 Fargate 启动类型的 Amazon ECS 集群。在该集群上创建一个 ECS 服务。将 ECS 服务设置为 NLB 的目标，在 Amazon ECS 中处理数据。</u></p>
<p>C. 使用 AWS Global Accelerator。在两个区域中各创建一个应用程序负载均衡器（ALB）作为端点。创建一个采用 Fargate 启动类型的 Amazon ECS 集群。在该集群上创建一个 ECS 服务。将 ECS 服务设置为 ALB 的目标。在 Amazon ECS 中处理数据。</p>
<p>D. 配置 Amazon Route 53 故障转移路由策略。在两个区域中各创建一个应用程序负载均衡器（ALB）。创建一个采用 Fargate 启动类型的 Amazon ECS 集群。在该集群上创建一个 ECS 服务。将 ECS 服务设置为 ALB 的目标。在 Amazon ECS 中处理数据。</p>
<ul>
<li><strong>UDP 协议</strong>：负载均衡器必须支持 UDP。<ul>
<li>NLB（Network Load Balancer）支持 UDP。</li>
<li>ALB（Application Load Balancer）不支持 UDP。</li>
</ul>
</li>
<li><strong>最小化延迟</strong>：设备全球分布 → 需要<strong>全球流量路由优化</strong>以减少延迟。<ul>
<li><strong>AWS Global Accelerator</strong> 使用静态 Anycast IP 和 AWS 全球骨干网，自动将用户流量路由到最近健康的 AWS 区域端点，降低延迟。</li>
<li>Route 53 基于 DNS 的故障转移有 DNS 缓存延迟（TTL），不如 Global Accelerator 实时。</li>
</ul>
</li>
<li><strong>快速故障转移</strong>：<ul>
<li>Global Accelerator 提供<strong>连续健康检查</strong>和跨区域自动故障转移（秒级）。</li>
<li>Route 53 故障转移依赖 DNS TTL，较慢（分钟级）。</li>
</ul>
</li>
</ul>
<p><br>409 一个 <strong>Windows IIS Web 应用程序</strong> 需要迁移到 AWS。<br>当前依赖：<strong>本地网络附加存储（NAS）</strong> 中托管的文件共享。<br>迁移方案：</p>
<ul>
<li>IIS Web 服务器迁移到<strong>多个可用区的 Amazon EC2 实例</strong>。</li>
<li>这些 EC2 实例需要连接到<strong>存储解决方案</strong>（替代本地 NAS）。</li>
<li>前端配置<strong>弹性负载均衡器</strong>（ELB）分发流量。</li>
</ul>
<p>要求：选择对本地文件共享的<strong>最具弹性和耐用性</strong>的替代方案。</p>
<p>A. 将文件共享迁移到 Amazon RDS。<br>B. 将文件共享迁移到 AWS Storage Gateway。<br>C. <u>将文件共享迁移到适用于 Windows 文件服务器的 Amazon FSx。</u><br>D. 将文件共享迁移到 Amazon Elastic File System（Amazon EFS）。</p>
<ul>
<li><strong>Amazon FSx for Windows File Server</strong>：<ul>
<li>完全托管的 Windows 原生文件系统，支持 SMB 协议。</li>
<li>默认跨多个可用区部署（多 AZ 选项），提供高可用性和持久性。</li>
<li>专为 Windows 应用程序设计，与 Active Directory 集成。</li>
<li>✅ <strong>最适合替代 Windows NAS</strong>。</li>
</ul>
</li>
<li><strong>Amazon EFS</strong>：<ul>
<li>托管的 NFS 文件系统，主要面向 Linux。</li>
<li>虽然可以通过 NFS 挂载到 Windows，但<strong>不是原生 SMB</strong>，兼容性和性能可能不佳，不推荐用于 Windows IIS。</li>
</ul>
</li>
<li><strong>AWS Storage Gateway</strong>：<ul>
<li>提供混合云存储，文件网关支持 SMB&#x2F;NFS，但主要用于本地到云的文件共享缓存&#x2F;备份，不是为云原生高可用共享存储设计（虽然可用，但不如 FSx 弹性强）。</li>
</ul>
</li>
<li><strong>Amazon RDS</strong>：<ul>
<li>关系型数据库服务，不是文件共享服务。</li>
<li>❌ 完全不相关。</li>
</ul>
</li>
</ul>
<p><br>410 一家公司在 Amazon EC2 实例上部署新应用程序，应用程序会将数据写入 <strong>Amazon EBS 卷</strong>。<br>要求：确保写入 EBS 卷的所有数据在<strong>静态时都处于加密状态</strong>。<br>问：哪种解决方案能满足这一要求？</p>
<p>A. 创建一个指定 EBS 加密的 IAM 角色。将该角色附加到 EC2 实例。</p>
<p>B. <u>将 EBS 卷创建为加密卷。将 EBS 卷附加到 EC2 实例。</u></p>
<p>C. 创建一个 EC2 实例标签，其键为 Encrypt，值为 True。为所有需要在 EBS 级别进行加密的实例添加此标签。</p>
<p>D. 创建一个 AWS 密钥管理服务（AWS KMS）密钥策略，以在账户中强制实施 EBS 加密。确保该密钥策略处于活动状态。</p>
<h3 id="EBS-静态加密机制"><a href="#EBS-静态加密机制" class="headerlink" title="EBS 静态加密机制"></a>EBS 静态加密机制</h3><ul>
<li>EBS 卷的加密在<strong>创建时</strong>启用，启用后卷上的所有数据（包括快照）都会被加密。</li>
<li>加密使用 <strong>AWS KMS</strong> 密钥（默认的 AWS 托管密钥 <code>aws/ebs</code> 或客户托管密钥 CMK）。</li>
<li><strong>无法对现有未加密卷启用加密</strong>（除非通过快照复制并创建新加密卷）。</li>
</ul>
<h3 id="2-需求实现"><a href="#2-需求实现" class="headerlink" title="2. 需求实现"></a>2. 需求实现</h3><p>要确保写入 EBS 卷的所有数据静态加密，最直接的方法是<strong>创建加密的 EBS 卷并附加到 EC2 实例</strong>。</p>
<p><br>411 一家公司有一个 <strong>使用模式不稳定</strong> 的 Web 应用程序：</p>
<ul>
<li>每月初使用量很大。</li>
<li>每周初使用量适中。</li>
<li>一周内的使用量难以预测。</li>
<li>应用程序当前由 <strong>本地 Web 服务器 + MySQL 数据库服务器</strong> 组成。</li>
<li>希望将应用程序迁移到 AWS 云。</li>
<li>要求：<ol>
<li><strong>经济高效</strong>（适应不稳定的使用量，避免为峰值预置过多资源）。</li>
<li><strong>不需要对数据库进行修改</strong>（即保持 MySQL 兼容性）。</li>
</ol>
</li>
</ul>
<p>A. 亚马逊 DynamoDB<br>B. 亚马逊 RDS for MySQL<br><u>C. 兼容 MySQL 的 Amazon Aurora 无服务器版（Amazon Aurora Serverless v2）</u><br>D. 在自动扩展组中的亚马逊 EC2 上部署的 MySQL</p>
<ul>
<li>Aurora Serverless v2 是 AWS 的无服务器关系数据库，可<strong>在几分之一秒内自动扩展计算资源</strong>，适应不可预测的工作负载。</li>
<li>兼容 MySQL 5.7&#x2F;8.0，无需修改应用。</li>
<li>比持续运行预置实例更经济（仅为实际使用的计算资源付费）。</li>
<li>相比传统 RDS，更适合使用模式不稳定的场景。</li>
</ul>
<p><br>412 一家图片托管公司将其对象存储在 <strong>Amazon S3 存储桶</strong>中。<br>要求：</p>
<ol>
<li>避免 S3 存储桶中的对象<strong>意外暴露给公众</strong>。</li>
<li><strong>整个 AWS 账户中的所有 S3 对象都需要保持私有状态</strong>。</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. 使用 Amazon GuardDuty 监控 S3 存储桶策略。创建一个自动修复操作规则，该规则使用 AWS Lambda 函数来修复任何使对象公开的更改。</p>
<p>B. 使用 AWS Trusted Advisor 查找可公开访问的 S3 存储桶。在 Trusted Advisor 中配置电子邮件通知，以便在检测到更改时发送通知。如果 S3 存储桶策略允许公共访问，请手动更改该策略。</p>
<p>C. 使用 AWS 资源访问管理器查找可公开访问的 S3 存储桶。当检测到变更时，使用 Amazon Simple Notification Service（Amazon SNS）调用 AWS Lambda 函数。部署一个 Lambda 函数，以编程方式纠正该变更。</p>
<p><u>D. 在账户级别使用 S3 阻止公共访问功能。使用 AWS Organizations 创建服务控制策略 (SCP)，防止 IAM 用户更改该设置。将 SCP 应用于该账户。</u></p>
<h3 id="1-需求核心"><a href="#1-需求核心" class="headerlink" title="1. 需求核心"></a>1. 需求核心</h3><ul>
<li>防止 <strong>任何 S3 对象被公开</strong>（意外或恶意设置）。</li>
<li>作用于<strong>整个 AWS 账户</strong>，确保所有现有和未来的 S3 存储桶默认私有。</li>
</ul>
<h3 id="2-AWS-相关功能"><a href="#2-AWS-相关功能" class="headerlink" title="2. AWS 相关功能"></a>2. AWS 相关功能</h3><ul>
<li><strong>S3 阻止公共访问（Block Public Access）</strong>：<ul>
<li>账户级别设置，可阻止<strong>任何形式的公共访问</strong>（通过 ACL 或策略）。</li>
<li>一旦启用，即使存储桶策略或 ACL 配置为公开，也会被拒绝。</li>
<li>这是 <strong>主动防护</strong>，而非事后检测修复。</li>
</ul>
</li>
<li><strong>GuardDuty</strong>：威胁检测服务，可检测 S3 公开，但属于<strong>事后监控</strong>。</li>
<li><strong>Trusted Advisor</strong>：检查公开存储桶，属于<strong>检查与建议</strong>，不主动阻止。</li>
<li><strong>AWS RAM</strong>：用于跨账户共享资源，与公开访问控制无关。</li>
</ul>
<p><br>413 一家电子商务公司的商店部署在 <strong>Amazon EC2 实例</strong> 上，是两层 Web 应用程序（Web 层 + 独立数据库层）。<br>问题：用户流量增长后，<strong>发送营销邮件和订单确认邮件出现严重延迟</strong>。<br>目标：</p>
<ol>
<li>减少解决复杂邮件发送问题的时间。</li>
<li>最大限度地降低运营开销。</li>
</ol>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p>A. 使用专门用于电子邮件处理的 EC2 实例创建一个独立的应用层。</p>
<p>B. <u>配置 Web 实例以通过亚马逊简单电子邮件服务（Amazon SES）发送电子邮件。</u></p>
<p>C. 配置 Web 实例通过亚马逊简单通知服务（Amazon SNS）发送电子邮件。</p>
<p>D. 使用专用于电子邮件处理的 EC2 实例创建单独的应用层。将这些实例放入一个自动扩展组中。</p>
<ul>
<li><strong>Amazon SES（Simple Email Service）</strong>：AWS 托管的高性价比电子邮件发送服务，处理大规模发送、退信、投递率、IP 信誉等问题，只需通过 API 调用即可发送邮件。</li>
<li><strong>Amazon SNS</strong>：主要用于消息推送（短信、移动推送、HTTP 等），虽然可通过 SNS 主题订阅邮件，但底层仍可能使用 SES 或第三方，且不是专为批量邮件设计，功能不如 SES 完整。</li>
</ul>
<p><br>414 一家公司拥有一个业务系统，每天生成<strong>数百份报告（CSV 格式）</strong>，保存到<strong>网络共享</strong>中。<br>需求：</p>
<ol>
<li>将这些数据<strong>近乎实时</strong>存储在 AWS 云中以进行分析。</li>
<li>以<strong>最少的管理开销</strong>满足要求。</li>
</ol>
<p>A. 使用 AWS DataSync 将文件传输到 Amazon S3。创建一个每天结束时运行的计划任务。</p>
<p>B. <u>创建一个 Amazon S3 文件网关。更新业务系统以使用来自 S3 文件网关的新网络共享</u>。</p>
<p>C. 使用 AWS DataSync 将文件传输到 Amazon S3。创建一个在自动化工作流中使用 DataSync API 的应用程序。</p>
<p>D. 部署一个 AWS Transfer for SFTP 端点。创建一个脚本，用于检查网络共享上的新文件并通过 SFTP 上传这些新文件。</p>
<ul>
<li><strong>AWS DataSync</strong>：专门用于自动、快速、安全地将数据从本地或网络共享同步到 AWS 存储（如 S3、EFS、FSx）。支持<strong>持续或计划同步</strong>，全托管，自动化程度高。</li>
<li><strong>Amazon S3 文件网关</strong>：提供本地 SMB&#x2F;NFS 共享接口，背后数据存储在 S3。业务系统可以直接写入网关共享，数据自动持久化到 S3，<strong>近乎实时</strong>。</li>
<li><strong>AWS Transfer for SFTP</strong>：托管 SFTP 服务，但需要业务系统或脚本主动通过 SFTP 上传文件，增加脚本管理和触发逻辑。</li>
<li><strong>自定义脚本 + 计划任务</strong>：管理开销大，非托管。</li>
</ul>
<p><br>415 一家公司正在 <strong>Amazon S3 Standard</strong> 中存储<strong>数 PB 的数据</strong>，分布在多个 S3 存储桶中。</p>
<ul>
<li>数据访问频率<strong>各不相同</strong>。</li>
<li>公司<strong>不了解所有数据的访问模式</strong>。</li>
<li>要求：为每个 S3 存储桶实施解决方案，以<strong>优化 S3 的使用成本</strong>。</li>
<li>目标：以<strong>最高的运营效率</strong>满足要求。</li>
</ul>
<p>A. <u>创建一个 S3 生命周期配置，其中包含一条规则，用于将 S3 存储桶中的对象转换到 S3 智能分层存储（S3 Intelligent-Tiering）。</u></p>
<p>B. 使用 S3 存储类别分析工具确定 S3 存储桶中每个对象的正确层级。将每个对象移动到确定的存储层级。</p>
<p>C. 创建一个 S3 生命周期配置，其中包含一条规则，用于将 S3 存储桶中的对象转换为 S3 Glacier 即时检索。</p>
<p>D. 创建一个 S3 生命周期配置，其中包含一条规则，用于将 S3 存储桶中的对象转换为 S3 单区域低频访问存储（S3 One Zone-IA）。</p>
<ul>
<li>数据量极大（PB 级），访问模式未知。</li>
<li>需要<strong>自动化、低成本优化</strong>，且<strong>运营效率最高</strong>（即尽量少的人工分析、决策和操作）。</li>
<li>S3 智能分层（Intelligent-Tiering）专为<strong>访问模式不明确</strong>的对象设计，自动在四个访问层（频繁访问、不频繁访问、归档即时访问、归档深度访问）之间移动对象，以优化成本。</li>
<li>智能分层每月仅收取少量对象监控费（对 PB 级数据可忽略），但可节省大量存储费用。</li>
</ul>
<p><br>416 一家全球电子商务公司将其 Web 应用程序托管在 AWS 上：</p>
<ul>
<li>包含<strong>静态内容和动态内容</strong>。</li>
<li>OLTP 数据存储在 <strong>Amazon RDS</strong> 数据库。</li>
<li>问题：网站用户遇到<strong>页面加载缓慢</strong>。</li>
</ul>
<p>问：解决方案架构师应采取哪些行动组合来解决此问题？<strong>（选两项）</strong></p>
<p>A. 配置一个 Amazon Redshift 集群。</p>
<p>B. <u>设置一个 Amazon CloudFront 分发。</u></p>
<p>C. 在 Amazon S3 中托管动态网页内容。</p>
<p>D. <u>为 RDS 数据库实例创建一个只读副本。</u></p>
<p>E. 为 RDS 数据库实例配置多可用区部署</p>
<h3 id="1-问题分析"><a href="#1-问题分析" class="headerlink" title="1. 问题分析"></a>1. 问题分析</h3><p>页面加载缓慢可能由于：</p>
<ol>
<li><strong>静态内容加载慢</strong>（全球用户距离源站远）。</li>
<li><strong>数据库查询慢</strong>（OLTP 数据库负载高，查询响应慢）。</li>
</ol>
<h3 id="2-针对性措施"><a href="#2-针对性措施" class="headerlink" title="2. 针对性措施"></a>2. 针对性措施</h3><ul>
<li><strong>静态内容加速</strong>：使用 <strong>CDN（CloudFront）</strong> 缓存静态内容（如图片、CSS、JS），从边缘节点就近提供给全球用户，减少延迟。</li>
<li><strong>数据库查询优化</strong>：如果慢的原因是数据库读取负载高（例如大量报表查询或复杂查询），可以为 RDS 创建 <strong>只读副本</strong>，将读查询分流到副本，减轻主实例压力。</li>
</ul>
<p><br>417 一家公司使用 <strong>Amazon EC2 实例</strong> 和 <strong>AWS Lambda 函数</strong> 运行应用程序。</p>
<ul>
<li>架构：VPC 包含公有子网和私有子网，<strong>EC2 实例运行在私有子网</strong>。</li>
<li>需求：<strong>Lambda 函数需要直接对 EC2 实例进行网络访问</strong>。</li>
<li>应用程序将运行至少 1 年，期间 Lambda 函数数量会增加。</li>
<li>要求：<ol>
<li><strong>最大限度地节省所有应用程序资源</strong>（成本优化）。</li>
<li><strong>保持服务之间的网络延迟较低</strong>。</li>
</ol>
</li>
</ul>
<p>A. 购买 EC2 实例节省计划。优化 Lambda 函数的持续时间、内存使用量和调用次数。将 Lambda 函数连接到包含 EC2 实例的私有子网。</p>
<p>B. 购买一个 EC2 实例节省计划。优化 Lambda 函数的持续时间、内存使用量、调用次数以及传输的数据量。将 Lambda 函数连接到 EC2 实例运行所在的同一 VPC 中的公共子网。</p>
<p>C. <u>购买计算节省计划。优化 Lambda 函数的持续时间和内存使用量、调用次数以及传输的数据量。将 Lambda 函数连接到包含 EC2 实例的私有子网。</u></p>
<p>D. 购买计算节省计划。优化 Lambda 函数的持续时间和内存使用量、调用次数以及传输的数据量。将 Lambda 函数保留在 Lambda 服务 VPC 中。</p>
<ul>
<li><strong>网络访问</strong>：Lambda 需要直接访问私有子网中的 EC2 实例 → 需要 <strong>将 Lambda 函数连接到 VPC</strong>（配置 VPC 网络接口到 Lambda 函数），使其能够与 EC2 实例通信。</li>
<li><strong>节省成本</strong>：运行至少 1 年 → 可以使用 <strong>AWS 节省计划（Savings Plans）</strong> 降低成本。</li>
<li><strong>计算节省计划</strong> 覆盖 EC2 实例、Lambda、Fargate 的使用量，<strong>比单独的 EC2 实例节省计划更全面</strong>（因为涉及 EC2 和 Lambda 两种资源）。</li>
<li><strong>低延迟</strong>：Lambda 与 EC2 在同一个 VPC 私有子网内通信，延迟最低（避免通过公网或 NAT）。</li>
</ul>
<p><br>418 一位解决方案架构师要解决一个跨账户访问问题：</p>
<ul>
<li>有两个 AWS 账户：<strong>开发账户</strong> 和 <strong>生产账户</strong>。</li>
<li>目前，团队成员通过 <strong>开发账户内的 IAM 用户</strong>（加入有权限的 IAM 组）来访问 <strong>开发账户里的 S3 存储桶</strong>。</li>
<li>现在需要让这些团队成员也能访问 <strong>生产账户中的某个 S3 存储桶</strong>。</li>
<li>生产账户中已经创建了一个 <strong>IAM 角色</strong>，并且该角色附加了策略可以访问该生产 S3 存储桶。</li>
</ul>
<p>问：<strong>哪种方案既能满足要求，又遵循最小权限原则？</strong></p>
<p>A. 将管理员访问权限策略附加到开发账户用户。<br>B. <u>将开发账户作为主体添加到生产账户中角色的信任策略中</u>。<br>C. 关闭生产账户中 S3 存储桶的 S3 阻止公共访问功能。<br>D. 在生产账户中为每个团队成员创建一个具有唯一凭证的用户。</p>
<h3 id="1-需求理解"><a href="#1-需求理解" class="headerlink" title="1. 需求理解"></a>1. 需求理解</h3><ul>
<li>团队成员已有 <strong>开发账户的用户</strong>（通过 IAM 组获得对开发 S3 的权限）。</li>
<li>目标是让他们还能访问 <strong>生产账户的特定 S3 存储桶</strong>，而不是所有资源。</li>
<li>最小权限原则：只给必要的权限，不扩大权限范围。</li>
</ul>
<h3 id="2-生产账户已经做了准备工作"><a href="#2-生产账户已经做了准备工作" class="headerlink" title="2. 生产账户已经做了准备工作"></a>2. 生产账户已经做了准备工作</h3><ul>
<li>已经创建了一个 <strong>IAM 角色</strong>，角色策略里允许访问生产 S3 存储桶。</li>
<li>角色的权限没问题，关键是 <strong>谁能代入（Assume）这个角色</strong>。</li>
</ul>
<h3 id="3-跨账户访问的标准做法"><a href="#3-跨账户访问的标准做法" class="headerlink" title="3. 跨账户访问的标准做法"></a>3. 跨账户访问的标准做法</h3><p>要让开发账户的用户访问生产账户的资源，正确做法是：</p>
<ol>
<li>在生产账户的角色 <strong>信任策略（Trust Policy）</strong> 中，允许来自开发账户的特定实体（可以是整个账户、特定用户或角色）来代入该角色。</li>
<li>开发账户的用户在访问时，通过 AWS STS（安全令牌服务）<strong>代入该角色</strong>，获得临时安全凭证去访问生产 S3。</li>
<li>临时凭证的权限 &#x3D; 该角色的权限，只限于 S3 存储桶，不会获得其他权限（符合最小权限原则）。</li>
</ol>
<p><br>419 一家公司使用 <strong>AWS Organizations</strong>（启用所有功能），在亚太东南 2 区（ap-southeast-2）运行 Amazon EC2 工作负载。<br>该公司已有一个 <strong>服务控制策略（SCP）</strong>，禁止在任何其他区域创建资源。<br>安全政策要求对所有静态数据加密。</p>
<p>审计发现：员工在 ap-southeast-2 区域为 EC2 创建 <strong>Amazon EBS 卷</strong>时，没有启用加密。<br>目标：确保该区域中所有新 EC2 实例使用的 EBS 卷都被加密，并且对创建 EBS 卷的员工影响最小。<br>强制对象：<strong>IAM 用户和根用户</strong>（包括 Root 用户）。</p>
<p>问：哪两个步骤组合可以满足要求？</p>
<p>A. 在 EC2 控制台中，选择 <strong>EBS 加密账户属性</strong>，定义默认加密密钥。<br>B. 创建一个 <strong>IAM 权限边界</strong>，附加到根组织单位（OU）；定义它当 <code>ec2:Encrypted</code> 为 <code>false</code> 时拒绝 <code>ec2:CreateVolume</code>。<br>C<u>. 创建一个 <strong>SCP</strong>，附加到根组织单位（OU）；定义它当 <code>ec2:Encrypted</code> 等于 <code>false</code> 时拒绝 <code>ec2:CreateVolume</code>。</u><br>D. 为每个账户更新 <strong>IAM 策略</strong>，当 <code>ec2:Encrypted</code> 为 <code>false</code> 时拒绝 <code>ec2:CreateVolume</code>。<br>E<u>. 在 <strong>组织管理账户</strong> 中，指定默认的 <strong>EBS 卷加密设置</strong>。</u></p>
<p><br>420 公司希望使用 <strong>Amazon RDS for PostgreSQL</strong> 来简化数据库管理，要求：</p>
<ol>
<li><strong>高可用性</strong>。</li>
<li>大多数情况下 <strong>40 秒内自动故障转移</strong>。</li>
<li><strong>减轻主实例的读取负担</strong>。</li>
<li><strong>尽可能降低成本</strong>。</li>
</ol>
<p>问：哪种解决方案满足要求？</p>
<p>A. 使用 <strong>RDS 多可用区数据库实例部署</strong>，创建一个只读副本，并将读取负载指向该只读副本。<br>B. 使用 <strong>RDS 多可用区数据库集群部署</strong>，创建两个只读副本，并将读取负载指向这些只读副本。<br>C. 使用 <strong>RDS 多可用区数据库实例部署</strong>，将读取负载指向多可用区对中的次要实例。<br>D. <u>使用 <strong>RDS 多可用区数据库集群部署</strong>，将读取负载指向读取端点。</u></p>
<ul>
<li><strong>RDS 多可用区数据库实例</strong>（Multi-AZ DB Instance）：<ul>
<li>一个主实例 + 一个同步备用实例（在不同 AZ）。</li>
<li>备用实例不能用于读取，仅用于故障转移。</li>
<li>故障转移时间通常 60–120 秒（取决于引擎与负载）。</li>
</ul>
</li>
<li><strong>RDS 多可用区数据库集群</strong>（Multi-AZ DB Cluster，对于 PostgreSQL 和 MySQL 可用）：<ul>
<li>包含一个主实例 + 两个可读备用实例（共 3 个 AZ）。</li>
<li>备用实例可以处理读取查询。</li>
<li>故障转移通常 <strong>小于 40 秒</strong>（AWS 宣传可低至 35 秒），并且备用实例可用于分担读负载。</li>
</ul>
</li>
</ul>
<p>多可用区数据库集群部署，读负载指向 <strong>读取端点</strong>（自动负载均衡到两个可读备用实例），满足快速故障转移、读负载分摊、成本较低（无需额外实例）</p>
<p><br>421 公司目前运行高可用 SFTP 服务：</p>
<ul>
<li>使用两台带弹性 IP 的 Linux EC2 实例。</li>
<li>只允许来自互联网上可信 IP 源的流量。</li>
<li>共享存储支持 SFTP 服务（用户账户在 SFTP 服务器中作为 Linux 用户管理）。</li>
</ul>
<p>现在需要改为 <strong>无服务器选项</strong>，要求：</p>
<ol>
<li><strong>高 IOPS 性能</strong>。</li>
<li><strong>高度可配置的安全性</strong>。</li>
<li><strong>保持对用户权限的控制</strong>。</li>
</ol>
<p>问：哪种解决方案满足要求？</p>
<p>A. 创建加密的 <strong>Amazon EBS 卷</strong> → 创建具有公共端点的 AWS Transfer Family SFTP 服务（仅允许受信 IP）→ 将 EBS 卷附加到 SFTP 端点 → 授予用户访问 SFTP 服务的权限。<br>B. 创建加密的 <strong>Amazon EFS 卷</strong> → 创建带弹性 IP 和互联网访问 VPC 端点的 AWS Transfer Family SFTP 服务 → 为终端节点附加仅允许受信 IP 的安全组 → 将 EFS 卷附加到服务终端节点 → 授予用户 SFTP 访问权限。<br>C. <u>创建启用默认加密的 <strong>Amazon S3 存储桶</strong> → 创建具有公共端点的 AWS Transfer Family SFTP 服务（仅允许受信 IP）→ 将 S3 存储桶附加到服务端点 → 授予用户访问权限。</u><br>D. 创建启用默认加密的 <strong>Amazon S3 存储桶</strong> → 创建 AWS Transfer Family SFTP 服务，其 VPC 端点位于私有子网（内部访问）→ 附加仅允许受信 IP 的安全组 → 将 S3 存储桶附加到服务端点 → 授予用户访问权限。</p>
<ul>
<li>当前架构：EC2 + 共享存储（可能是 EFS 或 NFS） + 弹性 IP + 基于 Linux 用户管理。</li>
<li>改为 <strong>无服务器</strong> → AWS Transfer Family（完全托管的 SFTP 服务）。</li>
<li><strong>高 IOPS 性能</strong> → S3 可以扩展性能（尤其是对大量小文件或使用 Transfer Family 时）；EBS 单个卷性能有限，且 Transfer Family <strong>不直接支持挂载 EBS 卷</strong>（选项 A 可能不可行，因为 AWS Transfer Family 后端存储是 S3 或 EFS，不是 EBS）。</li>
<li><strong>高度可配置的安全</strong> → Transfer Family 支持基于安全组&#x2F;IP 限制、IAM 策略、S3 桶策略、VPC 端点等。</li>
<li><strong>保持对用户权限的控制</strong> → Transfer Family 支持基于 S3 前缀或 EFS 文件路径的用户权限映射。</li>
</ul>
<p>AWS Transfer Family 支持的后端是 <strong>Amazon S3</strong> 或 <strong>Amazon EFS</strong>（对 SFTP 协议）。</p>
<p>原架构是互联网访问（通过弹性 IP），限制 IP。<br>AWS Transfer Family 提供两种端点类型：</p>
<ol>
<li><strong>公有端点</strong>（可通过互联网访问）→ 可搭配 IP 允许列表。</li>
<li><strong>VPC 端点</strong>（只能从 VPC 或连接的网络访问）→ 如果客户想要从互联网访问，需要自己建立 VPN&#x2F;Client VPN 或 AWS Direct Connect，或者使用 Transit Gateway 等，这改变了访问方式，可能不符合“来自互联网可信 IP”的场景。</li>
</ol>
<p><br>422 公司开发新的机器学习（ML）模型解决方案：</p>
<ul>
<li>模型为独立的微服务。</li>
<li>启动时从 Amazon S3 加载约 <strong>1 GB</strong> 模型数据到内存。</li>
<li>用户通过 <strong>异步 API</strong> 访问。</li>
<li>请求可以是单条或批量，并指定结果返回位置。</li>
<li>用户数：<strong>数百个</strong>。</li>
<li>使用模式不规律：<ul>
<li>有的模型可能几天或几周无人用。</li>
<li>有的模型可能一次性收到 <strong>数千个请求的批量任务</strong>。</li>
</ul>
</li>
</ul>
<p>问：解决方案架构师应推荐哪种设计？</p>
<p>A. 请求 → 网络负载均衡器（NLB） → 模型部署为 <strong>AWS Lambda 函数</strong>（由 NLB 调用）。<br>B. 请求 → 应用负载均衡器（ALB） → 模型部署为 <strong>Amazon ECS 服务</strong>，从 Amazon SQS 读取数据 → 用 <strong>AWS App Mesh</strong> 根据 SQS 队列大小扩展 ECS 集群实例。<br>C. 请求 → <strong>Amazon SQS 队列</strong> → 模型部署为 <strong>AWS Lambda 函数</strong>（由 SQS 事件触发）→ 用 <strong>AWS Auto Scaling</strong> 根据 SQS 队列大小增加 Lambda 函数的 vCPU 数量。<br>D. <u>请求 → <strong>Amazon SQS 队列</strong> → 模型部署为 <strong>Amazon ECS 服务</strong>，从该队列读取数据 → 启用 AWS Auto Scaling，根据队列大小扩展 ECS 集群和服务副本。</u></p>
<ul>
<li><strong>Lambda</strong>：<ul>
<li>优势：无闲置成本，根据请求自动扩缩。</li>
<li>劣势：<strong>冷启动加载 1 GB 模型数据</strong> 可能非常慢（Lambda 内存最大 10 GB，但启动从 S3 拉取 1 GB 数据，即便使用 &#x2F;tmp 存储，下载时间也很可观），且函数每次冷启动都要重新加载，对频繁突发还行，但如果有持续批量请求，冷启动会拖慢处理。</li>
<li>Lambda 适用于小内存、快速启动的任务，不适合 <strong>每次冷启动都加载 1 GB 模型数据</strong> 的场景，除非用 Provisioned Concurrency 预置并发来避免冷启动，但预置数百个不同模型会导致成本高、管理复杂。</li>
</ul>
</li>
<li><strong>ECS（容器）</strong>：<ul>
<li>可以长时间运行，只需在启动时加载一次模型数据，之后复用容器处理多个请求。</li>
<li>适合大内存、长运行时间的工作负载。</li>
<li>可基于队列长度自动扩缩容器数量。</li>
<li>长时间闲置的模型可缩容到 0，但启动新容器时仍需加载 1 GB 数据（比 Lambda 快一些，因为容器镜像可能包含模型缓存或使用 EFS，但题目没说用 EFS，只写 S3）。</li>
</ul>
</li>
</ul>
<p><br>423 题目给出了一个 IAM <strong>基于身份的策略（Identity-based policy）</strong> 的 JSON 内容。</p>
<p>策略允许对 SSM 服务执行 <code>ssm:ListDocuments</code> 和 <code>ssm:GetDocument</code> 操作。<br>现在问：此策略可以附加到哪些 <strong>IAM 主体（IAM principal）</strong>？（选两项。）</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;ssm:ListDocuments&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;ssm:GetDocument&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><u>A. 角色（Role）</u><br><u>B. 组（Group）</u><br>C. 组织（Organization）<br>D. Amazon ECS 资源<br>E. Amazon EC2 资源</p>
<ol>
<li><strong>IAM 基于身份的策略</strong> 可附加的 <strong>主体类型</strong> 在 IAM 中包括：<ul>
<li>IAM 用户（User）</li>
<li>IAM 组（Group）</li>
<li>IAM 角色（Role）</li>
</ul>
</li>
<li>这些策略可以 <strong>直接附加</strong> 到用户、组或角色上，用来定义它们的权限。</li>
<li><strong>组织（C）</strong> 使用的是 <strong>服务控制策略（SCP）</strong>，不是基于身份的策略，且附加到组织单位（OU）或整个组织，并非 IAM 身份。因此不能把这段 JSON 作为 SCP 直接附加到“组织”，格式可能类似但用法不同，且题目明确说是“作为基于身份的策略”，因此 C 不选。</li>
<li><strong>Amazon ECS 资源（D）</strong> 与 <strong>Amazon EC2 资源（E）</strong> 不是 IAM 主体。<ul>
<li>资源本身的权限由资源策略（如 S3 存储桶策略）或 IAM 角色（附加到 EC2 实例）控制，但不能直接把这段 JSON 策略“附加到 EC2 资源”或“ECS 资源”上，而应附加到这些资源使用的 IAM 角色上。</li>
</ul>
</li>
</ol>
<p><br>424 公司正在 EC2 按需实例上运行自定义应用程序，结构如下：</p>
<ul>
<li><strong>前端节点</strong>：需要 <strong>7x24 小时持续运行</strong>。</li>
<li><strong>后端节点</strong>：只需 <strong>根据工作负载运行一小段时间</strong>，数量在一天内变化。</li>
</ul>
<p>目标：根据工作负载扩展&#x2F;缩减后端节点，同时 <strong>最具成本效益</strong>。</p>
<p>A. 前端用 <strong>预留实例</strong>，后端用 <strong>AWS Fargate</strong>。<br>B<u>. 前端用 <strong>预留实例</strong>，后端用 <strong>Spot 实例</strong>。</u><br>C. 前端用 <strong>Spot 实例</strong>，后端用 <strong>预留实例</strong>。<br>D. 前端用 <strong>Spot 实例</strong>，后端用 <strong>AWS Fargate</strong>。</p>
<h3 id="1-成本效益原则"><a href="#1-成本效益原则" class="headerlink" title="1. 成本效益原则"></a>1. 成本效益原则</h3><ul>
<li><strong>持续稳定负载</strong> → 最适合 <strong>预留实例</strong>（预付费用，比按需便宜很多，比 Spot 稳定性高）。</li>
<li><strong>间歇性、可变负载</strong>、可容错中断 → 最适合 <strong>Spot 实例</strong>（比按需便宜很多，但可能被中断，不适合 7x24 小时关键前端）。</li>
</ul>
<h3 id="2-前端节点特点"><a href="#2-前端节点特点" class="headerlink" title="2. 前端节点特点"></a>2. 前端节点特点</h3><ul>
<li>7x24 小时运行，不能中断（应用程序可用性要求高）→ <strong>Spot 实例不合适</strong>（可能被回收）。</li>
<li>因此前端节点用 <strong>预留实例</strong> 最经济且稳定（选项 B 和 A 的前端选择正确；C 和 D 前端选择错误）。</li>
</ul>
<h3 id="3-后端节点特点"><a href="#3-后端节点特点" class="headerlink" title="3. 后端节点特点"></a>3. 后端节点特点</h3><ul>
<li>根据工作负载运行一小段时间，数量变化 → 适合 <strong>按需或 Spot</strong>，但 Spot 更便宜，且短时间任务可以容忍中断（可设计重试&#x2F;检查点）。</li>
<li><strong>AWS Fargate</strong> 是无服务器容器，按 vCPU&#x2F;内存使用时间计费，适合突发、短时任务，但通常比 Spot 实例 <strong>贵</strong>（因为 Fargate 是无服务器溢价）。</li>
<li>因此后端节点用 <strong>Spot 实例</strong> 比 Fargate 成本更低，也适合自动扩缩。</li>
</ul>
<p><br>425 公司原本在本地使用 <strong>高块存储容量</strong> 运行工作负载，每天的 <strong>峰值 IOPS 不超过 15,000</strong>。</p>
<p>现在要迁移到 Amazon EC2，并希望配置 <strong>与存储容量无关的磁盘性能</strong>。</p>
<p>问：哪种 <strong>Amazon EBS 卷类型</strong> 能满足要求且 <strong>最具成本效益</strong>？</p>
<p>A. GP2 卷类型<br>B. io2 卷类型<br>C. <u>GP3 卷类型</u><br>D. io1 卷类型</p>
<h3 id="1-理解“与存储容量无关的磁盘性能”"><a href="#1-理解“与存储容量无关的磁盘性能”" class="headerlink" title="1. 理解“与存储容量无关的磁盘性能”"></a>1. 理解“与存储容量无关的磁盘性能”</h3><ul>
<li>传统 EBS 卷类型（如 <strong>GP2</strong> 和 <strong>io1</strong>）的 IOPS 性能通常与卷大小（GiB）绑定：<ul>
<li>GP2：每 GiB 提供 3 IOPS（基准性能），最高 16,000 IOPS，但需要更大容量才能获得更高 IOPS。</li>
<li>io1&#x2F;io2：IOPS 与卷大小比例可配置（例如 50:1），但最高 IOPS 仍受容量影响，除非单独指定更高 IOPS（需额外费用）。</li>
</ul>
</li>
<li>从 <strong>GP3</strong> 开始，性能（IOPS、吞吐量）与容量解耦：可以独立调整 IOPS 和吞吐量，不受容量大小限制。</li>
</ul>
<h3 id="2-需求匹配"><a href="#2-需求匹配" class="headerlink" title="2. 需求匹配"></a>2. 需求匹配</h3><ul>
<li>峰值 IOPS 不超过 15,000。</li>
<li>希望性能与容量无关（即可以选择较小容量但依然获得高 IOPS）。</li>
<li>需要 <strong>最具成本效益</strong>。</li>
</ul>
<p>GP3 的设计就是解耦性能与容量，允许用户独立购买 IOPS（额外费用）和吞吐量（额外费用），在容量较小但需要较高 IOPS 时，通常比 GP2 或 io1 更经济，尤其当 IOPS 在几千到几万范围内。</p>
<h3 id="3-成本效益比较"><a href="#3-成本效益比较" class="headerlink" title="3. 成本效益比较"></a>3. 成本效益比较</h3><ul>
<li><strong>GP2</strong>：容量需达到 5,000 GiB 才能获得 15,000 IOPS（3 IOPS&#x2F;GiB），这意味着必须为不必要的容量付费 → 不经济。</li>
<li><strong>io1&#x2F;io2</strong>：为高 IOPS 和高耐久性设计（通常用于关键任务，99.999% 耐久性），成本高于 GP3，适合需要极高 IOPS（超过 16,000）或强耐久性的场景。</li>
<li><strong>GP3</strong>：基准 3,000 IOPS（免费），可以按 1,000 IOPS 增量购买额外性能，15,000 IOPS 只需在基准上增加 12,000 IOPS（额外付费），但容量可以很小（如 100 GiB），整体成本通常低于 GP2（当 IOPS 需求高、容量需求低时）。</li>
</ul>
<p><br>426 公司情况：</p>
<ul>
<li>医疗保健应用程序数据经常变化。</li>
<li>新法规要求 <strong>对所有存储数据层级进行审计访问</strong>。</li>
<li>当前应用程序托管在本地，<strong>存储容量即将耗尽</strong>。</li>
<li>需要将 <strong>现有数据安全迁移到 AWS</strong>，同时满足审计法规。</li>
</ul>
<p>问：哪种解决方案能满足要求？</p>
<p><u>A. 使用 <strong>AWS DataSync</strong> 将数据迁移到 <strong>Amazon S3</strong>，用 <strong>AWS CloudTrail 记录数据事件</strong></u>。<br>B. 使用 <strong>AWS Snowcone</strong> 将数据迁移到 <strong>Amazon S3</strong>，用 <strong>AWS CloudTrail 记录管理事件</strong>。<br>C. 使用 <strong>Amazon S3 Transfer Acceleration</strong> 将数据迁移到 <strong>Amazon S3</strong>，用 <strong>AWS CloudTrail 记录数据事件</strong>。<br>D. 使用 <strong>AWS Storage Gateway</strong> 将数据迁移到 <strong>Amazon S3</strong>，用 <strong>AWS CloudTrail 记录管理事件</strong>。</p>
<ul>
<li><p>迁移工具选择：</p>
<ul>
<li><strong>DataSync</strong>：专用于在线、自动、增量将本地文件系统或 NAS 数据同步到 AWS（S3、EFS、FSx），适合持续变化的数据，且支持加密、验证。</li>
<li><strong>Snowcone</strong>：离线设备，适合网络慢、数据量大、无带宽迁移的场景，但不适合数据经常变化时的初次迁移后的持续同步（除非只迁移一次历史数据）。</li>
<li><strong>S3 Transfer Acceleration</strong>：利用 CloudFront 边缘站点加速上传到 S3，只是加速网络传输，不是完整迁移管理工具。</li>
<li><strong>Storage Gateway</strong>：提供本地缓存与 S3 同步，可作为混合存储方案，但迁移数据不是其主要设计目标（它是为了让本地应用透明访问云存储）。</li>
</ul>
</li>
<li><p>AWS CloudTrail 分两种事件：</p>
<ul>
<li><strong>管理事件</strong>：对 AWS 资源进行配置&#x2F;管理的 API 调用（如创建桶）。</li>
<li><strong>数据事件</strong>：对资源内数据操作的 API 调用（如 <code>GetObject</code>、<code>PutObject</code>）。</li>
</ul>
</li>
<li><p>审计存储数据访问必须启用 <strong>数据事件记录</strong>。</p>
</li>
</ul>
<p><br>427 解决方案架构师要部署一个 <strong>复杂 Java 应用程序</strong>，条件：</p>
<ol>
<li>必须部署在 <strong>Apache Tomcat</strong> 上。</li>
<li>必须 <strong>具备高可用性</strong>。</li>
<li>带有 <strong>MySQL 数据库</strong>（这是应用程序的一部分）。</li>
</ol>
<p>问：应采取什么措施来满足这些要求？</p>
<p>A. 在 <strong>AWS Lambda</strong> 中部署应用程序，配置 <strong>Amazon API Gateway</strong> 连接 Lambda 函数。<br>B. <u>使用 <strong>AWS Elastic Beanstalk</strong> 部署应用程序，配置 <strong>负载均衡环境和滚动部署</strong>。</u><br>C. 将数据库迁移到 <strong>Amazon ElastiCache</strong>，配置安全组允许应用访问。<br>D. 启动一个 <strong>Amazon EC2 实例</strong>，安装 MySQL 和 Tomcat，制作 AMI，用 <strong>启动模板和自动扩展组</strong> 部署。</p>
<ul>
<li><strong>Apache Tomcat</strong> → Java 应用程序需要在 Web 容器（Tomcat）中运行，这属于传统 Web 应用服务器模式，不是无服务器函数。</li>
<li><strong>高可用性</strong> → 需要多实例、跨可用区部署、负载均衡、自动恢复。</li>
</ul>
<p>Elastic Beanstalk 是 AWS 针对 Web 应用（包括 Java&#x2F;Tomcat）的托管平台服务</p>
<p><br>428 无服务器应用使用：</p>
<ul>
<li>Amazon API Gateway</li>
<li>AWS Lambda</li>
<li>Amazon DynamoDB</li>
</ul>
<p>Lambda 函数需要对 DynamoDB 表进行 <strong>读写权限</strong>。<br>问：哪种方案能 <strong>最安全地</strong> 让 Lambda 函数访问 DynamoDB 表？</p>
<p>A. 创建 IAM 用户（具有编程访问权限），附加策略允许读写 DynamoDB 表，将 access_key_id 和 secret_access_key 存为 Lambda 环境变量，确保其他 AWS 用户没有对 Lambda 函数配置的读写权限。</p>
<p>B. <u>创建 IAM 角色（包含 Lambda 作为可信服务），附加策略允许读写 DynamoDB 表，更新 Lambda 函数配置，使用该角色作为执行角色。</u></p>
<p>C. 创建 IAM 用户（具有编程访问权限），附加策略允许读写 DynamoDB 表，将凭据作为安全字符串存在 AWS Systems Manager Parameter Store 中，更新 Lambda 代码在连接 DynamoDB 前获取这些参数。</p>
<p>D. 创建 IAM 角色（包含 DynamoDB 作为可信服务），附加策略允许 Lambda 函数进行读写访问，更新 Lambda 函数代码以将新角色作为执行角色附加。</p>
<ul>
<li><strong>IAM 角色信任策略</strong> 必须允许 <code>&quot;Service&quot;: &quot;lambda.amazonaws.com&quot;</code>，这样 Lambda 服务才能代入该角色。</li>
<li>策略附加到该角色上，授予对 DynamoDB 表的读写权限。</li>
<li>在 Lambda 控制台或基础设施代码中配置 <strong>执行角色</strong> 即可</li>
</ul>
<p><br>429 给出了一个附加到 <strong>IAM 用户组</strong> 的策略（且是该组的唯一策略），内容如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ec2:*&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;StringEquals&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;ec2:Region&quot;</span><span class="punctuation">:</span> <span class="string">&quot;us-east-1&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Deny&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;ec2:StopInstances&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;ec2:TerminateInstances&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;BoolIfExists&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;aws:MultiFactorAuthPresent&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>问：该策略对组成员的有效 IAM 权限是什么？</p>
<p>A. 允许组成员在 us-east-1 执行任何 EC2 操作，<strong>Deny 语句不适用</strong>（即允许所有，MFA 条件不影响）。<br>B. 除非使用 MFA 登录，否则组成员在 us-east-1 被拒绝<strong>所有</strong> EC2 权限。<br>C. 当使用 MFA 登录时，组成员被允许在所有区域执行 <code>StopInstances</code> 和 <code>TerminateInstances</code>，并且还允许执行任何其他 EC2 操作。<br>D. <u>仅当使用 MFA 登录时，组成员才被允许在 us-east-1 有 <code>StopInstances</code> 和 <code>TerminateInstances</code> 权限，组成员在 us-east-1 内可以执行任何其他 EC2 操作。</u></p>
<p><br>430 制造公司机器传感器上传 <strong>.csv 文件到 Amazon S3 存储桶</strong>。</p>
<p>需求：</p>
<ol>
<li>CSV 文件必须转换为图像，<strong>尽快</strong>用于图形报告自动生成。</li>
<li>图像在 <strong>1 个月后</strong> 无关紧要。</li>
<li>CSV 文件必须保留，用于 <strong>每年两次的 ML 模型训练</strong>（训练和审计会提前几周计划）。</li>
<li>要求 <strong>最具成本效益</strong>。</li>
</ol>
<p>问：哪两个步骤组合能满足要求？</p>
<p>A. 启动一个 <strong>Amazon EC2 Spot 实例</strong>，每小时下载 CSV 文件、生成图像、上传图像到 S3。<br>B. <u>设计一个 <strong>AWS Lambda 函数</strong>，当上传 CSV 文件时触发，将其转换为图像并存储到 S3</u>。<br>C. 为 S3 桶中的 CSV 文件和图像文件创建 <strong>生命周期规则</strong>：CSV 文件在 <strong>1 天后从 S3 标准转为 S3 Glacier</strong>。图像文件在 <strong>30 天后过期</strong>。<br>D. <u>为 S3 桶中的 CSV 文件和图像文件创建 <strong>生命周期规则</strong>：CSV 文件在 <strong>1 天后从 S3 标准转为 S3 单区域-IA（One Zone-IA）</strong>。图像文件在 <strong>30 天后过期</strong></u>。<br>E. 为 S3 桶中的 CSV 文件和图像文件创建 <strong>生命周期规则</strong>：CSV 文件在 <strong>1 天后从 S3 标准转为 S3 标准-IA（Standard-IA）</strong>。图像文件保存在 <strong>低冗余存储（RRS）</strong> 中。</p>
<h3 id="1-实时性要求"><a href="#1-实时性要求" class="headerlink" title="1. 实时性要求"></a>1. 实时性要求</h3><ul>
<li>CSV 文件必须 <strong>尽快</strong> 转为图像 → 最佳方式是文件上传后立即触发转换，而不是每小时批量（A 选项的 Spot 实例每小时运行一次不符合“尽快”）。</li>
<li><strong>Lambda 函数（B）</strong> 由 S3 事件触发，可实现实时处理，无服务器，按实际使用付费，对于突发性传感器数据适合且成本效益高。</li>
</ul>
<h3 id="2-存储成本优化需求"><a href="#2-存储成本优化需求" class="headerlink" title="2. 存储成本优化需求"></a>2. 存储成本优化需求</h3><ul>
<li>CSV 文件需保留用于每年两次 ML 训练，且训练会提前几周计划 → 不需要实时访问，但需要可靠存储。</li>
<li>图像 1 个月后不再需要 → 可以设置过期删除（节省存储成本）。</li>
<li><strong>生命周期策略</strong> 可以自动转换存储层级或删除对象。</li>
</ul>
<h3 id="3-CSV-存储层级选择"><a href="#3-CSV-存储层级选择" class="headerlink" title="3. CSV 存储层级选择"></a>3. CSV 存储层级选择</h3><ul>
<li>每年仅用两次，可放在低频访问层，但注意：<ul>
<li><strong>S3 Glacier（C）</strong>：检索需要时间和费用（虽然便宜，但 ML 训练可能需要批量读取大量 CSV，Glacier 检索较慢且额外收费）。</li>
<li><strong>S3 单区域-IA（D）</strong>：成本比标准-IA 低，但 <strong>数据只存在一个 AZ</strong>，有丢失风险。CSV 文件用于 ML 训练，虽不常用但可能有长期价值，单区域-IA 耐久性稍低（99.999999999% → 99.999999999%? 实际上是 99.999999999% 的对象耐久性，但可用性 SLA 较低，且单 AZ 故障可能暂时不可用，但数据不丢），但题中未强调必须跨 AZ，考虑到成本效益，单区域-IA 可能可以接受，但需判断是否适合每年两次的 ML 训练（提前几周计划，可用性风险可接受）。不过通常 ML 训练数据会希望更可靠，标准-IA 可能更保险。</li>
<li><strong>S3 标准-IA（E）</strong>：跨 3 个 AZ，比单区域-IA 贵，但更可靠。对每年两次的用途，可能 E 更稳妥。</li>
</ul>
</li>
<li>但题要求 <strong>最具成本效益</strong>，且 ML 训练可提前几周计划，单区域-IA 更便宜且能满足可用性要求（提前计划时可以确认数据可访问）。</li>
</ul>
<h3 id="4-图像存储策略"><a href="#4-图像存储策略" class="headerlink" title="4. 图像存储策略"></a>4. 图像存储策略</h3><ul>
<li>图像 1 个月后无关紧要 → 可以 <strong>过期删除</strong>（C、D 正确），而非继续放在低冗余存储（E 的低冗余存储已不推荐，且未提过期）。</li>
<li>低冗余存储（RRS）不是生命周期操作，且已不推荐使用，E 不合适。</li>
</ul>
<p><br>431 公司开发新的视频游戏（Web 应用），三层架构，在 VPC 中：</p>
<ul>
<li>数据库层用 <strong>Amazon RDS MySQL</strong>。</li>
<li>多个玩家同时在线竞技。</li>
<li>需求：<ol>
<li>近乎实时显示 <strong>前十名排行榜</strong>。</li>
<li>提供 <strong>暂停和恢复游戏功能</strong>，同时保留当前分数。</li>
</ol>
</li>
</ul>
<p>问：解决方案架构师应采取什么措施来满足这些要求？</p>
<p>A. 为 <strong>Memcached 集群</strong> 设置 Amazon ElastiCache，缓存 Web 应用要显示的分数。<br>B. <u>为 <strong>Redis</strong> 设置 Amazon ElastiCache 集群，计算并缓存 Web 应用要显示的分数</u>。<br>C. 在 Web 应用前放 <strong>Amazon CloudFront</strong> 分发，缓存记分牌部分。<br>D. 在 RDS MySQL 上创建 <strong>只读副本</strong>，运行查询计算计分板，为 Web 应用提供读取流量。</p>
<p><strong>（Memcached）</strong>：</p>
<ul>
<li>Memcached 是纯内存键值存储，适合简单缓存，不支持复杂数据结构与排序，也不支持持久化（虽然可设置持久化但非原生强项）。</li>
<li>不能方便地“计算”排行榜（需要应用层取数据排序再缓存），且 Memcached 没有内置排序功能。</li>
</ul>
<p><strong>（Redis）</strong>：</p>
<ul>
<li>Redis 支持丰富数据结构，如 <strong>有序集合（Sorted Set）</strong>，可以天然地存储玩家分数并实时获取排名前 N。</li>
<li>支持持久化（RDB&#x2F;AOF），适合存储游戏状态以便暂停&#x2F;恢复。</li>
<li>ElastiCache for Redis 可以实现高并发读写，满足近乎实时排行榜需求。</li>
</ul>
<p><strong>（CloudFront）</strong>：</p>
<ul>
<li>CDN 用于缓存静态内容，但排行榜数据是动态的（实时变化），不适合用 CDN 缓存（除非边缘计算，但此题无此描述），且无法解决数据存储与排序问题。</li>
</ul>
<p><strong>（RDS 只读副本）</strong>：</p>
<ul>
<li>可以分担主库的查询压力，但仍需在 MySQL 中执行 <code>ORDER BY ... LIMIT 10</code>，当并发高、更新频繁时，性能仍可能不足，且无法达到“近乎实时”低延迟（与 Redis 内存排序相比）。</li>
</ul>
<p><br>432 电子商务公司希望：</p>
<ol>
<li>使用 <strong>机器学习算法</strong> 构建和训练模型。</li>
<li>利用模型 <strong>可视化复杂场景</strong> 并 <strong>检测客户数据中的趋势</strong>。</li>
<li>将 ML 模型与 <strong>报告平台集成</strong>，分析增强数据并直接用于 <strong>商业智能仪表板</strong>。</li>
<li>以 <strong>最少的运营开销</strong> 满足要求。</li>
</ol>
<p>A. 使用 <strong>AWS Glue</strong> 创建机器学习转换来构建和训练模型，用 <strong>Amazon OpenSearch Service</strong> 可视化数据。<br>B. <u>使用 <strong>Amazon SageMaker</strong> 构建和训练模型，用 <strong>Amazon QuickSight</strong> 可视化数据。</u><br>C. 使用 <strong>AWS Marketplace 中的预构建机器学习 AMI</strong> 构建和训练模型，用 <strong>Amazon OpenSearch</strong> 可视化数据。<br>D. 使用 <strong>Amazon QuickSight</strong> 通过计算字段构建和训练模型，用 <strong>Amazon QuickSight</strong> 可视化数据。</p>
<ul>
<li><strong>SageMaker</strong> 是 AWS 上 ML 建模的托管服务标准，减少运维负担。</li>
<li><strong>QuickSight</strong> 是 AWS 上 BI 与仪表板的托管服务，两者无缝集成，适合“分析增强数据并直接用于 BI 仪表板”。</li>
</ul>
<p><br>433 公司在多个 AWS 账户中运行生产和非生产工作负载，这些账户属于 <strong>AWS Organizations</strong> 中的一个组织。</p>
<p>要求：设计解决方案，<strong>防止成本使用标签被修改</strong>。</p>
<p>A. 创建自定义 <strong>AWS Config 规则</strong>，防止除授权主体外的用户修改标签。<br>B. 在 <strong>AWS CloudTrail</strong> 中创建自定义跟踪以防止标签修改。<br>C. <u>创建 <strong>服务控制策略（SCP）</strong>，防止标签被修改，除非由授权主体进行操作</u>。<br>D. 创建自定义的 <strong>Amazon CloudWatch 日志</strong> 以防止标签修改。</p>
<ul>
<li>“防止成本使用标签被修改” → 要阻止对标签（特别是用于成本分配的标签）的更改操作，比如 <code>ec2:CreateTags</code>、<code>ec2:DeleteTags</code>、<code>resource-groups:Tag</code> 等。</li>
</ul>
<p>AWS Config 规则用于评估资源是否符合规则，可以检测标签修改并告警或触发修复动作，但它 <strong>不能主动阻止</strong> 修改操作的发生</p>
<p>Config、CloudTrail、CloudWatch 都是监控&#x2F;审计工具，无法阻止操作发生</p>
<ul>
<li>SCP 是 AWS Organizations 中用于集中控制成员账户权限的策略，可以对所有账户强制执行“Deny”规则，适合在组织层面统一禁止标签修改，而无需在每个账户单独设置 IAM 策略。</li>
</ul>
<p><br>434 公司在 AWS 托管应用，架构如下：</p>
<ul>
<li>应用运行在 <strong>自动扩展组（ASG）</strong> 的 EC2 实例上。</li>
<li>前面有 <strong>弹性负载均衡器（ELB）</strong>。</li>
<li>后端有 <strong>Amazon DynamoDB 表</strong>。</li>
</ul>
<p>目标：确保应用能在另一个 AWS 区域可用，<strong>停机时间最短</strong>。</p>
<p>问：解决方案架构师应采取什么措施，以最少停机时间满足要求？</p>
<p>A. <u>在灾难恢复（DR）区域创建一个 ASG 和一个 ELB，将 DynamoDB 表配置为 <strong>全局表</strong>，配置 <strong>DNS 故障转移</strong> 指向 DR 区域的 ELB。</u><br>B. 创建一个 <strong>CloudFormation 模板</strong>，用于在需要时启动 EC2 实例、ELB 和 DynamoDB 表，配置 DNS 故障转移指向 DR 区域的 ELB。<br>C. 创建一个 <strong>CloudFormation 模板</strong>，用于在需要时启动 EC2 实例和 ELB，将 DynamoDB 表配置为 <strong>全局表</strong>，配置 DNS 故障转移指向 DR 区域的 ELB。<br>D. 在 DR 区域创建一个 ASG 和 ELB，将 DynamoDB 表配置为 <strong>全局表</strong>，创建一个 <strong>CloudWatch 警报</strong> 触发 Lambda 函数更新 Route 53 指向 DR 的 ELB。</p>
<ul>
<li>对于 <strong>最短停机时间</strong>，计算层应在 DR 区域 <strong>预先部署</strong>（可以是暖备，最小实例运行）。</li>
<li>数据库层用 DynamoDB 全局表实现跨区域实时复制。</li>
<li>流量切换用 Route 53 基于健康检查的 DNS 故障转移（或更快的 Global Accelerator&#x2F;CLB 跨区域，但题中选项只有 DNS）。</li>
</ul>
<p><br>435 公司需要 <strong>两周内</strong> 将本地 MySQL 数据库迁移到 AWS：</p>
<ul>
<li>数据库大小 <strong>20 TB</strong>（20 大字节 &#x3D; 20 TB）。</li>
<li>要求 <strong>最少停机时间</strong>。</li>
<li>要求 <strong>最具成本效益</strong>。</li>
</ul>
<p>A. <u>订购 <strong>AWS Snowball Edge 存储优化设备</strong>，用 AWS DMS + SCT 迁移数据库并持续复制变更，将设备送回 AWS 完成迁移并继续复制。</u><br>B. 订购 <strong>AWS Snowmobile</strong> 设备，用 AWS DMS + SCT 迁移数据库并持续复制变更，将设备送回 AWS 完成迁移并继续复制。<br>C. 订购 <strong>AWS Snowball Edge Compute Optimized（带 GPU）</strong>，用 AWS DMS + SCT 迁移数据库并持续复制变更，将设备送回 AWS 完成迁移并继续复制。<br>D. 订购 <strong>1 GB 专用 AWS Direct Connect</strong> 连接，用 AWS DMS + STS 迁移数据库并持续复制变更。</p>
<p>Snowmobile → 用于 <strong>PB 级</strong> 数据（如 100 PB 以上），20 TB 用 Snowmobile 不经济（超大规模才用），成本过高</p>
<p>Snowball Edge Compute Optimized（带 GPU）→ GPU 在此场景无用，且成本高于存储优化型，不经济</p>
<p><br>436 公司将本地 PostgreSQL 数据库迁移到 <strong>Amazon RDS for PostgreSQL 数据库实例</strong>。</p>
<ul>
<li>新产品推出，<strong>数据库工作负载增加</strong>。</li>
<li>希望 <strong>在不增加基础设施的情况下</strong> 应对更大的工作负载。</li>
<li>要求 <strong>最具成本效益</strong>。</li>
</ul>
<p>A. <u>为总工作负载 <strong>购买预留实例</strong>，<strong>增大</strong> RDS PostgreSQL 数据库实例的规模。</u><br>B. 将 RDS PostgreSQL 数据库实例 <strong>设置为多可用区（Multi-AZ）实例</strong>。<br>C. 为总工作负载 <strong>购买预留实例</strong>，再 <strong>添加一个</strong> RDS PostgreSQL 数据库实例。<br>D. 将 RDS PostgreSQL 数据库实例设为 <strong>按需数据库实例</strong>。</p>
<p><br>437 公司电子商务网站架构：</p>
<ul>
<li>EC2 实例在 Auto Scaling 组中。</li>
<li>前端有 <strong>应用程序负载均衡器（ALB）</strong>。</li>
<li>遭遇问题：来自 <strong>具有不断变化 IP 地址的非法外部系统</strong> 的高请求率。</li>
<li>安全团队担心可能是 <strong>DDoS 攻击</strong>。</li>
<li>要求：以 <strong>对合法用户影响最小</strong> 的方式阻止非法传入请求。</li>
</ul>
<p>A. 部署 <strong>Amazon Inspector</strong>，将其与 ALB 关联。<br>B. <u>部署 <strong>AWS WAF</strong>，将其与 ALB 关联，并配置 <strong>速率限制规则</strong></u>。<br>C. 向与 ALB 关联的 <strong>网络访问控制列表（NACL）</strong> 部署规则，以阻止传入流量。<br>D. 部署 <strong>Amazon GuardDuty</strong>，并在配置 GuardDuty 时启用 <strong>速率限制保护</strong>。</p>
<ul>
<li>对于 ALB 后的应用层 DDoS，AWS 推荐使用 <strong>AWS WAF</strong> 的速率限制规则。</li>
<li>如果还涉及大规模网络层 DDoS，可结合 AWS Shield Standard（自动提供）或 Advanced。</li>
</ul>
<p><br>438 公司希望与外部审计师共享会计数据：</p>
<ul>
<li>数据存储在 <strong>私有子网中的 Amazon RDS 数据库实例</strong>。</li>
<li>审计师 <strong>拥有自己的 AWS 账户</strong>。</li>
<li>审计师需要 <strong>属于自己的数据库副本</strong>（不是直接访问原库）。</li>
<li>问：最安全的方式是什么？</li>
</ul>
<p>A. 创建数据库的 <strong>只读副本</strong>，配置 <strong>IAM 数据库认证</strong> 以授予审计员访问权限。<br>B. 将数据库内容 <strong>导出到文本文件</strong>，存到 <strong>Amazon S3</strong>，为审计员创建一个 <strong>IAM 用户</strong>，授予其对 S3 的访问权限。<br>C. 将数据库的 <strong>快照复制到 Amazon S3</strong>，创建 <strong>IAM 用户</strong>，与审计员共享该用户的 <strong>密钥</strong>，授予其对 S3 的访问权限。<br>D. <u>创建数据库的 <strong>加密快照</strong>，与审计员 <strong>共享该快照</strong>，允许访问 <strong>AWS KMS 加密密钥</strong>。</u></p>
<ul>
<li>快照是静态加密的。</li>
<li>跨账户共享快照是 AWS 原生功能，无需数据导出到中间存储（如 S3）的额外步骤。</li>
<li>配合 KMS 密钥跨账户授权，审计师能解密并还原数据库，数据不经过公共网络。</li>
<li>审计师获得的是 <strong>独立副本</strong>，不影响原数据库，且完成后可自行删除。</li>
</ul>
<p><br>439 解决方案架构师配置了一个 VPC，其 <strong>IPv4 CIDR 范围较小</strong>。</p>
<ul>
<li>VPC 内的 EC2 实例数量增加，导致 <strong>IP 地址数量不足</strong>。</li>
<li>未来工作负载也需要更多 IP。</li>
<li>要求以 <strong>最小的运营开销</strong> 解决问题。</li>
</ul>
<p>A. <u>添加一个额外的 IPv4 CIDR 块以增加 IP 地址数量，并在 VPC 中创建额外的子网，在新子网中创建新资源。</u><br>B. 创建第二个 VPC（带额外子网），使用 <strong>VPC 对等连接</strong> 连接两个 VPC，更新路由，在第二个 VPC 中创建新资源。<br>C. 使用 <strong>AWS Transit Gateway</strong> 连接第二个 VPC 与第一个 VPC，更新路由，在第二个 VPC 中创建新资源。<br>D. 创建第二个 VPC，使用 <strong>站点到站点 VPN</strong>（通过虚拟专用网关和 EC2 VPN 解决方案）连接两个 VPC，更新路由，在第二个 VPC 中创建新资源。</p>
<p><br>440 公司在测试期间使用了 <strong>Amazon RDS for MySQL 数据库实例</strong>。<br>测试周期结束后，终止实例前，解决方案架构师创建了两份备份：</p>
<ol>
<li>使用 <strong>mysqldump 工具</strong> 创建 <strong>数据库转储文件</strong>（逻辑备份）。</li>
<li>启用 <strong>最终数据库快照选项</strong> 创建了一个 <strong>RDS 快照</strong>。</li>
</ol>
<p>现在公司计划新测试周期，希望从 <strong>最近的备份中创建一个新的数据库实例</strong>，并且已选择 <strong>与 MySQL 兼容的 Amazon Aurora 版本</strong> 来托管此数据库。</p>
<p>问：哪些解决方案将创建新的数据库实例？（选两项）</p>
<p>A. <u>直接将 <strong>RDS 快照导入 Aurora</strong>。</u><br>B. 将 <strong>RDS 快照上传到 Amazon S3</strong>，然后将该快照导入 Aurora。<br>C. <u>将 <strong>数据库转储上传到 Amazon S3</strong>，然后将数据库转储导入 Aurora。</u><br>D. 使用 <strong>AWS DMS</strong> 将 RDS 快照导入 Aurora。<br>E. 将 <strong>数据库转储上传到 Amazon S3</strong>，然后使用 <strong>AWS DMS</strong> 将数据库转储导入 Aurora。</p>
<ul>
<li><strong>RDS 快照（RDS for MySQL 的快照）</strong> 可以 <strong>直接还原</strong> 到 <strong>RDS for MySQL</strong> 实例，也可以 <strong>转换为 Aurora</strong>（通过 Aurora 的 <strong>从 RDS 快照还原</strong> 功能或 <strong>快照导入 Aurora</strong> 功能）。</li>
<li><strong>mysqldump 转储文件（逻辑备份）</strong> 可以 <strong>导入到新的 Aurora</strong> 实例，通常步骤是：<ol>
<li>将转储文件上传到 S3。</li>
<li>在 Aurora 实例中使用 <code>mysql</code> 客户端或 Aurora 的 <strong>从 S3 恢复</strong> 功能（对逻辑备份需执行 SQL 文件）。</li>
</ol>
</li>
</ul>
<p><br>441 公司托管一个多层 Web 应用程序：</p>
<ul>
<li>架构：<strong>应用程序负载均衡器（ALB）</strong> 后是 <strong>Amazon Linux EC2 实例</strong>，在多 AZ 的 <strong>Auto Scaling 组</strong> 中运行。</li>
<li>问题：当最终用户访问 <strong>大量静态 Web 内容</strong> 时，ASG 会启动更多 <strong>按需实例</strong>。</li>
<li>目标：<strong>优化成本</strong>（最具成本效益）。</li>
</ul>
<p>问：解决方案架构师应如何重新设计应用程序？</p>
<p>A. 更新 ASG，使用 <strong>预留实例</strong> 而非按需实例。<br>B. 更新 ASG，通过启动 <strong>竞价型实例</strong> 而非按需实例来扩展。<br><u>C. 创建一个 <strong>Amazon CloudFront 分发</strong>，用于从 <strong>Amazon S3 存储桶</strong> 托管静态网页内容。</u><br>D. 在 <strong>Amazon API Gateway API</strong> 后创建一个 <strong>AWS Lambda 函数</strong> 来托管静态网站内容。</p>
<p><br>442 公司在 <strong>多个 AWS 账户</strong> 中存储了数 PB 的数据。</p>
<ul>
<li>使用 <strong>AWS Lake Formation</strong> 管理数据湖。</li>
<li>数据科学团队希望 <strong>安全地将其账户中的特定数据与工程团队共享</strong>（用于分析目的）。</li>
<li>要求：<strong>最少的运营开销</strong>。</li>
</ul>
<p>A. 将所需数据复制到一个 <strong>公共账户</strong>，在该账户中创建 <strong>IAM 访问角色</strong>，通过权限策略指定工程团队账户用户为可信实体来授予访问权限。<br>B. <strong><u>在存储数据的每个账户中使用 Lake Formation 权限授予命令，允许所需的工程团队用户访问数据</u></strong>。<br>C. 使用 <strong>AWS Data Exchange</strong> 向工程团队账户私下发布所需数据。<br>D. 使用 <strong>Lake Formation 基于标签的访问控制（LF-TBAC）</strong> 来授权并为所需数据授予 <strong>跨账户权限</strong> 给工程团队账户。</p>
<h3 id="理解-Lake-Formation-跨账户共享方式"><a href="#理解-Lake-Formation-跨账户共享方式" class="headerlink" title="理解 Lake Formation 跨账户共享方式"></a>理解 Lake Formation 跨账户共享方式</h3><p>Lake Formation 支持跨账户共享数据目录（Data Catalog）和底层数据（S3）而无需复制数据，主要方法：</p>
<ol>
<li><strong>直接跨账户授权</strong>：在数据所有者账户中，使用 Lake Formation 向 <strong>目标账户</strong> 或该账户中的特定 IAM 主体授予权限（通过 <code>GrantPermissions</code> API&#x2F;控制台）。</li>
<li><strong>基于资源的跨账户共享</strong>：通过 Lake Formation 数据单元格过滤器（Data Cell Filters）或标签（LF-TBAC）实现跨账户权限。</li>
<li><strong>跨账户 IAM 角色</strong>：传统方式（A 选项），但涉及数据复制和手动 IAM 策略管理，开销大。</li>
</ol>
<p><br>443 公司希望在 AWS 上托管一个 <strong>可扩展的 Web 应用程序</strong>：</p>
<ul>
<li>用户来自 <strong>世界不同地理区域</strong>。</li>
<li>用户能够 <strong>下载和上传高达千兆字节（GB 级）的独特数据</strong>。</li>
<li>目标：<strong>经济高效</strong>，<strong>最小化上传下载延迟</strong>，<strong>提高性能</strong>。</li>
</ul>
<p>问：解决方案架构师应采取什么措施？</p>
<p>A. 使用 <strong>带传输加速功能的 Amazon S3</strong> 来托管应用程序。<br>B. 使用 <strong>带 CacheControl 标头的 Amazon S3</strong> 来托管应用程序。<br>C. <u>使用 <strong>带自动扩展的 Amazon EC2 和 Amazon CloudFront</strong> 来托管应用程序</u>。<br>D. 使用 <strong>带自动扩展的 Amazon EC2 和 Amazon ElastiCache</strong> 来托管应用程序。</p>
<p>444公司应用程序当前架构：</p>
<ul>
<li><strong>Amazon RDS 数据库实例</strong>（单可用区）。</li>
<li><strong>两个手动配置的 EC2 实例</strong>（运行 Web 服务器），位于 <strong>单个可用区</strong>。</li>
</ul>
<p>问题：</p>
<ul>
<li>员工删除了数据库实例，导致应用中断 <strong>24 小时</strong>。</li>
<li>公司对 <strong>整体可靠性</strong> 表示担忧。</li>
</ul>
<p>目标：<strong>最大程度提高应用程序基础设施的可靠性</strong>。</p>
<p>A. 删除一个 EC2 实例，在另一个 EC2 实例上启用终止保护；将数据库实例更新为多可用区，并启用删除保护。<br>B. <u>将数据库实例更新为多可用区，并启用删除保护；将 EC2 实例置于应用负载均衡器后，并在多可用区的 EC2 自动扩展组中运行它们。</u><br>C. 创建一个额外的数据库实例，以及 API Gateway + Lambda 函数；配置应用通过 API Gateway 调用 Lambda，让 Lambda 写入两个数据库实例。<br>D. 将 EC2 实例放在多可用区多个子网的自动扩展组中，使用 Spot 实例；设 CloudWatch 监控；将数据库更新为多可用区并启用删除保护。</p>
<p>使用 <strong>Spot 实例</strong> 会引入中断风险，降低可靠性（虽然成本低，但题目要求最大可靠性，不应使用 Spot）</p>
<p><br>445 公司情况：</p>
<ul>
<li>企业数据中心有 <strong>700 TB 数据</strong> 存储在 <strong>大型 NAS</strong> 上。</li>
<li>混合环境，有 <strong>10 Gbps AWS Direct Connect</strong> 连接。</li>
<li>监管审计要求 <strong>90 天内</strong> 将数据迁移到云端。</li>
<li>要求：<ol>
<li><strong>高效</strong>。</li>
<li><strong>无中断</strong>。</li>
<li><strong>迁移期间仍需能够访问和更新这些数据</strong>（即不能停写）。</li>
</ol>
</li>
</ul>
<p>A. <u>在本地创建一个 <strong>AWS DataSync 代理</strong>，创建数据传输任务，启动传输到 <strong>Amazon S3 存储桶</strong>。</u><br>B. 将数据备份到 <strong>AWS Snowball Edge 存储优化设备</strong>，运送设备到 AWS，在本地文件系统上挂载目标 S3 存储桶。<br>C. 使用 <strong>rsync</strong> 通过 Direct Connect 将数据从本地直接复制到 S3 存储桶。<br>D. 将数据备份到 <strong>磁带</strong>，运送磁带到 AWS，在本地文件系统上挂载目标 S3 存储桶。</p>
<p>Snowball 是离线迁移，设备寄送期间数据可能变化，且选项后半句“在本地文件系统上挂载目标 S3 存储桶”是指用 File Gateway 之类的混合方案，但不代表数据迁移期间本地 NAS 能持续写入并同步到 S3（需要额外配置）</p>
<p><br>446 公司数据：</p>
<ul>
<li><strong>PDF 格式</strong> 存储在 <strong>Amazon S3 存储桶</strong>。</li>
<li>法律要求：将所有 <strong>新数据和现有数据保留 7 年</strong>。</li>
<li>要求：以 <strong>最少的运营开销</strong> 满足。</li>
</ul>
<p>A. 开启 <strong>S3 版本控制</strong>，配置生命周期在 7 年后删除数据，为所有对象配置 <strong>MFA 删除</strong>。<br>B. 开启 <strong>S3 对象锁定</strong>（治理保留模式），保留期设为 7 年后过期，<strong>重新复制所有现有对象</strong>。<br>C. <u>开启 <strong>S3 对象锁定</strong>（合规性保留模式），保留期设为 7 年后过期，<strong>重新复制所有现有对象</strong>。</u><br>D. 开启 <strong>S3 对象锁定</strong>（合规性保留模式），保留期设为 <strong>7 天后过期</strong>。</p>
<p><br>447 公司有一个无状态 Web 应用：</p>
<ul>
<li>运行在 <strong>AWS Lambda 函数</strong> 上，由 <strong>Amazon API Gateway</strong> 调用。</li>
<li>希望在 <strong>多个 AWS 区域</strong> 部署此应用，以提供 <strong>区域故障转移</strong> 能力。</li>
<li>问：解决方案架构师应如何将流量路由到多个区域？</li>
</ul>
<p>A. <u>为每个区域创建 <strong>Amazon Route 53 健康检查</strong>，使用 <strong>双活故障转移</strong> 配置</u>。<br>B. 为每个区域创建一个带有 <strong>源站</strong> 的 <strong>Amazon CloudFront 分发</strong>，使用 CloudFront 健康检查来路由流量。<br>C. 创建一个 <strong>中转网关（Transit Gateway）</strong>，将其附加到每个区域中的 API 网关终端节点，配置中转网关以路由请求。<br>D. 在 <strong>主区域创建一个应用程序负载均衡器（ALB）</strong>，将目标组设置为指向每个区域中的 API 网关端点主机名。</p>
<p>对于跨区域故障转移的无服务器应用（API Gateway + Lambda），标准模式是：</p>
<ol>
<li>在每个区域部署完整的应用栈（API Gateway + Lambda）。</li>
<li>使用 <strong>Route 53</strong> 配置健康检查并设置路由策略（如故障转移或加权）。</li>
<li>用户通过同一个域名访问，Route 53 根据健康状态解析到不同区域的 API Gateway 端点。</li>
</ol>
<p><br>448 公司有两个 VPC：</p>
<ol>
<li><strong>管理 VPC</strong>：通过 <strong>VPN</strong> 连接到数据中心的 <strong>单个设备</strong>（客户网关设备）。</li>
<li><strong>生产 VPC</strong>：使用 <strong>虚拟专用网关</strong> 并附带有 <strong>两个 Direct Connect 连接</strong>。</li>
</ol>
<p>两个 VPC 之间使用 <strong>单个 VPC 对等连接</strong> 实现通信。</p>
<p>目标：<strong>减轻该架构中的单点故障</strong>。</p>
<p>A. 在管理 VPC 和生产 VPC 之间添加 <strong>一组 VPN</strong>。<br>B. 添加 <strong>第二个虚拟专用网关</strong> 并将其附加到管理 VPC。<br>C. <u>从 <strong>第二个客户网关设备</strong> 向管理 VPC 添加 <strong>第二组 VPN</strong>。</u><br>D. 在管理 VPC 和生产 VPC 之间添加 <strong>第二个 VPC 对等连接</strong></p>
<h3 id="1-分析现有架构的单点故障"><a href="#1-分析现有架构的单点故障" class="headerlink" title="1. 分析现有架构的单点故障"></a>1. 分析现有架构的单点故障</h3><ul>
<li><strong>管理 VPC 到数据中心的连接</strong>：只有 <strong>一个客户网关设备 + 一组 VPN</strong> → 如果该设备故障，管理 VPC 与数据中心的连接中断（单点故障）。</li>
<li><strong>生产 VPC 到数据中心的连接</strong>：已有虚拟专用网关 + 两个 Direct Connect 连接 → 已经是高可用（两个物理连接）。</li>
<li><strong>两个 VPC 之间的连接</strong>：单个 VPC 对等连接 → VPC 对等连接本身是区域级服务，没有“多个对等连接”来提升可用性的概念（对等连接是逻辑连接，其底层是 AWS 骨干网，通常不需要冗余对等连接来提高可用性，但题目可能认为需要冗余？实际上 VPC 对等连接在单个区域不提供“双活”配置，因为它不是物理链路）。</li>
</ul>
<h3 id="2-最明显的单点故障"><a href="#2-最明显的单点故障" class="headerlink" title="2. 最明显的单点故障"></a>2. 最明显的单点故障</h3><p>是 <strong>管理 VPC 连接数据中心的单一客户网关设备</strong>。因此应增加 <strong>第二个客户网关设备 + 第二组 VPN</strong> 以实现高可用 VPN 连接。</p>
<p><br>449 公司应用运行在 <strong>Oracle 数据库</strong> 上。</p>
<ul>
<li>由于 <strong>数据库、备份管理和数据中心维护的资源有限</strong>，计划快速迁移到 AWS。</li>
<li>应用使用 <strong>需要特权访问的第三方数据库功能</strong>（如需要 OS 级别访问或自定义数据库二进制文件的扩展）。</li>
<li>要求：以 <strong>最具成本效益</strong> 的方式迁移数据库。</li>
</ul>
<p>A. 将数据库迁移到 <strong>Amazon RDS for Oracle</strong>，用云服务替换第三方功能。<br>B. <u>将数据库迁移到 <strong>Amazon RDS Custom for Oracle</strong>，自定义数据库设置以支持第三方功能。</u><br>C. 将数据库迁移到 <strong>Oracle 的 Amazon EC2 AMI</strong>，自定义数据库设置以支持第三方功能。<br>D. 重写应用代码，消除对 Oracle 的依赖，迁移到 <strong>Amazon RDS for PostgreSQL</strong>。</p>
<ul>
<li><strong>RDS Custom for Oracle</strong> 允许客户访问底层 EC2 实例（SSH&#x2F;RDP），可以自定义配置、安装第三方软件，同时仍由 AWS 管理大部分运维（如备份、补丁、高可用配置），是 RDS 与 EC2 自建之间的平衡。</li>
</ul>
<p><br>450 公司有一个 <strong>部署在单台服务器上的三层 Web 应用程序</strong>（Web 层、应用层、数据库层在同一服务器）。</p>
<ul>
<li>希望迁移到 AWS，并且 <strong>符合 AWS 架构完善框架</strong>（Well-Architected Framework）。</li>
<li>与 AWS 在 <strong>安全性、可扩展性、弹性</strong> 方面的最佳实践保持一致。</li>
</ul>
<p>问：哪些 <strong>三个解决方案组合</strong> 能够满足要求？</p>
<p>A. 利用应用程序的现有架构在两个可用区中创建一个 VPC。通过 EC2 自动扩展组，在每个可用区的私有子网中的 EC2 实例上托管具有现有架构的应用程序。使用安全组和网络 ACL 保护 EC2 实例。</p>
<p>B. 设置安全组和网络 ACL 以控制对数据库层的访问。在私有子网中设置一个 Amazon RDS 数据库。</p>
<p>C<u>. 跨两个可用区创建一个 VPC。重构应用程序以托管 Web 层、应用程序层和数据库层。将每个层托管在其自己的私有子网中，并为 Web 层和应用程序层配置自动扩展组。</u></p>
<p>D. 使用单个 Amazon RDS 数据库。仅允许来自应用层安全组的数据访问。</p>
<p>E. <u>在 Web 层前使用弹性负载均衡器。通过使用包含引用的安全组来控制访问每个层的安全组。</u></p>
<p>F. <u>在私有子网中使用 Amazon RDS 数据库多可用区集群部署。仅允许来自应用层安全组的数据访问。</u></p>
<h3 id="当前三层架构迁移目标"><a href="#当前三层架构迁移目标" class="headerlink" title="当前三层架构迁移目标"></a>当前三层架构迁移目标</h3><p>原三层在同一服务器 → 应拆分为：</p>
<ul>
<li><p><strong>Web 层</strong>：公有子网（通过 ELB 暴露）。</p>
</li>
<li><p><strong>应用层</strong>：私有子网。</p>
</li>
<li><p><strong>数据库层</strong>：私有子网（最好用 RDS 多可用区实现高可用）。</p>
</li>
<li><p><strong>C</strong>（分层、跨 AZ、ASG）✅</p>
</li>
<li><p><strong>E</strong>（ELB + 安全组引用）✅</p>
</li>
<li><p><strong>F</strong>（RDS 多可用区 + 安全组访问）✅</p>
</li>
</ul>
<p><br>451 公司将应用和数据库迁移到 AWS Cloud，使用以下服务：</p>
<ul>
<li><strong>Amazon ECS</strong></li>
<li><strong>AWS Direct Connect</strong></li>
<li><strong>Amazon RDS</strong></li>
</ul>
<p>问：公司的运维团队将负责管理 <strong>哪些活动</strong>？（选三项）</p>
<p>A. 管理 <strong>Amazon RDS 基础设施层、操作系统和平台</strong>。<br>B. <u>创建 <strong>Amazon RDS 数据库实例</strong> 并配置计划的维护窗口。</u><br>C. <u>在 Amazon ECS 上配置 <strong>额外的软件组件</strong>，用于监控、补丁管理、日志管理和主机入侵检测。</u><br>D. 为 Amazon RDS 的所有 <strong>次要和主要数据库版本安装补丁</strong>。<br>E. 确保数据中心中 <strong>Amazon RDS 基础设施的物理安全</strong>。<br>F. <u>对通过 Direct Connect 传输的 <strong>数据进行传输中加密</strong>。</u></p>
<p>对于使用的服务，客户与 AWS 的责任划分：</p>
<ul>
<li><strong>Amazon RDS（托管数据库服务）</strong>：<br>AWS 负责：基础设施、物理安全、操作系统和数据库引擎的补丁管理（包括主&#x2F;次版本升级管理）、高可用性基础设施。<br>客户负责：创建和配置实例、数据库参数调优、数据安全（加密、访问控制）、在 AWS 提供的维护窗口内应用补丁（但补丁本身由 AWS 提供并自动应用，除非客户选择手动）。</li>
<li><strong>Amazon ECS（托管容器编排）</strong>：<br>如果使用 <strong>ECS on EC2</strong> 模式，客户负责 EC2 实例的操作系统、安全补丁、监控代理等额外软件安装。<br>如果使用 <strong>Fargate</strong> 模式，AWS 负责底层基础设施和操作系统。<br>但选项 C 说的是“在 Amazon ECS 上配置额外的软件组件…”，这通常指的是在 <strong>ECS on EC2</strong> 场景中在主机上安装代理软件，属于客户责任。</li>
<li><strong>AWS Direct Connect</strong>：<br>AWS 负责物理连接、端口到客户设备的链路。<br>客户负责：加密传输中的数据（例如通过 IPsec VPN over Direct Connect 或应用层加密）、配置路由、管理客户网关设备。</li>
</ul>
<p><br>452 公司有一个 <strong>基于 Java 的作业</strong>，运行在 <strong>Amazon EC2 实例</strong> 上：</p>
<ul>
<li>每小时运行一次，耗时 <strong>10 秒</strong>。</li>
<li>消耗 <strong>1 GB 内存</strong>。</li>
<li>CPU 使用情况：大部分时间利用率低，只在作业运行的 10 秒内出现 <strong>CPU 峰值</strong>。</li>
<li>目标：<strong>优化运行此作业的成本</strong>。</li>
</ul>
<p>A. 使用 <strong>AWS App2Container（A2C）</strong> 将作业容器化，在 <strong>AWS Fargate</strong> 上作为 <strong>Amazon ECS 任务</strong> 运行，配置为 <strong>0.5 vCPU 和 1 GB 内存</strong>。<br>B. <u>将代码复制到 <strong>AWS Lambda 函数</strong>（1 GB 内存），创建 <strong>Amazon EventBridge 计划规则</strong> 每小时运行一次。</u><br>C. 使用 <strong>A2C</strong> 将作业容器化，安装在现有的 <strong>Amazon Machine Image（AMI）</strong> 中，确保任务完成后调度程序停止容器。<br>D. 配置现有计划，在作业完成时 <strong>停止 EC2 实例</strong>，在下次作业开始时 <strong>重启 EC2 实例</strong>。</p>
<p><br>453 公司希望为 <strong>Amazon EC2 数据</strong> 和 <strong>多个 Amazon S3 存储桶</strong> 实施备份策略。</p>
<ul>
<li>监管要求：必须将备份文件保留特定时间段，且在保留期内 <strong>不得修改</strong> 这些文件。</li>
<li>问：哪种解决方案能满足要求？</li>
</ul>
<p>A. 使用 <strong>AWS Backup</strong> 创建一个具有 <strong>治理模式下 vault 锁</strong> 的备份 vault，创建所需的备份计划。<br>B. 使用 <strong>Amazon Data Lifecycle Manager</strong> 创建所需的自动快照策略。<br>C. 使用 <strong>Amazon S3 文件网关</strong> 创建备份，配置适当的 S3 生命周期管理。<br>D. <u>使用 <strong>AWS Backup</strong> 创建一个具有 <strong>合规模式下 vault 锁定</strong> 功能的备份库，制定所需的备份计划。</u></p>
<ul>
<li>AWS Backup 是 AWS 统一的备份服务，支持多种资源（符合 EC2 和 S3 需求）。</li>
<li>Vault 锁的合规模式提供严格的不可变性，满足监管要求。</li>
<li><strong>Vault 锁的治理模式</strong> 允许有特殊权限的用户（带 <code>backup:BypassGovernanceRetention</code>）在保留期内修改或删除备份，<strong>不是完全不可变</strong>。 ❌ 不符合“不得修改”的严格监管要求</li>
</ul>
<p><br>454 公司在多个 AWS 区域和账户中拥有资源。</p>
<ul>
<li>前员工没有提供资源清单详细信息。</li>
<li>新解决方案架构师需要 <strong>构建并绘制所有账户中各种工作负载的关系详情</strong>（即发现资源并生成架构图）。</li>
<li>要求：以 <strong>最高的运营效率</strong> 满足。</li>
</ul>
<p>A. 使用 <strong>AWS Systems Manager Inventory</strong> 从详细视图报告生成地图视图。<br>B. 使用 <strong>AWS Step Functions</strong> 收集工作负载详情，手动构建架构图。<br>C. <u>使用 <strong>AWS 上的工作负载发现功能</strong> 生成工作负载的架构图。</u><br>D. 使用 <strong>AWS X-Ray</strong> 查看工作负载详情，构建带有关系的架构图。</p>
<p>SSM Inventory 用于收集 EC2 实例的软件、配置等详细信息，但主要针对实例层级清单，不是跨服务、跨账户的全方位资源关系发现与绘图。</p>
<p>Step Functions 用于编排工作流，但本身不提供资源发现功能；需要自行编写代码调用 API 收集数据，再手动绘图，效率低</p>
<p>X-Ray 用于分布式跟踪、分析应用程序请求流（微服务层面），不是用于发现底层 AWS 资源清单和绘制静态架构图</p>
<p><br>455 公司使用 <strong>AWS Organizations</strong>，希望：</p>
<ol>
<li>为其部分 AWS 账户设置 <strong>不同的预算</strong>。</li>
<li>在特定时期内达到分配的预算阈值时：<ul>
<li>收到警报。</li>
<li>自动阻止在该 AWS 账户上配置额外资源。</li>
</ul>
</li>
</ol>
<p>问：哪些 <strong>三个解决方案组合</strong> 可以满足这些要求？</p>
<p>A. 使用 <strong>AWS 预算（Budgets）</strong> 创建预算，在所需 AWS 账户的 <strong>成本和使用报告部分</strong> 下设置预算金额。<br>B. 使用 <strong>AWS 预算</strong> 创建预算，在所需 AWS 账户的 <strong>账单仪表板</strong> 下设置预算金额。<br>C. 为 AWS 预算创建一个 <strong>IAM 用户</strong>，使其拥有所需权限来运行预算操作。<br>D. <u>为 AWS 预算创建一个 <strong>IAM 角色</strong>，使其能够凭借所需权限运行预算操作</u>。<br>E. 添加一个 <strong>警报</strong>，以便在每个账户达到预算阈值时通知公司；添加一个 <strong>预算操作</strong>，该操作选择使用 <strong>适当的配置规则创建的 IAM 身份</strong>，以防止额外资源的配置。<br>F. <u>添加一个 <strong>警报</strong>，以便在每个账户达到预算阈值时通知公司；添加一个 <strong>预算操作</strong>，该操作选择通过 <strong>适当的服务控制策略（SCP）创建的 IAM 身份</strong>，以防止额外资源的配置</u></p>
<h3 id="1-需求理解-1"><a href="#1-需求理解-1" class="headerlink" title="1. 需求理解"></a>1. 需求理解</h3><ul>
<li>多账户不同预算 → 可以在每个账户中单独创建 AWS 预算，或通过主账户使用 AWS Budgets 的多账户预算功能。</li>
<li>达到阈值时 <strong>警报</strong> → AWS Budgets 支持警报（电子邮件、SNS）。</li>
<li><strong>自动阻止配置额外资源</strong> → 这需要 <strong>预算操作（Budget Actions）</strong>，当预算阈值达到时，触发一个动作，例如 <strong>运行一个 IAM 策略或 SCP 来限制创建资源</strong>。</li>
</ul>
<h3 id="2-AWS-Budgets-预算操作机制"><a href="#2-AWS-Budgets-预算操作机制" class="headerlink" title="2. AWS Budgets 预算操作机制"></a>2. AWS Budgets 预算操作机制</h3><ul>
<li>预算操作需要一个 <strong>IAM 角色</strong>，该角色有权执行阻止操作（如附加 SCP 或应用 IAM 策略）。</li>
<li>阻止资源创建通常通过 <strong>SCP（服务控制策略）</strong> 在组织层面实现最有效（因为 SCP 可附加到账户，影响账户内所有用户和角色）。</li>
</ul>
<p>要实现完整流程：</p>
<ol>
<li><strong>创建预算</strong>（B 描述创建预算，尽管表述不够准确，但基本正确）。</li>
<li><strong>创建 IAM 角色</strong> 供预算操作使用（D）。</li>
<li><strong>设置警报和预算操作</strong>，并关联 SCP 来实现阻止（F）。</li>
</ol>
<p><br>456 公司在一个 AWS 区域的 <strong>Amazon EC2 实例</strong> 上运行应用程序。</p>
<p>要求：</p>
<ol>
<li>将 EC2 实例 <strong>备份到第二个区域</strong>。</li>
<li>在第二个区域 <strong>配置 EC2 资源</strong>（即需要时能启动实例）。</li>
<li>通过 <strong>一个 AWS 账户</strong> 集中管理这些 EC2 实例。</li>
<li><strong>最具成本效益</strong>。</li>
</ol>
<p>A. 制定灾难恢复（DR）计划，在第二个区域 <strong>配置数量相近的 EC2 实例</strong>，设置数据复制。<br>B. 创建 EC2 实例的 <strong>EBS 快照</strong>，定期将快照复制到第二个区域。<br>C. 使<u>用 <strong>AWS Backup</strong> 创建备份计划，为 EC2 实例配置 <strong>跨区域备份</strong></u>。<br>D. 在第二个区域部署数量相近的 EC2 实例，使用 <strong>AWS DataSync</strong> 将数据从源区域传输到第二个区域。</p>
<ul>
<li><strong>AWS Backup</strong> 是 AWS 统一的备份服务，支持跨区域备份 EBS 卷（EC2 实例）。</li>
<li>它自动化备份计划和跨区域复制，减少手动操作。</li>
<li>恢复时可在第二个区域从备份启动新 EC2 实例。</li>
</ul>
<p><br>457  公司构建一个向产品制造商传输数据的应用程序，要求：</p>
<ol>
<li>用户使用应用程序传输数据时，由 <strong>公司自己的身份提供商（IdP）</strong> 对用户进行身份验证。</li>
<li>必须使用 <strong>AS2 协议</strong>（适用性声明 2，一种用于安全传输商业数据的 EDI over HTTP 协议）。</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. 使用 <strong>AWS DataSync</strong> 传输数据，创建一个 <strong>Lambda 函数</strong> 用于 IdP 认证。<br>B. 使用 <strong>Amazon AppFlow</strong> 传输数据，为 IdP 认证创建一个 <strong>Amazon ECS 任务</strong>。<br>C. <u>使用 <strong>AWS Transfer Family</strong> 传输数据，创建一个 <strong>Lambda 函数</strong> 用于 IdP 认证。</u><br>D. 使用 <strong>AWS Storage Gateway</strong> 传输数据，创建一个 <strong>Amazon Cognito 身份池</strong> 用于 IdP 认证。</p>
<ul>
<li><p>AS2（Applicability Statement 2）用于 <strong>安全、可靠地传输 EDI（电子数据交换）消息</strong>，通常用于企业间 B2B 数据交换。</p>
</li>
<li><p>支持 AS2 的 AWS 服务是 <strong>AWS Transfer Family</strong>（具体为 <strong>AWS Transfer for AS2</strong>，它是 AWS Transfer Family 的一部分）。</p>
</li>
<li><p>其他服务（DataSync、AppFlow、Storage Gateway）不原生支持 AS2 协议</p>
</li>
<li><p>AWS Transfer Family 支持 <strong>自定义身份验证</strong>，可以通过 <strong>Lambda 函数</strong> 集成外部身份提供商（如 SAML、OIDC、LDAP 等）来验证用户。</p>
</li>
<li><p>因此可以在创建 Transfer Family 服务器时选择“自定义身份验证”，并指定一个 Lambda 函数去连接公司 IdP。</p>
</li>
</ul>
<p><br>458 解决方案架构师为 <strong>现金返还服务</strong> 在 <strong>Amazon API Gateway</strong> 中设计一个 <strong>REST API</strong>。</p>
<ul>
<li>应用的计算资源需要 <strong>1 GB 内存和 2 GB 存储</strong>。</li>
<li>应用要求数据采用 <strong>关系格式</strong>。</li>
<li>问：额外的 AWS 服务组合能够以 <strong>最少的管理工作量</strong> 满足这些要求？（选两项）</li>
</ul>
<p>A. Amazon EFS<br>B. <u>AWS Lambda</u><br>C. <u>Amazon RDS</u><br>D. Amazon DynamoDB<br>E. Amazon EKS</p>
<h3 id="计算层选择"><a href="#计算层选择" class="headerlink" title="计算层选择"></a>计算层选择</h3><ul>
<li>计算需求可选用 <strong>AWS Lambda</strong>（无服务器函数）或 <strong>容器&#x2F;EC2</strong>。</li>
<li><strong>Lambda</strong>：按需运行，无需管理服务器，内存可配置（最大 10 GB），存储可用临时存储（&#x2F;tmp 最大 10 GB），适合 API Gateway 后端，管理开销最小。 ✅</li>
<li><strong>EKS</strong>：Kubernetes 集群，管理开销大，不满足“最少管理”。 ❌</li>
<li>EFS 是文件存储服务，不是计算服务，不能直接用于运行业务逻辑。❌</li>
</ul>
<h3 id="数据库层选择"><a href="#数据库层选择" class="headerlink" title="数据库层选择"></a>数据库层选择</h3><ul>
<li>关系数据 → 可用 <strong>RDS</strong>（托管关系数据库）或 <strong>自建关系数据库</strong>。</li>
<li><strong>RDS</strong> 是全托管关系数据库服务，自动处理备份、补丁、高可用等，管理开销最小。 ✅</li>
<li><strong>DynamoDB</strong> 是 NoSQL 非关系型数据库，不符合“关系格式”要求。 ❌</li>
</ul>
<p><br>459 公司使用 <strong>AWS Organizations</strong> 在多个 AWS 账户中运行工作负载。</p>
<ul>
<li>已创建 <strong>标签策略</strong>，为 AWS 资源添加 <strong>部门标签</strong>（例如标签键 <code>department</code>）。</li>
<li>会计团队需要 <strong>确定在 Amazon EC2 上的消费支出</strong>，并 <strong>按部门划分成本</strong>（不考虑账户）。</li>
<li>会计团队有权访问 <strong>组织内所有账户的 AWS Cost Explorer</strong>。</li>
<li>要求：以 <strong>最具运营效率</strong> 的方式满足。</li>
</ul>
<p>A. <u>在组织管理账户的 <strong>计费控制台</strong> 中，激活名为 <code>department</code> 的 <strong>用户定义成本分配标签</strong>；在 Cost Explorer 中创建按标签名称分组的成本报告，并按 EC2 筛选。</u><br>B. 在组织管理账户的 <strong>账单控制台</strong> 中，激活名为 <code>department</code> 的 <strong>AWS 定义的成本分配标签</strong>；在 Cost Explorer 中创建按标签名称分组的成本报告，并按 EC2 筛选。<br>C. 在组织成员账户的计费控制台中，激活名为 <code>department</code> 的 <strong>用户定义成本分配标签</strong>；在 Cost Explorer 中创建按标签名称分组的成本报告，并按 EC2 筛选。<br>D. 在组织成员账户的计费控制台中，激活名为 <code>department</code> 的 <strong>AWS 定义的成本分配标签</strong>；在 Cost Explorer 中创建按标签名称分组的成本报告，并按 EC2 筛选。</p>
<h3 id="1-成本分配标签的类型"><a href="#1-成本分配标签的类型" class="headerlink" title="1. 成本分配标签的类型"></a>1. 成本分配标签的类型</h3><ul>
<li><strong>AWS 定义的成本分配标签</strong>：由 AWS 自动生成和分配的标签（如 <code>aws:createdBy</code>），不是用户自定义的。</li>
<li><strong>用户定义的成本分配标签</strong>：用户自己创建的标签（如 <code>department</code>、<code>project</code>），需要手动或通过策略应用到资源上。</li>
</ul>
<p>本题已通过 <strong>标签策略</strong> 强制为资源添加 <code>department</code> 标签，因此这是 <strong>用户自定义标签</strong>，不是 AWS 定义的。</p>
<h3 id="2-激活成本分配标签的位置"><a href="#2-激活成本分配标签的位置" class="headerlink" title="2. 激活成本分配标签的位置"></a>2. 激活成本分配标签的位置</h3><ul>
<li><p>要在 Cost Explorer 中按标签分组成本，必须先 <strong>在账单控制台激活该标签作为成本分配标签</strong>。</p>
</li>
<li><p>对于 <strong>多账户 Organizations</strong>，应在 <strong>管理账户（payer account）</strong> 的账单控制台中激活，这样该标签的成本分配数据会跨所有成员账户聚合。</p>
</li>
<li><p>如果在成员账户单独激活，则只能看到该账户内的标签成本数据，无法跨账户汇总，不符合“不考虑账户”的部门成本分析需求。</p>
</li>
<li><p><strong>A</strong>：管理账户 + 用户定义标签 <code>department</code> ✅<br>正确，因为标签是用户自定义的，且在管理账户激活后，Cost Explorer 可以跨账户按部门标签分组 EC2 成本。</p>
</li>
<li><p><strong>B</strong>：管理账户 + AWS 定义标签 <code>department</code> ❌<br><code>department</code> 不是 AWS 定义的标签，是用户自定义的。</p>
</li>
<li><p><strong>C</strong>：成员账户 + 用户定义标签 ❌<br>在成员账户激活无法跨账户聚合。</p>
</li>
<li><p><strong>D</strong>：成员账户 + AWS 定义标签 ❌<br>同样错误（标签类型错，且位置错）。</p>
</li>
</ul>
<p><br>460 公司希望在其 <strong>SaaS 应用程序 Salesforce</strong> 账户与 <strong>Amazon S3</strong> 之间安全地交换数据。</p>
<p>要求：</p>
<ol>
<li>使用 <strong>AWS KMS 客户托管密钥（CMK）</strong> 对 <strong>静态数据</strong> 加密。</li>
<li>对 <strong>传输中的数据</strong> 加密。</li>
<li>Salesforce 账户已启用 <strong>API 访问权限</strong>。</li>
</ol>
<p>问：哪种解决方案能满足要求？</p>
<p>A. 创建 <strong>AWS Lambda 函数</strong>，将数据从 Salesforce 安全传输到 Amazon S3。<br>B. 创建 <strong>AWS Step Functions 工作流</strong>，定义将数据从 Salesforce 安全传输到 Amazon S3 的任务。<br>C. <u>创建 <strong>Amazon AppFlow 流</strong>，将数据从 Salesforce 安全传输到 Amazon S3。</u><br>D. 为 Salesforce 创建一个 <strong>自定义连接器</strong>，将数据从 Salesforce 安全传输到 Amazon S3。</p>
<p>AppFlow 是专门为 <strong>SaaS ↔ AWS 数据流</strong> 设计的托管服务，内置对 Salesforce 的连接器，支持 OAuth 认证、字段映射、加密设置</p>
<p><br>461 公司开发一个 <strong>移动游戏应用</strong>，部署在单一 AWS 区域：</p>
<ul>
<li>应用在 <strong>多 EC2 实例</strong>（自动扩展组）上运行。</li>
<li>数据存储在 <strong>Amazon DynamoDB</strong>。</li>
<li>应用通信：<strong>TCP 和 UDP 流量</strong>（游戏常需要低延迟的实时双向通信，可能用到 UDP）。</li>
<li>应用将在 <strong>全球范围内使用</strong>。</li>
<li>目标：确保所有用户获得 <strong>尽可能低的延迟</strong>。</li>
</ul>
<p>A. 使用 <strong>AWS Global Accelerator</strong> 创建一个加速器，在加速器端点后创建一个 <strong>应用程序负载均衡器（ALB）</strong>（监听 TCP&#x2F;UDP），更新 ASG 在 ALB 注册实例。<br>B. <u>使用 <strong>AWS Global Accelerator</strong> 创建一个加速器，在加速器端点后创建一个 <strong>网络负载均衡器（NLB）</strong>（监听 TCP&#x2F;UDP），更新 ASG 在 NLB 注册实例。</u><br>C. 创建 <strong>Amazon CloudFront CDN</strong> 端点，在其后创建一个 <strong>NLB</strong>（监听 TCP&#x2F;UDP），更新 ASG 在 NLB 注册实例，更新 CloudFront 将 NLB 用作源站。<br>D. 创建 <strong>Amazon CloudFront CDN</strong> 端点，在其后创建一个 <strong>ALB</strong>（监听 TCP&#x2F;UDP），更新 ASG 在 ALB 注册实例，更新 CloudFront 将 ALB 用作源站。</p>
<ul>
<li><p><strong>CloudFront</strong> 主要用于缓存和加速 <strong>HTTP&#x2F;HTTPS（应用层）</strong> 内容，不支持 <strong>UDP</strong> 流量（UDP 不是 HTTP）。</p>
</li>
<li><p><strong>Global Accelerator</strong> 是为 <strong>TCP&#x2F;UDP</strong> 流量设计的全球加速服务，通过 Anycast IP 将用户流量通过 AWS 骨干网路由到最近的应用端点，减少延迟和抖动</p>
</li>
<li><p><strong>ALB</strong>：工作在第 7 层（HTTP&#x2F;HTTPS&#x2F;WebSocket），<strong>不支持 UDP</strong>。</p>
</li>
<li><p><strong>NLB</strong>：工作在第 4 层，支持 <strong>TCP、UDP、TLS</strong>。</p>
</li>
</ul>
<p><br>462 公司有一个处理客户订单的应用程序：</p>
<ul>
<li>托管在 <strong>Amazon EC2 实例</strong> 上。</li>
<li>订单保存到 <strong>Amazon Aurora 数据库</strong>。</li>
<li>问题：偶尔 <strong>流量高峰时</strong>，工作负载无法足够快地处理订单。</li>
<li>目标：将订单 <strong>既可靠又尽快</strong> 地写入数据库。</li>
</ul>
<p>A. 流量大时 <strong>增大 EC2 实例大小</strong>，向 <strong>Amazon SNS</strong> 发送指令，将数据库端点订阅到 SNS 主题。<br>B. <u>向 <strong>Amazon SQS 队列</strong> 写入订单，在 <strong>ALB 后的自动扩展组</strong> 中使用 EC2 实例从 SQS 队列读取并处理订单到数据库。</u><br>C. 向 <strong>Amazon SNS</strong> 写入订单，将数据库端点订阅到 SNS 主题，在 <strong>ALB 后的自动扩展组</strong> 中使用 EC2 实例从 SNS 主题读取。<br>D. 当 EC2 实例达到 CPU 阈值限制时，向 <strong>Amazon SQS 队列</strong> 写入订单，在 <strong>ALB 后的自动扩展组</strong> 中使用 EC2 实例的定时扩展从 SQS 队列读取并处理。</p>
<ul>
<li><strong>SQS</strong>：消息队列，支持消息持久化、消费者拉取、自动扩展消费者实例数量，适合订单缓冲与异步处理。</li>
<li><strong>SNS</strong>：发布&#x2F;订阅服务，消息推送给多个订阅者，不持久化（除非订阅者是 SQS 或 Lambda），不适合作为缓冲队列保证可靠处理。</li>
</ul>
<p><br>463 物联网公司推出带传感器的床垫：</p>
<ul>
<li>传感器收集用户睡眠数据，发送到 <strong>Amazon S3 存储桶</strong>。</li>
<li><strong>每个床垫</strong> 每晚收集约 <strong>2 MB</strong> 数据。</li>
<li>要求：<ol>
<li>对 <strong>每个床垫的数据单独处理和汇总</strong>。</li>
<li>处理结果 <strong>尽快可用</strong>。</li>
<li>处理任务需要 <strong>1 GB 内存</strong>，在 <strong>30 秒内完成</strong>。</li>
<li><strong>最具成本效益</strong>。</li>
</ol>
</li>
</ul>
<p>A. 使用带有 <strong>Scala 作业</strong> 的 <strong>AWS Glue</strong>。<br>B. 使用带有 <strong>Apache Spark 脚本</strong> 的 <strong>Amazon EMR</strong>。<br>C. <u>使用带有 <strong>Python 脚本</strong> 的 <strong>AWS Lambda</strong>。</u><br>D. 将 <strong>AWS Glue</strong> 与 <strong>PySpark 作业</strong> 配合使用。</p>
<ul>
<li><strong>AWS Glue</strong>：无服务器 ETL 服务，按 DPU 小时计费，适合大数据批量处理，但启动时间较慢（几分钟），对于 2 MB 的小文件处理不经济（DPU 有最小计费单位）。 ❌</li>
<li><strong>Amazon EMR</strong>：托管 Hadoop&#x2F;Spark 集群，适合大数据处理，但集群启动和运行成本高，对小规模、频繁的独立任务不经济。 ❌</li>
<li><strong>AWS Lambda</strong>：无服务器函数，按执行次数和内存使用时间（GB-秒）计费。<ul>
<li>单个任务：1 GB × 30 秒 &#x3D; 30 GB-秒，费用极低（每百万 GB-秒约 0.20 美元）。</li>
<li>可配置 S3 事件触发，数据一到达就立即处理，延迟低。</li>
<li>天然支持并行处理多个床垫数据（每个文件触发一个 Lambda）。</li>
</ul>
</li>
</ul>
<p><br>464 公司托管一个在线购物应用程序：</p>
<ul>
<li>所有订单存储在 <strong>Amazon RDS for PostgreSQL 单可用区数据库实例</strong>。</li>
<li>管理层希望 <strong>消除单点故障</strong>。</li>
<li>要求：<ol>
<li><strong>无需对应用程序代码进行任何更改</strong>。</li>
<li><strong>最大限度地减少数据库停机时间</strong>。</li>
</ol>
</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. <u>通过修改数据库实例，指定 <strong>多可用区选项</strong>，将现有数据库实例转换为多可用区部署。</u><br>B. 创建新的 <strong>RDS 多可用区部署</strong>，对当前 RDS 实例进行快照，然后用该快照恢复新的多可用区部署。<br>C. 在另一个可用区创建 <strong>PostgreSQL 只读副本</strong>，使用 <strong>Amazon Route 53 加权记录集</strong> 在数据库之间分配请求。<br>D. 将 RDS for PostgreSQL 数据库放在 <strong>Amazon EC2 Auto Scaling 组中</strong>（最小规模为两个），使用 Route 53 加权记录集在实例之间分配请求。</p>
<ul>
<li>RDS Multi-AZ 切换对应用程序透明（连接端点不变）。</li>
<li>转换过程中，RDS 会经历短暂故障转移（通常几十秒到几分钟），但这是 AWS 管理的，无需人工干预，且之后具备跨 AZ 高可用。</li>
<li>完全符合“消除单点故障、无需改代码、最小化停机时间”</li>
</ul>
<p><br>465 公司开发一个应用程序：</p>
<ul>
<li>部署在 <strong>同一可用区内</strong> 的多个 <strong>基于 Amazon EC2 Nitro 的实例</strong> 上。</li>
<li>要求：应用程序能够 <strong>同时写入多个 EC2 Nitro 实例中的多个块存储卷</strong>，以实现更高的应用可用性。</li>
<li>这描述的是 <strong>共享块存储</strong> 场景，即一个卷可同时挂载到多个实例进行读写。</li>
</ul>
<p>A. 使用 <strong>gp3 EBS 卷</strong> 与 <strong>Amazon EBS 多挂载功能</strong>。<br>B. 使用 <strong>st1 EBS 卷</strong> 与 <strong>EBS 多挂载功能</strong>。<br>C. <u>使用 <strong>io2 EBS 卷</strong> 与 <strong>EBS 多挂载功能</strong></u>。<br>D. 使用 <strong>gp2 EBS 卷</strong> 与 <strong>EBS 多挂载功能</strong>。</p>
<h3 id="1-EBS-多挂载（Multi-Attach）功能"><a href="#1-EBS-多挂载（Multi-Attach）功能" class="headerlink" title="1. EBS 多挂载（Multi-Attach）功能"></a>1. EBS 多挂载（Multi-Attach）功能</h3><ul>
<li>EBS Multi-Attach 允许 <strong>单个 EBS 卷同时挂载到同一可用区内的多个 EC2 Nitro 实例</strong>，支持并发读写（需要集群感知文件系统如 GFS2、OCFS2 等来协调写入，避免数据损坏）。</li>
<li>但 <strong>并非所有 EBS 卷类型都支持 Multi-Attach</strong>。</li>
</ul>
<h3 id="2-支持的卷类型"><a href="#2-支持的卷类型" class="headerlink" title="2. 支持的卷类型"></a>2. 支持的卷类型</h3><p>官方文档明确：只有 <strong>io1 和 io2（包括 io2 Block Express）</strong> 卷支持 Multi-Attach。</p>
<ul>
<li>gp2、gp3、st1、sc1 <strong>不支持</strong> Multi-Attach。</li>
</ul>
<p><br>466 公司设计了一个 <strong>无状态的两层应用程序</strong>：</p>
<ul>
<li>使用 <strong>单个可用区中的 Amazon EC2</strong>（计算层）。</li>
<li>使用 <strong>Amazon RDS 多可用区数据库实例</strong>（数据库层已有高可用）。</li>
<li>新管理层要求确保 <strong>应用程序具有高可用性</strong>。</li>
</ul>
<p>问：解决方案架构师应采取什么措施来满足这一要求？</p>
<p>A. <u>配置应用程序以使用 <strong>多可用区 EC2 自动扩展</strong> 并创建一个 <strong>应用程序负载均衡器</strong>。</u><br>B. 配置应用程序以对 <strong>EC2 实例进行快照</strong>，并将其发送到另一个 AWS 区域。<br>C. 配置应用程序以使用 <strong>Amazon Route 53 基于延迟的路由</strong> 向应用程序提交请求。<br>D. 配置 <strong>Amazon Route 53 规则</strong> 以处理传入请求，并创建一个 <strong>多可用区应用程序负载均衡器</strong>。</p>
<h3 id="1-当前架构短板"><a href="#1-当前架构短板" class="headerlink" title="1. 当前架构短板"></a>1. 当前架构短板</h3><ul>
<li>数据库层已经是 <strong>RDS Multi-AZ</strong>（跨可用区高可用）。</li>
<li>但应用层（EC2）在 <strong>单个可用区</strong> → 该 AZ 故障时应用不可用，不满足高可用性。</li>
<li>因此需要在应用层实现 <strong>跨可用区容错</strong>。</li>
</ul>
<h3 id="2-高可用方案核心"><a href="#2-高可用方案核心" class="headerlink" title="2. 高可用方案核心"></a>2. 高可用方案核心</h3><p>对于无状态应用层，高可用要求：</p>
<ol>
<li><strong>跨多个可用区部署实例</strong>。</li>
<li>使用 <strong>负载均衡器</strong> 分发流量并健康检查，故障时自动路由到健康实例。</li>
</ol>
<p><br>467 公司使用 <strong>AWS Organizations</strong>。</p>
<ul>
<li>一个 <strong>成员账户</strong> 购买了 <strong>计算节省计划（Compute Savings Plans）</strong>。</li>
<li>该账户的工作负载变化，<strong>不再能充分享受节省计划的全部好处</strong>，实际使用的计算能力 <strong>不到购买量的 50%</strong>。</li>
<li>问题：节省计划 <strong>承诺</strong> 在成员账户内未被充分利用。</li>
</ul>
<p>A. 在 <strong>购买了计算节省计划的成员账户</strong> 中，从账户控制台的 <strong>账单偏好设置</strong> 开启 <strong>折扣共享</strong>。<br>B. <u>在 <strong>公司组织的管理账户</strong> 控制台的 <strong>账单偏好设置</strong> 开启 <strong>折扣共享</strong></u>。<br>C. 将更多计算工作负载从 <strong>另一个 AWS 账户</strong> 迁移到拥有计算节省计划的账户。<br>D. 在 <strong>预留实例市场</strong> 出售多余的节省计划承诺。</p>
<h3 id="1-节省计划折扣共享机制"><a href="#1-节省计划折扣共享机制" class="headerlink" title="1. 节省计划折扣共享机制"></a>1. 节省计划折扣共享机制</h3><ul>
<li><strong>AWS Organizations</strong> 中，可以为 <strong>计算节省计划</strong> 和 <strong>EC2 实例节省计划</strong> 启用 <strong>折扣共享（Discount Sharing）</strong>。</li>
<li>开启后，节省计划的折扣可以 <strong>自动应用于组织内所有成员账户</strong> 的适用使用量，而不仅限于购买账户。</li>
<li>这样，如果购买账户的使用量不足，其他成员账户的使用量可以“吸收”剩余的承诺，从而充分利用节省计划，避免浪费。</li>
</ul>
<h3 id="2-开启位置"><a href="#2-开启位置" class="headerlink" title="2. 开启位置"></a>2. 开启位置</h3><ul>
<li>折扣共享必须在 <strong>管理账户（payer account）</strong> 中启用，因为它是组织级别的设置。</li>
<li>不能在成员账户单独开启。</li>
</ul>
<p><br>468 公司开发一个 <strong>微服务应用程序</strong>，为客户提供搜索目录。</p>
<ul>
<li>必须使用 <strong>REST API</strong> 向用户展示应用程序的前端。</li>
<li>REST API 必须访问 <strong>在私有 VPC 子网的容器中托管的后端服务</strong>。</li>
</ul>
<p>A. 使用 <strong>Amazon API Gateway</strong> 设计一个 <strong>WebSocket API</strong>，在私有子网的 <strong>Amazon ECS</strong> 中托管应用，为 API Gateway 创建一个 <strong>私有 VPC 链接</strong> 以访问 Amazon ECS。<br>B. <u>使用 <strong>Amazon API Gateway</strong> 设计一个 <strong>REST API</strong>，在私有子网的 <strong>Amazon ECS</strong> 中托管应用，为 API Gateway 创建一个 <strong>私有 VPC 链接</strong> 以访问 Amazon ECS。</u><br>C. 使用 <strong>Amazon API Gateway</strong> 设计一个 <strong>WebSocket API</strong>，在私有子网的 <strong>Amazon ECS</strong> 中托管应用，为 API Gateway 创建一个 <strong>安全组</strong> 以访问 Amazon ECS。<br>D. 使用 <strong>Amazon API Gateway</strong> 设计一个 <strong>REST API</strong>，在私有子网的 <strong>Amazon ECS</strong> 中托管应用，创建一个 <strong>安全组</strong> 使 API Gateway 能够访问 Amazon ECS。</p>
<h3 id="1-需求匹配"><a href="#1-需求匹配" class="headerlink" title="1. 需求匹配"></a>1. 需求匹配</h3><ul>
<li><strong>REST API</strong> → 排除 WebSocket API（A 和 C 错误）。</li>
<li>后端在 <strong>私有 VPC 子网的容器中</strong>（ECS），不公开到互联网。</li>
<li>API Gateway 需要安全地访问私有 VPC 内的 ECS 服务。</li>
</ul>
<h3 id="2-访问私有-VPC-内服务的方式"><a href="#2-访问私有-VPC-内服务的方式" class="headerlink" title="2. 访问私有 VPC 内服务的方式"></a>2. 访问私有 VPC 内服务的方式</h3><ul>
<li><strong>私有 VPC 链接（VPC Link）</strong>：允许 API Gateway 通过私有网络连接到 VPC 内的资源（如 NLB 或 ALB 后的服务），无需经过互联网，安全且是推荐方式。</li>
<li><strong>安全组（Security Group）</strong>：仅用于控制网络流量，但 API Gateway 是托管服务，无法直接向 ECS 安全组放行一个可预测的源 IP 范围（因为 API Gateway 公共端点的 IP 会变化），因此 <strong>仅靠安全组不可靠</strong>（且 API Gateway 公共端点无法直接访问私有子网，除非通过 VPC Link 或公有 NLB）。</li>
</ul>
<p><br>469 公司将收集的 <strong>原始数据</strong> 存储在 <strong>Amazon S3 存储桶</strong>。</p>
<ul>
<li>数据用于代表客户进行多种类型的分析。</li>
<li><strong>访问模式由请求的分析类型决定</strong>，公司 <strong>无法预测或控制访问模式</strong>。</li>
<li>目标：<strong>降低 S3 成本</strong>。</li>
</ul>
<p>A. 使用 <strong>S3 复制</strong> 将不带访问的对象转换为 <strong>S3 标准-IA</strong>。<br>B. 使用 <strong>S3 生命周期规则</strong> 将对象从 <strong>S3 标准</strong> 转换为 <strong>S3 标准-IA</strong>。<br>C. <u>使用 <strong>S3 生命周期规则</strong> 将对象从 <strong>S3 标准</strong> 转换为 <strong>S3 智能分层（S3 Intelligent-Tiering）</strong>。</u><br>D. 使用 <strong>S3 Inventory</strong> 识别未被访问的对象，并将它们从 <strong>S3 标准</strong> 过渡到 <strong>S3 智能分层</strong>。</p>
<ul>
<li><strong>S3 智能分层（Intelligent-Tiering）</strong> 专为 <strong>访问模式未知或不规律</strong> 的场景设计。</li>
</ul>
<p><br>470 公司在 <strong>具有 IPv6 地址的 Amazon EC2 实例</strong> 上托管应用程序。</p>
<ul>
<li>应用程序必须 <strong>使用互联网与其他外部应用程序发起通信</strong>（出站连接）。</li>
<li>安全政策：<strong>任何外部服务都不能发起与这些 EC2 实例的连接</strong>（禁止入站连接）。</li>
</ul>
<p>问：解决方案架构师应推荐什么来解决此问题？</p>
<p>A. 创建一个 <strong>NAT 网关</strong> 并将其作为子网路由表的目标。<br>B. 创建一个 <strong>互联网网关（IGW）</strong> 并将其作为子网路由表的目标。<br>C. 创建一个 <strong>虚拟专用网关（VGW）</strong> 并将其作为子网路由表的目标。<br>D. <u>创建一个 <strong>仅出口互联网网关（Egress-Only Internet Gateway, EIGW）</strong> 并将其作为子网路由表的目标。</u></p>
<h3 id="1-网络需求分析"><a href="#1-网络需求分析" class="headerlink" title="1. 网络需求分析"></a>1. 网络需求分析</h3><ul>
<li>EC2 实例有 <strong>IPv6 地址</strong>（注意是 IPv6，不是 IPv4）。</li>
<li>需要 <strong>出站互联网访问</strong>（实例主动访问外部）。</li>
<li>不允许 <strong>外部发起入站连接</strong>（即实例不能被从互联网访问）。</li>
</ul>
<h3 id="2-IPv6-的出站访问控制"><a href="#2-IPv6-的出站访问控制" class="headerlink" title="2. IPv6 的出站访问控制"></a>2. IPv6 的出站访问控制</h3><ul>
<li>对于 <strong>IPv4</strong>，通常用 <strong>NAT 网关</strong> 隐藏实例的私有 IP，使其可以出站但不能被入站访问。</li>
<li>但对于 <strong>IPv6</strong>，没有私有 IPv6 地址的概念（通常使用公有 IPv6 地址）。若使用 <strong>互联网网关（IGW）</strong>，实例会获得公有 IPv6 地址，<strong>外部可以直接访问</strong>（违反安全政策）。</li>
<li><strong>仅出口互联网网关（Egress-Only Internet Gateway）</strong> 是专门为 IPv6 设计的组件，它允许实例主动发起出站连接，但阻止互联网对实例的入站连接，符合要求。</li>
</ul>
<p><br>471 公司创建一个在 <strong>VPC 的容器中</strong> 运行的应用程序：</p>
<ul>
<li>应用程序在 <strong>Amazon S3 存储桶</strong> 中存储和访问数据。</li>
<li>开发阶段：每天在 S3 中存储和访问 <strong>1 TB 数据</strong>。</li>
<li>要求：<ol>
<li><strong>最大限度地降低成本</strong>。</li>
<li><strong>尽可能防止流量通过互联网传输</strong>。</li>
</ol>
</li>
</ul>
<p>A. 为 S3 存储桶启用 <strong>S3 智能分层</strong>。<br>B. 为 S3 存储桶启用 <strong>S3 传输加速</strong>。<br>C. <u>为 Amazon S3 创建一个 <strong>网关 VPC 端点（Gateway VPC Endpoint）</strong>，将此端点与 VPC 中所有路由表关联。</u><br>D. 在 VPC 中为 Amazon S3 创建一个 <strong>接口端点（Interface VPC Endpoint）</strong>，将此端点与 VPC 中所有路由表关联。</p>
<h3 id="1-防止流量通过互联网传输"><a href="#1-防止流量通过互联网传输" class="headerlink" title="1. 防止流量通过互联网传输"></a>1. 防止流量通过互联网传输</h3><ul>
<li>容器在 VPC 内，访问 S3 默认会通过 <strong>互联网</strong>（经 IGW 出去）。</li>
<li>要避免互联网传输，应使用 <strong>VPC 端点（VPC Endpoint）</strong>，使流量通过 AWS 私有网络直达 S3。</li>
<li>VPC 端点有两种：<ul>
<li><strong>网关端点（Gateway Endpoint）</strong>：适用于 S3 和 DynamoDB，免费（仅标准数据费用），在路由表中添加路由指向该端点。</li>
<li><strong>接口端点（Interface Endpoint）</strong>：适用于其他 AWS 服务（通过 PrivateLink），按小时和数据处理量收费，成本较高。</li>
</ul>
</li>
</ul>
<h3 id="2-成本最小化"><a href="#2-成本最小化" class="headerlink" title="2. 成本最小化"></a>2. 成本最小化</h3><ul>
<li>网关端点 <strong>免费</strong>（无小时费，无流量费），只支付 S3 标准费用。</li>
<li>接口端点 <strong>收费</strong>（按可用区、数据量计费）。</li>
<li>因此对于 S3 访问，<strong>网关端点</strong> 是成本最低且能避免互联网流量的方案。</li>
</ul>
<p><br>472 公司拥有一个 <strong>移动聊天应用程序</strong>，数据存储基于 <strong>Amazon DynamoDB</strong>。</p>
<ul>
<li>用户希望 <strong>以尽可能低的延迟读取新消息</strong>。</li>
<li>要求：设计一个 <strong>最优解决方案</strong>，且只需对应用程序进行 <strong>最少的更改</strong></li>
</ul>
<p>A. <u>为新消息表配置 <strong>Amazon DynamoDB 加速器（DAX）</strong>，更新代码以使用 DAX 端点</u>。<br>B. 添加 <strong>DynamoDB 只读副本</strong> 以应对增加的读取负载，更新应用程序以指向只读副本的读取端点。<br>C. 将 DynamoDB 中新消息表的 <strong>读取容量单位（RCU）数量加倍</strong>，继续使用现有的 DynamoDB 端点。<br>D. 向应用程序堆栈添加 <strong>适用于 Redis 的 Amazon ElastiCache 缓存</strong>，更新应用程序以指向 Redis 缓存端点，而非 DynamoDB。</p>
<ul>
<li>DAX 是 DynamoDB 原生加速方案，对应用透明（几乎无需逻辑修改）。</li>
<li>延迟最低（微秒级）。</li>
<li>自动缓存、自动失效，无需手动管理缓存一致性。</li>
</ul>
<p><br>473 公司在 <strong>应用程序负载均衡器（ALB）</strong> 后面的 <strong>Amazon EC2 实例</strong> 上托管一个网站：</p>
<ul>
<li>网站提供 <strong>静态内容</strong>。</li>
<li>网站流量增长，公司担心 <strong>成本会增加</strong>。</li>
</ul>
<p>问：解决方案架构师应该怎么做？</p>
<p>A. <u>创建一个 <strong>Amazon CloudFront 分发</strong>，在边缘位置缓存静态文件。</u><br>B. 创建一个 <strong>Amazon ElastiCache 集群</strong>，将 ALB 连接到 ElastiCache 以提供缓存文件。<br>C. 创建一个 <strong>AWS WAF Web ACL</strong> 并将其与 ALB 关联，向该 Web ACL 添加一条规则以缓存静态文件。<br>D. 在备用 AWS 区域创建第二个 ALB，将用户流量路由到最近的区域以降低数据传输成本。</p>
<p><br>474 公司在多个 AWS 区域拥有多个 VPC：</p>
<ul>
<li>原本各区域的工作负载相互 <strong>隔离</strong>。</li>
<li>现在新应用发布要求：<strong>每个 VPC 必须能够与所有区域的其他所有 VPC 进行通信</strong>（全互联）。</li>
<li>要求：以 <strong>最少的管理工作量</strong> 满足</li>
</ul>
<p>A. 使用 <strong>VPC 对等连接</strong> 管理单一区域内 VPC 通信，使用 <strong>跨区域 VPC 对等连接</strong> 管理跨区域 VPC 通信。<br>B. 在所有区域使用 <strong>AWS Direct Connect 网关</strong> 来连接跨区域的 VPC 并管理 VPC 通信。<br>C. <u>使用 <strong>AWS Transit Gateway</strong> 在单个区域内管理 VPC 通信，并通过 <strong>Transit Gateway 对等连接</strong> 实现跨区域通信。</u><br>D. 在所有区域使用 <strong>AWS PrivateLink</strong> 连接跨区域的 VPC 并管理 VPC 通信。</p>
<h3 id="1-全互联网络需求"><a href="#1-全互联网络需求" class="headerlink" title="1. 全互联网络需求"></a>1. 全互联网络需求</h3><ul>
<li>多区域、多 VPC 全互联（any-to-any）通信。</li>
<li>若用 VPC 对等连接（选项 A）：<ul>
<li>每个 VPC 需要与其他所有 VPC 建立对等连接，包括跨区域对等。</li>
<li>连接数呈 <strong>n×(n-1)&#x2F;2</strong> 增长，管理复杂（需为每对 VPC 创建并接受请求、更新路由表），工作量巨大。</li>
</ul>
</li>
<li>因此 A 不符合“最少管理”。</li>
</ul>
<h3 id="2-集中式网络枢纽方案"><a href="#2-集中式网络枢纽方案" class="headerlink" title="2. 集中式网络枢纽方案"></a>2. 集中式网络枢纽方案</h3><ul>
<li><strong>Transit Gateway（TGW）</strong> 是区域级网络中心，可连接同一区域内的多个 VPC。</li>
<li>通过 <strong>Transit Gateway 跨区域对等（Inter-Region Peering）</strong>，可将不同区域的 TGW 连接起来，实现跨区域 VPC 间路由。</li>
<li>这种 <strong>星型拓扑</strong> 大大简化管理与路由配置，符合“最少管理”</li>
</ul>
<p><br>475 公司设计一个将使用 <strong>Amazon ECS</strong> 的容器化应用程序，需要：</p>
<ol>
<li>访问一个 <strong>高耐用性的共享文件系统</strong>。</li>
<li>能够将数据 <strong>恢复到另一个 AWS 区域</strong>，<strong>RPO（恢复点目标）为 8 小时</strong>。</li>
<li>文件系统需要 <strong>在一个区域内的每个可用区提供一个挂载目标</strong>。</li>
<li>希望使用 <strong>AWS Backup</strong> 来管理到另一个区域的复制。</li>
</ol>
<p>A. 具有多可用区部署的 <strong>Amazon FSx for Windows 文件服务器</strong>。<br>B. 多可用区部署的 <strong>Amazon FSx for NetApp ONTAP</strong>。<br>C. <u>具有标准存储类的 <strong>Amazon EFS</strong></u>。<br>D. <strong>Amazon FSx for OpenZFS</strong>。</p>
<h3 id="1-每个可用区一个挂载目标"><a href="#1-每个可用区一个挂载目标" class="headerlink" title="1. 每个可用区一个挂载目标"></a>1. 每个可用区一个挂载目标</h3><ul>
<li>这是 <strong>Amazon EFS</strong> 的典型特性：EFS 文件系统在所在区域内的 <strong>每个可用区自动提供挂载目标</strong>（通过 EFS 挂载目标 IP&#x2F;DNS），便于跨可用区的 EC2&#x2F;ECS 容器挂载同一文件系统。</li>
<li>FSx 系列（Windows、ONTAP、OpenZFS）的挂载目标通常与文件服务器所在的子网&#x2F;AZ 相关，不会自动在每个 AZ 提供挂载目标（除非手动配置多 AZ 部署并分别设置挂载点，但通常是一个主挂载点）。</li>
</ul>
<h3 id="2-跨区域复制与-AWS-Backup"><a href="#2-跨区域复制与-AWS-Backup" class="headerlink" title="2. 跨区域复制与 AWS Backup"></a>2. 跨区域复制与 AWS Backup</h3><ul>
<li>AWS Backup 支持对 <strong>EFS 和 FSx</strong> 进行备份和跨区域复制。</li>
<li>但题目要求 <strong>使用 AWS Backup 来管理到另一个区域的复制</strong>，且 RPO 8 小时 → 可以通过 AWS Backup 计划定期备份（如每 8 小时）并复制到另一个区域。</li>
</ul>
<h3 id="3-高耐用性"><a href="#3-高耐用性" class="headerlink" title="3. 高耐用性"></a>3. 高耐用性</h3><ul>
<li>EFS 标准存储类提供 <strong>11 个 9（99.999999999%）</strong> 的持久性，且跨多个 AZ 存储数据，满足高耐用性。</li>
</ul>
<p><br>476 公司预计快速增长，解决方案架构师需要：</p>
<ul>
<li>在 AWS 上配置现有用户，并向新用户授予权限。</li>
<li>决定 <strong>创建 IAM 组</strong>，并根据部门将新用户添加到相应的 IAM 组。</li>
<li>问：授予新用户权限的 <strong>最安全的额外操作</strong> 是什么？</li>
</ul>
<p>A. 应用 <strong>服务控制策略（SCP）</strong> 来管理访问权限。<br>B. 创建具有最小权限的 <strong>IAM 角色</strong>，将这些角色附加到 IAM 用户组。<br>C. <u>创建一个授予 <strong>最小权限</strong> 的 <strong>IAM 策略</strong>，将该策略附加到 IAM 组。</u><br>D. 创建 <strong>IAM 角色</strong>，将这些角色与定义最大权限的 <strong>权限边界</strong> 相关联。</p>
<p>SCP 是 <strong>AWS Organizations 的服务控制策略</strong>，用于在组织&#x2F;OU 层面限制成员账户的最大权限，不适用于在单个账户内对 IAM 组&#x2F;用户授权，且 SCP 通常用于禁止某些操作，而不是精细授权</p>
<p>IAM 角色是用于委派临时权限的实体，<strong>不能直接附加到 IAM 组</strong>（角色是给用户、服务或外部身份担任的，不是组的属性）</p>
<p>477一个组需要权限：</p>
<ol>
<li><strong>列出一个 Amazon S3 存储桶</strong>（<code>s3:ListBucket</code>）。</li>
<li><strong>从该存储桶中删除对象</strong>（<code>s3:DeleteObject</code>）。</li>
</ol>
<p>管理员创建了以下 IAM 策略并附加到该组：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;s3:ListBucket&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;s3:DeleteObject&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;arn:aws:s3:::bucket-name&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<p>但 <strong>该组无法删除存储桶中的对象</strong>。<br>公司遵循 <strong>最小权限访问规则</strong>。</p>
<p>问：解决方案架构师应在策略中添加哪条语句来修正存储桶访问权限？</p>
<p>A.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;s3:*Object&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;arn:aws:s3:::bucket-name/*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span></span><br></pre></td></tr></table></figure>

<p>B.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;s3:*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;arn:aws:s3:::bucket-name/*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span></span><br></pre></td></tr></table></figure>

<p>C.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;s3:DeleteObject&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;arn:aws:s3:::bucket-name*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span></span><br></pre></td></tr></table></figure>

<p><u>D.</u></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;s3:DeleteObject&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;arn:aws:s3:::bucket-name/*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span></span><br></pre></td></tr></table></figure>







<p><br>478 律师事务所需要向公众分享信息：</p>
<ul>
<li>包括 <strong>数百个必须可供公众阅读的文件</strong>。</li>
<li>要求：在 <strong>指定的未来日期之前</strong>，<strong>任何人都不得修改或删除这些文件</strong>（不可变）。</li>
<li>目标：以 <strong>最安全的方式</strong> 满足要求。</li>
</ul>
<p>A. 将所有文件上传到配置为 <strong>静态网站托管</strong> 的 S3 存储桶，向任何 AWS 主体授予 <strong>只读 IAM 权限</strong> 直至指定日期。<br>B. <u>创建一个启用了 <strong>S3 版本控制</strong> 的新 S3 存储桶，使用 <strong>S3 对象锁定</strong> 并设置与指定日期相符的保留期，将 S3 存储桶配置为静态网站托管，设置 <strong>S3 存储桶策略</strong> 允许对对象的只读访问。</u><br>C. 创建一个启用了 <strong>S3 版本控制</strong> 的新 S3 存储桶，配置 <strong>事件触发器</strong> 在对象被修改&#x2F;删除时运行 <strong>Lambda 函数</strong>，用私有 S3 存储桶中的原始版本替换这些对象。<br>D. 将所有文件上传到配置为 <strong>静态网站托管</strong> 的 S3 存储桶，选择包含这些文件的文件夹，根据指定日期使用 <strong>S3 对象锁定</strong>，向访问该 S3 存储桶的所有 AWS 主体授予 <strong>只读 IAM 权限</strong>。</p>
<h3 id="1-需求分解"><a href="#1-需求分解" class="headerlink" title="1. 需求分解"></a>1. 需求分解</h3><ul>
<li><strong>公开读取</strong>：文件需要被公众访问（静态网站或公开读取权限）。</li>
<li><strong>不可修改&#x2F;删除直到指定日期</strong>：需要 <strong>对象不可变性（immutability）</strong> 功能。</li>
<li><strong>最安全</strong>：确保机制可靠、无法绕过。</li>
</ul>
<h3 id="2-不可变性方案"><a href="#2-不可变性方案" class="headerlink" title="2. 不可变性方案"></a>2. 不可变性方案</h3><ul>
<li><strong>S3 对象锁定（Object Lock）</strong> 是 S3 原生功能，可设置 <strong>保留期（Retention Period）</strong>，在保留期内禁止任何用户（包括根用户）删除或覆盖对象。</li>
<li>对象锁定支持两种模式：<strong>治理模式（Governance mode）</strong> 和 <strong>合规模式（Compliance mode）</strong>。<ul>
<li>对于“任何人都不得修改或删除”，应使用 <strong>合规模式</strong>（更严格）。</li>
</ul>
</li>
<li>对象锁定可以在 <strong>存储桶级别启用</strong>，并在上传对象时指定保留期。</li>
</ul>
<p><br>479 一家公司手动配置了一套新网站的基础设施原型，包括自动扩展组、应用负载均衡器和 Amazon RDS 数据库。配置验证后，公司希望以自动化方式在两个可用区中为开发和生产环境立即部署相同的基础设施。<br>解决方案架构师应推荐什么方案来满足这些要求？</p>
<p>A. 使用 AWS Systems Manager 在两个可用区中复制和配置原型基础设施<br>B. <u>以原型基础设施为指导，将基础设施定义为模板。使用 AWS CloudFormation 部署该基础设施</u><br>C. 使用 AWS Config 记录原型基础设施中使用的资源清单。使用 AWS Config 将原型基础设施部署到两个可用区<br>D. 使用 AWS Elastic Beanstalk 并对其进行配置，使其自动引用原型基础设施，以便在两个可用区中自动部署新环境</p>
<p>AWS CloudFormation 是 AWS 的基础设施即代码（IaC）服务，可以通过编写模板来描述整个基础设施（ASG、ALB、RDS 等），并支持跨可用区部署，可重复用于开发、生产环境，完全符合“自动化部署”和“立即部署”的要求。</p>
<p>AWS Systems Manager 主要用于运维管理、自动化运维任务、补丁管理等，不适合用于大规模基础设施的编排和跨可用区完整部署。</p>
<p>AWS Config 用于审计和记录资源配置合规性，不用于部署基础设施</p>
<p>AWS Elastic Beanstalk 主要用于快速部署应用环境（平台即服务），虽然可以管理负载均衡器、自动扩展等，但对 RDS 的支持通常是作为外部资源链接，并且要完全复制手动的复杂多组件原型，使用 CloudFormation 比 Elastic Beanstalk 更灵活可控，也更符合“以原型为指导定义模板”的 IaC 最佳实践。</p>
<p><br>480  一个业务应用程序托管在 Amazon EC2 上，并使用 Amazon S3 进行加密对象存储。首席信息安全官要求：这两个服务之间的任何应用程序流量都不应经过公共互联网。<br>解决方案架构师应使用哪种功能来满足该合规性要求？</p>
<p>A. AWS 密钥管理服务（AWS KMS）<br>B. <u>VPC 终端节点（VPC Endpoint）</u><br>C. 私有子网<br>D. 虚拟专用网关（Virtual Private Gateway）</p>
<p>虚拟专用网关用于连接 VPC 和客户本地网络的 VPN 或 Direct Connect，与 EC2 访问 S3 的内部流量路径无关</p>
<p>私有子网只能确保 EC2 没有公网 IP，但如果 EC2 访问 S3 仍然走公网端点（<a target="_blank" rel="noopener" href="https://s3.amazonaws.com/">s3.amazonaws.com</a>），流量还是会经过互联网；仅靠私有子网无法确保流量在 AWS 内部网络中传输。</p>
<p><br>481 一家公司在 AWS 上托管三层 Web 应用程序，使用多可用区 Amazon RDS for MySQL 作为数据库层，Amazon ElastiCache 作为缓存层。要求：当客户向数据库中添加项目时，缓存中也应同时添加或更新数据，保证缓存数据与数据库数据始终一致。<br>哪种缓存策略可以满足这些要求？</p>
<p>A. 实施延迟加载缓存策略<br>B. <u>实施直写式缓存策略（Write-Through）</u><br>C. 实施添加 TTL 缓存策略<br>D. 实施 AWS AppConfig 缓存策略</p>
<p>延迟加载（Lazy Loading，也叫 Cache-Aside）策略中，缓存更新是在缓存未命中时从数据库加载，写入时只写数据库，之后缓存失效，下次读取时再更新。这会导致短暂的数据不一致，不满足“始终一致”要求。</p>
<p>TTL（生存时间）策略只是让缓存数据到期后失效，并不能保证写入时缓存立即更新，不能保证一致性</p>
<p><br>482 一家公司想把 100GB 历史数据从本地迁移到 Amazon S3，本地互联网带宽为 100 Mbps，需要对传输到 S3 的数据加密，并且未来新数据会直接存到 S3。<br>问：哪种方案能以最低运营开销满足要求？</p>
<p>A. 使用 AWS CLI 的 s3 sync 命令将数据直接移动到 S3 存储桶<br>B. <u>使用 AWS DataSync 将数据从本地位置迁移到 S3 存储桶</u><br>C. 使用 AWS Snowball 将数据迁移到 S3 存储桶<br>D. 从本地设置 IPsec VPN 到 AWS，用 AWS CLI 的 s3 cp 命令将数据直接移动到 S3 存储桶</p>
<p><br>483 一家公司将一个运行在 Windows 容器、基于 .NET 6 框架的 Windows 作业进行了容器化处理，希望在 AWS 云中运行此作业。<br>作业每 10 分钟运行一次，每次运行时间为 1 到 3 分钟。<br>问：哪种解决方案最具有成本效益地满足要求？</p>
<p>A. 基于作业的容器镜像创建一个 AWS Lambda 函数。配置 Amazon EventBridge 每 10 分钟调用一次该函数。<br>B. 使用 AWS Batch 创建一个使用 AWS Fargate 资源的作业。将作业调度配置为每 10 分钟运行一次。<br>C. <u>使用 AWS Fargate 上的 Amazon Elastic Container Service（Amazon ECS）来运行作业。基于此创建一个定时任务每 10 分钟运行一次的作业的容器镜像。</u><br>D. 在 AWS Fargate 上使用 Amazon Elastic Container Service（Amazon ECS）来运行作业。基于作业的容器镜像创建一个独立任务。使用 Windows 任务计划程序每 10 分钟运行一次该作业。</p>
<p>Lambda 原本支持 .NET 6 运行时（包括 Windows？），但注意 Lambda 对 Windows 容器支持有限（截至知识截止时，Lambda 不支持 Windows 容器运行，只支持自定义容器镜像基于 Linux，Windows 容器不能直接在 Lambda 运行），因此此方案不可行。</p>
<p><br>484 一家公司希望从多个独立的 AWS 账户迁移到一个整合的多账户架构，计划为不同业务部门创建多个新的 AWS 账户。<br>要求：使用集中式企业目录服务对这些 AWS 账户的访问进行身份验证。<br>问：解决方案架构师应推荐哪两项操作组合来满足这些要求？</p>
<p>A. <u>在 AWS Organizations 中创建一个新组织，并启用所有功能。在其中创建新的 AWS 账户</u>。<br>B. 设置一个 Amazon Cognito 身份池。配置 AWS IAM Identity Center（AWS 单点登录）以接受 Amazon Cognito 认证。<br>C. 配置服务控制策略（SCP）以管理 AWS 账户。将 AWS IAM Identity Center（AWS 单点登录）添加到 AWS Directory Service。<br>D. 在 AWS Organizations 中创建一个新组织。将该组织的身份验证机制配置为直接使用 AWS Directory Service。<br>E. <u>在组织中设置 AWS IAM Identity Center（AWS 单点登录）。配置 IAM Identity Center，并将其与公司的企业目录服务集成。</u></p>
<p><strong>解析</strong>：</p>
<ol>
<li><strong>多账户架构</strong>需要 AWS Organizations 来集中管理多个账户，所以 <strong>A</strong> 是必要的初始步骤。</li>
<li><strong>集中式企业目录服务</strong>用于身份验证，IAM Identity Center（原 AWS SSO）支持与外部身份源（如企业 Active Directory、AWS Managed AD 或其他 SAML 2.0 身份提供者）集成，以实现 SSO 访问 AWS 账户。所以 <strong>E</strong> 是正确实现方式。<ul>
<li>注意：IAM Identity Center 不“添加到” AWS Directory Service，而是可以连接已有的目录（包括 AWS Managed Microsoft AD 或 公司自建 AD）。</li>
</ul>
</li>
<li><strong>B</strong>：Cognito 主要用于移动&#x2F;Web 应用的用户身份管理，不是为企业目录集成 AWS 多账户访问的首选方案（IAM Identity Center 更直接）。</li>
<li><strong>C</strong>：SCP 是用于权限管控的策略，不是身份验证机制；且 IAM Identity Center 不“添加到” Directory Service，逻辑反了。</li>
<li><strong>D</strong>：AWS Organizations 本身不直接配置身份验证机制，身份验证是通过 IAM 或 IAM Identity Center 实现的，不能直接将组织“配置为使用 AWS Directory Service”。</li>
</ol>
<p>485一家公司需要存储旧新闻素材的视频档案，要求：</p>
<ul>
<li>成本最低</li>
<li>很少需要恢复文件</li>
<li>恢复时必须在最多 5 分钟内可用</li>
</ul>
<p>问：最具成本效益的解决方案是什么？</p>
<p>A. <u>将视频档案存储在 Amazon S3 Glacier 中，并使用加急检索</u>。<br>B. 将视频档案存储在 Amazon S3 Glacier 中，并使用标准检索。<br>C. 将视频档案存储在 Amazon S3 标准不频繁访问（S3 Standard-IA）中。<br>D. 将视频档案存储在 Amazon S3 One Zone-不常访问（S3 One Zone-IA）中</p>
<p>S3 Glacier（现在应指 S3 Glacier Flexible Retrieval 或之前的 S3 Glacier）的 <strong>加急检索（Expedited Retrieval）</strong> 通常在 1–5 分钟内可取回，但检索费用较高。对于很少访问且要求 5 分钟内可用的场景，如果“很少恢复”意味着几年才恢复一两次，那么 Glacier + 加急检索可能是可行的低成本存储+偶尔的快速恢复方案</p>
<p>S3 One Zone-IA 存储成本比 Standard-IA 低（仅存单可用区），但依然比 Glacier 高很多，可随时访问</p>
<p>S3 Standard-IA 随时可取（毫秒级）</p>
<p>S3 Glacier 的 <strong>标准检索（Standard Retrieval）</strong> 需要 3–5 小时，不满足 5 分钟内可用的要求</p>
<p><br>486 一家公司在 AWS 上构建三层应用程序：</p>
<ul>
<li>表现层：静态网站</li>
<li>逻辑层：容器化应用</li>
<li>数据层：关系数据库<br>要求：简化部署并降低运营成本。</li>
</ul>
<p>问：哪种解决方案能满足这些要求？v</p>
<p>A. <u>使用 Amazon S3 托管静态内容，将 Amazon ECS 与 AWS Fargate 用于计算，数据库使用 Amazon RDS 集群。</u><br>B. 使用 Amazon CloudFront 托管静态内容（应配合 S3），使用 Amazon ECS with EC2 提供计算能力，使用 Amazon RDS 集群。<br>C. 使用 Amazon S3 托管静态内容，使用 Amazon EKS with AWS Fargate 提供计算能力，使用 Amazon RDS 集群。<br>D. 使用 Amazon EC2 预留实例托管静态内容，使用 Amazon EKS with EC2 提供计算能力，使用 Amazon RDS 集群。</p>
<p>S3（静态网站托管）、ECS Fargate（无服务器容器，无需管理节点）、RDS（托管数据库） → 全部是托管服务，部署简单，按需付费，运维成本低</p>
<p><br>487 一家公司为其应用程序寻找存储解决方案，要求：</p>
<ul>
<li>高可用性和可扩展性</li>
<li>能作为文件系统</li>
<li>可通过原生协议被 AWS 中多个 Linux 实例和本地环境挂载</li>
<li>没有最小容量要求</li>
<li>公司已有站点到站点 VPN 连接本地网络到 VPC</li>
</ul>
<p>问：哪种存储解决方案能满足这些要求？</p>
<p>A. 亚马逊 FSx 多可用区部署<br>B. 亚马逊弹性块存储（Amazon EBS）多挂载卷<br>C. <u>具有多个挂载目标的亚马逊弹性文件系统（Amazon EFS）</u><br>D. 具有单个挂载目标和多个访问点的亚马逊弹性文件系统（Amazon EFS）</p>
<p>Amazon FSx（Windows 或 Lustre 等）支持多可用区部署，高可用。但 FSx for Windows 使用 SMB 协议（不适合 Linux 原生协议），FSx for Lustre 高性能计算场景，虽然支持 Linux，但主要针对高性能计算，并且通常需要最小容量或性能要求，不一定符合“没有最小容量要求”且适合通用 Linux 文件共享场景。</p>
<p><br>488 一家成立 4 年的媒体公司正在使用 AWS Organizations 的全功能集来管理 AWS 账户。<br>财务团队要求：成员账户的账单信息不得被任何人访问，包括成员账户的根用户。<br>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 将所有财务团队用户添加到一个 IAM 组中。为该组附加一个名为 Billing 的 AWS 托管策略。<br>B. 附加基于身份的策略，以拒绝所有用户（包括根用户）访问账单信息。<br>C. <u>创建服务控制策略（SCP）以拒绝访问账单信息。将该 SCP 附加到根组织单位（OU）。</u><br>D. 从组织的所有功能套餐转换为组织的合并计费功能套餐。</p>
<p>服务控制策略（SCP）是在 AWS Organizations 全功能集下可用，可以附加到 OU 或账户，限制该 OU 或账户下所有身份（包括根用户）的权限。创建 SCP 明确拒绝访问账单信息并附加到根 OU，会影响其下所有成员账户，满足“包括成员账户的根用户”的限制要求</p>
<p><br>489 一家电商公司在 AWS 上运行应用，与本地仓库集成。使用 Amazon SNS 向本地 HTTPS 端点发送订单消息。部分订单消息未被接收。<br>要求：保留未送达的消息，并允许在长达 14 天内对这些消息进行分析。<br>问：哪种解决方案能以最少的开发工作量满足要求？</p>
<p><strong>选项</strong>：<br>A. 配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon Kinesis 数据流目标，保留期为 14 天。<br>B. 在应用程序和 Amazon SNS 之间添加一个保留期为 14 天的 Amazon Simple Queue Service（Amazon SQS）队列。<br>C. <u>配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon Simple Queue Service（Amazon SQS）目标，且带有一个 14 天的保留期。</u><br>D. 配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon DynamoDB 目标，且设置了生存时间（TTL）属性，保留期为 14 天。</p>
<p>B在应用程序和 SNS 之间加 SQS 队列，这是改变了架构顺序（SNS 之前就队列），不能捕获 SNS 发送失败的消息，无法满足“未送达的消息”捕获要求。</p>
<p><br>490 一家游戏公司使用 Amazon DynamoDB 存储用户信息、地理位置、玩家数据和排行榜。<br>要求：</p>
<ol>
<li>通过最少的代码配置将数据持续备份到 Amazon S3</li>
<li>备份不得影响应用程序可用性</li>
<li>备份不得影响为表定义的读取容量单位（RCU）</li>
</ol>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. 使用 Amazon EMR 集群。创建一个 Apache Hive 作业，将数据备份到 Amazon S3。<br>B. <u>通过持续备份将数据直接从 DynamoDB 导出到 Amazon S3。为其开启时间点恢复功能</u>。<br>C. 配置 Amazon DynamoDB Streams。创建一个 AWS Lambda 函数来消费该流并将数据导出到 Amazon S3 存储桶。<br>D. 创建一个 AWS Lambda 函数，定期将数据库表中的数据导出到 Amazon S3。为该表开启时间点恢复功能。</p>
<p>持续备份包括 PITR 和按需导出功能，可以通过导出到 S3 功能实现将快照数据导出到 S3，而导出过程使用独立于表的读取容量（采用扫描而非消耗 RCU 的方式，AWS 声明不影响表性能）。这是 AWS 推荐的无服务器、低代码备份方案。</p>
<p><br>491 一位解决方案架构师正在为一家银行设计异步应用程序，用于处理信用卡数据验证请求。要求：</p>
<ol>
<li>应用程序必须安全</li>
<li>能够至少处理每个请求一次（at-least-once processing）<br>问：哪种解决方案最具成本效益地满足这些要求？</li>
</ol>
<p>A. <u>使用 AWS Lambda 事件源映射。将 Amazon SQS 标准队列设置为事件源。使用 AWS KMS（SSE-KMS）进行加密。为 Lambda 执行角色添加 kms:Decrypt 权限</u>。<br>B. 使用 AWS Lambda 事件源映射。使用 Amazon SQS FIFO 队列作为事件源。使用 SQS 托管加密密钥（SSE-SQS）进行加密。为 Lambda 函数添加加密密钥调用权限。<br>C. 使用 AWS Lambda 事件源映射。将 Amazon SQS FIFO 队列设置为事件源。使用 AWS KMS 密钥（SSE-KMS）。为 Lambda 执行角色添加 kms:Decrypt 权限。<br>D. 使用 AWS Lambda 事件源映射。将 Amazon SQS 标准队列设置为事件源。使用 AWS KMS 密钥（SSE-KMS）进行加密。为 Lambda 函数添加加密密钥调用权限</p>
<ol>
<li><strong>安全性</strong>：需加密队列中的消息，SQS 支持服务器端加密（SSE）。SSE-SQS（SQS 托管密钥）免费；SSE-KMS（AWS KMS 托管密钥）更安全但会产生 KMS 密钥使用成本。</li>
<li><strong>至少处理一次</strong>：SQS 标准队列提供至少一次交付（但有极低概率重复），SQS FIFO 队列提供严格一次处理（但不一定成本效益最高）。</li>
<li><strong>成本效益</strong>：标准队列比 FIFO 队列便宜，且对于“至少一次”来说，标准队列已满足要求。</li>
</ol>
<p>逐项分析：</p>
<ul>
<li><strong>A</strong>：标准队列 + SSE-KMS 加密。标准队列满足至少一次处理，成本低于 FIFO；SSE-KMS 提供密钥管理，安全，但 KMS 会有少量成本。不过银行场景对安全要求高，使用 KMS 是合理的。</li>
<li><strong>B</strong>：FIFO 队列 + SSE-SQS 加密。FIFO 队列提供精确一次处理，但价格更高（按请求数计费更贵），且题目只要求至少一次，不要求严格一次，因此 FIFO 成本效益较低。SSE-SQS 免费但安全级别低于 KMS。</li>
<li><strong>C</strong>：FIFO 队列 + SSE-KMS 加密，成本最高（FIFO 费用 + KMS 费用）。</li>
<li><strong>D</strong>：与 A 类似，但 A 明确说“为 Lambda 执行角色添加 kms:Decrypt 权限”，D 说“为 Lambda 函数添加加密密钥调用权限”，表达不准确；A 描述更符合 AWS 权限模型。</li>
</ul>
<p><br>492 一家公司有多个开发 AWS 账户，员工常使用过大的 EC2 实例，导致超出年度预算。公司希望集中限制这些账户中 AWS 资源的创建。<br>要求：以最少的开发工作量满足这些要求。</p>
<p><strong>选项</strong>：<br>A. 开发使用经批准的 EC2 创建流程的 AWS Systems Manager 模板。使用经批准的 Systems Manager 模板来配置 EC2 实例。<br>B. <u>使用 AWS Organizations 将账户组织到组织单位（OUs）中。定义并附加一个服务控制策略（SCP）来控制 EC2 实例类型的使用。</u><br>C. 配置一个 Amazon EventBridge 规则，当创建 EC2 实例时调用 AWS Lambda 函数。停止不允许的 EC2 实例类型。<br>D. 为员工设置 AWS 服务目录产品，以创建允许的 EC2 实例类型。确保员工只能通过使用服务目录产品来部署 EC2 实例。</p>
<p>Systems Manager 模板（如 SSM Automation 或 EC2 Image Builder）可用于标准化部署，但需要员工主动使用这些模板，不能强制阻止直接创建不合规的 EC2 实例，也无法集中跨账户限制。</p>
<p>AWS Organizations 服务控制策略（SCP）可以在组织单位（OU）或账户级别集中设置权限边界，禁止某些 EC2 实例类型的创建。这是集中化、无需编写额外代码（最少开发工作量）、且能强制执行的控制方式。</p>
<p>AWS 服务目录可以控制员工只能通过预定义产品启动实例，但需要创建和管理产品组合，且员工可能绕过服务目录直接使用 EC2 控制台&#x2F;API，除非配合 SCP 或 IAM 完全禁止直接访问 EC2 创建权限，这会增加配置复杂度</p>
<p><br>493 一家公司希望利用 AI 评估客户服务电话的质量。<br>当前处理四种不同语言的电话，包括英语，未来还会增加新的语言。<br>公司没有资源定期维护机器学习模型。<br>要求：</p>
<ol>
<li>根据客服通话录音生成书面的情感分析报告。</li>
<li>客服通话录音文本必须被翻译成英语。</li>
</ol>
<p>问：哪些步骤组合可以满足这些要求？（选三项）</p>
<p><strong>选项</strong>：<br>A. 使用 Amazon Comprehend 将录音翻译成英语。<br>B. 使用 Amazon Lex 创建书面情感分析报告。<br>C. 使用 Amazon Polly 将录音转换为文本。<br>D. 使<u>用 Amazon Transcribe 将任何语言的录音转换为文本</u>。<br>E. <u>使用 Amazon Translate 将任何语言的文本翻译成英语。</u><br><u>F. 使用 Amazon Comprehend 创建情感分析报告</u>。</p>
<ul>
<li><strong>A</strong>：Amazon Comprehend 不支持语音翻译，只支持文本分析。</li>
<li><strong>B</strong>：Amazon Lex 是用于构建对话机器人的服务，不能用于情感分析报告。</li>
<li><strong>C</strong>：Amazon Polly 是文本转语音，不是语音转文本，功能相反。</li>
</ul>
<p><br>494 一家公司使用 Amazon EC2 实例，管理员尝试用 AWS CLI 终止 EC2 实例，收到 403 访问被拒绝。<br>管理员使用的 IAM 角色附加了给定的 IAM 策略。</p>
<p>策略内容：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;ec2:TerminateInstances&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;*&quot;</span><span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Deny&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;ec2:TerminateInstances&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;NotIpAddress&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;aws:SourceIp&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;192.0.2.0/24&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="string">&quot;203.0.113.0/24&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;*&quot;</span><span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>问：请求失败的原因是什么？</p>
<p><strong>选项</strong>：<br>A. EC2 实例具有包含拒绝语句的基于资源的策略。<br>B. 策略声明中未指定主体。<br>C. “Action” 字段未授予终止 EC2 实例所需的操作权限。<br><u>D. 终止 EC2 实例的请求并非源自 CIDR 块 192.0.2.0&#x2F;24 或 203.0.113.0&#x2F;24。</u></p>
<p><br>495 一家公司正在进行内部审计，希望确保与 AWS Lake Formation 数据湖关联的 Amazon S3 存储桶中的数据不包含敏感客户或员工数据。<br>要求：发现个人身份信息（PII）或财务信息，包括护照号码和信用卡号。<br>问：哪种解决方案能满足这些要求？</p>
<p><strong>选项</strong>：<br>A. 在该账户上配置 AWS Audit Manager。选择支付卡行业数据安全标准（PCI DSS）进行审计。<br>B. 在 S3 存储桶上配置 Amazon S3 清单。配置 Amazon Athena 以查询该清单。<br>C. <u>配置 Amazon Macie 以运行数据发现作业，该作业使用托管标识符来识别所需的数据类型。</u><br>D. 使用 Amazon S3 Select 在整个 S3 存储桶中运行报告。</p>
<p><strong>解析</strong>：</p>
<ul>
<li><strong>A</strong>：AWS Audit Manager 主要用于自动化合规审计准备，收集证据，生成审计报告，但它不是专门用于主动扫描和发现敏感数据的工具。虽然 PCI DSS 审计会涉及信用卡数据，但不能直接发现 S3 存储桶中的敏感数据内容。</li>
<li><strong>B</strong>：S3 清单仅列出对象的元数据（如大小、加密状态等），不扫描内容；Athena 可以查询清单，但仍无法检测内容中的 PII 或金融信息。</li>
<li><strong>C</strong>：Amazon Macie 是专门用于发现、分类和保护敏感数据的服务。它使用机器学习与托管标识符（如信用卡号、护照号等）自动扫描 S3 存储桶，并生成数据发现报告，正好满足“发现 PII 或财务信息”的要求。</li>
<li><strong>D</strong>：S3 Select 用于检索对象内容的子集，不能用于大规模内容敏感数据发现，且需要事先知道查询条件，不适合未知敏感数据定位。</li>
</ul>
<p><br>496 一家公司在本地服务器上托管应用程序，存储容量即将耗尽。应用程序既使用块存储也使用 NFS 存储。<br>要求：</p>
<ul>
<li>高性能解决方案</li>
<li>支持本地缓存</li>
<li>无需重新架构现有应用程序</li>
</ul>
<p>问：应采取哪些行动组合来满足这些要求？（选两项）</p>
<p><strong>选项</strong>：<br>A. 将 Amazon S3 作为文件系统挂载到本地服务器。<br>B. <u>部署 AWS Storage Gateway 文件网关以替换 NFS 存储</u>。<br>C. 部署 AWS Snowball Edge，为本地服务器提供 NFS 挂载。<br>D. <u>部署一个 AWS Storage Gateway 卷网关来替换块存储</u>。<br>E. 部署亚马逊弹性文件系统（Amazon EFS）卷并将其挂载到本地服务器</p>
<p>逐项分析：</p>
<ul>
<li><strong>A</strong>：将 S3 作为文件系统挂载（如使用 S3 File Gateway 或第三方工具），这本质上是文件存储（对象存储模拟文件系统），但 S3 不是高性能块存储，也不直接支持本地块存储场景。</li>
<li><strong>B</strong>：Storage Gateway 文件网关提供 NFS 或 SMB 接口，将后端存储在 S3，支持本地缓存（缓存频繁访问的数据），适合替换 NFS 存储，无需重构应用 → 符合要求。</li>
<li><strong>C</strong>：Snowball Edge 是物理设备，主要用于大规模数据传输或边缘计算，可提供本地存储（包括 NFS），但它是临时性设备，不适合长期扩展存储容量（除非作为缓存或临时扩展）。而且它不直接与 AWS 存储服务透明集成（需要迁移数据）。</li>
<li><strong>D</strong>：Storage Gateway 卷网关提供 iSCSI 接口（块存储），支持本地缓存，后端是 Amazon EBS 快照和 S3，适合替换本地块存储，无需重构应用 → 符合要求。</li>
<li><strong>E</strong>：Amazon EFS 是托管 NFS 文件系统，但 EFS 要求通过 VPN 或 Direct Connect 挂载到本地，且<strong>没有内置本地缓存</strong>（虽然有 EFS 加速器如 DataSync 可缓存，但 EFS 原生不支持本地缓存），性能可能不如带本地缓存的 Storage Gateway。</li>
</ul>
<p><br>497 一家公司有一项服务，从同一 AWS 区域的 Amazon S3 存储桶读写大量数据。该服务部署在 VPC 私有子网中的 Amazon EC2 实例上。当前通过公有子网中的 NAT 网关与 Amazon S3 通信。<br>公司希望找到能降低数据输出成本的解决方案。<br>问：哪种方案能以最具成本效益的方式满足要求？</p>
<p><strong>选项</strong>：<br>A. 在公有子网中配置一个专用的 EC2 NAT 实例。为私有子网配置路由表，将该实例的弹性网络接口用作所有 S3 流量的目的地。<br>B. 在私有子网中配置一个专用的 EC2 NAT 实例。为公有子网配置路由表，将该实例的弹性网络接口用作所有 S3 流量的目标。<br>C. <u>配置一个 VPC 网关终端节点。为私有子网配置路由表，使其将网关终端节点用作所有 S3 流量的路由</u>。<br>D. 配置第二个 NAT 网关。为私有子网配置路由表，将此 NAT 网关用作所有 S3 流量的目标。</p>
<p><strong>解析</strong>：</p>
<ul>
<li>当前架构：私有子网 EC2 → NAT 网关 → 公网 → S3（同一区域）</li>
<li>问题：通过 NAT 网关访问 S3 会产生 <strong>数据传出费用</strong>（NAT 网关数据传出收费，且 S3 通过公网访问也会产生区域内的数据传输费？注意：S3 同区域通过公网访问仍收少量数据传输费；而通过 VPC 端点则不收费）。</li>
<li>目标：降低数据输出成本。</li>
</ul>
<p>解决方案比较：</p>
<ul>
<li><strong>A 和 B</strong>：使用 EC2 NAT 实例依然经过公网访问 S3，数据传输费用与 NAT 网关类似，且 NAT 实例还有管理开销，不降低费用。</li>
<li><strong>C</strong>：<strong>VPC 网关终端节点（Gateway VPC Endpoint for S3）</strong> 允许私有子网通过 AWS 内部网络直接访问 S3，不经过 NAT 网关或互联网，因此 <strong>不产生 NAT 网关数据传出费用</strong>，且 S3 同区域数据传输免费。这是 AWS 推荐的成本效益最佳方案。</li>
<li><strong>D</strong>：增加第二个 NAT 网关不会减少数据传输费用，反而可能增加成本（双 NAT 网关收费）。</li>
</ul>
<p><br>498 一家公司使用 Amazon S3 存储高分辨率图片，存储桶启用了版本控制。为了尽量减少应用变更，图片存储为 S3 对象的最新版本。<br>要求：只需保留图片的两个最新版本。<br>公司希望降低成本（S3 存储桶是大额支出），并以最少的运营开销降低 S3 成本。</p>
<p><strong>选项</strong>：<br>A. <u>使用 S3 生命周期删除过期的对象版本，并保留最近的两个版本</u>。<br>B. 使用 AWS Lambda 函数检查旧版本，并删除除最近两个版本之外的所有版本。<br>C. 使用 S3 批量操作删除当前对象版本，仅保留最近的两个版本。<br>D. 停用 S3 存储桶的版本控制并保留最近的两个版本。</p>
<p>S3 生命周期策略支持<strong>版本过期规则</strong>，可以配置为仅保留最近 N 个版本（本例 N&#x3D;2），自动删除旧版本。这是全托管、自动化、无需额外运维工作的方案，且符合最少运营开销要求</p>
<p><br>499 一家公司需要降低其 1 Gbps AWS Direct Connect 连接的成本。当前平均连接利用率低于 10%。<br>要求：在不影响安全性的前提下降低成本。</p>
<p><strong>选项</strong>：<br>A. 建立一个新的 1 Gbps Direct Connect 连接。与另一个 AWS 账户共享该连接。<br>B. 在 AWS 管理控制台中设置一个新的 200 Mbps Direct Connect 连接。<br>C. 联系 AWS Direct Connect 合作伙伴，订购 1 Gbps 连接。与另一个 AWS 账户共享该连接。<br>D. <u>联系 AWS Direct Connect 合作伙伴，为现有 AWS 账户订购 200 Mbps 的托管连接。</u></p>
<p><strong>解析</strong>：</p>
<ul>
<li>当前使用 1 Gbps 的 Direct Connect 连接，利用率低于 10%，说明带宽远远超出需求，导致不必要的成本。</li>
<li>降低成本的方式是<strong>降低带宽</strong>（例如改为 200 Mbps）。</li>
<li>注意：AWS Direct Connect 有两种方式：<ol>
<li><strong>专线端口</strong>（1 Gbps 或 10 Gbps）由客户向 AWS 或合作伙伴订购，按端口速度计费，即使利用率低也固定收费。</li>
<li><strong>托管连接</strong>（Hosted Connections）由 AWS Direct Connect 合作伙伴提供，可提供更低带宽（如 50 Mbps、100 Mbps、200 Mbps 等），按所选带宽计费。</li>
</ol>
</li>
<li>由于已有 1 Gbps 连接，要降低成本，应该改为更低带宽的托管连接。</li>
</ul>
<p>对各选项分析：</p>
<ul>
<li><strong>A</strong>：新建 1 Gbps 连接并与另一个账户共享，不会降低成本（可能增加成本）。</li>
<li><strong>B</strong>：在 AWS 控制台中设置新的 200 Mbps Direct Connect 连接，但 AWS 控制台直接订购的是 1 Gbps 或 10 Gbps 专线端口，不能直接订购 200 Mbps（200 Mbps 属于托管连接，需通过合作伙伴订购）。因此 B 不可行。</li>
<li><strong>C</strong>：联系合作伙伴订购 1 Gbps 连接并共享，依然是 1 Gbps，不降低成本。</li>
<li><strong>D</strong>：联系 AWS Direct Connect 合作伙伴，为现有 AWS 账户订购 200 Mbps 托管连接。这样可以减少带宽（从而降低成本），且不影响安全性（连接依然是专用的、私有的）。</li>
</ul>
<p><br>500 一家公司在本地有多台 Windows 文件服务器，希望将文件迁移并整合到 Amazon FSx for Windows File Server 文件系统。<br>要求：必须保留文件权限（确保访问权限不变）。<br>问：哪些解决方案能满足这些要求？（选两项）</p>
<p><strong>选项</strong>：<br>A. <u>在本地部署 AWS DataSync 代理。计划 DataSync 任务，将数据传输到适用于 Windows 文件服务器的 FSx 文件系统。</u><br>B. 使用 AWS CLI 将每个文件服务器上的共享复制到 Amazon S3 存储桶。计划 AWS DataSync 任务，将数据传输到适用于 Windows 文件服务器的 FSx 文件系统。<br>C. 从每个文件服务器中移除驱动器，将驱动器运送到 AWS 以导入到 Amazon S3。安排 AWS DataSync 任务将数据传输到适用于 Windows 文件服务器的 FSx 文件系统。<br>D. <u>订购一台 AWS Snowcone 设备，连接到本地网络，在其上启动 AWS DataSync 代理，安排 DataSync 任务将数据传输到适用于 Windows 文件服务器的 FSx 文件系统。</u><br>E. 订购一台 AWS Snowball Edge 存储优化型设备，连接到本地网络，使用 AWS CLI 将数据复制到设备，将设备寄回 AWS 导入 S3，再通过 DataSync 将数据传输到 FSx for Windows File Server。</p>
<p><strong>解析</strong>：</p>
<ul>
<li><strong>关键需求</strong>：迁移到 FSx for Windows File Server 并保留文件权限（如 NTFS 权限）。</li>
<li>AWS DataSync 支持在本地文件系统（包括 Windows）与 AWS 存储服务（如 FSx for Windows File Server）之间同步数据，并<strong>保留元数据</strong>（包括文件权限、时间戳等）。</li>
<li>因此，任何使用 DataSync 从源 Windows 文件服务器直接同步到 FSx for Windows 的方案都可以保留权限。</li>
</ul>
<p>对各选项分析：</p>
<ul>
<li><strong>A</strong>：在本地部署 DataSync 代理，直接同步到 FSx for Windows → 可以保留文件权限，且步骤简单。</li>
<li><strong>B</strong>：先用 AWS CLI 复制到 S3（CLI 复制可能丢失 Windows 元数据权限），再从 S3 到 FSx 使用 DataSync，但 S3 不保存 NTFS 权限，导致最终权限丢失。</li>
<li><strong>C</strong>：物理驱动器寄送到 AWS 导入 S3（通过 AWS Snowball 或导入导出服务），同样 S3 不保留权限，后续 DataSync 从 S3 到 FSx 无法恢复权限。</li>
<li><strong>D</strong>：Snowcone 设备上启动 DataSync 代理，通过 DataSync 直接同步到 FSx → 可以保留权限，Snowcone 作为边缘设备运行 DataSync 代理，适合小规模数据迁移。</li>
<li><strong>E</strong>：通过 Snowball Edge 复制数据（CLI 复制可能不保留元数据）再寄回导入 S3，然后从 S3 用 DataSync 到 FSx，同样 S3 无法保留权限。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T400/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T400/" class="post-title-link" itemprop="url">AWS架构师T400</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T400"><a href="#AWS架构师T400" class="headerlink" title="AWS架构师T400"></a>AWS架构师T400</h1><p><br>301 一所大学需要将 30TB 的本地 Windows 文件服务器数据迁移到 Amazon FSx for Windows File Server，网络带宽为共享的 1Gbps，要求在 5 天内完成迁移，并且能控制迁移过程占用的带宽，以减少对其他部门的影响。问哪个 AWS 解决方案最适合。</p>
<p>A. AWS Snowcone（亚马逊智能）<br>B. 亚马逊 FSx 文件网关<br><u>C. AWS DataSync</u><br>D. AWS Transfer Family（AWS 代言者）</p>
<p> <strong>AWS Snowcone</strong></p>
<ul>
<li>这是物理设备（边缘存储设备），适合离线迁移或极差网络环境</li>
</ul>
<p><strong>Amazon FSx 文件网关</strong></p>
<ul>
<li>AWS Storage Gateway 中的“文件网关”可为本地提供 SMB&#x2F;NFS 接口，缓存到 AWS，但通常用于混合云持续访问，不是一次性迁移工具</li>
</ul>
<p> <strong>AWS DataSync</strong></p>
<ul>
<li>专门用于在本地存储与 AWS 存储服务（包括 FSx for Windows）之间自动、快速、安全地迁移大量数据</li>
</ul>
<p><strong>WS Transfer Family</strong></p>
<ul>
<li>用于通过 SFTP、FTPS、FTP 协议上传文件到 AWS（如 Amazon S3、EFS），并不直接支持迁移到 FSx for Windows File Server 并保持 Windows 权限元数据</li>
</ul>
<p><br>302 一家公司开发了一个移动应用，用户拍摄慢动作视频并上传到 Amazon S3，然后从 S3 直接获取播放。由于原始视频文件太大，导致移动设备播放时出现缓冲和卡顿。公司希望以最小运营开销提高应用的性能和扩展性。需要选择两种解决方案组合</p>
<p>A. <u>部署 Amazon CloudFront 用于内容分发和缓存。</u><br>B. 使用 AWS DataSync 在其他 S3 存储桶中跨 AWS 区域复制视频文件。<br>C. <u>使用 Amazon Elastic Transcoder 将视频文件转换为更合适的格式</u>。<br>D. 在本地区域部署一组自动密封的 Amazon EC2 实例，用于内容分发和缓存。<br>E. 部署一个 Amazon EC2 实例的自动扩展组，将视频文件转换为更合适的格式。</p>
<ul>
<li><strong>Elastic Transcoder</strong> 将视频转换为更适合流媒体的格式，减小文件大小，从根本上减少缓冲。</li>
<li><strong>CloudFront</strong> 通过 CDN 缓存转码后的视频，加快全球分发速度，降低延迟和源站负载。</li>
</ul>
<p><br>303 一家公司正在 Amazon ECS Fargate 上部署新应用，并监控 CPU&#x2F;内存使用率。他们预计会有大量流量，但希望在利用率低时降低成本。问解决方案架构师应推荐什么方案。</p>
<p>A. 使用 Amazon EC2 自动扩展，根据以往的流量模式在特定时段进行扩展。<br>B. 使用 AWS Lambda 函数，基于触发 Amazon CloudWatch 警报的指标违规情况来扩展 Amazon ECS。<br>C. 当 ECS 指标突破触发 Amazon CloudWatch 警报时，使用带有简单扩展策略的 Amazon EC2 Auto Scaling 进行扩展。<br>D. <u>使用 <strong>AWS 应用程序自动扩展</strong>及其<strong>目标跟踪策略</strong>，在 ECS 指标突破触发 Amazon CloudWatch 警报时进行扩展。</u></p>
<p>错误地引用 EC2 Auto Scaling 用于 Fargate</p>
<p>简单扩展策略（一次调整固定数量）可能响应不及时，并且依赖警报触发有延迟，不如目标跟踪策略平稳</p>
<ul>
<li>WS Application Auto Scaling 是专为 ECS、DynamoDB、Lambda 等设计的自动扩缩容服务。</li>
<li>支持目标跟踪策略（例如将平均 CPU 利用率保持在 70%），可根据实时指标自动增加或减少任务数量，无需手动干预或创建复杂警报。</li>
</ul>
<p><br>304 一家公司已在另一个 AWS 区域建立了灾难恢复站点，需要定期在两个区域的 NFS 文件系统之间双向传输大量数据，并要求<strong>运营开销最少</strong></p>
<p>A. <u>使用 AWS DataSync</u>。<br>B. 使用 AWS Snowball 设备。<br>C. 在 Amazon EC2 上设置 SFTP 服务器。<br>D. 使用 AWS 数据库迁移服务（AWS DMS）。</p>
<p>AWS DataSync 是专门用于在本地存储、AWS 存储服务（如 Amazon EFS、Amazon FSx 或 S3）之间<strong>自动、高效、安全地同步数据</strong>的服务</p>
<p><br>305 一家公司要为托管在 AWS 上的游戏应用程序设计共享存储解决方案，要求：</p>
<ol>
<li>客户端能通过 <strong>SMB 协议</strong> 访问数据。</li>
<li>解决方案必须是 <strong>完全托管</strong> 的。</li>
</ol>
<p>A. 创建一个 AWS DataSync 任务，将数据作为可挂载文件系统共享。将该文件系统挂载到应用服务器上。<br>B. 创建一个 Amazon EC2 Windows 实例。在该实例上安装并配置 Windows 文件共享角色。将应用服务器连接到文件共享。<br><u><strong>C. 创建一个适用于 Windows 文件服务器的 Amazon FSx 文件系统。将该文件系统附加到源服务器。连接应用服务器到文件系统</strong></u>。<br>D. 创建一个 Amazon S3 存储桶。为应用程序分配一个 IAM 角色以授予对该 S3 存储桶的访问权限。将 S3 存储桶挂载到应用程序服务器。</p>
<ol>
<li><strong>SMB 客户端访问</strong> → 需要支持 SMB（Server Message Block）协议的共享文件系统，通常用于 Windows 环境或跨平台文件共享。</li>
<li><strong>完全托管</strong> → AWS 负责底层维护、修补、备份、扩展等，无需用户管理服务器。</li>
</ol>
<p>Amazon FSx for Windows File Server 是<strong>完全托管的原生 Windows 文件系统</strong>，原生支持 SMB 协议，可被 Windows 或支持 SMB 的客户端直接访问</p>
<p><br>306 公司需要在 Amazon EC2 上运行一个<strong>延迟敏感、高交易量（超 10 万笔&#x2F;秒）、高网络吞吐量</strong>的内存数据库应用，并要求经济高效的网络设计以<strong>最小化数据传输费用</strong></p>
<p>A. <u>在同一 AWS 区域内的同一可用区中启动所有 EC2 实例。指定一个放置组，其中包含启动 EC2 实例时采用集群策略</u>。<br>B. 在同一 AWS 区域内的不同可用区中启动所有 EC2 实例。启动 EC2 实例时，指定一个采用分区策略的放置组。<br>C. 部署一个自动扩展组，基于网络利用率目标在不同的可用区中启动 EC2 实例。<br>D. 部署一个具有步进式扩展策略的自动扩展组，以便在不同的可用区中启动 EC2 实例。</p>
<ol>
<li><strong>延迟敏感 + 高网络吞吐量</strong> → 需要尽可能低的网络延迟和高带宽。</li>
<li><strong>经济高效，最小化数据传输费用</strong> → AWS 对同一可用区内 EC2 实例间的数据传输<strong>免费</strong>，跨可用区（AZ）则按流量收费</li>
</ol>
<p><br>307 一家公司主要将应用服务器运行在本地，计划迁移到 AWS，希望<strong>尽量减少在本地扩展 iSCSI 存储的需求</strong>，并只将<strong>最近访问的数据保留在本地存储</strong>。问应使用哪种 AWS 解决方案。</p>
<p>A. 亚马逊 S3 文件网关<br>B. AWS 存储网关磁带网关<br>C. AWS 存储网关卷网关存储卷<br>D. <u>AWS 存储网关卷网关缓存卷</u></p>
<ol>
<li><strong>本地应用服务器使用 iSCSI 存储</strong> → 需要 iSCSI 块存储接口。</li>
<li><strong>尽量减少本地存储扩展</strong> → 希望将较少访问的数据移到云端，减少本地容量投入。</li>
<li><strong>只将最近访问的数据保留在本地存储</strong> → 需要<strong>缓存</strong>机制，将热数据（频繁访问）保留在本地，冷数据迁移到云端。</li>
</ol>
<p><strong>亚马逊 S3 文件网关</strong> - 提供<strong>文件级</strong>访问（NFS&#x2F;SMB），不是<strong>块级</strong>（iSCSI）存储</p>
<p>卷网关有两种模式：<strong>存储卷模式</strong>和<strong>缓存卷模式</strong>。</p>
<ul>
<li><p><strong>存储卷模式</strong>：数据<strong>主要存储在 AWS</strong>（Amazon EBS），本地网关仅存储元数据，应用通过 iSCSI 访问。</p>
</li>
<li><p><strong>缓存卷模式</strong>：数据<strong>主要存储在 AWS（S3）</strong>，本地网关设备<strong>缓存频繁访问的数据</strong>（最近访问的数据保留在本地），较少访问的数据在云端</p>
</li>
</ul>
<p><br>308 一家公司有多个 AWS 账户（已设置合并计费），运行着高性能的 Amazon RDS for Oracle 按需实例（90 天）。财务团队可以访问合并计费账户和所有其他账户的 Trusted Advisor，他们需要通过适当的账户查看 Trusted Advisor 检查，以找到降低 RDS 成本的方法。需要选择两种步骤组合来满足要求。</p>
<p>A. 使用运行 RDS 实例的账户中的 Trusted Advisor 建议。<br><u>B. 使用合并账单账户中的 Trusted Advisor 建议，同时查看所有 RDS 实例检查。</u><br>C. 查看 Amazon RDS 预留实例优化的 Trusted Advisor 检查。<br><u>D. 查看 Amazon RDS 空闲数据库实例的 Trusted Advisor 检查。</u><br>E. 查看 Amazon Redshift 预留节点优化的 Trusted Advisor 检查。</p>
<ul>
<li><p><strong>Trusted Advisor</strong> 提供成本优化检查，其中有关 RDS 的成本建议主要包括：</p>
<ol>
<li><strong>RDS 预留实例优化</strong>：建议将长期运行的按需实例转为预留实例以节省费用。</li>
<li><strong>RDS 空闲数据库实例检测</strong>：建议关闭或缩减低利用率的实例。</li>
</ol>
</li>
<li><p><strong>合并计费</strong>的“管理账户”可以看到所有关联账户的 Trusted Advisor 检查（如果启用了“业务级”或“企业级”支持计划），从而统一查看跨账户的 RDS 使用情况，做出更全面的成本优化建议。</p>
</li>
<li><p>题目提到 RDS 实例已运行 90 天，且是按需实例，正是预留实例优化的典型场景（长期稳定运行）。</p>
</li>
<li><p>空闲数据库检查可以识别低利用率实例，建议停止或删除，节省成本。</p>
</li>
</ul>
<p><br>309 解决方案架构师需要找出所有<strong>不再被访问或很少被访问的 Amazon S3 存储桶</strong>，以优化存储成本，并要求<strong>运营开销最少</strong>。</p>
<p>A. <u>使用 S3 Storage Lens 仪表板分析存储桶访问模式，以获取高级活动指标</u>。<br>B. 使用 AWS 管理控制台中的 S3 仪表板分析存储桶访问模式。<br>C. 为存储桶开启 Amazon CloudWatch 的 BucketSizeBytes 指标，使用 Amazon Athena 分析访问模式。<br>D. 开启 AWS CloudTrail 进行 S3 对象监控，使用 CloudTrail 日志与 CloudWatch Logs 集成来分析访问模式。</p>
<ul>
<li><p><strong>S3 Storage Lens</strong> 是 AWS 提供的<strong>免费&#x2F;付费</strong>的存储分析工具，提供组织级、跨账户、跨区域的 S3 存储使用情况和活动指标。</p>
</li>
<li><p>S3 控制台提供基本的存储桶指标（如存储大小、对象数量），但<strong>不提供详细的访问频率或活动指标</strong>，无法直接识别“很少访问”的存储桶</p>
</li>
<li><p>BucketSizeBytes 是存储容量指标，不是<strong>访问活动指标</strong>，无法反映访问频率。</p>
</li>
<li><p>CloudTrail 可以记录 S3 API 调用（如 GetObject、PutObject），但需要手动开启、解析大量日志，再结合 CloudWatch Logs 分析，配置复杂且成本较高</p>
</li>
</ul>
<p><br>310 一家公司在美国东部1区的S3中存储大型AI&#x2F;ML数据集，通过Web应用（EC2 + ALB）销售访问权限。客户购买后获得S3预签名URL来下载文件。客户分布在北美和欧洲。公司希望<strong>降低数据传输成本</strong>并<strong>保持或提高性能</strong>。</p>
<p>A. 在现有S3存储桶上配置S3传输加速，将请求定向到传输加速端点，继续使用S3预签名URL。<br>B. <u>部署Amazon CloudFront分发，以S3存储桶为源，将请求定向到CloudFront URL，切换到CloudFront签名URL进行访问控制</u>。<br>C. 在eu-central-1区域设置第二个S3存储桶并配置跨区域复制，将客户定向到最近的区域，继续使用S3预签名URL。<br>D. 修改Web应用，直接从S3流式传输数据给用户，并在应用中实现访问控制。</p>
<p><br>311 公司要设计一个处理保险报价的Web应用，用户提交报价请求，要求：</p>
<ol>
<li><strong>按报价类型分类</strong>处理。</li>
<li><strong>24小时内必须回复，且消息不能丢失</strong>（可靠性与时效性）。</li>
<li><strong>最大化运营效率，维护工作最少</strong>（即尽量使用托管服务、简化架构）。</li>
</ol>
<p>A. 为每种报价类型创建多个 Amazon Kinesis 数据流，让 Web 应用发消息到对应流，后端应用服务器组使用 KCL 从各自流汇聚消息。<br>B. 为每种报价类型创建 Lambda + SNS 主题，让 Lambda 订阅 SNS，Web 应用发布请求到对应 SNS 主题。<br>C. <u>创建一个 SNS 主题，将多个 SQS 队列订阅到该主题，用 SNS 消息过滤将消息路由到正确的 SQS 队列（按报价类型），每个后端应用服务器组使用各自的 SQS 队列。</u><br>D. 创建多个 Kinesis Data Firehose 传输流，将数据流式传输到 OpenSearch Service，后端从 OpenSearch 搜索并处理消息。</p>
<p>SQS 提供<strong>至少一次传递、持久存储、可配置保留期（最长14天）</strong>，能保证消息不丢失并在24小时内处理</p>
<p><br>312 公司有一个在多个EC2实例上运行的应用程序，每个实例有多个EBS数据卷。要求：</p>
<ol>
<li><strong>每晚备份</strong>EC2实例的配置和数据（即EBS卷）。</li>
<li>能够<strong>在另一个AWS区域恢复</strong>（需跨区域备份）。</li>
<li>以<strong>最高的运营效率</strong>满足要求（即自动化、托管服务、最少维护）</li>
</ol>
<p>A. 编写 Lambda 函数，安排EBS卷的夜间快照，并复制快照到另一个区域。<br>B. <u>使用 AWS Backup 创建备份计划执行夜间备份，将备份复制到另一区域，添加应用程序的 EC2 实例作为资源。</u><br>C. 使用 AWS Backup 创建备份计划执行夜间备份，将备份复制到另一区域，将应用程序的 EBS 卷添加为资源。<br>D. 编写 Lambda 函数，安排EBS卷的夜间快照，并复制快照到不同可用区。</p>
<ul>
<li>AWS Backup是<strong>全托管备份服务</strong>，支持<strong>EC2实例级备份</strong>（包括所有连接的EBS卷、实例配置元数据）。</li>
</ul>
<p><br>313 一家公司正在 AWS 上构建移动应用，计划扩展到<strong>数百万用户</strong>。需要建立一个平台，让授权用户能在移动设备上观看公司内容。问解决方案架构师应推荐什么方案</p>
<p>A. 将内容发布到公共 Amazon S3 存储桶，使用 AWS KMS 密钥传输内容。<br>B. 在移动应用和 AWS 环境之间设置 IPsec VPN 以流式传输内容。<br>C. <u>使用 Amazon CloudFront，提供签名 URL 来流式传输内容</u>。<br>D. 在移动应用和 AWS 环境之间设置 AWS 客户端 VPN 以流式传输内容。</p>
<p><br>314 公司有一个本地MySQL数据库，供全球销售团队使用，访问模式<strong>不频繁</strong>。销售团队要求<strong>停机时间尽可能短</strong>。数据库管理员希望迁移到AWS，并且由于未来用户可能增加，<strong>不希望选择特定的实例类型</strong>（即希望自动扩展，无需预先选择实例规格）。</p>
<p>问解决方案架构师应推荐哪种服务。</p>
<p>A. 亚马逊 Aurora MySQL<br>B<u>. 适用于 MySQL 的 Amazon Aurora 无服务器版</u><br>C. 亚马逊 Redshift Spectrum<br>D. 适用于 MySQL 的亚马逊关系型数据库（Amazon RDS for MySQL）</p>
<ol>
<li><strong>访问模式不频繁</strong> → 数据库可能长时间闲置，要求成本优化（不为闲置资源持续付费）。</li>
<li><strong>停机时间尽可能短</strong> → 迁移和运行中都需要高可用性，尽量减小业务中断。</li>
<li><strong>不希望选择特定实例类型</strong> → 希望自动扩展计算能力，无需预选实例规格，以适应未来用户增长的不确定性。</li>
</ol>
<ul>
<li><p>Aurora 是高性能、高可用的 MySQL 兼容数据库，但需要选择<strong>实例类型和大小</strong>（预配置容量）。</p>
</li>
<li><p>Aurora Serverless 可根据应用程序需求<strong>自动扩展和收缩数据库容量</strong>，在无连接时甚至可以缩容到零，按每秒实际使用量计费。</p>
</li>
<li><p>RDS for MySQL 是托管 MySQL 服务，但仍需选择实例类型和大小，无法自动伸缩计算资源（除非手动修改实例类型）。</p>
</li>
</ul>
<p><br>315 公司因本地自定义应用程序漏洞导致数据泄露，现正迁移应用程序到 Amazon EC2 实例。<br>要求：</p>
<ol>
<li><strong>主动扫描 EC2 实例上的漏洞</strong>。</li>
<li>发送<strong>详细说明发现结果的报告</strong>。</li>
</ol>
<p>问哪种解决方案能满足这些要求</p>
<p>A. 部署 AWS Shield 扫描 EC2 实例漏洞，用 Lambda 将发现记录到 CloudTrail。<br>B. 部署 Amazon Macie 和 Lambda 扫描 EC2 实例漏洞，将发现记录到 CloudTrail。<br>C. 开启 Amazon GuardDuty，将 GuardDuty 代理部署到 EC2 实例，配置 Lambda 生成和分发报告。<br>D. <u>开启 Amazon Inspector，将 Amazon Inspector 代理部署到 EC2 实例，配置 Lambda 生成和分发报告</u></p>
<ul>
<li><p>AWS Shield 是<strong>DDoS 防护服务</strong>，不提供漏洞扫描功能</p>
</li>
<li><p>Amazon Macie 是用于<strong>发现和保护敏感数据</strong>（如 PII）的服务，通过机器学习识别 S3 等存储中的数据分类，<strong>不扫描 EC2 实例的漏洞</strong>。</p>
</li>
<li><p>GuardDuty 是<strong>威胁检测服务</strong>，通过分析 VPC 流日志、CloudTrail 事件等来识别恶意活动或异常行为，但它<strong>不是主动漏洞扫描工具</strong>，而是持续监控安全事件</p>
</li>
</ul>
<p>Amazon Inspector 是<strong>自动化的漏洞管理服务</strong>，专门用于<strong>评估 EC2 实例和容器镜像的漏洞与安全合规性</strong>。</p>
<p><br>316 公司使用 Amazon EC2 实例运行脚本，轮询并处理 Amazon SQS 队列中的消息。希望在保持处理不断增加的消息能力的同时，降低运营成本。问解决方案架构师应推荐什么。</p>
<p>A. 增大 EC2 实例的规模以更快地处理消息。<br>B. 使用 Amazon EventBridge 在 EC2 实例利用率不足时关闭实例。<br>C. <u>将 EC2 实例上的脚本迁移到具有适当运行时的 AWS Lambda 函数。</u><br>D. 使用 AWS Systems Manager Run Command 按需运行脚本。</p>
<p>因为 Lambda + SQS 集成提供了无服务器、按需扩展的消息处理能力，按实际使用付费，在保持甚至提高处理能力的同时，大幅降低了运营成本。</p>
<p><br>317 公司有遗留应用程序生成 CSV 文件并存到 S3，新的商用现成（COTS）应用程序可以分析 Amazon Redshift 和 S3 中的数据，但<strong>无法处理 CSV 格式</strong>。公司无法修改遗留应用程序，需要一种解决方案让 COTS 应用能使用这些数据，且要求<strong>运营开销最小</strong>。</p>
<p><u>A. 创建按计划运行的 AWS Glue ETL 作业，处理 CSV 文件并将处理后数据存储在 Amazon Redshift 中。</u><br>B. 开发 Python 脚本运行在 EC2 上，通过 cron 将 CSV 转换为 SQL 文件，输出到 S3。<br>C. 创建 Lambda 函数和 DynamoDB 表，用 S3 事件触发 Lambda 做 ETL，将处理后数据存入 DynamoDB。<br>D. 使用 EventBridge 按周计划启动 Amazon EMR 集群，执行 ETL 作业，将处理后数据存入 Amazon Redshift。</p>
<ul>
<li>Lambda 可处理 CSV 转换，但存入 <strong>DynamoDB（NoSQL 键值存储）</strong> 不适合复杂 SQL 查询，COTS 应用可能不支持 DynamoDB 作为数据源（题目说仅支持 Redshift 和 S3）。</li>
</ul>
<p><br>318 公司将其 IT 环境迁移到 AWS 后，发现用户在配置过大的 Amazon EC2 实例和修改安全组规则时没有遵循变更控制流程。解决方案架构师需要制定策略来<strong>跟踪和审计这些资源清单及配置变更</strong>。需要选择两项措施。</p>
<p><u>A. 启用 AWS CloudTrail 并将其用于审计。</u><br>B. 对 Amazon EC2 实例使用数据生命周期策略。<br>C. 启用 AWS Trusted Advisor 并参考安全仪表板。<br>D. <u>启用 AWS Config 并创建用于审计和合规目的的规则。</u><br>E. 使用 AWS CloudFormation 模板恢复以前的资源配置。</p>
<ol>
<li><strong>跟踪和审计资源清单</strong> → 需要记录资源（如 EC2 实例规格、安全组规则）的当前状态和配置。</li>
<li><strong>跟踪和审计配置变更</strong> → 需要记录谁、何时、对资源做了哪些变更。</li>
</ol>
<p>CloudTrail 记录<strong>API 调用和账户活动</strong>，包括谁、何时、在哪个资源上执行了什么操作（如启动 EC2 实例、修改安全组规则）</p>
<p>AWS Config 记录<strong>资源配置历史</strong>和变更详情，提供资源清单（当前和历史状态），并可通过自定义规则检测不合规配置（如 EC2 实例类型是否超出允许范围、安全组规则是否违规）。</p>
<p><br>319 公司有数百个基于 Linux 的 Amazon EC2 实例，系统管理员使用共享 SSH 密钥进行管理。安全审计要求移除所有共享密钥，需要提供一种安全的 EC2 实例访问解决方案，同时使管理开销最小。</p>
<p>A. <u>使用 AWS Systems Manager Session Manager 连接到 EC2 实例</u>。<br>B. 使用 AWS STS 按需生成一次性 SSH 密钥。<br>C. 允许对一组堡垒机实例进行共享 SSH 访问，其他实例仅允许来自堡垒机的 SSH 访问。<br>D. 使用 Amazon Cognito 自定义授权方对用户进行身份验证，调用 Lambda 函数生成临时 SSH 密钥。</p>
<ul>
<li>Session Manager 是 AWS Systems Manager 的功能，允许通过浏览器或 AWS CLI 直接连接 EC2 实例，<strong>无需 SSH 密钥或堡垒机</strong>。</li>
<li>访问基于 IAM 权限控制，会话活动自动记录到 CloudTrail 和 S3，满足安全审计要求。</li>
<li>完全托管，无需管理密钥或额外基础设施，只需为实例安装 SSM Agent（许多 AMI 已预装），配置 IAM 角色即可。</li>
</ul>
<p><br>320 公司使用一批 Amazon EC2 实例从本地数据源摄取 JSON 格式数据，速率最高 1 MB&#x2F;s。现有问题：EC2 重启时传输中的数据会丢失。数据科学团队需要<strong>近实时查询</strong>已摄取的数据。<br>要求解决方案：提供近实时查询、可扩展性、将数据丢失降至最低。</p>
<p>A. <u>将数据发布到 Amazon Kinesis Data Streams，使用 Kinesis Data Analytics 查询数据。</u><br>B. 将数据发布到 Amazon Kinesis Data Firehose，以 Amazon Redshift 为目标，用 Redshift 查询数据。<br>C. 将数据存储在 EC2 实例存储，然后发布到 Kinesis Data Firehose 以 S3 为目标，用 Amazon Athena 查询数据。<br>D. 将数据存储在 Amazon EBS 卷，发布到 Amazon ElastiCache for Redis，订阅 Redis 频道查询数据。</p>
<ul>
<li><p><strong>Kinesis Data Streams</strong> 提供实时数据流摄取，数据持久化保留（默认 24 小时，可延长），EC2 实例将数据直接发送到 KDS，即使 EC2 重启，数据也不会丢失（因为已发送到 KDS）。</p>
</li>
<li><p><strong>Kinesis Data Analytics</strong> 支持对数据流进行近实时 SQL 查询，结果可输出到其他服务或直接查询。</p>
</li>
<li><p>Kinesis Data Firehose 是用于将数据流式传输到存储或分析服务的<strong>摄取和批量加载服务</strong>，并非为<strong>近实时查询</strong>设计（Redshift 是数据仓库，导入和查询通常有分钟级延迟，非秒级近实时）。</p>
</li>
<li><p>Firehose 有缓冲时间（如 60 秒或更大）才写入 Redshift，且 Redshift 不适合高频即时查询流式数据。</p>
</li>
</ul>
<p><br>321 解决方案架构师需要确保上传到 Amazon S3 存储桶的所有对象都经过加密，问应采取什么措施。</p>
<p>A. 更新存储桶策略，若 PutObject 未设置 s3:x-amz-acl 头部，则拒绝该操作。<br>B. 更新存储桶策略，若 PutObject 未将 s3:x-amz-acl 头部设置为 private，则拒绝该操作。<br>C. 更新存储桶策略，若 PutObject 未将 aws:SecureTransport 标头设置为 true，则拒绝该操作。<br>D. <u>更新存储桶策略，若 PutObject 未设置 x-amz-server-side-encryption 头部，则拒绝该操作。</u></p>
<p>因为它利用 S3 存储桶策略的条件键，强制客户端在上传时指定加密方式，确保所有对象静态加密。这是 AWS 推荐的最佳实践</p>
<p><br>322 一个多层应用程序的用户从移动设备上传图像。应用程序需要为每个图像生成缩略图（可能需要长达60秒），但公司希望<strong>更快地响应通知用户原始图像已收到</strong>，而不是等待缩略图生成完成。解决方案架构师需要设计应用以<strong>异步方式将请求分发到不同应用层</strong>。</p>
<p>A. 编写自定义 AWS Lambda 函数生成缩略图并提醒用户，使用图像上传过程作为事件源调用 Lambda。<br>B. 创建 AWS Step Functions 工作流，处理应用各层间编排，并在缩略图生成完成后提醒用户。<br>C. <u>创建一个 Amazon SQS 消息队列，上传图像后在 SQS 中放置一条生成缩略图的消息，并立即通知用户图像已收到。</u><br>D. 创建 Amazon SNS 通知主题和订阅，上传完成后使用一个订阅触发缩略图生成，生成完成后使用第二个订阅推送通知给用户。</p>
<ul>
<li><strong>SQS 解耦效果好</strong>：上传完成后，Web 层可立即返回确认给用户，同时将图像元信息放入 SQS 队列。</li>
<li>后台工作进程（如 EC2 或 Lambda）从 SQS 拉取消息异步生成缩略图，生成时间不影响用户响应。</li>
</ul>
<p>323公司大楼每个入口有徽章读取器（传感器），扫描徽章后通过 HTTPS 发送一条消息（包含谁、哪个入口）。需要设计系统处理这些传感器消息，要求：</p>
<ol>
<li><strong>高可用性</strong>。</li>
<li>结果可供安全团队分析。</li>
</ol>
<p>A. 启动一个 Amazon EC2 实例作为 HTTPS 端点并处理消息，将结果保存到 Amazon S3。<br>B. <u>在 Amazon API Gateway 中创建 HTTPS 端点，调用 AWS Lambda 函数处理消息，将结果保存到 Amazon DynamoDB。</u><br>C. 使用 Amazon Route 53 将传入的传感器消息定向到 AWS Lambda 函数，配置 Lambda 将结果保存到 DynamoDB。<br>D. 为 Amazon S3 创建网关 VPC 端点，通过站点到站点 VPN 将传感器数据直接写入 S3 存储桶。</p>
<ul>
<li><strong>API Gateway</strong> 提供托管、可扩展的 HTTPS 端点，自动处理 SSL、高可用、负载均衡。</li>
<li><strong>Lambda</strong> 无服务器计算，自动扩展，按需执行，适合处理不规则的传感器消息流。</li>
<li><strong>DynamoDB</strong> 是 NoSQL 数据库，可持久化存储结构化消息（如人员 ID、入口 ID、时间戳），并支持快速查询和后续分析（可通过 Athena 或导出到其他分析工具）</li>
</ul>
<p><br>324 公司希望为本地 iSCSI 存储卷（数百TB）实施灾难恢复计划，要求：</p>
<ol>
<li><strong>终端用户能够立即访问本地系统中的所有文件类型，且不会遇到延迟问题</strong> → 保持本地低延迟访问。</li>
<li><strong>对公司现有基础设施改动最小</strong> → 尽量不改变现有应用程序访问方式（现有使用 iSCSI 块存储）。</li>
</ol>
<p>A. 预置一个 Amazon S3 文件网关（VM 形式在本地），本地缓存 10 TB，修改应用通过 NFS 访问，恢复时用 EC2 挂载 S3 桶。<br>B. 配置 AWS 存储网关磁带网关，将数据备份到虚拟磁带库，恢复时从磁带恢复数据到 EC2 的 EBS 卷。<br>C. 配置 AWS 存储网关卷网关缓存卷，本地缓存 10 TB，通过 iSCSI 挂载到现有文件服务器并复制文件，定时快照，恢复时还原快照到 EC2 的 EBS 卷。<br>D. <u>配置 AWS 存储网关卷网关存储卷，磁盘空间与现有相同，通过 iSCSI 挂载复制文件，定时快照，恢复时还原到 EC2 的 EBS 卷。</u></p>
<ul>
<li><p><strong>缓存卷模式</strong>：数据主要存储在 S3，本地仅缓存频繁访问的数据（本地缓存大小可设置，如 10 TB），通过 iSCSI 挂载给本地服务器。</p>
</li>
<li><p>本地用户访问缓存命中时无延迟，未命中数据从云端获取（有延迟），但“所有文件类型”都可能被访问，若缓存不足可能有延迟问题。</p>
</li>
<li><p>对数百TB数据来说，10 TB 缓存可能无法保证所有文件访问无延迟，但可以通过智能缓存算法优化。</p>
</li>
<li><p><strong>存储卷模式</strong>：数据主要存储在本地，异步备份到 AWS，本地磁盘空间需与原始数据相同（数百TB），不符合“降低成本”且本地仍需大量存储。</p>
</li>
<li><p>虽然本地访问无延迟（因为数据全在本地），但并未利用云存储优势，且本地存储成本仍高。</p>
</li>
</ul>
<p><br>325 公司通过 Amazon S3 托管一个 Web 应用程序，使用 <strong>Amazon Cognito 作为身份提供商</strong>对用户进行身份验证，并返回 <strong>JWT 令牌</strong>，该令牌用于访问另一个 S3 存储桶中的受保护资源。<br>部署后用户报告错误，无法访问受保护内容。解决方案架构师需要提供适当的权限来解决此问题。</p>
<p><u>A. 更新 Amazon Cognito 身份池以承担适当的 IAM 角色，从而访问受保护内容。</u><br>B. 更新 S3 ACL 以允许应用程序访问受保护的内容。<br>C. 将应用程序重新部署到 Amazon S3，以防止 S3 最终一致性读取影响用户访问。<br>D. 更新 Amazon Cognito 用户池，在身份池中使用自定义属性映射，并向用户授予访问受保护内容的适当权限。</p>
<ul>
<li>Amazon Cognito 提供 <strong>用户池（User Pools）</strong> 和 <strong>身份池（Identity Pools）</strong>：<ul>
<li><strong>用户池</strong>：管理用户身份验证（返回 JWT ID Token）。</li>
<li><strong>身份池</strong>：将身份转换为 AWS 临时凭证（IAM Role），以访问 AWS 资源（如 S3、DynamoDB）。</li>
</ul>
</li>
<li>当前架构：用户登录 → Cognito 用户池验证 → 返回 JWT → 该 JWT 用于访问 S3 受保护内容。<br>但<strong>仅凭 JWT 本身不能直接访问 S3</strong>，需要获取 AWS 临时凭证来调用 AWS API。这通常通过 <strong>Cognito 身份池</strong> 实现：用户用 JWT 向身份池换取临时凭证。</li>
</ul>
<p><br>326 图片托管公司上传大型资产到 <strong>Amazon S3 标准存储桶</strong>，使用分片上传并可能覆盖相同对象。</p>
<ul>
<li>上传后 <strong>30 天内</strong>频繁访问。</li>
<li>30 天后访问频率降低，但<strong>访问模式不一致</strong>（即有些对象偶尔被访问，有些可能不再被访问）。<br>要求：保持高可用性和弹性，同时优化 S3 存储成本。<br>需选择两项操作组合。</li>
</ul>
<p>A. <u>30 天后将资产移至 S3 智能分层存储。</u><br>B. <u>配置 S3 生命周期策略以清理不完整的分片上传</u>。<br>C. 配置 S3 生命周期策略以清理过期的对象删除标记。<br>D. 30 天后将资产移至 S3 标准 - 不常访问（S3 Standard-IA）。<br>E. 30 天后将资产移至 S3 单区域 - 不常访问存储（S3 One Zone-IA）。</p>
<p>智能分层存储自动将对象在<strong>频繁访问层</strong>和<strong>不频繁访问层</strong>之间移动，无需人工干预</p>
<ul>
<li>S3 Standard-IA 适用于不常访问但需要高可用性和低延迟检索的数据（存储在多个 AZ）。</li>
<li>但它的特点是<strong>按访问次数收取检索费用</strong>，如果对象访问模式不一致且偶尔被访问，可能会产生较高的检索费用。</li>
</ul>
<p><br>327 一个 VPC 中的 EC2 实例位于私有子网，包含高度敏感数据。根据公司政策：</p>
<ul>
<li>EC2 实例只能访问互联网上<strong>经过批准的第三方软件仓库 URL</strong>，以获取软件更新。</li>
<li><strong>其他所有互联网流量必须阻断</strong>。</li>
</ul>
<p>问哪种解决方案符合要求</p>
<p>A. <u>更新私有子网的路由表，将出站流量路由到 AWS 网络防火墙，配置域名列表规则组</u>。<br>B. 设置 AWS WAF Web ACL，创建自定义规则基于源 IP 和目标 IP 过滤流量。<br>C. 实施严格的入站安全组规则，配置出站规则通过指定 URL 仅允许流向授权软件仓库的流量。<br>D. 在 EC2 实例前配置 ALB，将所有出站流量导向 ALB，在 ALB 的目标组中使用基于 URL 的规则监听器实现出站访问。</p>
<ul>
<li><p>AWS Network Firewall 是托管的网络防火墙服务，可部署在 VPC 中，通过<strong>规则组</strong>控制流量。</p>
</li>
<li><p>支持 <strong>域名列表规则组</strong>（Domain Lists），可基于域名（如 <code>approved-software-repo.com</code>）允许或拒绝流量。</p>
</li>
<li><p>将私有子网出站流量路由到 Network Firewall 端点（网关），防火墙根据域名规则放行或阻止。</p>
</li>
<li><p>WAF不直接控制私有子网 EC2 的出站互联网访问，WAF 主要防御入站 Web 攻击。</p>
</li>
<li><p>安全组是实例级别的防火墙，可控制入站和出站流量，但只能基于 <strong>IP 地址、端口和协议</strong>，<strong>不能基于域名&#x2F;URL</strong>。</p>
</li>
<li><p>ALB 是第 7 层负载均衡器，通常用于<strong>入站</strong>流量分发，而不是控制出站流量</p>
</li>
</ul>
<p><br>328 公司有一个三层电子商务应用：</p>
<ul>
<li>网站托管在 <strong>Amazon S3</strong>。</li>
<li>API 托管在 <strong>ALB 后的三个 EC2 实例</strong>上，包含静态内容、动态内容，以及处理销售请求的<strong>后端工作程序</strong>。</li>
<li>预计在新产品发布期间，销售请求数量会有<strong>显著且突然的增长</strong>。<br>目标：确保所有请求都能成功处理。</li>
</ul>
<p>A. 为动态内容添加 Amazon CloudFront 分发，增加 EC2 实例数量以应对流量增长。<br>B. 为静态内容添加 Amazon CloudFront 分发，将 EC2 实例放入自动扩展组以便根据网络流量启动新实例。<br>C. 为动态内容添加 Amazon CloudFront 分发，在 ALB 前添加 Amazon ElastiCache 实例以减少 API 需要处理的流量。<br>D. <u>为静态内容添加 Amazon CloudFront 分发，添加 Amazon SQS 队列接收来自网站的请求，使 EC2 实例稍后处理。</u></p>
<p><br>329 安全审计发现 Amazon EC2 实例未定期打补丁。<br>要求解决方案：</p>
<ol>
<li><strong>定期安全扫描</strong>大量 EC2 实例。</li>
<li><strong>按固定计划为 EC2 实例打补丁</strong>。</li>
<li><strong>提供每个实例的补丁状态报告</strong>。</li>
</ol>
<p>A. 设置 Amazon Macie 扫描 EC2 实例漏洞，在每个实例上设置定时任务按计划打补丁。<br>B. 开启 Amazon GuardDuty 扫描 EC2 漏洞，配置 Systems Manager Session Manager 按计划打补丁。<br>C. 设置 Amazon Detective 扫描 EC2 漏洞，设置 EventBridge 计划规则按计划打补丁。<br><u>D. 开启 Amazon Inspector 扫描 EC2 漏洞，设置 AWS Systems Manager 补丁管理器按计划打补丁。</u></p>
<ul>
<li><strong>Amazon Inspector</strong> 是<strong>自动化的漏洞管理服务</strong>，可定期扫描 EC2 实例的软件漏洞（包括缺失的补丁），并生成详细报告。</li>
<li><strong>AWS Systems Manager Patch Manager</strong> 是专门的补丁管理服务，可<strong>按计划为大量 EC2 实例自动打补丁</strong>，并提供每个实例的补丁合规性状态报告</li>
</ul>
<p><br>330 公司计划将数据存储在 Amazon RDS 数据库实例上，要求<strong>对静态数据进行加密</strong>。问解决方案架构师应采取什么措施来满足这一要求。</p>
<p>A. <u>在 AWS KMS 中创建一个密钥，为数据库实例启用加密。</u><br>B. 创建一个加密密钥，将该密钥存储在 AWS Secrets Manager 中，使用该密钥对数据库实例进行加密。<br>C. 在 AWS Certificate Manager（ACM）中生成证书，使用该证书在数据库实例上启用 SSL&#x2F;TLS。<br>D. 在 IAM 中生成证书，使用该证书在数据库实例上启用 SSL&#x2F;TLS</p>
<ul>
<li><p>Secrets Manager 用于存储和管理敏感信息（如数据库凭证、API 密钥），但<strong>不用于加密 RDS 底层存储</strong>。</p>
</li>
<li><p>ACM 提供 SSL&#x2F;TLS 证书，用于<strong>传输中加密</strong>（如 RDS 连接加密），不用于<strong>静态数据加密</strong>。</p>
</li>
<li><p>IAM 可以上传证书，但同样用于<strong>传输加密</strong>，而不是静态加密</p>
</li>
</ul>
<p>331公司需在 <strong>30 天内</strong> 将 <strong>20 TB</strong> 数据从数据中心迁移到 AWS 云，网络带宽限制为 <strong>15 Mbps</strong>，且利用率不能超过 <strong>70%</strong>（即实际可用带宽约 <strong>10.5 Mbps</strong>）。问解决方案架构师应采取什么措施。</p>
<p>A. <u>使用 AWS Snowball。</u><br>B. 使用 AWS DataSync。<br>C. 使用安全的 VPN 连接。<br>D. 使用 Amazon S3 传输加速</p>
<ul>
<li>Snowball 是物理设备，用于离线大规模数据传输，可绕过网络带宽限制。</li>
</ul>
<p><br>332 公司需要为员工提供对机密敏感文件的安全访问权限，要求：</p>
<ol>
<li><strong>只能由授权用户访问</strong>（需身份验证与授权）。</li>
<li><strong>文件安全下载到员工设备</strong>（传输安全）。</li>
<li>文件目前存储在<strong>本地 Windows 文件服务器</strong>，但容量即将耗尽（需扩展存储容量）。</li>
</ol>
<p>问哪种解决方案能满足要求。</p>
<p>A. 将文件服务器迁移到公共子网中的 Amazon EC2 实例，配置安全组仅允许员工的 IP 地址入站。<br>B. <u>将文件迁移到 Amazon FSx for Windows File Server，与本地 AD 集成，配置 AWS 客户端 VPN。</u><br>C. 将文件迁移到 Amazon S3，创建私有 VPC 终端节点，创建签名 URL 允许下载。<br>D. 将文件迁移到 Amazon S3，创建公共 VPC 端点，员工使用 IAM Identity Center 登录。</p>
<ul>
<li><strong>Amazon FSx for Windows</strong> 是完全托管的 Windows 文件服务器，支持 SMB 协议，可无缝集成本地 Active Directory，实现基于域用户的身份验证和文件权限控制。</li>
<li><strong>AWS Client VPN</strong> 提供安全的远程访问，员工可通过 VPN 连接访问 FSx 文件系统，如同在本地网络一样</li>
</ul>
<p><br>333 公司应用程序运行在 ALB 后的 EC2 实例上，实例位于跨多 AZ 的自动扩展组中。<br><strong>每月第一天的午夜</strong>，月末财务批处理运行，导致 CPU 利用率立即达到 100%，应用变慢甚至可能停机。<br>要求：确保应用程序能处理工作负载并避免停机</p>
<p>A. 在 ALB 前配置 Amazon CloudFront 分发。<br>B. 基于 CPU 利用率配置 EC2 自动扩展简单扩展策略。<br>C. <u>根据月度计划配置 EC2 Auto Scaling 定时扩展策略</u>。<br>D. 配置 Amazon ElastiCache 以减轻部分 EC2 实例的工作负载。</p>
<ul>
<li>ElastiCache 是内存缓存，可用于减少数据库查询负载，但题目未说明 CPU 高是由于数据库查询引起；可能是批处理任务本身需要大量计算，缓存无法缓解。</li>
</ul>
<p><br>334 公司希望<strong>客户</strong>能够使用<strong>本地 Microsoft Active Directory</strong> 凭据，通过 <strong>SFTP 客户端</strong> 下载存储在 Amazon S3 中的文件。<br>要求：</p>
<ol>
<li>最少的运营开销。</li>
<li>无需更改客户应用程序。</li>
</ol>
<p>A. <u>使用 SFTP 为 Amazon S3 设置 AWS Transfer Family，配置集成的 Active Directory 身份验证。</u><br>B. 设置 AWS DMS 同步本地客户端与 Amazon S3，配置集成的 Active Directory 身份验证。<br>C. 使用 AWS IAM Identity Center 设置 AWS DataSync，在本地位置和 S3 位置之间同步。<br>D. 设置一个带有 SFTP 的 Windows EC2 实例，集成 IAM。</p>
<ul>
<li><p><strong>AWS Transfer Family</strong> 是<strong>全托管</strong>的 SFTP、FTPS、FTP 服务，可直接使用 S3 作为后端存储。</p>
</li>
<li><p>支持与本地 Active Directory 集成作为身份提供商（通过 AWS Directory Service 或直接连接本地 AD）。</p>
</li>
<li><p>客户继续使用现有 SFTP 客户端，无需更改应用。</p>
</li>
<li><p><strong>DataSync</strong> 用于数据同步（如本地到 S3），不是提供 SFTP 访问的服务。</p>
</li>
</ul>
<p><br>335  公司面临需求突然增长，需要从 AMI 配置大型 EC2 实例，实例在自动扩展组中运行。<br>要求：提供<strong>最小的初始化延迟</strong>以满足需求（即实例启动速度要快）。</p>
<p>A. 使用 <code>aws ec2 register-image</code> 命令从快照创建 AMI，使用 AWS Step Functions 替换自动扩展组中的 AMI。<br>B. <u>启用 EBS 快照的快速快照恢复功能，使用该快照创建 AMI</u>。<br>C. 在 Amazon DLM 中启用 AMI 创建并定义生命周期规则，创建 Lambda 函数修改自动扩展组中的 AMI。<br>D. 使用 EventBridge 调用 AWS Backup 生命周期策略配置 AMI，在 EventBridge 中将自动扩展组容量限制配置为事件源。</p>
<ol>
<li><strong>从 AMI 启动大型 EC2 实例</strong> → AMI 包含根卷快照，实例启动时需要从快照恢复数据到新 EBS 卷。</li>
<li><strong>最小化初始化延迟</strong> → 需要加快 AMI 根卷的加载速度，避免从快照恢复数据的延迟（尤其是大型卷）。</li>
</ol>
<p><br>336 公司有多层 Web 应用，使用 Amazon Aurora MySQL 数据库，应用层在 EC2 实例上。<br>IT 安全准则要求：</p>
<ol>
<li><strong>数据库凭据必须加密</strong>。</li>
<li><strong>每 14 天轮换一次</strong>。<br>要求：以<strong>最少的运维工作</strong>满足要求</li>
</ol>
<p>A. <u>创建新的 KMS 加密密钥，使用 AWS Secrets Manager 创建密钥（含凭证）与 Aurora 集群关联，配置 14 天自定义轮换周期。</u><br>B. 在 AWS Systems Manager 参数存储中创建用户名（字符串）和密码（SecureString）参数，用 KMS 加密，应用层加载参数，用 Lambda 每 14 天轮换密码。<br>C. 将凭证文件存储在 KMS 加密的 EFS 文件系统上，挂载到 EC2 实例，用 Lambda 每 14 天轮换 Aurora 凭证并写入文件。<br>D. 将凭证文件存储在 KMS 加密的 S3 存储桶中，应用定期下载，用 Lambda 每 14 天轮换 Aurora 凭证并上传到 S3 文件。</p>
<p><br>337 公司 Web 应用的后端使用 Amazon RDS for MySQL，配置了一个<strong>主实例</strong>和<strong>五个读取副本</strong>用于扩展读取。<br>要求：</p>
<ul>
<li>副本与主实例的<strong>复制延迟不得超过 1 秒</strong>。</li>
<li>数据库定期运行预定的<strong>存储过程</strong>。</li>
</ul>
<p>问题：随着流量增加，副本在峰值负载期间出现额外延迟。<br>目标：<strong>尽可能减少复制延迟</strong>，同时<strong>最小化应用程序代码更改</strong>和<strong>最小化持续运营开销</strong>。</p>
<p>A. <u>将数据库迁移到 Amazon Aurora MySQL，用 Aurora 副本替换只读副本，并配置 Aurora 自动扩展。将存储过程替换为 Aurora MySQL 原生函数</u>。<br>B. 在数据库前部署 Amazon ElastiCache for Redis 集群，修改应用先在缓存中检查，用 Lambda 函数替换存储过程。<br>C. 将数据库迁移到 Amazon EC2 实例上运行的 MySQL 数据库，为所有副本选择大型计算优化型 EC2 实例，在 EC2 实例上维护存储过程。<br>D. 将数据库迁移到 Amazon DynamoDB，配置大量读取容量单位，配置检索容量扩展，用 DynamoDB 流替换存储过程。</p>
<ul>
<li><p><strong>Amazon Aurora</strong> 提供<strong>高性能、低延迟的复制</strong>，其存储层与计算层分离，副本通过共享存储实现，<strong>复制延迟通常远低于 1 秒</strong>（毫秒级），非常适合高读取扩展和低延迟复制需求。</p>
</li>
<li><p>DynamoDB 是 NoSQL 键值&#x2F;文档数据库，不原生支持 SQL 查询和存储过程，需要完全重写数据模型和应用逻辑，<strong>代码改动巨大</strong>。</p>
</li>
</ul>
<p><br>338 解决方案架构师需要为高容量 SaaS 平台制定灾难恢复计划，数据全部存储在 Amazon Aurora MySQL 数据库集群中。<br>要求：</p>
<ul>
<li><strong>将数据复制到备用的 AWS 区域</strong>（跨区域 DR）。</li>
<li><strong>以最具成本效益的方式</strong>满足要求。</li>
</ul>
<p>A. 使用 MySQL 二进制日志复制到备用区域的 Aurora 集群，在备用区域为 Aurora 集群配置一个数据库实例。<br>B. 为数据库集群设置 Aurora 全局数据库，设置完成后从次要区域移除数据库实例。<br>C. 使用 AWS DMS 将数据持续复制到次要区域的 Aurora 集群，从次要区域移除数据库实例。<br>D. <u>为数据库集群设置 <strong>Aurora 全局数据库</strong>，在次要区域中指定至少一个数据库实例。</u></p>
<p>因为 Aurora Global Database 是专为跨区域灾难恢复设计的原生功能，设置简单，运维成本低，且次要区域保留实例可随时故障转移，符合成本效益和 DR 要求。</p>
<p><br>339 公司有一个自定义应用程序，其中<strong>嵌入了凭据</strong>（硬编码或配置文件）用于连接 Amazon RDS MySQL 数据库实例。<br>管理层要求：</p>
<ol>
<li><strong>提高应用程序安全性</strong>。</li>
<li><strong>尽可能减少编程工作</strong>。</li>
</ol>
<p>A. 使用 AWS KMS 创建密钥，配置应用程序从 KMS 加载数据库凭证，启用自动密钥轮换。<br>B. 在 RDS MySQL 上为应用创建凭证，存储在 AWS Secrets Manager 中，配置应用从 Secrets Manager 加载凭证，创建一个 Lambda 函数来轮换 Secrets Manager 中的凭证。<br>C. <u>在 RDS MySQL 上为应用创建凭证，存储在 Secrets Manager 中，配置应用从 Secrets Manager 加载凭证，设置凭证轮换计划</u>。<br>D. 在 RDS MySQL 上为应用创建凭证，存储在 AWS Systems Manager Parameter Store 中，配置应用从 Parameter Store 加载凭证，使用 Parameter Store 为 RDS MySQL 中的用户设置凭证轮换计划。</p>
<ul>
<li>KMS 用于加密数据，<strong>不用于存储数据库凭据</strong>。</li>
</ul>
<p><br>340 媒体公司在 AWS 上托管网站，架构包括 ALB 后的 EC2 实例和 Aurora 数据库。<br>网络安全团队报告应用程序易受 <strong>SQL 注入攻击</strong>。问公司应如何解决。</p>
<p>A. <u>在 ALB 前使用 AWS WAF，将适当的 Web ACL 与 AWS WAF 关联。</u><br>B. 创建一个 ALB 监听器规则，以固定响应应对 SQL 注入。<br>C. 订阅 AWS Shield Advanced 以自动阻止所有 SQL 注入尝试。<br>D. 设置 Amazon Inspector 以自动阻止所有 SQL 注入尝试。</p>
<ul>
<li><p><strong>AWS WAF（Web 应用程序防火墙）</strong> 专门用于防护 Web 应用层攻击，包括 SQL 注入、XSS 等。</p>
</li>
<li><p><strong>AWS Shield Advanced</strong> 提供针对 DDoS 攻击的增强防护，<strong>不防御 SQL 注入</strong>（这是应用层攻击，不是 DDoS）。</p>
</li>
<li><p><strong>Amazon Inspector</strong> 是漏洞评估服务，用于扫描 EC2 实例、容器镜像的漏洞，并提供报告，但<strong>不会主动阻止攻击</strong></p>
</li>
</ul>
<p><br>341 公司有一个由 <strong>AWS Lake Formation</strong> 管理的 S3 数据湖。<br>他们希望将数据湖中的数据与 <strong>Amazon Aurora MySQL</strong> 中的运营数据结合，在 <strong>Amazon QuickSight</strong> 中创建可视化。<br>要求：</p>
<ul>
<li>实施<strong>列级授权</strong>，让营销团队只能访问数据库中的部分列。</li>
<li>以<strong>最少的运营开销</strong>满足要求。</li>
</ul>
<p>A. 使用 Amazon EMR 将数据从数据库直接提取到 QuickSight SPICE 引擎，仅包含所需列。<br>B. 使用 AWS Glue Studio 将数据从数据库接入 S3 数据湖，为 QuickSight 用户附加 IAM 策略以实施列级访问控制，在 QuickSight 中使用 S3 作为数据源。<br>C. 使用 AWS Glue Elastic Views 为 S3 中的数据库创建物化视图，创建 S3 存储桶策略实施列级访问控制，在 Quick Sight 中使用 S3 作为数据源。<br>D. <u>使用 Lake Formation 蓝图将数据从数据库接入 S3 数据湖，使用 Lake Formation 为 QuickSight 用户实施列级访问控制，在 QuickSight 中使用 Amazon Athena 作为数据源。</u></p>
<ul>
<li><strong>Lake Formation 蓝图</strong> 可自动化从关系数据库（如 Aurora MySQL）到 S3 数据湖的数据摄取。</li>
<li><strong>Lake Formation 支持列级和行级精细化访问控制</strong>，可以针对不同用户或组（如营销团队）设置仅能访问特定列。</li>
<li>Quick Sight 可通过 <strong>Athena</strong> 查询 S3 数据（通过 Lake Formation 管理的权限），Athena 会继承 Lake Formation 的权限设置，从而实现列级过滤。</li>
</ul>
<p><br>342 一家交易处理公司每周在 EC2 实例上运行脚本化批处理作业，EC2 实例位于自动扩展组（ASG）中。</p>
<ul>
<li>交易数量可能变化，但每次运行时的<strong>基准 CPU 利用率至少为 60%</strong>。</li>
<li>需要在<strong>作业运行前 30 分钟配置好容量</strong>（即提前扩容）。</li>
<li>目前工程师手动修改 ASG 参数，公司没有资源分析容量趋势，需要<strong>自动化修改 ASG 期望容量</strong>。</li>
<li>要求：<strong>最小的运营开销</strong>。</li>
</ul>
<p>A. 为 ASG 创建动态扩展策略，基于 CPU 利用率指标扩展，目标值设置为 60%。<br>B. 为 ASG 创建定时扩展策略，设置期望容量、最小&#x2F;最大容量，重复周期为每周，开始时间设为作业运行前 30 分钟。<br>C. <u>为 ASG 创建预测性扩展策略，基于预测扩展，扩展指标为 CPU 利用率，目标值设为 60%，在策略中将实例设置为提前 30 分钟启动</u>。<br>D. 创建一个 EventBridge 事件，当 ASG 的 CPU 利用率达到 60% 时调用 Lambda 函数，将 ASG 的期望容量和最大容量增加 20%。</p>
<ul>
<li><strong>预测性扩展（Predictive Scaling）</strong> 使用机器学习分析历史负载模式，<strong>预测未来需求</strong>并提前启动实例。</li>
<li>可以设置为<strong>提前 30 分钟启动实例</strong>以满足批处理作业需求。</li>
</ul>
<p><br>343 公司目前有一个 MySQL 数据库运行在私有子网的 <strong>Amazon EC2 实例</strong>上，并执行<strong>定时备份</strong>。<br>要求设计<strong>灾难恢复架构</strong>，需包含<strong>多个 AWS 区域</strong>，并以<strong>最少的运营开销</strong>满足要求</p>
<p>A. 将 MySQL 数据库迁移到多个 EC2 实例，在 DR 区域配置备用 EC2 实例，开启复制。<br>B. 将 MySQL 数据库迁移到 Amazon RDS，使用多可用区部署，在不同可用区的主数据库实例开启读取复制。<br>C. <u>将 MySQL 数据库迁移到 Amazon Aurora 全球数据库，在主区域托管主数据库集群，在 DR 区域托管次要数据库集群。</u><br>D. 将 MySQL 数据库的计划备份存储在配置了 S3 跨区域复制（CRR）的 Amazon S3 存储桶中，使用该数据备份在 DR 区域恢复数据库。</p>
<ul>
<li><strong>Aurora Global Database</strong> 是专门为跨区域灾难恢复设计的服务。</li>
<li>它自动在次要区域创建一个<strong>只读集群</strong>，数据异步复制（通常延迟 &lt;1 秒），支持快速故障转移（RTO 分钟级）</li>
</ul>
<p><br>344 公司有一个 Java 应用程序使用 Amazon SQS 来解析消息，但该程序无法解析大小超过 <strong>256 KB</strong> 的消息。<br>要求：</p>
<ul>
<li>使应用程序能够解析高达 <strong>50 MB</strong> 的消息。</li>
<li>对<strong>代码的改动最少</strong>。</li>
</ul>
<p>A. <u>使用适用于 Java 的 Amazon SQS 扩展客户端库在 Amazon S3 中托管大于 256 KB 的消息。</u><br>B. 使用 Amazon EventBridge 而非 Amazon SQS 来发布来自应用程序的大型消息。<br>C. 更改 Amazon SQS 中的限制，以处理大于 256 KB 的消息。<br>D. 将大于 256 KB 的消息存储在 Amazon EFS 中，配置 Amazon SQS 在消息中引用此位置。</p>
<ul>
<li><strong>SQS 扩展客户端库</strong> 是 AWS 官方提供的库，专门用于处理大于 256 KB 的消息。</li>
</ul>
<p><br>345 公司希望限制对其主要 Web 应用程序内容的访问，并保护这些内容。要求：</p>
<ul>
<li>用户数：<strong>不到 100 名用户</strong>。</li>
<li><strong>无服务器架构</strong>和身份验证解决方案。</li>
<li>与主要 Web 应用集成，并在<strong>全球范围</strong>提供 Web 内容。</li>
<li>能够随用户群<strong>扩展</strong>，并<strong>尽可能降低登录延迟</strong>。</li>
<li><strong>最具成本效益</strong>。</li>
</ul>
<p>A. <u>使用 Amazon Cognito 进行身份验证，Lambda@Edge 进行授权，Amazon CloudFront 在全球提供应用程序。</u><br>B. 使用 AWS Directory Service for Microsoft AD 进行身份验证，AWS Lambda 进行授权，应用程序负载均衡器（ALB）在全球提供 Web 应用。<br>C. 使用 Amazon Cognito 进行身份验证，AWS Lambda 进行授权，Amazon S3 Transfer Acceleration 在全球提供 Web 应用。<br>D. 使用 AWS Directory Service for Microsoft AD 进行身份验证，Lambda@Edge 进行授权，AWS Elastic Beanstalk 在全球提供 Web 应用。</p>
<ul>
<li><p><strong>Amazon Cognito</strong> 是无服务器身份验证服务，适合管理少量到大量用户，按活跃用户数计费，成本低。</p>
</li>
<li><p><strong>Lambda@Edge</strong> 可运行在 CloudFront 边缘节点，进行<strong>授权检查</strong>（如验证 Cognito 令牌），实现靠近用户的低延迟授权。</p>
</li>
<li><p><strong>CloudFront</strong> 是全球 CDN，可缓存并分发 Web 内容，降低全球访问延迟。</p>
</li>
<li><p>Directory Service 是托管 Active Directory，适合企业级集成，但成本较高（按目录规模计费），对于 &lt;100 用户不划算。</p>
</li>
<li><p>S3 Transfer Acceleration 用于加快上传到 S3 的速度，不是用于全球 Web 内容分发和动态应用服务的解决方案</p>
</li>
<li><p>Directory Service 成本高，不适合少量用户场景。</p>
</li>
<li><p>Elastic Beanstalk 是平台即服务，但仍需管理 EC2 实例，不是完全无服务器，且全球部署复杂（需多区域部署）。</p>
</li>
</ul>
<p><br>346 公司数据中心有一个老化的 NAS 阵列，提供 <strong>SMB 共享</strong>和** NFS 共享**给客户端工作站。<br>不想购买新 NAS 或更新支持合同。</p>
<ul>
<li>部分数据频繁访问，大部分数据不活跃。<br>要求：</li>
</ul>
<ol>
<li>将数据迁移到 <strong>Amazon S3</strong>。</li>
<li>使用 <strong>S3 生命周期策略</strong>（转移不活跃数据到低频&#x2F;归档层）。</li>
<li><strong>保持客户端工作站的外观和感觉不变</strong>（即客户端仍通过原有协议访问共享，无需改变访问方式）。</li>
<li>已确定使用 <strong>AWS Storage Gateway</strong> 作为解决方案的一部分。<br>问：应配置哪种类型的存储网关？</li>
</ol>
<p>A. 卷网关<br>B. 磁带网关<br>C. 亚马逊 FSx 文件网关<br>D<u>. 亚马逊 S3 文件网关</u></p>
<ol>
<li><strong>保持客户端访问方式不变</strong> → 客户端当前通过 <strong>SMB&#x2F;NFS</strong> 访问 NAS，因此网关必须提供 <strong>SMB&#x2F;NFS 文件共享接口</strong>。</li>
<li><strong>后端数据存储在 Amazon S3</strong> → 网关需将文件操作映射到 S3。</li>
<li><strong>使用 S3 生命周期策略</strong> → 数据需直接存储在 S3 中，以便应用生命周期规则。</li>
<li><strong>频繁访问数据本地缓存，非活跃数据存于云端</strong> → 需要缓存机制。</li>
</ol>
<p> <strong>卷网关</strong> 提供 <strong>iSCSI 块存储</strong>接口，不是 <strong>SMB&#x2F;NFS 文件共享</strong></p>
<p> **磁带网关 **提供 <strong>虚拟磁带库（VTL）</strong> 接口，用于备份归档，不是文件共享。</p>
<p><br>347 公司有一个在 Amazon EC2 实例上运行的应用程序。解决方案架构师已经根据当前需求，标准化了特定的<strong>实例系列</strong>和<strong>各种实例大小</strong>。<br>要求：</p>
<ol>
<li><strong>在未来 3 年内最大限度地节省该应用的成本</strong>。</li>
<li><strong>能够在未来 6 个月内根据应用的受欢迎程度和使用情况更改实例系列和大小</strong>（即需要灵活性，能调整实例规格）。<br>问哪种解决方案能<strong>最具成本效益</strong>地满足要求。</li>
</ol>
<p>A. <u>计算节省计划</u><br>B. EC2 实例节省计划<br>C. 区域性预留实例<br>D. 标准预留实例</p>
<ul>
<li><strong>计算节省计划（Compute Savings Plans）</strong> 提供最大的灵活性：可应用于 <strong>EC2、Lambda、Fargate</strong> 的计算使用量。</li>
<li>在 EC2 上，它允许在<strong>任意实例系列、大小、操作系统、租期、区域</strong>之间变更（例如从 C5.large 切换到 M5.xlarge），只要满足承诺的使用金额即可。</li>
<li>承诺期可选 <strong>1 年或 3 年</strong>（选择 3 年折扣最大）。</li>
</ul>
<p><strong>C2 实例节省计划（EC2 Instance Savings Plans）</strong> 提供更高的折扣率，但灵活性较低：仅允许在<strong>特定区域、特定实例系列</strong>内更改实例大小（如 C5.large 到 C5.xlarge），<strong>不能跨实例系列更改</strong>（如 C5 到 M5）。</p>
<p><strong>区域性预留实例（Regional RIs）</strong> 可在同一 AWS 区域内的不同可用区之间灵活应用，但<strong>仍然绑定特定的实例系列、大小、操作系统</strong>（如 us-east-1 的 Linux C5.large）</p>
<ul>
<li><strong>标准预留实例（Standard RIs）</strong> 绑定到<strong>特定可用区、实例系列、大小、操作系统</strong>，灵活性最差。</li>
</ul>
<p><br>348 公司从大量可穿戴设备收集数据，存储在 <strong>Amazon DynamoDB</strong> 表中，并进行分析。</p>
<ul>
<li>数据工作负载是<strong>恒定且可预测的</strong>。</li>
<li>公司希望 DynamoDB 的<strong>支出不超过其预测预算</strong>。<br>问哪种解决方案能以<strong>最具成本效益</strong>的方式满足要求</li>
</ul>
<p>A. 使用预置模式 + DynamoDB Standard-IA，为预测的工作负载预留容量。<br>B. <u>使用预置模式，指定读取容量单位（RCU）和写入容量单位（WCU）</u>。<br>C. 使用按需模式，将 RCU&#x2F;WCU 设置到足够高水平以适应负载变化。<br>D. 使用按需模式，通过预留容量指定 RCU&#x2F;WCU。</p>
<p><strong>预置模式（Provisioned Mode）</strong> 允许提前定义读写容量，并按预留容量付费，与按需模式相比，对于<strong>可预测的恒定负载</strong>更经济</p>
<p><br>349 公司在 <strong>ap-southeast-3（雅加达）区域</strong> 的 Aurora PostgreSQL 数据库中存储机密数据，数据库使用 <strong>AWS KMS 客户托管密钥（CMK）</strong> 加密。<br>公司被收购，需要与收购公司的 AWS 账户（也在同一区域）<strong>安全共享数据库备份</strong>。问解决方案架构师应如何做。</p>
<p>A. 创建数据库快照，将该快照复制到新的未加密快照中，与收购公司账户共享新快照。<br>B. <u>创建数据库快照，将收购公司的 AWS 账户添加到 KMS 密钥策略中，与收购公司账户共享该快照。</u><br>C. 创建使用不同 AWS 托管 KMS 密钥的数据库快照，将收购公司账户添加到 KMS 密钥别名中，与收购公司账户共享快照。<br>D. 创建数据库快照，下载快照，将快照上传到 Amazon S3 存储桶，更新 S3 存储桶策略允许收购公司账户访问。</p>
<ul>
<li>加密快照必须通过<strong>修改 KMS 密钥策略</strong>，授予目标账户<strong>使用该密钥的权限</strong>（如 kms:Decrypt）。</li>
<li>然后通过 RDS 快照共享功能（<code>ModifyDBSnapshotAttribute</code>）将快照共享给目标账户。</li>
</ul>
<p><br>350 公司在 us-east-1 使用 <strong>100 GB 的 Amazon RDS for Microsoft SQL Server 单可用区</strong> 数据库实例存储客户交易。<br>要求：</p>
<ol>
<li>数据库实例需要<strong>高可用性和自动恢复能力</strong>。</li>
<li>每年运行几次报告，但报告流程会<strong>导致交易入账时间变长</strong>（报表负载影响主实例性能）。</li>
<li>需要一个<strong>提高报告流程性能</strong>的解决方案。<br>需要选择两个步骤组合以满足要求。</li>
</ol>
<p>A. <u>将数据库实例从单可用区修改为多可用区部署</u>。<br>B. 为当前数据库实例创建快照，将该快照还原到另一个可用区中的新 RDS 部署。<br>C. <u>在不同的可用区中创建数据库实例的只读副本，将所有报表请求指向该只读副本。</u><br>D. 将数据库迁移到 RDS Custom。<br>E. 使用 RDS Proxy 将报表请求限制在维护窗口内。</p>
<ul>
<li><strong>A（多可用区）</strong> 提供高可用性与自动恢复。</li>
<li><strong>C（只读副本）</strong> 分担报告负载，提高报告性能且减少对主实例影响。<br>两者结合可同时满足高可用性和报告性能要求。</li>
</ul>
<p><br>351 公司将数据管理应用程序迁移到 AWS，希望过渡到<strong>事件驱动型架构</strong>，要求：</p>
<ul>
<li>架构更具<strong>分布式特点</strong>。</li>
<li>在执行工作流的不同环节时采用<strong>无服务器概念</strong>。</li>
<li>最大限度地减少<strong>运营开销</strong>。</li>
</ul>
<p>问哪种解决方案能够满足要求。</p>
<p>A. 在 AWS Glue 中构建工作流，使用 AWS Glue 调用 Lambda 函数处理工作流步骤。<br>B. 在 AWS Step Functions 中构建工作流，在 Amazon EC2 实例上部署应用程序，使用 Step Functions 在 EC2 实例上调用工作流步骤。<br>C. 在 Amazon EventBridge 中构建工作流，使用 EventBridge 按计划调用 Lambda 函数处理工作流步骤。<br>D. <u>在 AWS Step Functions 中构建工作流，使用 Step Functions 创建状态机，用该状态机调用 Lambda 函数处理工作流步骤。</u></p>
<ul>
<li><p><strong>AWS Glue</strong> 主要用于 <strong>ETL（数据提取、转换、加载）</strong>，其工作流适用于数据管道编排，并非通用的事件驱动工作流服务。</p>
</li>
<li><p><strong>EventBridge</strong> 是事件总线，主要用于事件路由和基于规则触发目标（如 Lambda、Step Functions 等）。</p>
</li>
</ul>
<p><br>352 公司正在为在线多人游戏设计网络，游戏采用 <strong>UDP 协议</strong>，并部署在 <strong>八个 AWS 区域</strong>。<br>要求：</p>
<ul>
<li>网络架构需要<strong>最大限度地减少延迟和数据包丢失</strong>。</li>
<li>为终端用户提供<strong>高质量游戏体验</strong>。</li>
</ul>
<p>问哪种解决方案能满足要求。</p>
<p>A. 在每个区域设置一个中转网关，在每个中转网关之间创建跨区域对等连接附件。<br>B. <u>设置带有 UDP 监听器的 AWS Global Accelerator，并在每个区域设置终端节点组。</u><br>C. 启用 UDP 设置 Amazon CloudFront，在每个区域配置一个源站。<br>D. 在每个区域之间建立 VPC 对等连接网格，为每个 VPC 开启 UDP。</p>
<ul>
<li><strong>CloudFront</strong> 是 CDN，主要用于缓存和加速 <strong>HTTP&#x2F;HTTPS</strong> 内容，虽然现在也支持部分 UDP（如 QUIC），但并非为<strong>实时游戏 UDP 流量</strong>优化设计。</li>
</ul>
<p><br>353 公司有一个三层 Web 应用，当前托管在<strong>单个可用区</strong>的 EC2 实例上，自管理的 MySQL 数据库使用 <strong>1 TB 的预配置 IOPS SSD（io2）EBS 卷</strong>。</p>
<ul>
<li>预计流量峰值时 <strong>读取和写入 IOPS 均为 1000</strong>。</li>
<li>要求：<ol>
<li><strong>最小化干扰、稳定性能、降低成本</strong>。</li>
<li><strong>保留两倍 IOPS 的容量</strong>（即 2000 IOPS 能力）。</li>
<li><strong>将数据库层迁移到高可用且容错的全托管解决方案</strong>。</li>
</ol>
</li>
</ul>
<p>问哪种解决方案能以<strong>最具成本效益</strong>的方式满足要求</p>
<p>A. 使用带有 io2 Block Express EBS 卷的 Amazon RDS for MySQL 数据库实例的多可用区部署。<br>B. <u>使用配备通用型 SSD（gp2）EBS 卷的 Amazon RDS for MySQL 数据库实例的多可用区部署。</u><br>C. 使用 Amazon S3 智能分层访问层。<br>D. 使用两个大型 EC2 实例以主从模式托管数据库。</p>
<ol>
<li><strong>高可用且容错的全托管解决方案</strong> → 需迁移到 <strong>Amazon RDS</strong>（托管数据库服务）并采用<strong>多可用区（Multi-AZ）部署</strong>，以实现自动故障转移和容错。</li>
<li><strong>性能要求</strong>：峰值读写 IOPS 各 1000，总 2000 IOPS，且要求保留两倍容量（即需支持至少 2000 IOPS 持续性能）。</li>
<li><strong>成本效益</strong>：在满足性能和可用性前提下选择最经济的存储配置。</li>
<li>当前使用 <strong>io2 EBS 卷</strong>（预配置 IOPS SSD），可保证 IOPS 与容量成比例（每 GB 提供一定 IOPS，可额外配置）。</li>
</ol>
<p><br>354 公司有一个无服务器应用程序，使用 <strong>Amazon API Gateway、AWS Lambda</strong> 和 <strong>Amazon RDS for PostgreSQL</strong> 数据库。</p>
<ul>
<li>在流量高峰或不可预测时，由于<strong>数据库连接超时</strong>导致应用程序错误增加。</li>
<li>需要一种解决方案，以<strong>最少的代码更改</strong>来减少应用程序故障。</li>
</ul>
<p>问解决方案架构师应采取什么措施。</p>
<p>A. 降低 Lambda 并发率。<br>B. <u>在 RDS 数据库实例上启用 RDS Proxy。</u><br>C. 调整 RDS 数据库实例的类别以接受更多连接。<br>D. 将数据库迁移到具有按需扩展功能的 Amazon DynamoDB。</p>
<ol>
<li><strong>数据库连接超时问题</strong> → 原因可能是 Lambda 函数并发激增，每个函数打开一个数据库连接，导致 PostgreSQL 数据库连接数达到上限，新连接被拒绝或超时。</li>
<li><strong>最少的代码更改</strong> → 希望不修改或仅少量修改应用程序代码。</li>
<li><strong>流量高峰或不可预测</strong> → 需要弹性处理连接激增</li>
</ol>
<ul>
<li><strong>RDS Proxy</strong> 是托管数据库代理服务，专门用于<strong>管理数据库连接池</strong>，可复用连接，避免因大量并发 Lambda 函数导致数据库连接耗尽。</li>
<li>RDS Proxy 可<strong>自动扩展连接池</strong>，处理突发连接请求，减少连接超时</li>
</ul>
<p><br>355 公司正在将旧应用程序迁移到 AWS，该应用程序每小时运行一次<strong>批处理作业</strong>，属于 <strong>CPU 密集型</strong>。</p>
<ul>
<li>在本地服务器上，批处理作业平均需要 <strong>15 分钟</strong>完成。</li>
<li>本地服务器规格：<strong>64 vCPU + 512 GiB 内存</strong>。<br>要求：</li>
<li>在 AWS 上也能在 <strong>15 分钟内</strong> 运行该批处理作业。</li>
<li><strong>操作开销最小</strong>。</li>
</ul>
<p>A. 使用具有功能扩展的 AWS Lambda。<br>B. 使用带有 AWS Fargate 的 Amazon Elastic Container Service（Amazon ECS）。<br>C. 将 Amazon Lightsail 与 AWS Auto Scaling 配合使用。<br><u>D. 在 Amazon EC2 上使用 AWS Batch。</u></p>
<ul>
<li><p>Lambda 有<strong>资源限制</strong>：最大内存 10,240 MB（10 GB），CPU 按内存比例分配，远低于所需的 512 GiB 内存和 64 vCPU。</p>
</li>
<li><p>Fargate 是无服务器容器平台，最大支持 <strong>16 vCPU + 120 GB 内存</strong>（当前上限）</p>
</li>
<li><p>Lightsail 是简化虚拟专用服务器（VPS）服务，最大实例规格有限（通常较低），且难以达到 64 vCPU + 512 GiB 内存的配置。</p>
</li>
<li><p><strong>AWS Batch</strong> 是专门用于运行批处理作业的托管服务，可自动预置和管理计算资源（基于 EC2 或 Fargate）。</p>
</li>
</ul>
<p><br>356 公司将数据对象存储在 <strong>Amazon S3 标准存储</strong> 中。<br>发现 <strong>75% 的数据在 30 天后很少被访问</strong>。<br>要求：</p>
<ul>
<li>所有数据保持 <strong>即时可访问性</strong>（检索时间不能长）。</li>
<li>具备<strong>相同的高可用性和弹性</strong>（即数据持久性不低于 S3 标准）。</li>
<li><strong>最大限度地降低存储成本</strong>。</li>
</ul>
<p>问哪种存储解决方案能满足要求。</p>
<p>A. 30 天后将数据对象移至 S3 Glacier Deep Archive。<br>B. <u>30 天后将数据对象移至 S3 标准不频繁访问（S3 Standard-IA）。</u><br>C. 30 天后将数据对象移至 S3 单区域 - 不常访问（S3 One Zone-IA）。<br>D. 立即将数据对象移至 S3 单区域 - 不常访问存储（S3 One Zone-IA）。</p>
<ul>
<li><strong>S3 Standard-IA</strong> 提供与 S3 标准相同的<strong>高可用性和弹性</strong>（数据存储在多个 AZ）。</li>
<li>检索延迟低（即时访问），适合不常访问但仍需快速获取的数据。</li>
<li>价格低于 S3 标准存储（存储单价更低，但按访问次数收取检索费）</li>
</ul>
<p><br>357 一家游戏公司将公共记分牌从数据中心迁移到 AWS，应用部署在应用程序负载均衡器后的 EC2 Windows Server 实例上，包含静态文件和动态服务器端代码，需提供高可用性的存储解决方案，选择两项满足要求的步骤。</p>
<p>A. <u>将静态文件存储在Amazon S3上。使用Amazon CloudFront在边缘缓存对象</u>。<br>B. 将静态文件存储在Amazon S3上。使用Amazon ElastiCache在边缘缓存对象。<br>C. 将服务器端代码存储在Amazon Elastic File System（Amazon EFS）上。在每个EC2实例上挂载EFS卷以共享文件。<br>D. <u>将服务器端代码存储在Amazon FSx for Windows File Server上。挂载FSx for Windows File Server卷到每个EC2实例上以共享文件</u>。<br>E. 将服务器端代码存储在通用型SSD（gp2）Amazon Elastic Block Store（Amazon EBS）卷上。将该EBS卷挂载到每个EC2实例上以共享文件。</p>
<ul>
<li><p><strong>EFS</strong> 是 <strong>Linux</strong> 兼容的共享文件系统（NFS），不支持 Windows。</p>
</li>
<li><p><strong>FSx for Windows File Server</strong> 是完全托管的 Windows 原生共享文件系统，支持 SMB 协议，专为 Windows 环境设计。</p>
</li>
</ul>
<p><br>358 一家社交媒体公司的应用部署在 ALB 后的 EC2 实例上，ALB 是 CloudFront 分发的源站；应用在 S3 存储超 10 亿张图像，每秒处理数千张，需动态调整图像大小并向客户端提供适配格式，要求以最少运营开销实现该需求。</p>
<p>A. 在 EC2 实例上安装外部图像管理库，用其处理图像。</p>
<p>B. 创建 CloudFront 源请求策略，通过该策略自动调整图像大小，并依据请求的 User-Agent 头提供适配格式。</p>
<p>C. 将 <u>Lambda@Edge 函数与外部图像管理库配合使用，关联到提供图像服务的 CloudFront 行为。</u></p>
<p>D. 创建 CloudFront 响应头策略，通过该策略自动调整图像大小，并依据请求的 User-Agent 头提供适配格式。</p>
<p><br>359 医院需要将患者记录（PHI）存储在 Amazon S3 存储桶中。<br>合规团队要求：</p>
<ol>
<li>所有受保护的健康信息（PHI）在<strong>传输中和静态时</strong>都经过加密。</li>
<li>合规团队必须<strong>管理静态数据的加密密钥</strong>（即密钥控制权在团队手中，而非完全由 AWS 托管）。</li>
</ol>
<p>A. 在 ACM 中创建公共 SSL&#x2F;TLS 证书，将该证书与 S3 关联，为每个 S3 存储桶配置默认加密使用 SSE-KMS，指派合规团队管理 KMS 密钥。<br>B. 在 S3 存储桶策略上使用 <code>aws:SecureTransport</code> 条件仅允许 HTTPS（TLS）连接，为每个存储桶配置默认加密使用 SSE-S3，指派合规团队管理 SSE-S3 密钥。<br>C. <u>在 S3 存储桶策略上使用 <code>aws:SecureTransport</code> 条件仅允许 HTTPS（TLS）连接，为每个存储桶配置默认加密使用 SSE-KMS，指派合规团队管理 KMS 密钥。</u><br>D. 在 S3 存储桶策略上使用 <code>aws:SecureTransport</code> 条件仅允许 HTTPS（TLS）连接，使用 Amazon Macie 保护 S3 中敏感数据，指派合规团队管理 Macie。</p>
<ol>
<li><strong>传输中加密</strong> → 必须强制使用 HTTPS（TLS）访问 S3。</li>
<li><strong>静态加密</strong> → 必须对 S3 中存储的数据进行服务器端加密。</li>
<li><strong>管理静态数据加密密钥</strong> → 合规团队需拥有密钥管理控制权，这意味着使用 <strong>AWS KMS 客户托管密钥（CMK）</strong>，而非 AWS 托管密钥（SSE-S3 使用 AWS 托管密钥，用户无法管理）。</li>
</ol>
<ul>
<li>Macie 是敏感数据发现和分类服务，<strong>不是加密服务</strong>，无法满足静态加密要求。</li>
</ul>
<p><br>360 公司使用 <strong>Amazon API Gateway</strong> 在同一 VPC 中运行一个<strong>私有网关</strong>，包含两个 REST API：</p>
<ul>
<li><strong>BuyStock</strong> RESTful Web 服务调用 <strong>CheckFunds</strong> RESTful Web 服务。<br>但 VPC 流日志显示，BuyStock 调用 CheckFunds 是<strong>通过互联网而非 VPC</strong>。<br>要求：</li>
<li>实施解决方案使这些 API <strong>通过 VPC 进行通信</strong>（即流量不离开 AWS 内部网络）。</li>
<li><strong>对代码的改动最少</strong>。</li>
</ul>
<p>A. 在 HTTP 头中添加 X-API-Key 头以进行授权。<br>B. <u>使用接口端点。</u><br>C. 使用网关终端节点。<br>D. 在两个 REST API 之间添加一个 Amazon SQS 队列。</p>
<ul>
<li><strong>API Gateway 私有 API 支持 VPC 接口端点（Interface VPC Endpoint）</strong>，可通过私有 DNS 名称在 VPC 内部直接访问 API，无需经过互联网。</li>
<li>只需为 API Gateway 创建接口端点，然后 BuyStock 服务调用 CheckFunds 时使用该端点的私有 DNS，流量即通过 AWS 内部网络。</li>
</ul>
<p><br>361 公司托管了一个多人游戏应用程序，要求：</p>
<ol>
<li>能够以 <strong>亚毫秒级延迟</strong> 读取数据（对频繁访问的数据要求极高读取性能）。</li>
<li>对<strong>历史数据</strong>执行<strong>一次性查询</strong>（分析或批量查询，对延迟要求不高）。</li>
<li>以<strong>最少的运营开销</strong>满足要求。</li>
</ol>
<p>A. 对于频繁访问的数据使用 Amazon RDS，运行定期自定义脚本将数据导出到 S3。<br>B. 将数据直接存储在 S3 中，实施 S3 生命周期策略，将较旧数据移至 S3 Glacier Deep Archive，使用 Amazon Athena 对 S3 数据运行一次性查询。<br>C. <u>对频繁访问的数据使用带有 DynamoDB 加速器（DAX）的 Amazon DynamoDB，通过 DynamoDB 表导出功能将数据导出到 S3，使用 Amazon Athena 对 S3 数据运行一次性查询。</u><br>D. 对于频繁访问的数据使用 Amazon DynamoDB，开启流功能到 Kinesis Data Streams，使用 Kinesis Data Firehose 从 Kinesis 读取数据并存储在 S3 中。</p>
<ul>
<li>RDS 是关系数据库，读取延迟通常在毫秒级，很难达到<strong>亚毫秒级</strong>，尤其在高并发游戏场景。</li>
</ul>
<p>S3 是对象存储，读取延迟较高（几十到几百毫秒），无法满足 <strong>亚毫秒级延迟</strong></p>
<ul>
<li><p><strong>Amazon DynamoDB</strong> 是 NoSQL 数据库，本身提供毫秒级延迟（个位数毫秒）。</p>
</li>
<li><p><strong>DynamoDB Accelerator（DAX）</strong> 是完全托管的内存缓存，可提供 <strong>亚毫秒级（微秒级）</strong> 读取延迟，适合高频访问的游戏数据。</p>
</li>
<li><p><strong>DynamoDB 表导出到 S3</strong> 是托管功能，可将数据自动导出到 S3，无需自定义脚本，运营开销低。</p>
</li>
<li><p><strong>Amazon Athena</strong> 可对 S3 中的历史数据运行一次性 SQL 查询，无需管理基础设施。</p>
</li>
<li><p>同样使用 DynamoDB 满足高性能读取，但未提及 DAX，无法保证亚毫秒级延迟。</p>
</li>
<li><p>通过 Kinesis 流和 Firehose 将数据实时传输到 S3 可用于历史分析，但架构复杂，且仍需额外配置查询工具（如 Athena）。</p>
</li>
</ul>
<p><br>362 公司支付处理系统要求：</p>
<ul>
<li><strong>特定支付 ID 的消息按照发送时的顺序被接收</strong>（即保证同一支付 ID 的消息有序处理）。</li>
<li>否则支付可能被错误处理。<br>问解决方案架构师应采取哪些措施来满足要求（选两项）。</li>
</ul>
<p>A. 将消息写入 Amazon DynamoDB 表，使用支付 ID 作为分区键。<br>B. <u>将消息写入 Amazon Kinesis 数据流，使用支付 ID 作为分区键</u>。<br>C. 将消息写入 Amazon ElastiCache for Memcached 集群，使用支付 ID 作为键。<br>D. 将消息写入 Amazon SQS 标准队列，设置消息属性以使用支付 ID。<br>E. <u>将消息写入 Amazon SQS FIFO 队列，将消息组设置为使用支付 ID</u>。</p>
<ul>
<li><p><strong>Kinesis Data Streams</strong> 中，数据记录通过分区键（Partition Key）分配到特定分片（Shard）。</p>
</li>
<li><p><strong>同一分区键的记录保证按顺序写入同一分片，并可按顺序读取</strong>，因此相同支付 ID 的消息会保持顺序。</p>
</li>
<li><p><strong>SQS 标准队列提供尽力而为的顺序，不保证严格的消息顺序</strong>，可能因分布式处理导致消息乱序。</p>
</li>
</ul>
<p><br>363 一家公司构建游戏系统，需要向<strong>三个独立服务（排行榜、匹配、认证）</strong> 发送<strong>独特事件</strong>，同时要求<strong>保证事件的顺序</strong>。<br>要求设计一个 AWS 事件驱动系统来满足<strong>顺序保证</strong>与<strong>多目标分发</strong>。</p>
<p>A. 亚马逊 EventBridge 事件总线<br>B. <u>亚马逊简单通知服务（Amazon SNS）FIFO 主题</u><br>C. 亚马逊简单通知服务（Amazon SNS）标准主题<br>D. 亚马逊简单队列服务（Amazon SQS）FIFO 队列</p>
<p>SQS 单个 FIFO 队列可保证顺序，但无法直接将一条消息同时分发给多个消费者队列（除非每个消费者轮询同一队列，但这不符合“独立服务独立处理”的需求）。</p>
<p><br>364 医院在架构中使用 <strong>Amazon SQS</strong> 和 <strong>Amazon SNS</strong>，用于收集患者症状数据。<br>要求：</p>
<ol>
<li>数据在<strong>静态（at rest）</strong> 和<strong>传输（in transit）</strong> 中必须加密。</li>
<li>只有医院授权人员才能访问数据。</li>
</ol>
<p>要选<strong>两个正确步骤</strong>来满足要求。</p>
<p><strong>A.</strong> 开启 SQS 组件的服务器端加密。更新默认密钥策略，将密钥使用权限限制在一组授权主体范围内。</p>
<p><strong>B.</strong> <u>使用 AWS KMS 客户密钥在 SNS 组件上开启服务器端加密托管密钥。应用密钥策略以将密钥使用限制为一组授权主体。</u></p>
<p><strong>C.</strong> 开启 SNS 组件的加密功能。更新默认密钥策略，将密钥使用权限限制在一组授权主体范围内。在主题策略中设置条件，只允许通过 TLS 进行加密连接。</p>
<p><strong>D.</strong> <u>使用 AWS KMS 客户管理的密钥为 SQS 组件开启服务器端加密。应用密钥策略以将密钥使用限制在一组授权主体范围内。在队列策略中设置条件，仅允许通过 TLS 进行加密连接。</u></p>
<p><strong>E.</strong> 使用 AWS KMS 的客户托管密钥为 SQS 组件开启服务器端加密。应用 IAM 策略以将密钥使用限制在一组授权主体范围内。在队列策略中设置条件，只允许通过 TLS 进行加密连接。</p>
<ul>
<li><strong>静态加密</strong>：SQS 和 SNS 都需开启服务器端加密（SSE），最好使用 AWS KMS 客户托管密钥（CMK）。</li>
<li><strong>传输加密</strong>：必须强制使用 TLS（HTTPS）来发布消息到 SNS 或 SQS，以及订阅&#x2F;消费时使用 HTTPS。这可在 SNS 主题策略或 SQS 队列策略中通过 <code>aws:SecureTransport</code> 条件实现。</li>
<li><strong>访问控制</strong>：<ul>
<li>限制谁可以使用 KMS 密钥进行加解密 → 通过 <strong>KMS 密钥策略</strong> 来限制授权 IAM 主体（用户&#x2F;角色）。</li>
<li>限制谁可以访问 SQS 队列或 SNS 主题 → 通过 IAM 策略或 SQS 队列策略 &#x2F; SNS 主题策略控制。</li>
</ul>
</li>
</ul>
<p><br>365 公司有一个由 Amazon RDS 支持的 Web 应用程序。<br>事件：<strong>数据库管理员意外编辑数据库表导致数据丢失</strong>。<br>恢复要求：<strong>能将数据库恢复到过去 30 天内任何更改发生前 5 分钟的状态</strong>。</p>
<p>A. 只读副本<br>B. 手动快照<br>C. <u>自动备份</u><br>D. 多可用区部署</p>
<ul>
<li>RDS 的自动备份包括两部分：<ol>
<li>每日自动全量快照。</li>
<li><strong>事务日志备份（持续进行）</strong>。</li>
</ol>
</li>
<li>启用自动备份后，RDS 会保留事务日志，从而允许执行<strong>时间点恢复（PITR）</strong>，可以恢复到保留期（最多 35 天）内的任意时间点，精确到几秒钟。</li>
</ul>
<p>手动快照没有自动连续的事务日志备份，只能恢复到快照创建的时间点，无法做到“过去 30 天内任意时间点前 5 分钟”。</p>
<p><br>366 公司架构：</p>
<ul>
<li><strong>Amazon API Gateway</strong> → <strong>AWS Lambda</strong> → <strong>Amazon DynamoDB</strong></li>
<li>用户认证使用 <strong>Amazon Cognito 用户池</strong>（已识别用户身份）。</li>
<li>需求：<strong>只有拥有订阅的用户才能访问付费内容</strong>（即根据用户是否订阅来控制访问权限）。</li>
<li>限制条件：<strong>以最小的运营开销</strong>满足要求。</li>
</ul>
<p>A. 在 API Gateway API 上启用 API 缓存和节流。<br>B. 在 API Gateway API 上设置 AWS WAF。创建一条规则来筛选拥有订阅的用户。<br>C. 对 DynamoDB 表中的高级内容应用细粒度的 IAM 权限。<br>D. <u>实施 API 使用计划和 API 密钥，以限制未订阅用户的访问</u></p>
<ul>
<li><strong>API Gateway 使用计划（Usage Plans）</strong> 和 <strong>API 密钥（API Keys）</strong> 通常用于对 API 访问进行计量、限流和授权。</li>
<li>可以为 <strong>已订阅用户</strong> 和 <strong>未订阅用户</strong> 分配不同的 API 密钥，并将这些密钥关联到不同的使用计划。</li>
<li>在使用计划中，可以限制某些 API 方法（如访问付费内容的接口）仅允许特定 API 密钥访问。</li>
<li>优势：<ol>
<li><strong>原生集成</strong>：API Gateway 原生支持，无需修改 Lambda 函数逻辑（或只需很少改动）。</li>
<li><strong>最小运营开销</strong>：管理员只需在用户订阅状态变更时分配或撤销 API 密钥即可。</li>
<li><strong>无需额外安全组件</strong>：复用现有 Cognito 认证，API 密钥作为第二层授权。</li>
</ol>
</li>
<li>需要注意的是：API 密钥通常标识客户端或项目，而非最终用户。但在此场景中，可以将 API 密钥按订阅状态分类，已订阅用户获得一个密钥，未订阅用户获得另一个（或无密钥），从而实现访问控制。</li>
</ul>
<p><br>367 一家公司的全球 UDP 应用程序托管在美国、亚洲、欧洲的本地数据中心，必须满足合规性要求（应用程序在本地托管）。<br>当前使用 <strong>Amazon Route 53 基于延迟的路由</strong> 为全球用户路由请求。<br><strong>需求</strong>：提高应用程序的性能和可用性。</p>
<p>A. <u>在三个 AWS 区域中配置三个网络负载均衡器（NLB）以连接本地端点。使用 AWS Global Accelerator 创建一个加速器，并将这些 NLB 注册为其端点。通过使用指向加速器 DNS 的 CNAME 提供对应用程序的访问。</u></p>
<p>B. 在三个 AWS 区域中配置三个应用程序负载均衡器（ALB）以连接本地端点。使用 AWS Global Accelerator 创建一个加速器，并将这些 ALB 注册为其端点。通过使用指向加速器 DNS 的 CNAME 来提供对应用程序的访问。</p>
<p>C. 在三个 AWS 区域中配置三个网络负载均衡器（NLB）以连接本地端点。在 Route 53 中，创建一个指向这三个 NLB 的基于延迟的记录，并将其用作 Amazon CloudFront 分发的源站。通过使用指向 CloudFront DNS 的 CNAME 来提供对应用程序的访问。</p>
<p>D. 在三个 AWS 区域中配置三个应用程序负载均衡器（ALB）以连接本地端点。在 Route 53 中，创建一个基于延迟的记录指向这三个 ALB，并将其用作 Amazon CloudFront 分发的源站。通过使用指向 CloudFront DNS 的 CNAME 来提供对应用程序的访问。</p>
<ul>
<li>NLB 支持 UDP，可以连接本地端点（例如通过 IP 目标组指向本地服务器）。</li>
<li>Global Accelerator 加速器将 NLB 作为端点，提供 Anycast IP，流量通过 AWS 骨干网优化路由至最近的 NLB，再转发到本地。</li>
<li>ALB 不支持 UDP，因此无法用于基于 UDP 的应用程序。</li>
<li>但 CloudFront 主要用于 HTTP(S) 加速和缓存，不支持通用 UDP 流量。</li>
</ul>
<p><br>368 一位解决方案架构师希望 <strong>所有新用户的 IAM 用户密码</strong> 满足以下要求：</p>
<ol>
<li>有特定的密码复杂度要求。</li>
<li>有强制密码轮换周期。</li>
</ol>
<p>问：应采取什么措施来实现这一目标？</p>
<p><u>A. 为整个 AWS 账户设置总体密码策略。</u><br>B. 为 AWS 账户中的每个 IAM 用户设置密码策略。<br>C. 使用第三方供应商软件来设置密码要求。<br>D. 将 Amazon CloudWatch 规则附加到 Create_newuser 事件，以按相应要求设置密码。</p>
<ul>
<li>设置后，所有<strong>新创建</strong>的 IAM 用户在设置密码时就会强制满足该策略，并且现有用户下次更改密码时也会遵循。</li>
</ul>
<p><br>369 一家公司将一个应用程序迁移到 Amazon EC2 Linux 实例上。<br>其中<strong>一个 EC2 实例</strong>上按计划运行多个<strong>时长 1 小时的任务</strong>。</p>
<ul>
<li>任务由不同团队编写，使用<strong>不同的编程语言</strong>。</li>
<li>公司担心<strong>单个实例</strong>上运行这些任务的<strong>性能和可扩展性问题</strong>。</li>
</ul>
<p>解决方案架构师需要实施解决方案以解决这些问题，并满足 <strong>最小的运营开销</strong>。</p>
<p>A. <u>使用 AWS Batch 将任务作为作业运行。通过 Amazon EventBridge（Amazon CloudWatch Events）来调度这些作业。</u></p>
<p>B. 将 EC2 实例转换为容器。使用 AWS App Runner 按需创建容器，以作业形式运行任务。</p>
<p>C. 将任务复制到 AWS Lambda 函数中。使用 Amazon EventBridge（Amazon CloudWatch Events）来调度 Lambda 函数。</p>
<p>D. 为运行这些任务的 EC2 实例创建一个亚马逊机器镜像（AMI）。使用该 AMI 创建一个自动扩展组，以运行该实例的多个副本。</p>
<ul>
<li><p>AWS Batch 是专门运行批量计算作业的托管服务，可以处理长时间运行的任务（支持长达数小时甚至数天）。</p>
</li>
<li><p>AWS App Runner 主要用于 Web 应用&#x2F;API 的托管容器服务，并不适合计划性批处理作业（它主要面向 HTTP 服务持续运行，而非按计划触发的一次性作业）。</p>
</li>
<li><p>Lambda 最大执行时间<strong>15 分钟</strong>（现已支持某些区域最长 15 分钟，但题目任务长达 1 小时）。</p>
</li>
</ul>
<p><br>370 一家公司在 VPC 中运行一个公共三层 Web 应用程序：</p>
<ul>
<li>EC2 实例部署在多个可用区。</li>
<li>在<strong>私有子网</strong>中运行的 EC2 实例需要<strong>通过互联网与外部许可证服务器通信</strong>。</li>
<li>需要的是一个<strong>能最大限度减少运维工作的托管解决方案</strong>。</li>
</ul>
<p>A. 在公有子网中配置一个 NAT 实例。用指向该 NAT 实例的默认路由修改每个私有子网的路由表。</p>
<p>B. 在私有子网中配置一个 NAT 实例。用指向该 NAT 实例的默认路由修改每个私有子网的路由表。</p>
<p>C. <u>在公有子网中配置一个 <strong>NAT 网关</strong>。用指向 NAT 网关的默认路由修改每个私有子网的路由表。</u></p>
<p>D. 在私有子网中配置一个 NAT 网关。用指向该 NAT 网关的默认路由修改每个私有子网的路由表。</p>
<ul>
<li><p>NAT 网关<strong>不能</strong>部署在私有子网，必须部署在公有子网（AWS 规定</p>
</li>
<li><p>配置路由表后，私有子网实例可通过 NAT 网关访问互联网。</p>
</li>
<li><p>NAT 实例不是托管服务，需要手动管理，不符合“最大限度减少运维工作”。</p>
</li>
</ul>
<p><br>371 一家公司需要创建一个 <strong>Amazon EKS 集群</strong>，用于托管数字媒体流应用程序。<br>该集群将使用<strong>托管节点组</strong>，节点由 <strong>Amazon EBS 卷</strong> 提供存储支持。<br>公司要求：使用 <strong>AWS KMS 客户托管密钥（CMK）</strong> 对所有静态数据进行加密。<br>目标：<strong>以最小的运营开销</strong> 满足要求。<br>需选择 <strong>两项</strong> 正确的操作组合。</p>
<p>A. 使用一个 Kubernetes 插件，该插件利用客户管理的密钥来执行数据加密。<br>B. 创建 EKS 集群后，找到 EBS 卷。使用客户管理的密钥启用加密。<br><u>C. 在将要创建 EKS 集群的 AWS 区域中，默认启用 EBS 加密。选择客户管理的密钥作为默认密钥。</u><br><u>D. 创建 EKS 集群。创建一个 IAM 角色，该角色具有授予对客户托管密钥的权限的策略。将该角色与 EKS 集群相关联。</u><br>E. 将客户管理的密钥作为 Kubernetes 密钥存储在 EKS 集群中。使用客户管理的密钥对 EBS 卷进行加密。</p>
<ul>
<li><p>这是 <strong>AWS 区域级 EBS 加密设置</strong>，启用后该区域所有新 EBS 卷都会自动使用指定 CMK 加密。</p>
</li>
<li><p>EKS 节点组创建时自动应用，无需额外配置节点组或启动模板</p>
</li>
<li><p>要使节点组实例能使用 CMK 加密&#x2F;解密 EBS 卷，<strong>节点实例的 IAM 角色</strong> 必须有相应 KMS 权限。</p>
</li>
<li><p>创建 EKS 集群时，托管节点组配置可以指定 IAM 角色（节点实例角色），该角色需要包含访问 CMK 的权限。</p>
</li>
<li><p><strong>C</strong>：在区域级别启用 EBS 默认加密，指定 CMK 作为默认密钥 → 确保新建卷自动加密。</p>
</li>
<li><p><strong>D</strong>：确保 EKS 节点组的 IAM 角色有访问 CMK 的权限 → 节点能正常加解密卷。</p>
</li>
</ul>
<p><br>372 一家公司希望将 Oracle 数据库迁移到 AWS。<br>数据库目前有一个单一的表，存储了<strong>数百万张高分辨率 GIS 图像</strong>，通过<strong>地理编码</strong>标识。<br>灾害发生时，<strong>每隔几分钟就会有上万张图像更新</strong>（高写入负载）。<br>每个地理编码对应一张图像（一行数据）。<br>要求：</p>
<ul>
<li>高可用</li>
<li>可扩展（尤其是高写入期间）</li>
<li>最具成本效益</li>
</ul>
<p>A. 将图像和地理编码存储在数据库表中。使用运行在 Amazon RDS 多可用区数据库实例上的 Oracle。</p>
<p>B. <u>将图像存储在 Amazon S3 存储桶中。使用 Amazon DynamoDB，将地理编码作为键和图像 S3 对象指针。</u></p>
<p>C. 将图像和地理编码存储在 Amazon DynamoDB 表中。在高负载时段配置 DynamoDB 加速器（DAX）。</p>
<p>D. 将图像存储在 Amazon S3 存储桶中。将地理编码和图像的 S3 URL 存储在数据库表中。使用在 Amazon RDS 多可用区数据库实例上运行的 Oracle。</p>
<ul>
<li>图像存在 DynamoDB 中作为属性值 → DynamoDB 每项最大 400 KB，高分辨率图像很大，可能超过限制，即使分块存储也会使成本极高（DynamoDB 存储费比 S3 贵很多）。</li>
<li>DAX 是读缓存，对高写入场景无帮助。</li>
<li>元数据存在 Oracle RDS 中 → 同样有高并发写入扩展性问题，Oracle RDS 对“几分钟上万次更新”难以自动扩展，可能成为瓶颈且成本高。</li>
</ul>
<p><br>373 一个应用程序从汽车物联网传感器收集数据，通过 <strong>Amazon Kinesis Data Firehose</strong> 流式传输，存储在 <strong>Amazon S3</strong> 中。<br>数据特点：</p>
<ul>
<li>每年生成数万亿个 S3 对象。</li>
<li><strong>每天早上</strong>，使用<strong>过去 30 天的数据</strong>重新训练一套机器学习模型。</li>
<li><strong>每年四次</strong>，使用<strong>过去 12 个月的数据</strong>进行分析和训练其他机器学习模型。</li>
<li>数据必须能够以<strong>最小延迟获取</strong>，保存期限长达 <strong>1 年</strong>。</li>
<li><strong>1 年之后</strong>，数据必须留存以作<strong>归档之用</strong>。</li>
</ul>
<p>要求：选择 <strong>最具成本效益的存储解决方案</strong>。</p>
<p>A. 使用 S3 智能分层存储类别。创建 S3 生命周期策略，将对象在 1 年后转换到 S3 Glacier 深度归档。</p>
<p>B. 使用 S3 Intelligent-Tiering 存储类别。将 S3 Intelligent-Tiering 配置为在 1 年后自动将对象移动到 S3 Glacier Deep Archive。</p>
<p>C. 使用 S3 标准 - 不常访问（S3 Standard-IA）存储类别。创建一个 S3 生命周期策略，将对象在 1 年后转换到 S3 Glacier 深度归档。</p>
<p>D. <u>使用 S3 标准存储类别。创建一个 S3 生命周期策略，将对象转换为 S3 标准不频繁访问存储类别（S3 Standard-IA），30 天后再过渡到 S3 Glacier 深度归档存储。</u></p>
<ul>
<li>前 30 天用 S3 Standard（适合频繁访问）。</li>
<li>30 天后转 Standard-IA（适合不频繁访问且需要低延迟）。</li>
<li>1 年后（第 365 天）转 Glacier Deep Archive（归档）。</li>
</ul>
<p><br>374 一家公司在 <strong>us-east-1</strong> 区域的三个独立 VPC 中运行多个业务应用程序。<br>要求：</p>
<ol>
<li>这些应用程序必须能够在 <strong>VPC 之间进行通信</strong>。</li>
<li>每天必须持续将数百 GB 数据发送到 <strong>本地数据中心</strong>的一个对<strong>延迟敏感</strong>的应用程序。</li>
<li>需要设计一个<strong>成本效益最大化</strong>的网络连接解决方案。</li>
</ol>
<p>A. 从数据中心配置三个 AWS 站点到站点 VPN 连接。通过为每个 VPC 配置一个 VPN 连接来建立连接。</p>
<p>B. 在每个 VPC 中部署第三方虚拟网络设备。在数据中心和每个虚拟设备之间建立 IPsec VPN 隧道。</p>
<p>C. 从数据中心到美国东部 1 区的 Direct Connect 网关建立三条 AWS Direct Connect 连接。通过将每个 VPC 配置为使用其中一条 Direct Connect 连接来建立连接。</p>
<p>D. <u>从数据中心到 AWS 建立一个 AWS Direct Connect 连接。创建一个中转网关，并将每个 VPC 连接到中转网关。建立 Direct Connect 连接和中转网关之间的连通性。</u></p>
<ul>
<li><p><strong>Site-to-Site VPN</strong>：</p>
<ul>
<li><strong>通过互联网加密隧道</strong>。</li>
<li>延迟和抖动较大，不适合对延迟敏感的应用。</li>
<li>数据传输数百 GB 时，互联网带宽成本可能较高，且性能可能不稳定。</li>
</ul>
</li>
<li><p><strong>AWS Direct Connect</strong>：</p>
<ul>
<li>专用网络连接，低延迟、高带宽、更稳定。</li>
<li>适合大量数据传输和延迟敏感应用。</li>
<li>但 Direct Connect 物理端口成本固定，建立多个连接会增加成本。</li>
</ul>
</li>
<li><p><strong>Transit Gateway</strong>：</p>
<ul>
<li>用于集中管理 VPC 间、VPC 与本地网络间的路由。</li>
<li>可简化网络架构，避免全互联的复杂性和成本。</li>
</ul>
</li>
<li><p>一个 Direct Connect 连接满足数据中心与 AWS 的低延迟、高带宽需求，成本远低于三条。</p>
</li>
<li><p>Transit Gateway 集中连接所有 VPC，实现 VPC 间通信（通过 Transit Gateway 路由）。</p>
</li>
<li><p>Direct Connect 通过 Direct Connect Gateway 或虚拟接口（VIF）连接到 Transit Gateway，从而使数据中心可以通过一个连接访问所有 VPC，且 VPC 间通信也通过 Transit Gateway。</p>
</li>
</ul>
<p><br>375 一家电子商务公司在构建分布式订单处理应用程序，涉及：</p>
<ul>
<li>多个无服务器函数和 AWS 服务完成订单处理任务。</li>
<li>任务工作流中需要<strong>人工审批</strong>。</li>
<li>解决方案必须能够：<ol>
<li>将多个 Lambda 函数组合成<strong>响应迅速的无服务器应用程序</strong>。</li>
<li><strong>协调在 Amazon EC2 实例、容器或本地服务器上运行的数据和服务</strong>。</li>
</ol>
</li>
<li>要求以<strong>最少的运营开销</strong>满足需求。</li>
</ul>
<p>A. <u>使用 AWS Step Functions 构建应用程序</u>。</p>
<p>B. 在 AWS Glue 作业中集成所有应用程序组件。</p>
<p>C. 使用亚马逊简单队列服务（Amazon SQS）来构建该应用程序。</p>
<p>D. 使用 AWS Lambda 函数和 Amazon EventBridge 事件来构建应用程序。</p>
<p><br>376 一家公司已启动 <strong>Amazon RDS for MySQL</strong> 数据库实例。<br>连接情况：</p>
<ul>
<li>大多数连接来自<strong>无服务器应用程序</strong>（如 Lambda 函数）。</li>
<li>数据库访问流量在<strong>随机时间间隔变化显著</strong>。</li>
<li>在需求高峰期，用户遇到<strong>数据库连接被拒绝</strong>的错误。</li>
<li>要求以<strong>最少的运营开销</strong>解决问题。</li>
</ul>
<p>A. <u>在 RDS Proxy 中创建一个代理。配置用户的应用程序，使其通过 RDS Proxy 使用数据库实例。</u></p>
<p>B. 在用户的应用程序和数据库实例之间部署 Amazon ElastiCache for Memcached。</p>
<p>C. 将数据库实例迁移到具有更高 I&#x2F;O 容量的不同实例类型。配置用户的应用程序以使用新的数据库实例。</p>
<p>D. 为数据库实例配置多可用区。配置用户的应用程序以在数据库实例之间切换。</p>
<ul>
<li><strong>RDS Proxy</strong> 是 AWS 托管数据库代理服务，专为无服务器和突发连接场景设计。</li>
<li>功能：<ol>
<li>连接池：复用数据库连接，避免大量短期连接冲击数据库。</li>
<li>减少数据库负载：代理层处理连接建立&#x2F;断开，数据库实例只维护少量长期连接。</li>
<li>故障转移快速：减少应用在故障转移时的连接错误。</li>
</ol>
</li>
</ul>
<p><br>377 一家公司部署了新的审计系统，用于集中管理 EC2 实例的以下信息：</p>
<ul>
<li>操作系统版本</li>
<li>补丁程序</li>
<li>已安装软件</li>
</ul>
<p>要求：确保通过 <strong>EC2 Auto Scaling 组</strong> 配置的所有实例，在<strong>启动和终止后能立即</strong>成功向审计系统发送报告。</p>
<p>A. 使用定时的 AWS Lambda 函数，并在所有 EC2 实例上远程运行脚本，将数据发送到审计系统。</p>
<p>B. <u>使用 EC2 Auto Scaling 生命周期挂钩运行自定义脚本，在实例启动和终止时向审计系统发送数据。</u></p>
<p>C. 使用 EC2 自动扩展启动配置，通过用户数据运行自定义脚本，以便在实例启动和终止时向审计系统发送数据。</p>
<p>D. 在实例操作系统上运行自定义脚本来将数据发送到审计系统。配置该脚本，使其在实例启动和终止时由 EC2 Auto Scaling 组调用。</p>
<p><br>378 一家公司正在开发一款<strong>实时多人游戏</strong>，使用 <strong>UDP</strong> 进行客户端与服务器的通信。</p>
<ul>
<li>游戏服务器在自动扩展组中。</li>
<li>预计白天出现需求高峰 → 服务器平台需要自动扩展。</li>
<li>需要存储<strong>玩家分数和其他非关系型数据</strong>。</li>
<li>数据库要求：<strong>无需干预即可扩展</strong>（即完全托管、自动扩展）。</li>
</ul>
<p>问：解决方案架构师应推荐哪种方案？</p>
<p>A. 使用 Amazon Route 53 进行流量分配，并使用 Amazon Aurora Serverless 进行数据存储。</p>
<p>B. <u>使用网络负载均衡器进行流量分配，并使用 Amazon DynamoDB 按需模式进行数据存储。</u></p>
<p>C. 使用网络负载均衡器进行流量分配，并使用 Amazon Aurora 全球数据库进行数据存储。</p>
<p>D. 使用应用程序负载均衡器进行流量分配，并使用 Amazon DynamoDB 全局表进行数据存储。</p>
<p><strong>负载均衡器</strong>：</p>
<ul>
<li><strong>网络负载均衡器（NLB）</strong>：支持 TCP&#x2F;UDP，适用于游戏等非 HTTP 流量，可与自动扩展组集成。</li>
<li><strong>应用程序负载均衡器（ALB）</strong>：仅支持 HTTP&#x2F;HTTPS&#x2F;gRPC，<strong>不支持 UDP</strong>。</li>
<li><strong>Route 53</strong>：DNS 负载均衡，支持基于延迟&#x2F;地理位置&#x2F;加权等路由，但通常用于 HTTP(S) 或 TCP，对于实时游戏 UDP 流量，直接使用 NLB 更常见。</li>
</ul>
<p><strong>数据库</strong>：</p>
<ul>
<li><strong>Amazon DynamoDB</strong>：NoSQL，完全托管，自动扩展，有<strong>按需模式（On-Demand）</strong> 自动适应流量，无需预置容量，完美符合“无需干预即可扩展”。</li>
<li><strong>Amazon Aurora Serverless</strong>：是关系型数据库（SQL），适用于不定负载的 SQL 工作负载，但数据模型是非关系型，用 Aurora 不合适。</li>
<li><strong>Amazon Aurora 全球数据库</strong>：是关系型跨区域复制方案，同样不适合非关系型数据存储。</li>
</ul>
<p><br>379 一家公司的前端应用程序使用以下架构：</p>
<ul>
<li>前端 ↔ <strong>Amazon API Gateway</strong> ↔ <strong>AWS Lambda 函数</strong>（处理请求） ↔ <strong>Amazon RDS 数据库</strong>。</li>
<li>Lambda 函数在收到请求时：<ol>
<li><strong>加载许多库</strong>（初始化时间可能较长）。</li>
<li>连接到 RDS 数据库，处理数据，返回结果。</li>
</ol>
</li>
<li>目标：<ol>
<li>对所有用户<strong>尽可能降低响应延迟</strong>。</li>
<li>对<strong>运营进行最少改动</strong>。</li>
</ol>
</li>
</ul>
<p>A. 在前端应用程序和数据库之间建立连接，通过绕过 API 来加快查询速度。</p>
<p>B. <u>为处理请求的 Lambda 函数配置预置并发</u>。</p>
<p>C. 在 Amazon S3 中缓存查询结果，以便更快地检索类似数据集。</p>
<p>D. 增大数据库规模，以增加 Lambda 可同时建立的连接数。</p>
<ul>
<li><strong>预置并发（Provisioned Concurrency）</strong> 是 Lambda 的功能，预先初始化一定数量的函数实例，使其处于<strong>就绪状态</strong>，避免冷启动。</li>
<li>初始化好的实例已经加载了库和可能建立了数据库连接（如果连接池在初始化时建立）。</li>
</ul>
<p><br>380 一家公司正在将本地工作负载迁移到 AWS，已在使用多个 <strong>Amazon EC2 实例</strong>和 <strong>Amazon RDS 数据库实例</strong>。<br>需求：</p>
<ul>
<li>在<strong>非工作时间自动启动和停止 EC2 实例及数据库实例</strong>（即定时启停）。</li>
<li>解决方案必须<strong>最大限度地降低成本和基础设施维护工作</strong>。</li>
</ul>
<p>A. 使用弹性调整大小来扩展 EC2 实例。在非工作时间将数据库实例缩容至零。</p>
<p>B. 探索 AWS Marketplace，寻找能按计划自动启动和停止 EC2 实例及数据库实例的合作伙伴解决方案。</p>
<p>C. 启动另一个 EC2 实例。配置 crontab 计划以运行 shell 脚本，这些脚本将按计划启动和停止现有的 EC2 实例和数据库实例。</p>
<p>D. <u>创建一个 AWS Lambda 函数，用于启动和停止 EC2 实例及数据库实例。配置 Amazon EventBridge，使其按计划调用该 Lambda 函数</u></p>
<ul>
<li>“弹性调整大小”可能指 EC2 Auto Scaling 或修改实例类型，但 RDS 无法“缩容至零”</li>
<li>RDS 实例可以通过 <code>StopDBInstance</code> API 停止（部分引擎支持），停止期间只收取存储费用，大幅节省计算费用。</li>
<li>EC2 实例停止后只收 EBS 存储费，不收实例费。</li>
<li>Lambda + EventBridge 是 AWS 推荐的成本优化和自动化模式，符合“基础设施即代码”和最小维护原则。</li>
</ul>
<p><br>381 公司托管一个三层 Web 应用程序，包含 <strong>PostgreSQL 数据库</strong>，存储文档的元数据。</p>
<ul>
<li>文档存储在 <strong>Amazon S3</strong>。</li>
<li>文档通常只写入一次，但会频繁更新（推测元数据也会相应更新）。</li>
<li>每月需要搜索元数据中的关键术语生成报告，此过程使用<strong>关系查询</strong>，目前耗时几小时。</li>
<li>要求：<ol>
<li>报告生成过程<strong>不得阻止文档修改或新文档添加</strong>（即不影响主数据库的写入操作）。</li>
<li>加快报告生成过程。</li>
<li>对<strong>应用程序代码改动最小</strong>。</li>
</ol>
</li>
</ul>
<p>A. 新建一个包含读取副本的 Amazon DocumentDB（兼容 MongoDB）集群。扩展该读取副本以生成报告。</p>
<p>B. <u>新建一个包含 Aurora 只读副本的 Amazon Aurora PostgreSQL 数据库集群。向该 Aurora 只读副本发送查询来生成报告。</u></p>
<p>C. 新建一个 Amazon RDS for PostgreSQL 多可用区数据库实例。配置报表模块以查询 RDS 的备用节点，确保报表模块不会对主节点造成影响。</p>
<p>D. 新建一个 Amazon DynamoDB 表来存储文档。使用固定的写入容量以支持新文档条目。自动扩展读取容量以支持报告生成。</p>
<p><br>382 一家公司在 AWS 上拥有三层应用程序，用于从用户设备收集传感器数据。<br>架构流量路径：</p>
<ul>
<li>用户设备 → <strong>网络负载均衡器（NLB）</strong> → <strong>Web 层 EC2 实例</strong> → <strong>应用层 EC2 实例</strong> → <strong>数据库</strong>。</li>
</ul>
<p>需求：</p>
<ul>
<li>提高 <strong>传输中数据（in-transit data）</strong> 的安全性。</li>
<li>问解决方案架构师应采取什么措施。</li>
</ul>
<p>A. <u>配置 TLS 监听器。在 NLB 上部署服务器证书。</u></p>
<p>B. 配置 AWS Shield Advanced。在网络负载均衡器（NLB）上启用 AWS WAF。</p>
<p>C. 将负载均衡器更改为应用程序负载均衡器（ALB）。在 ALB 上启用 AWS WAF。</p>
<p>D. 使用 AWS 密钥管理服务（AWS KMS）对 EC2 实例上的 Amazon 弹性块存储（Amazon EBS）卷进行加密。</p>
<ul>
<li>NLB 支持 <strong>TLS 监听器</strong>（需要在 NLB 上配置 TLS 证书）。</li>
<li>这样用户设备到 NLB 的流量会被 TLS 加密</li>
<li>AWS Shield Advanced 提供 DDoS 防护。</li>
<li>AWS WAF 提供 Web 应用防火墙（防护 SQL 注入、XSS 等），但 <strong>NLB 不支持 WAF</strong>（WAF 只能与 ALB、CloudFront、API Gateway 集成）。</li>
<li>这两者主要是防护攻击，不是直接加密传输数据。</li>
<li>EBS 加密保护的是 <strong>静态数据（at-rest）</strong>，不是传输中数据。</li>
</ul>
<p><br>383 一家公司计划将一款<strong>商用现成（COTS）应用程序</strong>从本地迁移到 AWS。</p>
<ul>
<li>软件许可模式：<strong>基于插槽和内核（socket and core-based）</strong> 的许可。</li>
<li>具有可预测的容量和 uptime 要求。</li>
<li>公司希望<strong>使用今年早些时候已购买的现有许可证</strong>（即自带许可证到 AWS，许可证绑定到特定物理硬件特性）。</li>
<li>问：哪种 <strong>Amazon EC2 定价选项最具成本效益</strong>？</li>
</ul>
<p>A<u>. 专用预留主机（Dedicated Reserved Hosts）</u><br>B. 专用按需主机（Dedicated On-Demand Hosts）<br>C. 专用预留实例（Dedicated Reserved Instances）<br>D. 专用按需实例（Dedicated On-Demand Instances）</p>
<ul>
<li><strong>专用主机（Dedicated Host）</strong>：物理服务器专供客户使用，可见 socket&#x2F;core 信息，适合<strong>基于物理硬件特征的许可证绑定</strong>。</li>
<li><strong>专用实例（Dedicated Instance）</strong>：实例运行在专用于客户的硬件上，但客户不控制底层物理主机，且可能在不同时间迁移到不同主机（不利于固定 socket&#x2F;core 的许可证）。</li>
<li><strong>按需（On-Demand）</strong>：无预付，按小时计费，成本较高。</li>
<li><strong>预留（Reserved）</strong>：预付 1 年或 3 年，大幅降低成本。</li>
</ul>
<p><br>384 一家公司在多个可用区的 <strong>Amazon EC2 Linux 实例</strong> 上运行应用程序。<br>存储层要求：</p>
<ol>
<li><strong>高可用</strong>（多可用区冗余）。</li>
<li><strong>符合 POSIX 标准</strong>（即需要文件系统接口，支持文件&#x2F;目录操作）。</li>
<li><strong>最高级别的数据持久性</strong>（即 99.999999999% 耐久性）。</li>
<li><strong>能够在各个 EC2 实例之间共享</strong>（多实例并发访问同一文件系统）。</li>
<li>数据在<strong>最初 30 天频繁访问</strong>，之后访问频率降低。</li>
<li><strong>最具成本效益</strong>的方案。</li>
</ol>
<p>A. 使用 Amazon S3 标准存储类别。创建 S3 生命周期策略，将不常访问的数据移至 S3 Glacier。</p>
<p>B. 使用 Amazon S3 标准存储类别。创建一个 S3 生命周期策略，将不常访问的数据移至 S3 标准 - 不常访问（S3 Standard-IA）。</p>
<p>C. <u>使用亚马逊弹性文件系统（Amazon EFS）标准存储类别。创建一个生命周期管理策略以将不常访问的数据迁移到 EFS 标准 - 不常访问（EFS Standard-IA）</u>。</p>
<p>D. 使用亚马逊弹性文件系统（Amazon EFS）单区域存储类别。创建生命周期管理策略，将不常访问的数据移至 EFS 单区域 - 不常访问（EFS One Zone-IA）。</p>
<p>S3是对象存储，<strong>不原生支持 POSIX 文件系统接口</strong>，不能直接挂载为共享文件系统给多个 EC2 实例同时读写</p>
<p>满足 <strong>POSIX、共享、高可用、自动成本优化</strong> 的唯一 AWS 原生服务是 <strong>Amazon EFS</strong>，且需使用<strong>标准（多可用区）存储类</strong>，并启用生命周期策略将不常访问的数据移至 <strong>EFS Standard-IA</strong>。</p>
<p><br>385 解决方案架构师正在设计新的 VPC，包含：</p>
<ul>
<li>两个公有子网 → 用于负载均衡器。</li>
<li>两个私有子网 → 用于 Web 服务器。</li>
<li>两个私有子网 → 用于 MySQL 数据库。</li>
</ul>
<p>已知：</p>
<ul>
<li>Web 服务器仅使用 <strong>HTTPS</strong>（意味着从负载均衡器到 Web 服务器的流量是 HTTP 还是 HTTPS？题目没说，但通常负载均衡器到 Web 服务器可以是 HTTP 或 HTTPS，安全组应根据实际端口配置）。</li>
<li>已为负载均衡器创建安全组，允许来自 <code>0.0.0.0/0</code> 的 <strong>443</strong> 端口访问（即允许公网 HTTPS 流量到负载均衡器）。</li>
<li>公司政策：<strong>每个资源仅拥有完成其任务所必需的最少访问权限</strong>（即最小权限原则）。</li>
</ul>
<p>问：解决方案架构师应采用哪种<strong>额外的配置策略</strong>来满足这些要求？</p>
<p>A. 为 Web 服务器创建一个安全组，并允许来自 0.0.0.0&#x2F;0 的 443 端口访问。为 MySQL 服务器创建一个安全组，并允许来自 Web 服务器安全组的 3306 端口访问。</p>
<p>B. 为 Web 服务器创建网络 ACL，并允许来自 0.0.0.0&#x2F;0 的 443 端口的流量。为 MySQL 服务器创建网络 ACL，并允许来自 Web 服务器安全组的 3306 端口的流量。</p>
<p>C. <u>为 Web 服务器创建一个安全组，并允许来自负载均衡器的 443 端口的流量。为 MySQL 服务器创建一个安全组，并允许来自 Web 服务器安全组的 3306 端口</u>。</p>
<p>D. 为 Web 服务器创建网络 ACL，并允许来自负载均衡器的 443 端口的流量。为 MySQL 服务器创建网络 ACL，并允许来自 Web 服务器安全组的 3306 端口的流量。</p>
<h3 id="1-安全组-vs-网络-ACL"><a href="#1-安全组-vs-网络-ACL" class="headerlink" title="1. 安全组 vs 网络 ACL"></a>1. 安全组 vs 网络 ACL</h3><ul>
<li><strong>安全组（Security Group）</strong>：作用于实例级别，是有状态防火墙，通常用于精细的实例访问控制（允许&#x2F;拒绝基于源安全组或 CIDR）。</li>
<li><strong>网络 ACL（Network ACL）</strong>：作用于子网级别，是无状态防火墙，通常用于子网级别的粗粒度流量控制（如阻止特定 IP 范围）。</li>
<li>最小权限最佳实践：优先使用<strong>安全组</strong>实现实例级别的精细控制，且允许基于<strong>安全组 ID</strong> 作为源，而不是开放给整个 CIDR（如 <code>0.0.0.0/0</code>）。</li>
</ul>
<h3 id="2-流量路径与最小权限"><a href="#2-流量路径与最小权限" class="headerlink" title="2. 流量路径与最小权限"></a>2. 流量路径与最小权限</h3><ul>
<li><strong>公网用户</strong> → <strong>负载均衡器（443）</strong> → <strong>Web 服务器（私有子网）</strong> → <strong>MySQL 服务器（私有子网）</strong>。</li>
<li>负载均衡器已允许 <code>0.0.0.0/0:443</code>（公网 HTTPS）。</li>
<li>Web 服务器安全组应只允许来自<strong>负载均衡器安全组</strong>的流量（如果负载均衡器与 Web 服务器之间用 HTTPS，则是 443；如果用 HTTP，则是 80），而不是 <code>0.0.0.0/0</code>（否则公网可直接访问 Web 服务器，违反最小权限）。</li>
<li>MySQL 安全组应只允许来自 <strong>Web 服务器安全组</strong> 的 3306 端口。</li>
</ul>
<p>AWS 推荐的安全最佳实践是：</p>
<ol>
<li>负载均衡器面向公网开放 443。</li>
<li>Web 服务器安全组仅允许来自负载均衡器安全组的流量（端口 443 或 80，根据实际协议）。</li>
<li>数据库安全组仅允许来自 Web 服务器安全组的 3306 端口。</li>
</ol>
<p><br>386 一家电子商务公司运行多层应用程序：</p>
<ul>
<li>前端、后端层运行在 <strong>Amazon EC2</strong>。</li>
<li>数据库为 <strong>Amazon RDS for MySQL</strong>。</li>
<li>后端频繁调用数据库以返回<strong>相同的数据集</strong>，导致性能下降。</li>
</ul>
<p>要求：提升后端性能。</p>
<p>A. 实施 Amazon SNS 来存储数据库调用。<br><u>B. 实施 Amazon ElasticCache 以缓存大型数据集。</u><br>C. 部署一个 RDS for MySQL 只读副本以缓存数据库调用。<br>D. 实施 Amazon Kinesis Data Firehose 以将调用流式传输到数据库。</p>
<p>对于“频繁调用数据库返回相同数据集”的性能问题，最直接有效的解决方案是使用<strong>内存缓存</strong>（如 ElastiCache）。</p>
<ul>
<li><strong>只读副本</strong>：可以分散读负载，但<strong>不缓存查询结果</strong>，仍需执行相同查询，只是查询转移到副本，依然有数据库负载。</li>
</ul>
<p><br>387 一名新员工担任<strong>部署工程师</strong>，将使用 <strong>AWS CloudFormation 模板</strong> 创建多个 AWS 资源。<br>一位解决方案架构师希望该工程师在<strong>遵循最小权限原则</strong>的同时开展工作。<br>问：应采取哪些行动组合来实现这一目标？<strong>（选两项）</strong></p>
<p>A. 让部署工程师使用 AWS 账户根用户凭证来执行 AWS CloudFormation 堆栈操作。</p>
<p>B. 为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到已附加 PowerUsers IAM 策略的组中。</p>
<p>C. 为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到已附加 AdministratorAccess IAM 策略的组中。</p>
<p>D. <u>为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到具有允许权限的 IAM 策略的用户组中，仅允许 AWS CloudFormation 操作。</u></p>
<p>E. <u>为部署工程师创建一个 IAM 角色，以明确定义特定于 AWS CloudFormation 堆栈的权限，并使用该 IAM 角色启动堆栈。</u></p>
<ol>
<li><strong>使用 IAM 角色而不是长期凭证</strong>（E）。</li>
<li><strong>权限策略应精确限定</strong>，仅允许执行 CloudFormation 操作及创建模板中指定的资源类型（D 描述的仅允许 CloudFormation 操作可能不够，但如果策略设计得当，可以包含所需资源权限，则 D 也是一种最小权限的实现方式；但更常见是 E + 自定义策略）。</li>
</ol>
<p>常见考题中，正确答案为 <strong>D 和 E</strong>：</p>
<ul>
<li><strong>D</strong> 代表“仅允许 CloudFormation 操作”的策略方向（最小权限策略）。</li>
<li><strong>E</strong> 代表使用 IAM 角色来执行，且权限针对特定堆栈定制。</li>
</ul>
<p><br>388 公司在 VPC 中部署两层 Web 应用程序：</p>
<ul>
<li><strong>Web 层</strong>：EC2 自动扩展组，位于跨多个可用区的<strong>公有子网</strong>。</li>
<li><strong>数据库层</strong>：Amazon RDS for MySQL，位于<strong>私有子网</strong>。</li>
<li>Web 层需要访问数据库。</li>
</ul>
<p>问题：Web 应用程序报告<strong>无法连接到数据库</strong>，但数据库确认处于运行状态。<br>已知：<strong>网络 ACL、安全组、路由表</strong> 均处于<strong>默认状态</strong>。</p>
<p>问：解决方案架构师应建议采取什么措施来修复应用程序？</p>
<p>A. 向私有子网的网络 ACL 添加一条明确规则，以允许来自 Web 层 EC2 实例的流量。</p>
<p>B. 在 VPC 路由表中添加一条路由，以允许 Web 层的 EC2 实例和数据库层之间的通信。</p>
<p>C. 将 Web 层的 EC2 实例和数据库层的 RDS 实例部署到两个独立的 VPC 中，并配置 VPC 对等连接。</p>
<p>D. <u>向数据库层的 RDS 实例的安全组添加一条入站规则，以允许来自 Web 层安全组的流量。</u></p>
<p>数据库安全组需要明确允许来自 Web 层安全组（或 Web 层 IP 范围）的 3306 端口访问。</p>
<h3 id="1-默认状态的含义"><a href="#1-默认状态的含义" class="headerlink" title="1. 默认状态的含义"></a>1. 默认状态的含义</h3><ul>
<li><strong>默认网络 ACL</strong>：允许所有入站和出站流量（因此不是网络 ACL 的问题）。</li>
<li><strong>默认安全组</strong>：仅允许来自<strong>同一安全组内</strong>的流量，拒绝其他所有流量（这是关键）。</li>
<li><strong>默认路由表</strong>：公有子网有指向互联网网关的路由，私有子网有指向 VPC 本地（<code>10.0.0.0/16</code>）的路由，Web 层与数据库层在同一个 VPC 内，路由默认是通的。</li>
</ul>
<h3 id="2-问题推断"><a href="#2-问题推断" class="headerlink" title="2. 问题推断"></a>2. 问题推断</h3><p>Web 层和数据库层很可能处于<strong>不同的安全组</strong>（因为它们是不同层）。<br>默认安全组只允许来自同一安全组的流量，所以<strong>数据库安全组没有允许来自 Web 层安全组的流量</strong>，导致连接被拒绝。</p>
<p><br>389 一家公司将其在线广告业务的大型数据库存储在<strong>单个可用区</strong>的 <strong>Amazon RDS for MySQL</strong> 数据库实例中。<br>需求：</p>
<ul>
<li>希望<strong>业务报告查询能够运行</strong>。</li>
<li>同时<strong>不影响对生产数据库实例的写入操作</strong>。</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. <u>部署 RDS 只读副本以处理业务报告查询。</u><br>B. 通过将数据库实例置于弹性负载均衡器之后，对其进行水平扩展。<br>C. 将数据库实例升级到更大的实例类型，以处理写入操作和查询。<br>D. 在多个可用区部署数据库实例，以处理业务报告查询。</p>
<p><br>390 一家公司托管三层电子商务应用程序在 EC2 实例上，架构为：</p>
<ul>
<li>实例在 <strong>应用程序负载均衡器（ALB）</strong> 后的<strong>自动扩展组</strong>中运行。</li>
<li>数据存储在 <strong>Amazon RDS for MariaDB</strong> 多可用区数据库实例。</li>
<li>需求：优化交易过程中的<strong>客户会话管理</strong>，应用程序必须<strong>持久化存储会话数据</strong>。<br>问：哪些解决方案能满足要求？<strong>（选两项）</strong></li>
</ul>
<p>A. 在应用程序负载均衡器（ALB）上开启粘性会话功能（会话亲和性）。</p>
<p>B. <u>使用 Amazon DynamoDB 表存储客户会话信息</u>。</p>
<p>C. 部署 Amazon Cognito 用户池来管理用户会话信息。</p>
<p>D. <u>部署一个 Amazon ElastiCache for Redis 集群来存储客户会话信息</u>。</p>
<p>E. 在应用程序中使用 AWS Systems Manager Application Manager 来管理用户会话信息。</p>
<ul>
<li><strong>B. DynamoDB</strong>（持久化 NoSQL）</li>
<li><strong>D. ElastiCache for Redis</strong>（内存+持久化选项）</li>
</ul>
<h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><ul>
<li><strong>会话管理优化</strong>：在自动扩展组的多实例环境下，需要确保用户会话在多个实例间<strong>可共享或持久化</strong>，避免因实例故障或负载均衡转发到不同实例导致会话丢失。</li>
<li><strong>持久化存储会话数据</strong>：会话数据必须在实例重启、扩展、故障时仍不丢失。</li>
<li>常见的解决方案：<ol>
<li><strong>外部集中式会话存储</strong>（如数据库、缓存、NoSQL），使任何实例都能访问同一份会话数据。</li>
<li><strong>负载均衡器粘性会话</strong>（会话亲和性）可让同一用户请求总是转发到同一实例，但这<strong>不持久化存储</strong>会话数据（实例故障时会丢失会话），所以必须结合持久化存储方案</li>
</ol>
</li>
</ul>
<p><br>391 一家公司为其三层<strong>无状态 Web 应用程序</strong>制定备份策略：</p>
<ul>
<li><strong>Web 层</strong>：运行在 <strong>Amazon EC2 实例</strong> 上，位于<strong>自动扩展组</strong>中，具有动态扩展策略（实例数量可变化）。</li>
<li><strong>数据库层</strong>：运行在 <strong>Amazon RDS for PostgreSQL</strong> 上。</li>
<li>Web 应用<strong>不需要在 EC2 实例上使用临时本地存储</strong>（即数据不保存在实例本地，可能是无状态设计）。</li>
<li><strong>恢复点目标（RPO）为 2 小时</strong>。</li>
<li>备份策略必须在该环境中实现<strong>可扩展性最大化</strong>和<strong>资源利用率优化</strong>。</li>
</ul>
<p>问：哪种解决方案能满足这些要求？</p>
<p>A. 每 2 小时对 EC2 实例和数据库的 Amazon Elastic Block Store（Amazon EBS）卷进行快照，以满足恢复点目标（RPO）。</p>
<p>B. 配置快照生命周期策略以创建 Amazon Elastic Block Store（EBS）快照。在 Amazon RDS 中启用自动备份以满足恢复点目标（RPO）。</p>
<p>C. <u>保留 Web 层和应用层的最新亚马逊机器镜像（AMI）。启用自动备份功能，用于启用 Amazon RDS 的自动备份，并使用时间点恢复来满足恢复点目标（RPO）</u>。</p>
<p>D. 每 2 小时为 EC2 实例的 Amazon Elastic Block Store（EBS）卷拍摄快照。在 Amazon RDS 中启用自动备份，并使用时间点恢复来满足恢复点目标（RPO）。</p>
<p>无状态 Web 层备份 → 使用 <strong>AMI</strong> 即可。<br>有状态数据库备份 → 使用 <strong>RDS 自动备份 + PITR</strong></p>
<h3 id="1-备份需求"><a href="#1-备份需求" class="headerlink" title="1.备份需求"></a>1.备份需求</h3><ul>
<li><strong>EC2 层（Web&#x2F;应用层）</strong>：<ul>
<li>无状态应用 → 实例本身不存储持久化数据，重要配置和代码应通过启动模板&#x2F;用户数据或外部存储管理。</li>
<li>备份重点：确保能快速启动相同配置的新实例（通过 <strong>AMI</strong>），而不是频繁备份 EBS 卷（因为数据不变，且 EBS 快照成本高、管理复杂）。</li>
<li>动态扩展组 → 使用 <strong>最新 AMI</strong> 即可，AMI 已包含操作系统、软件、配置，无需频繁 EBS 快照。</li>
</ul>
</li>
<li><strong>数据库层（RDS PostgreSQL）</strong>：<ul>
<li>有状态，需要定期备份且满足 RPO 2 小时。</li>
<li>RDS 自动备份（每日快照 + 事务日志）支持<strong>时间点恢复（PITR）</strong>，可将数据库恢复到保留期（最多35天）内任意时间点，精度到几秒钟，满足 2 小时 RPO。</li>
</ul>
</li>
</ul>
<h3 id="2-可扩展性与资源利用率优化"><a href="#2-可扩展性与资源利用率优化" class="headerlink" title="2. 可扩展性与资源利用率优化"></a>2. 可扩展性与资源利用率优化</h3><ul>
<li>最大化可扩展性：自动扩展组能根据负载自动增减实例，备份策略不应阻碍扩展。</li>
<li>资源利用率优化：避免不必要的备份操作（如频繁 EBS 快照）造成额外存储成本和 I&#x2F;O 影响。</li>
</ul>
<p><br>392 一家公司希望在 AWS 上部署一个新的<strong>公共 Web 应用程序</strong>，架构：</p>
<ul>
<li><strong>Web 服务器层</strong>：使用 Amazon EC2 实例。</li>
<li><strong>数据库层</strong>：使用 Amazon RDS for MySQL 数据库实例。</li>
<li>应用程序必须<strong>安全</strong>且可供<strong>拥有动态 IP 地址的全球客户</strong>访问。</li>
</ul>
<p>问：解决方案架构师应如何配置<strong>安全组</strong>以满足这些要求？</p>
<p>A. <u>为 Web 服务器配置安全组，允许来自 <code>0.0.0.0/0</code> 的 443 端口入站流量。为数据库实例配置安全组，允许来自 Web 服务器安全组的 3306 端口入站流量</u>。</p>
<p>B. 为 Web 服务器配置安全组，允许来自客户 IP 地址的 443 端口入站流量。为数据库实例配置安全组，允许来自 Web 服务器安全组的 3306 端口入站流量。</p>
<p>C. 为 Web 服务器配置安全组，允许来自客户 IP 地址的 443 端口入站流量。为数据库实例配置安全组，允许来自客户 IP 地址的 3306 端口入站流量。</p>
<p>D. 为 Web 服务器配置安全组，允许来自 <code>0.0.0.0/0</code> 的 443 端口入站流量。为数据库实例配置安全组，允许来自 <code>0.0.0.0/0</code> 的 3306 端口入站流量。</p>
<ol>
<li>Web 服务器面向公网 HTTPS（443）开放。</li>
<li>数据库仅允许来自 Web 服务器安全组的内部连接（3306）</li>
</ol>
<p><br>393 一家支付处理公司记录与客户的所有<strong>语音通信</strong>，音频文件存储在 <strong>Amazon S3</strong> 存储桶中。<br>需求：</p>
<ol>
<li>从音频文件中<strong>提取文本</strong>（语音转文字）。</li>
<li>从文本中<strong>移除任何属于客户的个人身份信息（PII）</strong>。</li>
</ol>
<p>问：解决方案架构师应如何做才能满足这些要求？</p>
<p>A. 使用 Amazon Kinesis Video Streams 处理音频文件。使用 AWS Lambda 函数扫描已知的 PII 模式。</p>
<p>B. 当音频文件上传至 S3 存储桶时，调用 AWS Lambda 函数以启动 Amazon Textract 任务来分析通话录音。</p>
<p>C. <u>配置一个启用了个人身份信息（PII）脱敏功能的 Amazon Transcribe 转录任务。当音频文件上传到 S3 存储桶时，调用 AWS Lambda 函数启动转录作业。将输出存储在单独的 S3 存储桶中</u>。</p>
<p>D. 创建一个 Amazon Connect 联系流，用于接收开启了转录功能的音频文件。嵌入一个 AWS Lambda 函数以扫描已知的 PII 模式。当音频文件上传到 S3 存储桶时，使用 Amazon EventBridge 启动该联系流。</p>
<p><br>394 一家公司运行多层电子商务 Web 应用程序：</p>
<ul>
<li>应用在 <strong>Amazon EC2</strong> 实例上运行。</li>
<li>数据库为 <strong>Amazon RDS for MySQL 多可用区</strong>。</li>
<li>数据库实例最新一代，存储为 <strong>通用型 SSD（gp3）EBS 卷</strong>，容量 <strong>2000 GB</strong>。</li>
<li>问题：需求高峰期<strong>数据库性能下降</strong>。</li>
<li>分析发现：当<strong>读写 IOPS 超过 20,000</strong> 时性能下降。</li>
</ul>
<p>问：解决方案架构师应采取什么措施提高应用程序性能？</p>
<p>A. 将该卷替换为磁性卷。<br>B. 增加 gp3 卷的 IOPS 数量。<br>C. <u>将卷替换为预配置 IOPS SSD（io2）卷。</u><br>D. 用两个 1000 GB 的 gp3 卷替换 2000 GB 的 gp3 卷。</p>
<h3 id="1-问题诊断"><a href="#1-问题诊断" class="headerlink" title="1. 问题诊断"></a>1. 问题诊断</h3><ul>
<li><strong>gp3</strong> 卷性能：<ul>
<li>基准性能：<strong>3000 IOPS + 125 MB&#x2F;s 吞吐量</strong>。</li>
<li>可额外<strong>独立配置 IOPS</strong>（最高 16000 IOPS）和吞吐量（最高 1000 MB&#x2F;s）。</li>
<li>最大 <strong>IOPS 限制</strong>：16000（若超过此值需要更高性能卷）。</li>
</ul>
</li>
<li>题目中 <strong>读写 IOPS 超过 20,000 时性能下降</strong> → 说明当前 <strong>gp3 卷的 IOPS 上限（16000）可能不够</strong>（因为读写合计超过 20k，可能单方向或混合超过 gp3 上限），需要<strong>更高 IOPS 能力的存储类型</strong>。</li>
</ul>
<p><br>395 在上周的生产部署期间，某个 IAM 用户对公司账户中的 AWS 资源进行了多项配置更改。<br>一位解决方案架构师发现<strong>有几条安全组规则的配置不符合预期</strong>。<br>该架构师希望确认<strong>是哪个 IAM 用户</strong>进行了这些更改。</p>
<p>问：解决方案架构师应使用哪种服务来查找所需信息？</p>
<p>A. 亚马逊 GuardDuty<br>B. 亚马逊 Inspector<br>C. <u>AWS CloudTrail</u><br>D. AWS Config</p>
<p><strong>AWS CloudTrail</strong>：记录 AWS 账户中的 <strong>API 调用和事件</strong>，包括谁（IAM 用户&#x2F;角色）、何时、从哪里、做了什么操作。</p>
<p><br>396 一家公司在 AWS 上实施<strong>自管理的 DNS 服务</strong>，包含：</p>
<ul>
<li>不同 AWS 区域的 <strong>Amazon EC2 实例</strong>。</li>
<li><strong>AWS Global Accelerator</strong> 中标准加速器的端点（用于将流量路由到最近的 EC2 实例）。</li>
</ul>
<p>要求：<strong>保护该解决方案免受 DDoS 攻击</strong>。</p>
<p>问：解决方案架构师应采取什么措施来满足这一要求？</p>
<p>A. <u>订阅 AWS Shield Advanced。将加速器添加为要保护的资源。</u><br>B. 订阅 AWS Shield Advanced。将 EC2 实例添加为要保护的资源。<br>C. 创建包含基于速率规则的 AWS WAF Web ACL。将该 Web ACL 与加速器关联。<br>D. 创建一个包含基于速率规则的 AWS WAF Web ACL。将该 Web ACL 与 EC2 实例相关联。</p>
<ul>
<li>Shield Advanced 可保护 <strong>Global Accelerator</strong>（标准加速器）。</li>
<li>这是防御针对加速器 IP 的 DDoS 攻击的最直接方法。</li>
</ul>
<h3 id="1-服务保护对象"><a href="#1-服务保护对象" class="headerlink" title="1. 服务保护对象"></a>1. 服务保护对象</h3><ul>
<li><strong>AWS Shield Standard</strong>：免费，自动为所有 AWS 客户提供针对基础设施层（L3&#x2F;L4）DDoS 保护，已默认启用。</li>
<li><strong>AWS Shield Advanced</strong>：付费，提供更高级 DDoS 保护、费用保障、与 AWS WAF 集成、24&#x2F;7 DDoS 响应团队支持。<ul>
<li>Shield Advanced 可保护的资源包括：<strong>Elastic IP、CloudFront、Route 53、Global Accelerator、ALB、EC2 实例</strong>等。</li>
</ul>
</li>
</ul>
<h3 id="2-架构分析"><a href="#2-架构分析" class="headerlink" title="2. 架构分析"></a>2. 架构分析</h3><ul>
<li>流量路径：用户 → <strong>AWS Global Accelerator</strong>（入口） → 不同区域的 <strong>EC2 实例</strong>（DNS 服务）。</li>
<li>保护重点：<ol>
<li><strong>Global Accelerator</strong> 作为流量入口，是 DDoS 攻击的主要目标（L3&#x2F;L4 攻击可能针对加速器的 Anycast IP）。</li>
<li>EC2 实例也需要保护，但 Shield Advanced 可直接保护加速器，从而保护后端资源。</li>
</ol>
</li>
<li><strong>AWS WAF</strong> 主要用于防护 Web 应用层（L7）攻击（如 SQL 注入、跨站脚本等），并可通过基于速率的规则缓解部分 L7 DDoS，但<strong>WAF 不能防护网络&#x2F;传输层 DDoS</strong>（L3&#x2F;L4）。<ul>
<li>此外，WAF 只能关联到 <strong>CloudFront、ALB、API Gateway</strong>，<strong>不能直接关联到 Global Accelerator 或 EC2 实例</strong>（除非通过 ALB&#x2F;CloudFront 前置）。</li>
</ul>
</li>
</ul>
<p><br>397 一家电子商务公司需要运行一个<strong>每日定时任务</strong>，对销售记录进行汇总和筛选以用于分析。</p>
<ul>
<li>销售记录存储在 <strong>Amazon S3</strong> 存储桶中。</li>
<li>每个对象最大 <strong>10GB</strong>。</li>
<li>任务<strong>最多可能需要一小时</strong>完成。</li>
<li>CPU 和内存使用率<strong>恒定且预先可知</strong>。</li>
<li>要求：<strong>最大限度地减少运行这项工作所需的运维工作量</strong>。</li>
</ul>
<p>A. 创建一个具有 Amazon EventBridge 通知的 AWS Lambda 函数。将 EventBridge 事件安排为每天运行一次。</p>
<p>B. 创建一个 AWS Lambda 函数。创建一个 Amazon API Gateway HTTP API，并将该 API 与该函数集成。创建一个 Amazon EventBridge 定时事件，用于调用该 API 并触发该函数。</p>
<p>C<u>. 创建一个采用 AWS Fargate 启动类型的 Amazon Elastic Container Service（Amazon ECS）集群。创建一个 Amazon EventBridge 计划事件，该事件在集群上启动 ECS 任务以运行作业。</u></p>
<p>D. 创建一个采用 Amazon EC2 启动类型的 Amazon Elastic Container Service（Amazon ECS）集群，以及一个至少包含一台 EC2 实例的自动扩展组。创建一个 Amazon EventBridge 计划事件，以在该集群上启动 ECS 任务来运行作业。</p>
<p><br>398 公司需要将 <strong>600 TB</strong> 数据从本地网络附加存储（NAS）传输到 AWS 云。<br>要求：</p>
<ol>
<li>数据传输必须在 <strong>两周内</strong> 完成。</li>
<li>数据敏感，传输中必须<strong>加密</strong>。</li>
<li>公司互联网连接仅 <strong>100 Mbps</strong> 上传速度。</li>
<li>需要 <strong>最具成本效益</strong> 的方式。</li>
</ol>
<p>A. 使用 Amazon S3 多部分上传功能通过 HTTPS 传输文件。</p>
<p>B. 在本地 NAS 与最近的 AWS 区域之间创建 VPN 连接。通过 VPN 连接传输数据。</p>
<p>C. <u>使用 AWS Snow 系列控制台订购多个 AWS Snowball Edge 存储优化型设备。使用这些设备来将数据传输到 Amazon S3。</u></p>
<p>D. 在公司所在地与最近的 AWS 区域之间建立 10 Gbps 的 AWS Direct Connect 连接。通过 VPN 连接将数据传输到该区域，以将数据存储在 Amazon S3 中。</p>
<p><br>399 一家金融公司在 AWS 上托管 Web 应用程序，使用 <strong>Amazon API Gateway 区域 API 端点</strong> 让用户检索股票价格。</p>
<ul>
<li>安全团队注意到 <strong>API 请求数量增加</strong>，担心 <strong>HTTP 洪水攻击</strong> 可能导致应用程序下线。</li>
<li>需求：设计解决方案以<strong>保护应用程序免受此类攻击</strong>，且<strong>运营开销最小</strong>。</li>
</ul>
<p>A. 在 API Gateway 区域 API 端点前创建一个 Amazon CloudFront 分发，最大 TTL 为 24 小时。</p>
<p>B. <u>创建带有基于速率规则的区域性 AWS WAF Web ACL。将该 Web ACL 与 API Gateway 阶段相关联。</u></p>
<p>C. 使用 Amazon CloudWatch 指标监控计数指标，并在达到预定义速率时向安全团队发出警报。</p>
<p>D. 在 API Gateway 区域 API 端点前创建一个带有 Lambda@Edge 的 Amazon CloudFront 分发。创建一个 AWS Lambda 函数，以阻止来自超过预定义速率的 IP 地址的请求。</p>
<ul>
<li>AWS WAF 基于速率的规则是专门防御 HTTP 洪水攻击的托管功能，无需编码，配置后自动生效。</li>
<li>与 API Gateway 无缝集成，运营开销最小。</li>
<li>相比 Lambda@Edge 自定义方案，WAF 更标准、更易于维护</li>
</ul>
<p><br>400 一家气象初创公司拥有定制 Web 应用程序，在线销售天气数据：</p>
<ul>
<li>使用 <strong>Amazon DynamoDB</strong> 存储数据。</li>
<li>希望构建一项新服务：每当记录到<strong>新的天气事件</strong>时，向<strong>四个内部团队的经理发送警报</strong>。</li>
<li>要求：<ol>
<li><strong>不影响当前应用程序的性能</strong>。</li>
<li><strong>将运营开销降至最低</strong>。</li>
</ol>
</li>
</ul>
<p>A. 使用 DynamoDB 事务将新的事件数据写入表中。配置事务以通知内部团队。</p>
<p>B. 让当前应用程序向四个 Amazon SNS 主题发布消息。让每个团队订阅一个主题。</p>
<p>C. <u>在表上启用 Amazon DynamoDB Streams。使用触发器写入单个 Amazon Simple Notification Service（SNS）主题，团队可以订阅该主题</u>。</p>
<p>D. 为每条记录添加一个自定义属性，用于标记新项。编写一个定时任务，每分钟扫描一次表中的新项，并通知 Amazon Simple Queue Service（SQS）队列，各团队可以订阅该队列。</p>
<h3 id="1-需求核心"><a href="#1-需求核心" class="headerlink" title="1. 需求核心"></a>1. 需求核心</h3><ul>
<li><strong>新服务</strong>：监听 DynamoDB 中新插入的记录（新天气事件），实时触发通知。</li>
<li><strong>不影响当前应用性能</strong>：不能通过修改写入逻辑（如事务、同步发布消息）增加写入延迟或失败风险。</li>
<li><strong>运营开销最小</strong>：使用完全托管服务，减少自定义代码、定时任务和服务器管理。</li>
</ul>
<h3 id="2-技术方案对比"><a href="#2-技术方案对比" class="headerlink" title="2. 技术方案对比"></a>2. 技术方案对比</h3><ul>
<li><strong>DynamoDB Streams</strong>：捕获表的变更（插入、更新、删除），并以有序流提供，可触发 AWS Lambda 等处理程序，实现<strong>异步、解耦</strong>的处理。</li>
<li><strong>当前应用直接发布到 SNS</strong>：修改现有应用代码，增加发布消息的逻辑，可能影响性能（增加延迟和复杂度）且耦合。</li>
<li><strong>事务</strong>：DynamoDB 事务用于数据一致性，不适合作为通知机制，且会增加写入复杂性和延迟。</li>
<li><strong>定时扫描表</strong>：引入延迟（非实时），增加读取负载（扫描），运营开销大（需管理定时任务）。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T300/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T300/" class="post-title-link" itemprop="url">AWS架构师T300</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 10:13:29 / 修改时间：10:20:33" itemprop="dateCreated datePublished" datetime="2025-12-29T10:13:29+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T300"><a href="#AWS架构师T300" class="headerlink" title="AWS架构师T300"></a>AWS架构师T300</h1><p><br>201 一家公司正在开发一项针对移动应用用户的营销传播服务，要求如下：</p>
<ol>
<li>需要通过 <strong>SMS</strong> 向用户发送确认信息。</li>
<li>用户必须能够<strong>回复这些短信</strong>。</li>
<li>公司必须将这些<strong>回复保存一年</strong>，以便进行分析。</li>
</ol>
<p><strong><u>构建一个 Amazon Pinpoint 旅程。配置 Amazon Pinpoint，使其将事件发送到 Amazon Kinesis 数据流以进行分析和归档</u></strong></p>
<p><strong>Amazon Connect</strong> 是一个云联络中心服务，主要用于<strong>语音通话和聊天</strong>交互。</p>
<p><strong>Amazon Pinpoint</strong> 是 AWS 专门用于<strong>定向营销和通信</strong>的服务，支持电子邮件、SMS、推送通知等。它可以轻松配置用于发送营销确认短信</p>
<p><strong>Amazon SNS</strong> 可以用于<strong>发送</strong> SMS（通过 SMS 功能），但它对于处理<strong>双向 SMS 回复</strong>的支持不如 Pinpoint 直接和强大</p>
<p><br>202 公司正计划将其数据迁移到 <strong>Amazon S3 存储桶</strong>，要求如下：</p>
<ol>
<li>数据在 S3 存储桶中时必须进行<strong>加密</strong>。</li>
<li><strong>加密密钥必须每年自动轮换</strong>。</li>
<li>解决方案需要以<strong>最少的运营开销</strong>满足要求</li>
</ol>
<p><u>使用 AWS KMS 客户管理密钥并启用自动密钥轮换</u></p>
<p><br>203 一家金融公司的客户通过短信预约会面，架构如下：</p>
<ul>
<li>短信 → <strong>Web 应用 (EC2)</strong> → <strong>Amazon SQS 队列</strong> → <strong>发送邀请的应用 (EC2)</strong> → 发送邮件 &amp; 存入 <strong>DynamoDB</strong><br><strong>问题</strong>：随着公司扩张，客户反馈<strong>会议邀请送达所需的时间变长</strong>。<br>解决方案架构师应建议采取什么措施来解决此问题？</li>
</ul>
<p><u><strong>为发送会议邀请的应用程序添加自动扩展组，并基于 SQS 队列深度进行扩展</strong></u></p>
<p>问题出现在<strong>中间的处理环节</strong>——即从 SQS 队列中取出消息，到<strong>发送会议邀请邮件</strong>的这个应用程序， 随着业务量增长，处理会议的应用程序实例数量固定，导致 <strong>SQS 队列中的消息积压</strong>，从而增加了从预约到收到邀请的<strong>端到端延迟</strong></p>
<p><br>204 一家在线零售公司拥有超过 5000 万活跃客户，每天接收超过 25,000 份订单。数据存储情况：</p>
<ul>
<li>客户购买数据存储在 <strong>Amazon S3</strong> 中。</li>
<li>其他客户数据存储在 <strong>Amazon RDS</strong> 中。</li>
</ul>
<p><strong>要求</strong>：</p>
<ol>
<li>让各个团队都能获取<strong>所有数据</strong>（S3 + RDS），以便开展分析工作。</li>
<li>解决方案必须具备<strong>管理数据细粒度权限</strong>的能力。</li>
<li>必须<strong>最大限度地减少运营开销</strong>。</li>
</ol>
<p><strong><u>使用 AWS Lake Formation 创建数据湖。创建一个 AWS Glue JDBC 连接到 Amazon RDS。在 Lake Formation 中注册 S3 存储桶。使用 Lake Formation 访问控制来限制访问</u></strong></p>
<ol>
<li><strong>统一数据访问</strong>：<strong>AWS Lake Formation</strong> 是专门用于构建、保护和管理数据湖的服务。它可以在一个地方<strong>注册 S3 数据源</strong>，并通过 <strong>Glue JDBC 连接</strong>将 <strong>RDS 数据作为“虚拟表”</strong> 纳入数据湖范畴，实现数据的统一编录和查询（通过 Athena&#x2F;Redshift Spectrum）。</li>
<li><strong>细粒度权限管理</strong>：Lake Formation 提供<strong>集中、精细的访问控制</strong>。可以在<strong>数据库、表、列级别</strong>授予不同用户和团队的权限，甚至支持基于数据单元格的过滤（行级安全）。这完美满足了“管理数据细粒度权限”的要求。</li>
<li><strong>最小化运营开销</strong>：Lake Formation 简化了数据湖的安全和管理任务，自动化了数据发现、编录和权限配置的许多方面，是<strong>托管的数据治理解决方案</strong></li>
</ol>
<p><br>205 一家公司的营销网站目前托管在本地数据中心：</p>
<ul>
<li>由<strong>静态文档</strong>组成。</li>
<li>运行在一台服务器上。</li>
<li>管理员<strong>很少更新</strong>网站内容，使用 <strong>SFTP 客户端</strong>上传新文档。</li>
</ul>
<p>公司决定将网站托管在 AWS 上，并使用 <strong>Amazon CloudFront</strong>。解决方案架构师已经创建了 CloudFront 分发，现在需要设计一个作为 CloudFront 源站的网站托管架构，要求：</p>
<ul>
<li><strong>最具成本效益</strong></li>
<li><strong>具备弹性</strong></li>
</ul>
<p><strong><u>创建一个私有 Amazon S3 存储桶。使用 S3 存储桶策略允许来自 CloudFront 源访问标识 的访问。通过 AWS CLI 上传网站内容</u></strong></p>
<p><br>206 一家公司希望管理 Amazon 机器镜像，并需要设计一个应用程序，用于：</p>
<ul>
<li><strong>捕获 AWS API 调用</strong></li>
<li>在公司账户内调用 <strong>Amazon EC2 的 <code>CreateImage</code> API 操作时发送警报</strong><br>要求解决方案具有<strong>最少的运营开销</strong>。</li>
</ul>
<p><strong><u>为 <code>CreateImage</code> API 调用创建一条 Amazon EventBridge 规则。将目标配置为 Amazon SNS 主题，以便在检测到 <code>CreateImage</code> API 调用时发送警报</u></strong></p>
<p><br>207 一家公司拥有一个异步 API：</p>
<ul>
<li>使用 <strong>Amazon API Gateway</strong> 部署 API 前端。</li>
<li>使用一个 <strong>AWS Lambda</strong> 函数调用 <strong>Amazon DynamoDB</strong> 来存储用户请求，之后再分发到微服务。</li>
</ul>
<p><strong>问题</strong>：</p>
<ul>
<li>在预算内配置了尽可能多的 DynamoDB 吞吐量，但仍面临<strong>可用性问题</strong>，且<strong>用户请求不断丢失</strong>。</li>
</ul>
<p><strong><u>使用 亚马逊简单队列服务 SQS队列 和 Lambda 来缓冲对 DynamoDB 的写入。</u></strong></p>
<p><br>208 一家公司需要将数据从 <strong>Amazon EC2 实例</strong>迁移到 <strong>Amazon S3 存储桶</strong>，要求如下：</p>
<ol>
<li>确保<strong>没有 API 调用和数据通过公共互联网路由传输</strong>。</li>
<li><strong>只有 EC2 实例能够有权限</strong>向 S3 存储桶上传数据</li>
</ol>
<p><u>在 EC2 实例所在的子网中为 Amazon S3 创建一个<strong>接口 VPC 终端节点</strong>。为 S3 存储桶附加一个<strong>资源策略</strong>，仅允许 EC2 实例的 <strong>IAM 角色</strong>进行访问</u></p>
<ul>
<li><strong>网关 VPC 终端节点</strong> 确实是用于 S3 和 DynamoDB 的正确终端节点类型，它通过修改 VPC 路由表将指向 S3 的流量导向 AWS 内部网络。</li>
<li>但是，<strong>网关终端节点不支持关联安全组</strong>。安全组是用于<strong>接口 VPC 终端节点</strong>的。因此，该选项中“为该终端节点附加适当的安全组”是<strong>错误的陈述</strong>。</li>
</ul>
<p><br>209 一位解决方案架构师正在设计一个新应用程序的架构，该架构将部署到 AWS 云，特点如下：</p>
<ul>
<li>在 <strong>Amazon EC2 按需实例</strong>上运行。</li>
<li>在<strong>多个可用区自动扩展</strong>。</li>
<li><strong>EC2 实例在一天中频繁地进行扩缩容</strong>。</li>
<li><strong>应用程序负载均衡器</strong> 处理负载分配。</li>
<li>架构需要<strong>支持分布式会话数据管理</strong>。</li>
<li>公司愿意在必要时<strong>对代码进行修改</strong>。</li>
</ul>
<p> <u><strong>使用 Amazon ElastiCache 管理和存储会话数据</strong></u></p>
<ul>
<li><p><strong>Amazon ElastiCache</strong>（兼容 Redis 或 Memcached）是一个<strong>托管的内存数据存储</strong>，提供<strong>微秒级延迟</strong>。</p>
</li>
<li><p><strong>场景</strong>：一个在<strong>多可用区 Auto Scaling 组</strong>中运行的<strong>无状态 Web 应用程序</strong>。</p>
</li>
<li><p><strong>挑战</strong>：用户的<strong>会话数据</strong>（如购物车内容、登录状态）通常默认存储在单个 Web 服务器的内存中。当实例数量因自动扩展而频繁变化（增加或终止）时，如果用户的下一个请求被路由到不同的服务器，该服务器将无法访问之前服务器内存中的会话数据，导致会话丢失。</p>
</li>
<li><p><strong>目标</strong>：实现<strong>分布式会话管理</strong>，即将会话数据存储在一个<strong>所有 Web 实例都能访问的、外部的、共享的存储</strong>中</p>
</li>
</ul>
<p><br>210 一家食品配送公司的订单处理系统面临高峰时段扩展问题。当前架构：</p>
<ul>
<li><strong>订单收集</strong>：一组在 <strong>EC2 自动扩展组</strong> 中运行的 EC2 实例。</li>
<li><strong>订单履行</strong>：另一组在 <strong>EC2 自动扩展组</strong> 中运行的 EC2 实例。</li>
</ul>
<p><strong>特点与问题</strong>：</p>
<ul>
<li>订单收集<strong>快</strong>，订单履行<strong>慢</strong>（可能需要更长时间）。</li>
<li><strong>不能因为扩容事件而丢失数据</strong>。</li>
</ul>
<p><strong>要求</strong>：</p>
<ol>
<li>确保订单收集和履行流程在高峰期都能<strong>适当扩展</strong>。</li>
<li><strong>优化 AWS 资源利用率</strong>。</li>
</ol>
<p><u>提供两个 <strong>Amazon SQS 队列</strong>（一个用于收集，一个用于履行）。配置 EC2 实例以<strong>轮询各自的队列</strong>。基于<strong>每个队列的积压（积压量）创建一个指标</strong>。根据此指标扩展自动扩展组</u></p>
<p><br>211 一家公司托管着多个生产应用程序，其中一个应用程序的资源分布在<strong>多个 AWS 区域</strong>，包括：</p>
<ul>
<li><strong>EC2, Lambda, RDS, SNS, SQS</strong><br>所有公司资源都标记有 <strong><code>application</code></strong> 标签名称，以及对应的标签值。<br>解决方案架构师必须提供<strong>最快的解决方案</strong>来<strong>识别所有带此标签的组件</strong></li>
</ul>
<p><u>使用 <strong>AWS 资源组标签编辑器</strong>运行查询，以报告全球范围内带有应用程序标签的资源</u></p>
<p><br>212 一家公司需要每天将其数据库导出一次到 Amazon S3，供其他团队访问。数据特点：</p>
<ul>
<li>导出的<strong>对象大小在 2 GB 到 5 GB 之间</strong>。</li>
<li>在 S3 上的<strong>访问模式多变且变化迅速</strong>。</li>
<li>数据必须<strong>立即可用</strong>（毫秒级检索）。</li>
<li>数据最长需要保持可访问性达 <strong>3 个月</strong>。</li>
<li>需要<strong>最具成本效益</strong>的解决方案，且<strong>不会增加检索时间</strong></li>
</ul>
<p><u><strong>S3 智能分层</strong></u></p>
<p>S3 Intelligent-Tiering 会自动将对象在<strong>频繁访问层</strong>和<strong>不频繁访问层</strong>之间移动，移动的依据是对象的访问模式。如果对象超过 <strong>30 天</strong>未被访问，则自动移至不频繁访问层以节省成本；如果被再次访问，则自动移回频繁访问层。</p>
<p><br>213 一家公司正在开发新的移动应用，需要保护其应用程序负载均衡器（ALB）免受应用层攻击（如 XSS、SQL 注入）。<br>公司基础设施和运维人员很少，希望减轻管理、更新和保护服务器的责任</p>
<p><u>配置 AWS WAF 规则并将其与 ALB 关联</u></p>
<p>AWS Shield Advanced 主要防护 DDoS 攻击（网络&#x2F;传输层），虽然也包含一些 WAF 功能，但主要强项不在精细的应用层规则（如 SQL 注入、XSS）</p>
<p><br>214 一家公司每天向 Amazon S3 存储桶传输数百个 .csv 文件，需要将它们转换为 Apache Parquet 格式，并存储到另一个 S3 存储桶（转换后的数据存储桶）。<br>要求：以<strong>最少的开发工作量</strong>满足需求</p>
<p><u>创建一个 AWS Glue 爬虫来发现数据，创建一个 AWS Glue ETL 作业来转换数据，在输出步骤中指定转换后的数据存储桶</u></p>
<p>AWS Glue 是 AWS 专门为这类<strong>无服务器 ETL</strong> 场景设计的服务：</p>
<ul>
<li>自动生成代码</li>
<li>内置支持格式转换（CSV → Parquet）</li>
<li>完全托管，无需管理集群</li>
</ul>
<p><br>215 一家公司有 <strong>700 TB</strong> 的备份数据在本地 NAS，需要迁移到 AWS。</p>
<ul>
<li>访问需求：<strong>不常发生</strong>的监管请求</li>
<li>保留期：<strong>7 年</strong></li>
<li>迁移时间：<strong>1 个月内完成</strong></li>
<li>可用带宽：公共互联网 <strong>500 Mbps 专用带宽</strong></li>
<li>要求：<strong>最低成本</strong>迁移和存储</li>
</ul>
<p> <u>订购 AWS Snowball 设备传输数据，使用生命周期策略将文件过渡到 Amazon S3 Glacier Deep Archive</u></p>
<p><br>216 一家公司有一个无服务器网站，S3 存储桶中有数百万个对象，作为 CloudFront 的源站。<br>这些对象在加载前未加密，现在需要为<strong>所有现有对象</strong>和<strong>未来所有新对象</strong>启用加密。<br>要求：<strong>以最少的工作量</strong>满足要求</p>
<p> <strong><u>启用默认加密 + S3 清单 + S3 批量操作</u></strong></p>
<p><br>217 一家公司在 EC2 + ALB 后运行全球 Web 应用，数据存储在 Amazon Aurora。<br>需要创建灾难恢复（DR）方案，要求：</p>
<ul>
<li><strong>最大容忍停机时间</strong>：30 分钟</li>
<li><strong>可容忍数据丢失</strong></li>
<li>主基础设施正常时，<strong>DR 站点无需处理负载</strong>（即被动备用）</li>
</ul>
<p><u><strong>第二个区域部署应用 + Route 53 主动-被动故障转移 + Aurora 只读副本</strong></u></p>
<p>-被动：平时 DR 区域不接收流量，符合要求</p>
<p><br>218 一个 EC2 实例（Web 服务器）在公共子网中，有弹性 IP，使用<strong>默认安全组</strong>。<br>默认网络 ACL 已被修改为<strong>阻止所有流量</strong>。<br>需要让该 Web 服务器能从任何地方通过 <strong>443 端口</strong> 被访问。</p>
<p>要求：选择<strong>两项</strong>步骤组合来完成此任务。</p>
<p><u>创建一个安全组，其规则允许来自源 0.0.0.0&#x2F;0 的 TCP 端口 443 的流量</u></p>
<p><u>更新网络 ACL，以允许来自源 0.0.0.0&#x2F;0 的入站 TCP 端口 443，以及到目的 0.0.0.0&#x2F;0 的出站 TCP 端口 32768-65535。</u></p>
<h4 id="1-网络流量与-AWS-安全层次"><a href="#1-网络流量与-AWS-安全层次" class="headerlink" title="1. 网络流量与 AWS 安全层次"></a>1. 网络流量与 AWS 安全层次</h4><p>在 AWS VPC 中，流量要到达 EC2 实例必须通过两层：</p>
<ol>
<li><strong>网络 ACL（无状态）</strong>：子网级别，控制进出子网的流量。需要显式允许入站和出站。</li>
<li><strong>安全组（有状态）</strong>：实例级别，控制进出实例的流量。只需允许入站请求，出站响应自动放行。</li>
</ol>
<p>题目中：</p>
<ul>
<li>默认安全组目前没有明确允许 443（默认安全组初始只允许组内通信）。</li>
<li>网络 ACL 被改为阻止所有流量（默认 ACL 本来是允许所有的，但这里被修改为拒绝）。</li>
</ul>
<p>需要同时修改：</p>
<ul>
<li><strong>安全组</strong>（允许 443 入站）</li>
<li><strong>网络 ACL</strong>（允许 443 入站 + 高端口出站）</li>
</ul>
<p><br>219 一家公司的应用程序出现性能问题。</p>
<ul>
<li>应用程序是<strong>有状态的</strong>，需要在 EC2 实例上完成<strong>内存中的任务</strong>。</li>
<li>使用 <strong>AWS CloudFormation</strong> 部署基础设施，使用 <strong>M5 EC2 实例系列</strong>。</li>
<li>随着流量增加，性能下降，用户报告延迟。<br>要求：以<strong>最灵活效率</strong>的方式解决。</li>
</ul>
<p><u><strong>修改 CloudFormation 模板，将 M5 替换为 R5 实例，部署 CloudWatch 代理生成自定义应用延迟指标</strong></u></p>
<ul>
<li><strong>应用特点</strong>：有状态、内存中任务 → 可能内存容量或内存带宽是瓶颈。</li>
<li><strong>当前实例</strong>：M5 实例（通用型，平衡的计算、内存、网络资源）</li>
<li>T3 是突发性能实例，比 M5 内存可能更少（除 t3.xlarge 等外），且突发积分用尽后性能下降</li>
<li>R5 是内存优化型实例，适合内存中任务，可能解决单实例性能瓶颈</li>
</ul>
<p><br>220 设计一个新的 API（Amazon API Gateway），接收用户请求。</p>
<ul>
<li>请求量变化很大，<strong>可能几个小时没有请求</strong>。</li>
<li>数据处理<strong>异步</strong>，但应在请求发出后<strong>几秒内完成</strong>。</li>
<li>要求：<strong>最低成本</strong>。</li>
</ul>
<p><u>一个 AWS Lambda 函数</u></p>
<p>Glue 是 ETL 服务，主要用于大数据处理，作业启动慢</p>
<p><br>221 一家公司在 Amazon Linux EC2 实例上运行应用。</p>
<ul>
<li><strong>合规要求</strong>：所有应用程序日志文件保留 <strong>7 年</strong>。</li>
<li><strong>分析需求</strong>：报告工具必须能够<strong>同时访问所有文件</strong>。</li>
<li>要求：<strong>最具成本效益</strong>的存储解决方案</li>
</ul>
<p> <u>亚马逊 S3</u></p>
<p>222一家公司需要授予外部供应商访问其 AWS 账户的权限。</p>
<ul>
<li>供应商的<strong>自动化工具</strong>托管在<strong>供应商自己的 AWS 账户</strong>中。</li>
<li>供应商<strong>没有</strong>对公司账户的 IAM 访问权限。</li>
<li>目标：安全地向供应商授予访问权限</li>
</ul>
<p><u>在公司账户中创建一个 IAM 角色，以委派对供应商 IAM 角色的访问权限。为该角色附加适当的 IAM 策略，以提供供应商所需的权限</u></p>
<p><br>223 一个 Java Spring Boot 应用部署在<strong>私有子网</strong>的 <strong>Amazon EKS Pod</strong> 中。</p>
<ul>
<li>应用需要向 <strong>Amazon DynamoDB</strong> 写入数据。</li>
<li>要求：确保应用能与 DynamoDB 交互，且<strong>不将流量暴露到互联网</strong>。</li>
<li>要求：选择<strong>两项</strong>步骤组合。</li>
</ul>
<p><u>为 EKS Pod 附加一个具有足够权限的 IAM 角色。</u></p>
<p><u>为 DynamoDB 创建一个 VPC 终端节点</u></p>
<p><br>224 一家公司将 Web 应用迁移到 AWS，目前是单个区域的单个 EC2 实例。</p>
<ul>
<li>目标：重新设计架构以实现<strong>高可用性和容错能力</strong>。</li>
<li>要求：<strong>流量必须随机到达所有运行中的 EC2 实例</strong>。</li>
<li>要求：选择<strong>两项</strong>步骤组合。</li>
</ul>
<p><u>创建 Amazon Route 53 多值答案路由策略</u></p>
<p><u>启动四个 EC2 实例：两个实例位于一个可用区，另外两个实例位于另一个可用区</u></p>
<p><strong>多值答案路由</strong>会随机返回多个健康资源记录，客户端随机选择一个</p>
<p><br>225 一家媒体公司需要将用户活动数据分析功能迁移到 AWS。</p>
<ul>
<li>数据量：持续增长至 <strong>PB 级</strong>。</li>
<li>要求：构建<strong>高可用</strong>的数据接入解决方案。</li>
<li>要求：支持使用 <strong>SQL</strong> 对<strong>现有数据和新数据</strong>进行<strong>按需分析</strong>。</li>
<li>要求：以<strong>最少的运营开销</strong>满足要求。</li>
</ul>
<p><u>将活动数据发送到 Amazon Kinesis Data Firehose 传输流，配置该流以将数据传输到 Amazon Redshift 集群</u></p>
<ul>
<li><p>Kinesis Data Stream 负责高可用数据接入，S3 提供 PB 级存储。</p>
</li>
<li><p>但 S3 本身不支持 SQL 查询，需要额外配合 <strong>Amazon Athena</strong> 或 <strong>Redshift Spectrum</strong> 才能实现 SQL 分析</p>
</li>
<li><p><strong>Kinesis Data Firehose</strong>：全托管的数据摄取服务，自动扩展、高可用，将数据直接加载到 Redshift。</p>
</li>
<li><p><strong>Amazon Redshift</strong>：全托管的数据仓库，专为 PB 级数据的 SQL 分析优化，支持对已有数据和新增数据执行高性能查询。</p>
</li>
<li><p>Firehose 自动将流数据批量加载到 Redshift，无需管理服务器或扩展</p>
</li>
</ul>
<p><br>226 一家公司通过运行在 <strong>EC2 实例</strong>上的 RESTful Web 服务从数千台远程设备收集数据。</p>
<ul>
<li>当前流程：EC2 接收原始数据 → 转换数据 → 存储到 <strong>Amazon S3</strong>。</li>
<li>设备数量将增加到<strong>数百万台</strong>。</li>
<li>要求：<strong>高度可扩展</strong>且<strong>最大限度减少运营开销</strong>的解决方案。</li>
<li>要求：选择<strong>两项</strong>步骤组合</li>
</ul>
<p><u>使用 AWS Glue 处理 Amazon S3 中的原始数据</u> - 将已有的数据转换逻辑从 EC2 迁移到无服务器的 AWS Glue</p>
<p><u>使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流，配置 Amazon Kinesis Data Firehose 以使用该数据流作为源，将数据传输到 Amazon S3。</u></p>
<p><br>227 一家公司使用 AWS Organizations 在多账户中强制实施 CloudTrail。</p>
<ul>
<li>CloudTrail 日志需要保留 <strong>3 年</strong>。</li>
<li>目标 S3 存储桶已启用 <strong>S3 版本控制</strong>。</li>
<li>现有的 S3 生命周期策略会在 <strong>3 年后删除当前对象</strong>。</li>
<li><strong>问题</strong>：4 年后，对象数量持续增加，但新日志数量稳定。</li>
<li>要求：以<strong>最具成本效益</strong>的方式删除超过 3 年的对象。</li>
</ul>
<p> <u>配置 S3 生命周期策略以删除先前版本和当前版本</u></p>
<ul>
<li>CloudTrail 本身没有“对象过期”配置，它只负责将日志写入 S3。</li>
</ul>
<p>生命周期策略根据时间戳</p>
<ol>
<li><strong>自动化</strong>：它是一个全托管的、按计划运行的后台服务。</li>
<li><strong>基于规则</strong>：严格依据您配置的规则（天数&#x2F;日期、存储类型、前缀等）来识别目标对象。</li>
</ol>
<p><br>228 一家公司有一个 API，接收来自监控设备的实时数据，并存储在 <strong>Amazon RDS</strong> 中。</p>
<ul>
<li>数据量有波动，<strong>流量高峰期 API 经常返回超时错误</strong>。</li>
<li>根本原因：<strong>数据库无法处理来自 API 的写入流量</strong>。</li>
<li>要求：<ol>
<li><strong>尽量减少与数据库的连接数量</strong>。</li>
<li><strong>确保在流量高峰期不会丢失数据</strong>。</li>
</ol>
</li>
</ul>
<p><u>修改 API，将传入的数据写入 Amazon SQS 队列。使用 Amazon SQS 调用的 AWS Lambda 函数将队列中的数据写入数据库</u></p>
<ul>
<li><strong>削峰填谷</strong>：平滑掉写入流量的波动，避免直接冲击数据库。</li>
<li><strong>解耦</strong>：将 API 的实时数据接收与数据库的批量写入分离开。</li>
</ul>
<p><br>229 一家公司在 <strong>EC2 实例上自行管理 MySQL 数据库</strong>。</p>
<ul>
<li>当前问题：需要<strong>手动管理</strong>复制和扩展。</li>
<li>新方案要求：<ol>
<li>简化<strong>根据需要添加或移除计算容量</strong>的过程。</li>
<li>以<strong>最小的运维工作量</strong>提供更出色的<strong>性能、扩展性和耐久性</strong></li>
</ol>
</li>
</ul>
<p><u>将数据库迁移到适用于 Aurora MySQL 的 Amazon Aurora Serverless。</u></p>
<p><strong>Aurora Serverless</strong> 是自动扩展、按需调整计算容力的全托管数据库服务</p>
<p><br>230 一家公司目前使用<strong>两个 NAT 实例</strong>，担心无法支持应用所需的流量。</p>
<ul>
<li>目标：实施一个<strong>高可用、容错、能自动扩展</strong>的解决方案。</li>
<li>NAT 实例：是用户自行管理的 EC2 实例，负责为私有子网提供互联网出口</li>
</ul>
<p><u>移除这两个 NAT 实例，并在不同的可用区中用两个 NAT 网关替换它们</u></p>
<ul>
<li><strong>NAT 网关</strong> 是托管服务，无需用户管理扩展、打补丁。</li>
<li>在每个需要出站互联网访问的<strong>可用区</strong>创建一个 NAT 网关，是 AWS 推荐的最佳实践。</li>
<li>每个私有子网的路由表指向其所在 AZ 的 NAT 网关。</li>
<li>当一个 AZ 故障时，只有该 AZ 受影响，其他 AZ 的流量正常。</li>
</ul>
<p><br>231 一个应用程序运行在 <strong>VPC A</strong> 中的 EC2 实例上（有弹性 IP）。</p>
<ul>
<li>该应用需要访问 <strong>VPC B</strong> 中的数据库。</li>
<li>两个 VPC 位于<strong>同一 AWS 账户</strong>中。</li>
<li>要求：<strong>最安全地</strong>提供所需的访问权限</li>
</ul>
<p><u>配置 VPC A 和 VPC B 之间的 VPC 对等连接。</u></p>
<ul>
<li><strong>最安全</strong>意味着：<ol>
<li><strong>网络流量不经过公共互联网</strong>。</li>
<li>数据库<strong>不暴露公网 IP</strong>，减少攻击面。</li>
<li>使用 AWS 内部网络，利用安全组和网络 ACL 进行精细控制。</li>
</ol>
</li>
</ul>
<p><strong>VPC 对等</strong>直接在两个 VPC 之间创建私有网络连接，<strong>流量不经过互联网</strong></p>
<p><br>232 一家公司在 EC2 实例上为客户运行演示环境，每个环境在自己的 VPC 中隔离。</p>
<ul>
<li>要求：当<strong>建立对某个环境的 RDP 或 SSH 访问时</strong>，运营团队需要收到通知。</li>
<li>关键点：检测的是 <strong>RDP&#x2F;SSH 连接的建立</strong>，而不是实例的状态变化。</li>
</ul>
<p><u>将 VPC 流日志发布到 Amazon CloudWatch Logs，创建所需的指标筛选器，创建 CloudWatch 指标告警，并在告警处于 ALARM 状态时设置通知操作</u></p>
<ul>
<li><strong>使用 VPC 流日志 + CloudWatch Logs + 指标筛选器 + 告警</strong></li>
<li>需要一种方法来监控到 EC2 实例的特定端口（SSH 22, RDP 3389）的<strong>成功连接</strong>。</li>
<li><strong>VPC 流日志</strong>可以捕获所有进出 EC2 实例网络接口的 IP 流量信息，包括接受的（ACCEPT）和拒绝的（REJECT）数据包。</li>
<li>可以创建一个 <strong>CloudWatch Logs 指标筛选器</strong>，来匹配流日志中 <code>dstport</code> 为 22 或 3389 且 <code>action</code> 为 “ACCEPT” 的日志行。</li>
<li>当筛选器匹配到日志时，触发一个 <strong>CloudWatch 告警</strong>，该告警可以发送通知（例如通过 SNS）。</li>
</ul>
<p><br>233 一位解决方案架构师创建了一个新的 AWS 账户，必须<strong>保护 AWS 账户根用户的访问安全</strong>。<br>要求：选择<strong>两项</strong>操作组合来实现此目标。</p>
<p><u>确保根用户使用强密码。</u><br><u>为根用户启用多因素认证</u></p>
<p><br>234 一家公司正在构建一个新的基于 Web 的 CRM 应用程序。</p>
<ul>
<li>架构：多个 EC2 实例（由 EBS 支持）位于 ALB 之后，使用 Amazon Aurora 数据库。</li>
<li>安全要求：所有数据在<strong>静态</strong>和<strong>传输中</strong>都必须加密。</li>
</ul>
<p><u>使用 AWS KMS 对静态的 EBS 卷和 Aurora 数据库存储进行加密。将 ACM 证书附加到 ALB 以加密传输中的数据。</u></p>
<ul>
<li><strong>EBS 加密</strong>：使用 KMS 密钥。</li>
<li><strong>Aurora 加密</strong>：使用 KMS 密钥。</li>
<li><strong>ALB 传输加密</strong>：使用 ACM 提供的 TLS 证书。</li>
</ul>
<p><br>235 一家公司正在将本地 <strong>Oracle 数据库</strong> 迁移到 <strong>Amazon Aurora PostgreSQL</strong>。</p>
<ul>
<li>多个应用程序写入相同的表。</li>
<li>应用程序需要<strong>逐个迁移</strong>，每次迁移间隔一个月。</li>
<li>担忧：数据库有<strong>大量的读写操作</strong>。</li>
<li>要求：在整个迁移过程中，<strong>两个数据库的数据必须保持同步</strong></li>
</ul>
<p><u>将 AWS Schema Conversion Tool 与使用内存优化型复制实例的 AWS DMS 配合使用。创建一个全量加载加变更数据捕获（CDC）的复制任务以及一个表映射来选择所有表。</u></p>
<p>这是一个典型的 <strong>异构数据库迁移</strong>（Oracle → PostgreSQL），并且要求 <strong>持续同步</strong>，因为应用是逐个迁移的，迁移周期长达数月。</p>
<ul>
<li><strong>AWS DMS</strong>：是完成此类任务的<strong>核心服务</strong>。它可以执行：<ul>
<li><strong>全量加载</strong>：一次性迁移现有数据。</li>
<li><strong>变更数据捕获</strong>：持续复制源数据库的变更。</li>
</ul>
</li>
<li><strong>AWS Schema Conversion Tool</strong>：专门用于<strong>异构数据库迁移</strong>。它会自动将源数据库的 schema 和代码对象（存储过程、函数等）转换为目标数据库兼容的格式。<strong>对于 Oracle 到 PostgreSQL 的迁移，SCT 是强烈推荐的</strong>。</li>
</ul>
<p><strong>AWS DataSync</strong>：主要用于<strong>文件数据</strong>的迁移（如 NFS、SMB），不适用于数据库的持续逻辑复制。❌ 不适用于此场景。</p>
<p><br>236 一家公司有一个用于<strong>图像共享</strong>的三层应用程序。</p>
<ul>
<li>当前架构：<ul>
<li>前端层：1个 EC2 实例</li>
<li>应用层：1个 EC2 实例</li>
<li>数据层：1个 EC2 实例运行 MySQL</li>
</ul>
</li>
<li>目标：设计一个<strong>可扩展且高可用</strong>的解决方案。</li>
<li>关键约束：对<strong>应用程序的改动要尽可能少</strong>。</li>
</ul>
<p><u>为前端层和应用层使用负载均衡的多可用区 AWS Elastic Beanstalk 环境，将数据库迁移到 Amazon RDS 多可用区数据库实例，使用 Amazon S3 存储和提供用户图像。</u></p>
<p><strong>Elastic Beanstalk (前端&amp;应用) + RDS 多可用区 (数据库) + S3 (图像)</strong></p>
<ul>
<li><strong>Elastic Beanstalk</strong>：为前端和应用层提供多可用区、负载均衡、自动扩展的托管环境，<strong>无需重写应用代码</strong>。</li>
<li><strong>Amazon RDS 多可用区</strong>：为 MySQL 数据库提供高可用、故障转移的托管服务，兼容现有应用（连接字符串不变）。</li>
<li><strong>Amazon S3</strong>：用于存储和提供用户图像，这是<strong>最佳实践</strong>，能极大减轻数据库负载，并本身具备高可用和无限扩展能力。</li>
</ul>
<p><br>237 一个在 <strong>VPC-A</strong>（账户 A）中的 EC2 实例需要访问 <strong>VPC-B</strong>（账户 B）中的 EC2 实例上的文件。</p>
<ul>
<li>要求：<ol>
<li>配置<strong>安全访问</strong>。</li>
<li>连接<strong>不应存在单点故障</strong>。</li>
<li>连接<strong>不应有带宽方面的问题</strong>（即带宽不应成为瓶颈）。</li>
</ol>
</li>
</ul>
<p><u><strong>在 VPC-A 和 VPC-B 之间建立 VPC 对等连接</strong></u></p>
<ul>
<li><strong>VPC 对等</strong> 直接在两个 VPC 之间建立私有网络连接，<strong>不经过公网</strong>，因此安全。</li>
<li>它使用 AWS 的<strong>内部骨干网</strong>，提供<strong>高带宽</strong>和<strong>低延迟</strong>。</li>
<li>连接本身是<strong>冗余的</strong>，由 AWS 管理底层基础设施，<strong>没有单点故障</strong>。</li>
<li>支持<strong>跨账户</strong>对等。</li>
</ul>
<p><br>238 一家公司希望为工程师团队使用单独的 AWS 账户。</p>
<ul>
<li>要求：在每个账户当月的 <strong>Amazon EC2 实例使用量</strong>超过特定阈值时<strong>立即收到通知</strong>。</li>
<li>目标：以<strong>最具成本效益</strong>的方式满足要求</li>
</ul>
<p><u>使用 <strong>AWS 预算</strong>为每个账户创建<strong>成本预算</strong>。将周期设置为每月。将范围设置为 EC2 实例。为预算设置警报阈值。配置 Amazon SNS 主题，以便在超过阈值时接收通知</u></p>
<p><strong>AWS 预算 + SNS 通知</strong></p>
<ul>
<li><strong>AWS Budgets</strong> 是 AWS 专门为成本监控和告警设计的服务。</li>
<li>可以创建<strong>成本预算</strong>，将范围限定为特定服务（如 EC2），设置月度周期和警报阈值。</li>
<li>当预测或实际成本超过阈值时，可以<strong>自动通过 SNS、Email 等方式立即发送通知</strong>。</li>
</ul>
<p><br>239 需要设计一个新的微服务，要求：</p>
<ol>
<li>客户端通过调用 <strong>HTTPS 端点</strong>访问。</li>
<li>微服务必须使用 <strong>AWS IAM</strong> 对调用进行身份验证。</li>
<li>微服务逻辑用 <strong>Go 1.x</strong> 编写，部署为<strong>单个 AWS Lambda 函数</strong>。</li>
<li>目标：以<strong>最具运营效率</strong>的方式部署该函数。</li>
</ol>
<p><u><strong>Amazon API Gateway REST API + Lambda + IAM 身份验证</strong></u></p>
<p><br>240 一家公司已将数据仓库迁移到 AWS，并拥有 <strong>AWS Direct Connect</strong> 连接。</p>
<ul>
<li>办公室用户使用可视化工具查询数据仓库。</li>
<li><strong>查询结果集平均 50 MB</strong>（从数据仓库返回）。</li>
<li><strong>可视化工具网页约 500 KB</strong>（发送给用户）。</li>
<li>查询结果<strong>不会被缓存</strong>。</li>
<li>目标：提供<strong>最低的数据传输出口成本</strong>。</li>
</ul>
<p><u>在与数据仓库相同的 AWS 区域管理可视化工具，并通过位于同一区域的 Direct Connect 连接访问它。</u></p>
<p>在 AWS 中，<strong>数据传出到互联网</strong> 的费用通常远高于 <strong>在 AWS 内部同一区域传输</strong> 或通过 <strong>Direct Connect</strong> 传输的费用</p>
<p>所以不经过互联网的比较符合要求</p>
<p><br>241 一家在线学习公司正迁移到 AWS，在 PostgreSQL 数据库中存储学生记录。</p>
<ul>
<li>要求：确保数据<strong>始终能在多个 AWS 区域可用且处于在线状态</strong>。</li>
<li>目标：<strong>操作开销最少</strong>的解决方案。</li>
</ul>
<p><u>将 PostgreSQL 数据库迁移到 Amazon RDS for PostgreSQL 数据库实例，在另一个区域创建一个只读副本。</u></p>
<ul>
<li>主实例在一个区域，在<strong>另一个区域创建一个只读副本</strong>。</li>
<li><strong>满足多区域在线要求</strong>：第二个区域有一个<strong>在线、可读</strong>的数据库副本。</li>
<li>这是 <strong>RDS 的原生功能</strong>，只需在控制台点击或 CLI 命令即可设置，由 AWS 管理复制、监控和故障转移</li>
</ul>
<p><br>242 一家公司使用 7 台 EC2 实例托管 Web 应用。</p>
<ul>
<li>要求：在响应 DNS 查询时，<strong>返回所有健康的 EC2 实例的 IP 地址</strong>。</li>
<li>关键点：DNS 查询响应要包含<strong>多个 IP 地址</strong>。</li>
</ul>
<p><u><strong>多值路由策略</strong></u></p>
<p><strong>简单路由</strong> - 返回一个或多个记录值，但<strong>没有健康检查</strong>。通常用于单记录或轮询多个记录（无健康检查）。</p>
<p><strong>延迟路由</strong> - 根据用户到 AWS 区域的网络延迟，返回延迟最低的区域的记录（通常一个 IP）</p>
<p><strong>多值路由</strong> - 为同一记录创建多个资源记录（如多个 A 记录），并<strong>为每个记录关联独立的健康检查</strong>。DNS 查询会返回所有<strong>健康</strong>的记录值（最多 8 个）。</p>
<p><strong>地理位置路由</strong> - 根据用户的地理位置返回特定的记录。</p>
<p><br>243 一家医学研究实验室在 <strong>Amazon S3</strong> 存储桶中生成了研究数据。</p>
<ul>
<li>目标：以<strong>最小的延迟</strong>向全国的诊所提供这些数据。</li>
<li>诊所使用<strong>本地、基于文件的应用程序</strong>（需要文件系统接口访问）。</li>
<li>诊所对 S3 存储桶有<strong>只读权限</strong>。</li>
<li>核心挑战：数据在云端（S3），应用程序在本地，需要低延迟访问</li>
</ul>
<p><u><strong>在每个诊所部署 Storage Gateway 文件网关</strong></u></p>
<ul>
<li><strong>Storage Gateway 文件网关</strong> 是一个本地缓存设备&#x2F;虚拟机，它提供 <strong>NFS 或 SMB 文件共享</strong> 接口。</li>
<li>它背后连接的是 <strong>Amazon S3</strong>。用户访问本地网关的共享文件夹时，网关会从 S3 获取文件，并<strong>缓存在本地</strong>。</li>
</ul>
<p><br>244 一家公司使用单个 EC2 实例运行内容管理系统，该实例上<strong>同时运行 Web 服务器和数据库软件</strong>。</p>
<ul>
<li>要求：<ol>
<li>使网站平台<strong>具备高可用性</strong>。</li>
<li>让网站<strong>能扩展以满足用户需求</strong>。</li>
</ol>
</li>
</ul>
<p><u>将数据库迁移到 Amazon Aurora，并在另一个可用区配置一个只读副本。从 EC2 实例创建一个 AMI。在两个可用区配置一个应用程序负载均衡器。附加一个在两个可用区使用该 AMI 的自动扩展组。</u></p>
<p><strong>Aurora (跨 AZ 只读副本) + 多 AZ 自动扩展组 + 多 AZ ALB</strong></p>
<p><br>245 一家公司计划在 AWS 上推出应用程序。</p>
<ul>
<li>架构：ALB 将流量导向<strong>单个目标组</strong>中的至少两台 EC2 实例，实例位于<strong>自动扩展组</strong>中。</li>
<li>环境：需要<strong>开发环境</strong>和<strong>生产环境</strong>。</li>
<li>生产环境特点：会出现<strong>流量高峰时段</strong>。</li>
<li>目标：以<strong>最具成本效益的方式配置开发环境</strong></li>
</ul>
<p><u>减少开发环境自动扩展组中 EC2 实例的最大数量</u></p>
<p><br>246 一家公司在多个可用区的<strong>私有子网</strong>中运行 EC2 实例（Web 应用）。</p>
<ul>
<li>部署了一个<strong>面向互联网的应用程序负载均衡器</strong>，并将这些 EC2 实例指定为目标组。</li>
<li><strong>问题</strong>：互联网流量无法到达这些 EC2 实例。</li>
<li>目标：重新配置架构以解决问题。</li>
</ul>
<p><u>在每个可用区中创建公有子网。将公有子网与应用程序负载均衡器（ALB）相关联。更新公有子网的路由表，添加一条指向私有子网的路由</u></p>
<ul>
<li><strong>LB</strong> 部署在<strong>公有子网</strong>（拥有到互联网网关的路由），接收来自互联网的流量。</li>
<li><strong>EC2 实例</strong>部署在<strong>私有子网</strong>（没有到互联网网关的路由，只有到 NAT 网关的路由以访问互联网）。</li>
<li><strong>流量路径</strong>：客户端 → 互联网 → 互联网网关 → <strong>ALB (公有子网)</strong> → 目标组 → <strong>EC2 实例 (私有子网)</strong>。</li>
</ul>
<p><strong>关键点</strong>：ALB 与 EC2 实例之间的流量是 <strong>AWS 内部网络流量</strong>，不经过互联网网关。因此，EC2 实例在私有子网是<strong>正确的</strong>，不需要公网 IP 或到互联网网关的路由。</p>
<p><br>247 一家公司在 <strong>Amazon RDS for MySQL</strong> 中部署了数据库。</p>
<ul>
<li>问题：交易数量增加导致<strong>读取缓慢</strong>。</li>
<li>建议方案：添加一个<strong>只读副本</strong>。</li>
<li>要求：解决方案架构师在实施此变更前应采取哪<strong>两项</strong>行动组合？</li>
</ul>
<p><u>允许源数据库实例上的长时间运行的事务完成</u></p>
<p><u>通过将备份保留期设置为非 0 值，在源实例上启用自动备份</u></p>
<ol>
<li><strong>启用自动备份</strong>（备份保留期 &gt; 0） → <strong>E</strong></li>
<li><strong>确保二进制日志复制已启用</strong>（通常自动备份已包含此功能，但需确认） → <strong>A</strong></li>
</ol>
<p>同时，从<strong>运营最佳实践</strong>角度，应在低负载时段操作，让长时间事务完成 → <strong>C</strong></p>
<ul>
<li><strong>E 是绝对必须的</strong>（没有备份就无法创建副本）。</li>
<li><strong>C 是实施前的重要准备</strong>，以避免过程出现问题。</li>
<li>A 虽然正确，但在 RDS 中，一旦启用自动备份（E），二进制日志复制会自动启用，因此 E 已经隐含了 A 的一部分。所以从“行动组合”来看，选 <strong>C 和 E</strong> 更全面（一个确保功能可用，一个确保操作平滑）。</li>
</ul>
<p><br>248 一家公司在 <strong>EC2 实例</strong>上运行分析软件。</p>
<ul>
<li><p>软件接收用户作业请求，处理已上传到 <strong>Amazon S3</strong> 的数据。</p>
</li>
<li><p><strong>问题</strong>：部分提交的数据未得到处理。</p>
</li>
<li><p><strong>监控显示</strong>：EC2 实例 <strong>CPU 利用率始终接近 100%</strong></p>
</li>
<li><p><strong>目标</strong>：</p>
<ol>
<li>提升系统性能。</li>
<li>根据用户负载扩展系统。</li>
</ol>
</li>
</ul>
<p><u>将传入请求路由到 Amazon Simple Queue Service，根据队列大小配置 EC2 自动扩展组，更新软件以从队列读取数据。</u></p>
<ul>
<li><strong>SQS</strong> 作为<strong>消息队列</strong>，可靠地接收和存储所有用户作业请求，<strong>确保没有请求丢失</strong>（解决了“数据未处理”问题）。</li>
<li><strong>自动扩展组</strong>根据 <strong>SQS 队列大小</strong>（积压的作业数量）自动增加或减少 EC2 实例数量，<strong>完美实现根据负载扩展</strong>。</li>
</ul>
<p><br>249 一家公司为托管在 AWS 上的媒体应用程序实施<strong>共享存储解决方案</strong>。</p>
<ul>
<li>要求：<ol>
<li>能够使用 <strong>SMB 客户端</strong>访问数据。</li>
<li>解决方案必须是<strong>完全托管</strong>的。</li>
</ol>
</li>
<li>关键：SMB 协议是 Windows 文件共享的标准协议。</li>
</ul>
<p><u>创建一个适用于 Windows 文件服务器的 Amazon FSx 文件系统，将该文件系统附加到源服务器，将应用服务器连接到该文件系统。</u></p>
<p><br>250 安全团队要求在 <strong>VPC 流量日志</strong> 中捕获网络流量。</p>
<ul>
<li><strong>访问模式</strong>：<ul>
<li>前 <strong>90 天内</strong>被<strong>频繁访问</strong>。</li>
<li>90 天后<strong>被间歇性访问</strong>。</li>
</ul>
</li>
<li>目标：在配置日志时，应采取什么措施来满足这些要求？</li>
</ul>
<p> <u>使用 Amazon S3 作为目标，启用 S3 生命周期策略，在 90 天后将日志转换为 S3 标准不频繁访问。</u></p>
<p>VPC 流量日志可以发送到三个目的地：</p>
<ol>
<li><strong>Amazon CloudWatch Logs</strong></li>
<li><strong>Amazon S3</strong></li>
<li><strong>Amazon Kinesis Data Firehose</strong>（然后可转发到 S3、Redshift 等）</li>
</ol>
<p><br>251 一个 <strong>EC2 实例</strong> 位于新 <strong>VPC 的私有子网</strong> 内。</p>
<ul>
<li>当前：该子网<strong>没有出站互联网访问权限</strong>。</li>
<li>需求：EC2 实例需要能够<strong>从外部供应商下载月度安全更新</strong>（即需要出站互联网访问）。</li>
<li>关键：私有子网内的实例<strong>不能有公有 IP</strong>，因此不能直接通过互联网网关访问互联网。</li>
</ul>
<p><u><strong>创建 NAT 网关并放置在公有子网，私有子网路由指向 NAT 网关</strong></u></p>
<h4 id="私有子网出站互联网访问的原理"><a href="#私有子网出站互联网访问的原理" class="headerlink" title="私有子网出站互联网访问的原理"></a>私有子网出站互联网访问的原理</h4><ul>
<li>私有子网中的 EC2 实例<strong>没有公有 IP 地址</strong>。</li>
<li>它们不能直接通过<strong>互联网网关</strong>访问互联网，因为互联网网关要求源 IP 是公网 IP。</li>
<li>解决方案：使用 <strong>NAT（网络地址转换）</strong> 设备。<ul>
<li>NAT 设备位于<strong>公有子网</strong>，拥有公有 IP。</li>
<li>私有子网的流量路由到 NAT 设备，由 NAT 设备代表实例访问互联网，并将响应返回给实例。</li>
</ul>
</li>
</ul>
<p><br>252 需要设计一个系统来存储<strong>客户案例文件</strong>（公司的核心资产）。</p>
<ul>
<li>文件数量会随时间增加。</li>
<li>要求：<ol>
<li>文件必须能从<strong>多个 EC2 应用服务器同时访问</strong>。</li>
<li>解决方案必须具备<strong>内置冗余功能</strong>（即高可用、持久性）</li>
</ol>
</li>
</ul>
<p><u>亚马逊弹性文件系统（Amazon EFS）</u></p>
<p><br>253 一位解决方案架构师创建了两个 IAM 策略：<strong>Policy1</strong> 和 <strong>Policy2</strong>。</p>
<p>策略1 </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;iam:Get*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;iam:List*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;kms:List*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;ec2:*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;ds:*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;logs:Get*&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;logs:Describe*&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>策略2 </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Deny&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ds:Delete*&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<ul>
<li>这两个策略都附加到了一个 <strong>IAM 用户组</strong>。</li>
<li>一名云工程师被添加到这个 IAM 组中。</li>
<li>问题：这名云工程师能够执行哪项操作？</li>
</ul>
<p><u>删除 Amazon EC2 实例</u></p>
<h4 id="IAM-权限评估原则"><a href="#IAM-权限评估原则" class="headerlink" title="IAM 权限评估原则"></a>IAM 权限评估原则</h4><ul>
<li><strong>Allow + Deny 同时存在时，Deny 优先</strong>。</li>
<li>权限是 <strong>Allow 权限</strong> 减去 <strong>Deny 权限</strong> 的结果。</li>
<li>需要检查每个操作所需的 API 操作是否在 Allow 列表中，且不被 Deny 列表覆盖。</li>
</ul>
<p><br>254 一家公司迁移三层应用到 VPC 后，安全团队发现 EC2 安全组规则没有应用<strong>最小权限原则</strong>。</p>
<ul>
<li>问题：各层之间的入站&#x2F;出站规则过于宽松。</li>
<li>目标：解决此安全问题，即实现<strong>最小权限原则</strong></li>
</ul>
<p><u><strong>使用安全组 ID 作为源或目标</strong></u></p>
<p><strong>安全组规则不支持直接引用实例 ID</strong>作为源或目标</p>
<ul>
<li><strong>最小权限原则</strong>：只授予必要的访问权限，不多不少。</li>
<li>在 AWS 安全组上下文中，这意味着：<ul>
<li>入站规则：只允许来自<strong>特定可信源</strong>的特定端口流量。</li>
<li>出站规则：只允许发送到<strong>特定可信目标</strong>的特定端口流量。</li>
</ul>
</li>
<li>避免使用过于宽泛的源&#x2F;目标，如整个 VPC CIDR (<code>10.0.0.0/16</code>) 或整个子网 CIDR (<code>10.0.1.0/24</code>)，因为这允许了不必要的访问。</li>
</ul>
<p><br>255 一家公司的电子商务结账流程：</p>
<ol>
<li>将订单写入数据库。</li>
<li>调用服务处理付款。</li>
</ol>
<ul>
<li><strong>问题</strong>：结账过程出现超时，用户重新提交表单时，会为<strong>同一笔预期交易生成多个唯一订单</strong>（重复订单）。</li>
<li>目标：<strong>重构工作流以防止创建多个订单</strong>。</li>
</ul>
<p><u>将订单存储在数据库中，向 Amazon SQS FIFO 队列发送一条包含订单号的消息。设置支付服务以检索消息并处理订单，从队列中删除该消息</u></p>
<p><br>256 正在使用 <strong>Amazon S3 存储桶</strong> 实施文档审核应用程序。</p>
<ul>
<li>要求：<ol>
<li><strong>防止文档被意外删除</strong>。</li>
<li><strong>确保所有版本的文档都可获取</strong>。</li>
<li>用户必须能够<strong>下载、修改和上传文档</strong>。</li>
</ol>
</li>
<li>要求：选择<strong>两项</strong>操作组合。</li>
</ul>
<p><u>启用存储桶的版本控制</u> - 它<strong>为每个对象的每次修改保存一个版本</strong>。</p>
<p><u>在存储桶上启用 MFA 删除功能</u> - 它要求<strong>在永久删除对象版本或暂停版本控制时，提供 MFA 设备生成的代码</strong></p>
<ul>
<li><strong>防止意外删除</strong>：需要一种机制，使得删除操作需要额外验证或可以被恢复。</li>
<li><strong>所有版本可获取</strong>：需要保留对象的每一个版本（覆盖或删除后仍能访问旧版本）。</li>
<li><strong>用户可下载、修改、上传</strong>：用户需要读写权限，但不能随意永久删除</li>
</ul>
<p><br>257 一家公司需要构建一个解决方案，以报告 AWS 账户中<strong>所有应用程序的 EC2 自动扩展事件</strong>。</p>
<ul>
<li>要求：<ol>
<li>使用<strong>无服务器解决方案</strong>将 EC2 自动扩展状态数据存储在 <strong>Amazon S3</strong> 中。</li>
<li>使用 S3 中的数据在仪表盘中提供<strong>近实时更新</strong>。</li>
<li><strong>不得影响 EC2 实例的启动速度</strong>。</li>
</ol>
</li>
<li>核心：如何将<strong>自动扩展事件数据</strong>迁移到 S3</li>
</ul>
<p><u>使用 Amazon CloudWatch 指标流将 EC2 Auto Scaling 状态数据发送到 Amazon Kinesis Data Firehose，将数据存储在 Amazon S3 中</u></p>
<p><br>258 一家公司的应用程序每小时将数百个 <strong>.csv 文件</strong>放入 Amazon S3 存储桶，每个文件 <strong>1 GB</strong>。</p>
<ul>
<li>要求：每次上传文件时，需要将文件转换为 <strong>Apache Parquet 格式</strong>，并将输出文件放入另一个 S3 存储桶。</li>
<li>目标：以<strong>最少的运营开销</strong>满足要求。</li>
</ul>
<p><u>创建一个 AWS Glue ETL 作业来转换文件并输出到 S3。为每个 S3 PUT 事件创建一个 Lambda 函数来调用该 ETL 作业。</u></p>
<ul>
<li><strong>AWS Glue</strong> 是<strong>无服务器 ETL 服务</strong>，专为数据转换设计，支持从 S3 读取 CSV 并写入 Parquet 到 S3。</li>
</ul>
<p><br>259 一家公司需要为所有 Amazon RDS 数据库实例实施新的数据保留政策。</p>
<ul>
<li>要求：<ol>
<li>将<strong>每日备份至少保留 2 年</strong>。</li>
<li>备份必须具有<strong>一致性并可恢复</strong>。</li>
</ol>
</li>
<li>目标：推荐解决方案。</li>
</ul>
<p><u>在 AWS Backup 中创建一个备份库，创建一个新的备份计划（每日日程，2 年有效期），将 RDS 数据库实例分配到备份计划中。</u></p>
<p><br>260 一家公司需要将本地 Windows Server SMB 文件共享迁移到 AWS。</p>
<ul>
<li>当前：本地 <strong>自管理的 Active Directory</strong> 控制对文件和文件夹的访问。</li>
<li>目标：使用 <strong>Amazon FSx for Windows File Server</strong> 作为解决方案的一部分。</li>
<li>迁移后要求：<strong>本地 Active Directory 组</strong> 必须能够限制对 FSx 的 SMB 共享、文件夹和文件的访问。</li>
<li>现状：已经创建了一个 FSx for Windows File Server 文件系统</li>
</ul>
<p><u>将文件系统加入 Active Directory 以限制访问</u></p>
<h4 id="需求核心：身份与权限集成"><a href="#需求核心：身份与权限集成" class="headerlink" title="需求核心：身份与权限集成"></a>需求核心：身份与权限集成</h4><ul>
<li>权限模型需要沿用现有的 <strong>Active Directory 组</strong>。</li>
<li>这意味着 FSx 文件系统必须能够<strong>识别和信任</strong>本地的 AD 用户和组。</li>
<li>FSx for Windows File Server 原生支持 <strong>Active Directory 集成</strong>，以实现基于 AD 用户&#x2F;组的 NTFS 权限控制</li>
</ul>
<p><br>261 一家公司的零售网站面向全球用户部署。</p>
<ul>
<li>当前架构：ELB + 多个 EC2 实例（跨多个可用区的自动扩展组）。</li>
<li>新需求：根据<strong>客户访问网站所使用的设备</strong>，提供<strong>不同版本的内容</strong>。</li>
<li>要求：选择<strong>两项</strong>行动组合。</li>
</ul>
<p><u>配置 Amazon CloudFront 以缓存内容的多个版本。</u></p>
<p> <u>配置 Lambda@Edge 函数，根据 User-Agent 标头向用户发送特定对象</u></p>
<p><br>262 一家公司计划使用 <strong>Amazon ElastiCache</strong>。</p>
<ul>
<li>架构：<ul>
<li><strong>缓存 VPC</strong>：包含 ElastiCache 集群。</li>
<li><strong>应用 VPC</strong>：包含应用程序的 EC2 实例。</li>
<li>两个 VPC 都位于<strong>同一区域</strong>（us-east-1）。</li>
</ul>
</li>
<li>需求：为应用程序 EC2 实例提供对 ElastiCache 集群的访问权限。</li>
<li>目标：以<strong>最具成本效益</strong>的方式满足要求</li>
</ul>
<p><u>在 VPC 之间创建对等连接，为对等连接添加路由表条目，为 ElastiCache 集群的安全组配置入站规则以允许来自应用程序的入站连接</u></p>
<h4 id="场景分析"><a href="#场景分析" class="headerlink" title=". 场景分析"></a>. 场景分析</h4><ul>
<li><p>两个 VPC 在<strong>同一区域</strong>。</p>
</li>
<li><p>需要让应用 VPC 中的 EC2 访问缓存 VPC 中的 ElastiCache。</p>
</li>
<li><p><strong>最具成本效益</strong>：意味着应选择最简单、最直接、费用最低的互联方式。</p>
</li>
<li><p><strong>VPC 对等连接</strong>：在同一区域的两个 VPC 之间直接建立私有连接，<strong>不产生数据传输费用</strong>（同一区域流量免费），只有少量 API 调用费用。是最简单、成本最低的跨 VPC 互联方式。</p>
</li>
<li><p><strong>中转网关（中转 VPC）</strong>：适用于连接<strong>多个 VPC</strong>（通常大于 2 个）或跨区域连接。它按小时和数据处理量收费，比简单的 VPC 对等<strong>成本更高且更复杂</strong></p>
</li>
</ul>
<p><br>263 一家公司正在构建由多个微服务组成的应用程序，决定使用<strong>容器技术</strong>在 AWS 上部署。</p>
<ul>
<li>要求：<ol>
<li>解决方案能<strong>最大限度减少持续维护和扩展工作</strong>。</li>
<li><strong>无法管理额外的基础设施</strong>。</li>
</ol>
</li>
<li>目标：选择<strong>两项</strong>行动组合。</li>
</ul>
<p> <u>部署一个 Amazon Elastic Container Service（Amazon ECS）集群。</u></p>
<p> <u>部署具有 Fargate 启动类型的 Amazon ECS 服务，指定所需的任务数量级别大于或等于 2</u></p>
<ul>
<li><strong>减少维护和扩展工作</strong>：优先选择<strong>托管服务</strong>，让 AWS 处理底层服务器、补丁、扩展等。</li>
<li><strong>无法管理额外的基础设施</strong>：这意味着用户<strong>不想管理 EC2 实例</strong>（服务器）。<br>这强烈指向 <strong>无服务器容器</strong> 选项，即 <strong>AWS Fargate</strong>。</li>
</ul>
<p><br>264 一家公司的 Web 应用程序托管在 <strong>10 个 EC2 实例</strong>上，流量由 <strong>Amazon Route 53</strong> 引导（DNS 轮询）。</p>
<ul>
<li><strong>问题</strong>：偶尔出现超时错误。</li>
<li><strong>根因</strong>：一些 DNS 查询返回了<strong>不健康实例的 IP 地址</strong>。</li>
<li>目标：解决超时错误。</li>
</ul>
<p><u>在 EC2 实例前创建一个带有健康检查的应用程序负载均衡器（ALB），从 Route 53 路由到该 ALB。</u></p>
<ul>
<li>当前架构：Route 53 直接返回多个 EC2 实例的 IP（可能是<strong>简单路由或多值路由</strong>），但没有健康检查或健康检查未生效。</li>
<li>DNS 缓存：客户端或递归 DNS 服务器会缓存 DNS 响应，即使后端实例已不健康，客户端仍可能尝试连接旧的 IP，导致超时。</li>
<li><strong>DNS 层面健康检查的局限性</strong>：即使 Route 53 健康检查将不健康实例从 DNS 响应中移除，已缓存的 DNS 记录在 TTL 过期前仍然会导致流量导向不健康实例。</li>
<li>Route 53 只需将域名解析到 ALB 的 DNS 名称（或一个固定 IP）。ALB 后面的实例变化对客户端透明</li>
</ul>
<p>故障转移策略用于<strong>主-备</strong>场景，不适合负载均衡 10 个实例</p>
<p><br>265 需要设计一个包含 <strong>Web 层、应用层、数据库层</strong> 的<strong>高可用应用程序</strong>。</p>
<ul>
<li>要求：<ol>
<li><strong>HTTPS 内容分发应尽可能靠近边缘，且交付时间最短</strong> → 需要使用 <strong>CDN（Amazon CloudFront）</strong>。</li>
<li><strong>安全性最高</strong>。</li>
</ol>
</li>
<li>目标：选择满足要求且安全性最高的解决方案。</li>
</ul>
<p><u>配置一个公共 ALB，在私有子网中部署多个冗余 EC2 实例，配置 CloudFront 使用公共 ALB 作为源</u></p>
<ul>
<li><strong>Web&#x2F;应用服务器</strong>（EC2 实例）应部署在<strong>私有子网</strong>，不直接暴露在互联网上，减少攻击面。</li>
<li><strong>公共入口点</strong>：应该只有 <strong>负载均衡器（ALB）</strong> 或 <strong>CloudFront</strong> 部署在公有子网，接收互联网流量。</li>
<li><strong>CloudFront 作为 CDN</strong> 应放在最外层，将 ALB 作为源站，而不是直接以 EC2 实例为源。</li>
</ul>
<p><br>266 一家公司拥有一个在 AWS 上运行的<strong>热门游戏平台</strong>。</p>
<ul>
<li><strong>特点</strong>：<strong>对延迟敏感</strong>（影响体验和公平性）。</li>
<li><strong>部署</strong>：应用程序部署在<strong>每个 AWS 区域</strong>（多区域部署），运行在 <strong>EC2 实例</strong>上，这些实例是 <strong>ALB 后自动扩展组</strong>的一部分。</li>
<li><strong>需求</strong>：实施一种机制来<strong>监控应用程序的健康状况</strong>，并<strong>将流量重定向到健康的端点</strong>。</li>
<li>隐含需求：需要在<strong>全球范围</strong>内做健康检查和流量导向，而不仅仅是单个区域内部。</li>
</ul>
<p> <u>在 AWS Global Accelerator 中配置一个加速器，为应用程序端口添加监听器，附加到每个区域的区域终端节点，将 ALB 添加为终端节点。</u></p>
<p><br>267 一家公司有 <strong>100 万用户</strong> 使用其移动应用程序。</p>
<ul>
<li>需求：<ol>
<li><strong>近乎实时地分析数据使用情况</strong>。</li>
<li><strong>近乎实时地对数据进行加密</strong>。</li>
<li>将数据以 <strong>Apache Parquet 格式</strong> 存储在 <strong>一个集中位置</strong>，以便进一步处理。</li>
</ol>
</li>
<li>目标：以<strong>最少的运营开销</strong>满足要求。</li>
</ul>
<p><u>创建一个 Amazon Kinesis Data Firehose 交付流，将数据存储在 Amazon S3 中。创建一个 Amazon Kinesis 数据分析应用程序用于分析数据</u></p>
<ul>
<li><strong>数据流</strong>：移动应用 → 数据收集 → 实时分析 + 存储。</li>
<li><strong>实时分析</strong>：“近乎实时”意味着需要流处理，而不是批处理。</li>
<li><strong>加密</strong>：在传输和静态时加密。</li>
<li><strong>存储格式</strong>：Parquet（一种列式存储格式，适合分析）。</li>
<li><strong>集中存储</strong>：Amazon S3 是标准的集中数据湖存储。</li>
<li><strong>最少运营开销</strong>：优先选择<strong>无服务器、全托管</strong>服务。</li>
</ul>
<p><strong>Amazon Kinesis Data Analytics</strong> 是<strong>完全托管</strong>的服务，用于使用 SQL 或 Apache Flink 实时处理流数据。运营开销为零。</p>
<p><strong>Amazon EMR</strong> 是托管集群服务，虽然功能强大，但需要选择实例类型、管理扩展等，<strong>运营开销较大</strong>。</p>
<p><br>268 一家游戏公司有一个展示分数的 Web 应用程序。</p>
<ul>
<li>架构：EC2 实例（ALB 后） + <strong>Amazon RDS for MySQL</strong> 数据库。</li>
<li><strong>问题</strong>：<strong>数据库读取性能问题</strong>，导致用户遇到长时间延迟和中断。</li>
<li><strong>目标</strong>：改善用户体验。</li>
<li><strong>约束</strong>：<strong>尽量减少对应用程序架构的改动</strong>。</li>
</ul>
<p><u>在数据库前使用 Amazon ElastiCache</u></p>
<ul>
<li><p><strong>ElastiCache</strong> 是托管的内存缓存服务（支持 Redis 或 Memcached）。</p>
</li>
<li><p><strong>DynamoDB</strong> 是 NoSQL 键值&#x2F;文档数据库，适用于高吞吐、低延迟的特定访问模式。</p>
</li>
<li><p>迁移需要<strong>重写数据模型和大量应用代码</strong>，改动极大。</p>
</li>
</ul>
<p><br>269 一家电子商务公司的 Web 应用程序基于 <strong>Amazon RDS</strong>，发现<strong>性能下降</strong>。</p>
<ul>
<li><strong>原因</strong>：业务分析师触发的<strong>只读 SQL 查询数量增加</strong>，影响了主数据库性能。</li>
<li><strong>目标</strong>：在对现有 <strong>Web 应用程序进行最少更改</strong>的情况下解决此问题。</li>
<li>关键：这些是<strong>只读查询</strong>，且来自<strong>业务分析师</strong>（可能使用 BI 工具或临时查询），不是核心应用流量。</li>
</ul>
<p><u>创建主数据库的只读副本，并让业务分析师运行他们的查询</u></p>
<ul>
<li>ElastiCache 是<strong>内存缓存</strong>（Redis&#x2F;Memcached），不是为复杂 SQL 查询设计的。</li>
<li>Redshift 是<strong>数据仓库</strong>，专为大规模分析查询优化。</li>
<li>DynamoDB 是 NoSQL 键值&#x2F;文档数据库，<strong>不支持标准 SQL 查询</strong>。</li>
</ul>
<p><br>270 公司使用S3 进行存储加密</p>
<ul>
<li><strong>静态加密</strong>（数据在 S3 存储时已加密）</li>
<li><strong>传输加密</strong>（数据上传过程中必须加密）</li>
<li>需要确保<strong>数据在上传到 S3 之前就已经处于加密状态</strong>（也就是客户端加密，不是到 S3 再加密）</li>
</ul>
<p><u><strong>使用客户端加密对上传到 S3 存储桶的数据进行加密</strong></u></p>
<p><br>271 架构师发现</p>
<ul>
<li>批处理作业每晚 <strong>1 点开始</strong></li>
<li>当前自动扩容需要 <strong>1 小时</strong> 才能达到峰值容量</li>
<li>峰值容量每晚 <strong>相同</strong></li>
<li>需要<strong>经济高效</strong>且<strong>快速达到所需容量</strong>，并且完成后还能<strong>自动缩容</strong></li>
</ul>
<p><u><strong>配置定时扩展以扩展到所需的计算级别</strong></u></p>
<ul>
<li>由于峰值容量每晚固定、时间固定（1点开始），可以提前在 1 点之前定时将容量设到峰值（比如 12:55 调整期望实例数到峰值），这样 1 点时已有足够实例。</li>
<li>批处理完后，可以用另一个定时动作或基于负载的缩容策略缩容</li>
</ul>
<p><br>272 公司现有架构在美国西部 1 区，通过 ALB + EC2 提供动态网站。</p>
<ul>
<li>网站需支持多种语言（意味着可能要根据 <code>Accept-Language</code> 头提供不同内容）。</li>
<li>用户在全球各地访问延迟高，需要改善性能，但公司不想在其他区域重建架构。</li>
</ul>
<p><u><strong>配置 CloudFront 分发以 ALB 为源，基于 Accept-Language 缓存</strong></u></p>
<ol>
<li><strong>动态网站</strong> → 可能大部分页面是动态生成，但也许部分内容可缓存。</li>
<li><strong>基于语言</strong> → 缓存需要考虑 <code>Accept-Language</code> 请求头来区分不同版本。</li>
<li><strong>全球低延迟</strong> → 需要 CDN 或边缘节点缓存动态内容。</li>
<li><strong>不想多区域重建</strong> → 不能在其他区域复制整个架构。</li>
</ol>
<p><br>273 一个电子商务公司目前单区域运行</p>
<ul>
<li>要加<strong>另一个 AWS 区域</strong>作为灾难恢复</li>
<li>要求数据库在 DR 区域<strong>保持最新状态</strong>，延迟尽可能低</li>
<li>DR 区域的其他基础设施（应用服务器等）以<strong>降低的容量运行</strong>，必要时可扩容</li>
<li>要求 <strong>RTO（恢复时间目标）最低</strong></li>
</ul>
<p><u><strong>使用带有热备用部署的 Amazon Aurora 全球数据库</strong></u></p>
<ol>
<li><strong>数据库保持最新</strong> → 需要跨区域同步或复制。</li>
<li><strong>延迟尽可能低</strong> → 可能是强调复制延迟低。</li>
<li><strong>DR 区域基础设施降低容量运行，可扩容</strong> → 应用层平时用小规模，灾难时扩容。</li>
<li><strong>RTO 最低</strong> → 切换到 DR 区域要快。所以选用热部署</li>
</ol>
<p><br>274 公司在EC2 实例上运行应用程序</p>
<ul>
<li>需要 DR 方案，<strong>RTO &lt; 4 小时</strong></li>
<li>正常运行期间使用<strong>尽可能少的 AWS 资源</strong>（成本低）</li>
<li>要求<strong>最具运营效率</strong></li>
</ul>
<p><u><strong>用 AMI 备份 + 复制到备用区域 + CloudFormation 在备用区域部署</strong></u></p>
<ul>
<li>AMI 复制到备用区域 ✅</li>
<li>用 CloudFormation 自动化部署基础设施 → 标准化，可重复，运营效率高</li>
<li>RTO &lt; 4 小时可行（需定期更新 AMI，灾难时 CloudFormation 快速启动）</li>
<li>正常运行时备用区域无资源运行（仅在灾难时启动）</li>
<li>✅ 符合最少资源要求，运营效率最高（IaC 最佳实践）</li>
</ul>
<p><br>275 公司有着基于浏览器的内部应用，工作时间自动扩展到 20 个实例，夜间缩减到 2 个。</p>
<ul>
<li><strong>员工抱怨</strong>：<strong>一天开始</strong>时（例如早上刚上班）应用非常慢，到上午中旬就很顺畅。</li>
<li><strong>原因推测</strong>：早上员工刚上班，访问量突增，但自动扩展策略可能基于 CPU 利用率等指标触发扩展，从 2 个实例扩展到 20 个需要时间（扩容速度跟不上突然增加的负载）。</li>
<li>目标：<strong>解决启动时的性能问题</strong>，同时<strong>保持低成本</strong>（不能全天保持 20 个实例）。</li>
</ul>
<p><u><strong>实施一项计划任务，在办公室即将开门前将期望容量设置为 20</strong></u></p>
<p><strong>实现一个在较低 CPU 阈值下触发的目标跟踪动作，并缩短冷却时间</strong></p>
<ul>
<li>通过调整阈值和冷却时间加快扩容速度，但早上从 2 个到 20 个仍需经过多次扩容周期</li>
</ul>
<p><br>276 一家公司的多层应用运行在自动扩展组（EC2）与 RDS for Oracle 数据库上。流量持续增长导致 EC2 实例过载且 RDS 存储耗尽。自动扩展组目前无扩展指标，仅设定了最小健康实例数。需要选择两项措施，使系统能针对增长流量自动扩展。</p>
<p><u>为 RDS for Oracle 配置存储自动扩展</u></p>
<p><u>将自动扩展组配置为基于平均 CPU 扩展</u></p>
<p><br>277 公司提供在线服务，</p>
<ul>
<li>当前架构：<strong>EFS 标准版</strong> 存储视频，多个 Linux EC2 实例访问并处理（转码）。</li>
<li>问题：服务越来越受欢迎 → <strong>存储成本过高</strong>。</li>
<li>目标：最具成本效益的存储解决方案。</li>
</ul>
<p><u><strong>使用 Amazon S3 存储视频内容，处理时将文件临时转移到连接到服务器的 Amazon EBS 卷上</strong></u></p>
<ul>
<li>S3 存储成本远低于 EFS（尤其针对大量视频内容）。</li>
<li>处理时，每个 EC2 实例可以从 S3 下载视频到自己的 EBS 卷（或实例存储）进行转码，处理完结果可存回 S3</li>
</ul>
<p><br>278 公司创建一个应用程序</p>
<ol>
<li><strong>存储结构</strong>：以<strong>层级结构化关系</strong>存储员工数据（暗示是树状、多级关系，可能是部门-员工等）。</li>
<li><strong>性能要求</strong>：高流量查询，<strong>低延迟响应</strong>。</li>
<li><strong>安全要求</strong>：保护所有敏感数据。</li>
<li><strong>额外需求</strong>：如果员工数据中有财务信息，需要<strong>每月收到电子邮件通知</strong></li>
</ol>
<p><u><strong>使用 Amazon DynamoDB 按层级存储员工数据。每月将数据导出到 Amazon S3</strong></u></p>
<p><u>为AWS账户配置Amazon Macie。将Macie与Amazon EventBridge集成，通过Amazon Simple Notification Service（Amazon SNS）订阅发送每月通知。</u></p>
<p><br>279 公司应用以 DynamoDB 为后端。合规要求：</p>
<ul>
<li>每月一次数据库备份</li>
<li>备份必须<strong>可访问&#x2F;可用</strong> 6 个月</li>
<li>备份必须<strong>保留</strong> 7 年</li>
</ul>
<p><u>使用 <strong>AWS Backup</strong> 计划：</u></p>
<ul>
<li><u>每月第一天执行备份</u></li>
<li><u>生命周期策略在 6 个月后将备份转为冷存储（仍保留但成本更低）</u></li>
<li><u>保留期设为 7 年</u><br><u>符合全部要求，且为托管方案。</u></li>
</ul>
<p><br>280 公司网站使用 CloudFront，已将访问日志保存到 S3 存储桶。现在需要对日志进行<strong>高级分析并创建可视化</strong>。需选择合适的技术方案</p>
<p><u>用 <strong>Amazon Athena</strong> 查询 + <strong>Amazon QuickSight</strong> 可视化</u><br><u>→ Athena 直接查 S3 日志，QuickSight 是 AWS 原生 BI 工具，可连接 Athena 做可视化</u></p>
<p><br>281 公司使用 Amazon RDS for PostgreSQL，合规要求所有生产数据库的 <strong>恢复点目标（RPO）低于 1 秒</strong>。<br>RPO 衡量数据丢失的最大允许时间，要求 &lt;1 秒意味着必须<strong>近实时同步复制</strong>，确保故障时数据丢失不超过 1 秒。</p>
<p><u><strong>为数据库实例启用多可用区部署</strong></u></p>
<p><br>282 公司 Web 应用架构：</p>
<ul>
<li>EC2 实例位于 <strong>VPC 私有子网</strong></li>
<li>ALB 位于 <strong>公共子网</strong>，将流量导向 EC2 实例</li>
<li>新安全要求：<ol>
<li>限制从 <strong>ALB 到 EC2 实例</strong>的入站流量</li>
<li>阻止来自 <strong>私有子网内部其他来源</strong> 或 <strong>外部任何其他来源</strong> 对 EC2 的直接访问</li>
</ol>
</li>
</ul>
<p> <u>为 EC2 实例配置安全组，使其仅允许来自 ALB 安全组的流量</u></p>
<p><br>283 公司有两个应用：</p>
<ol>
<li>模拟应用（Linux） → 每 5 分钟输出数据到 <strong>NFS 共享目录</strong></li>
<li>可视化应用（Windows 桌面程序） → 显示模拟结果，需要 <strong>SMB 文件系统</strong></li>
</ol>
<ul>
<li>现状：公司维护<strong>两个同步的文件系统</strong>（可能是分别提供 NFS 和 SMB），导致<strong>数据重复、资源效率低</strong>。</li>
<li>要求：迁移到 AWS，<strong>不需修改应用代码</strong>，且要解决存储重复问题</li>
</ul>
<p><u>迁移到 Linux EC2 + Windows EC2 + <strong>Amazon FSx for NetApp ONTAP</strong></u><br>→ FSx for ONTAP 支持<strong>同时提供 NFS 和 SMB 协议</strong>，Linux 挂载 NFS，Windows 挂载 SMB，访问同一份数据</p>
<p><br>284 管理层需要一份 <strong>按用户列出的 AWS 计费项目报告</strong>，用于制定部门预算。要求找出<strong>最有效的方法</strong>获取此信息</p>
<p><u>在成本资源管理器（Cost Explorer）中创建报告并下载</u></p>
<p><br>285 公司用 Amazon S3 托管静态网站。</p>
<ul>
<li>现在想在网页上加一个 <strong>联系表单</strong>，需有<strong>动态服务器端组件</strong>（因为要处理用户输入的姓名、邮箱、电话、留言）。</li>
<li>每月访问量 <strong>&lt; 100 次</strong>（极低流量）。</li>
<li>要求：<strong>最具成本效益</strong>的解决方案。</li>
</ul>
<p><u>创建 <strong>Amazon API Gateway + Lambda 后端</strong>，Lambda 调用 Amazon SES 发邮件</u>→ Lambda 按调用次数计费，每月 100 次访问几乎免费；SES 发送邮件成本极低 </p>
<p><br>286 静态网站托管架构：Amazon CloudFront（CDN）分发，源站为 Amazon S3，后端有数据库。</p>
<ul>
<li>问题：Git 仓库更新后，通过 CI&#x2F;CD 管道成功部署到 S3，但网站（用户访问的 CloudFront 分发）未反映出更新。</li>
<li>已知条件：CI&#x2F;CD 管道正常，Webhook 配置正确，部署成功消息已收到。</li>
<li>需求：实施一个解决方案，使网站能显示更新内容。</li>
</ul>
<p><u><strong>（使 CloudFront 缓存失效）</strong></u></p>
<p>静态网站内容（HTML&#x2F;CSS&#x2F;JS）已通过 CI&#x2F;CD 更新到 S3，但用户访问 CloudFront 时仍看到旧版本。这是因为 CloudFront 会缓存源站（S3）的内容以提升性能，默认缓存行为可能导致用户未及时获取新内容</p>
<p><br>287 需将基于 Windows 的三层应用（应用层、业务层、数据库层 - Microsoft SQL Server）从本地迁移到 AWS。</p>
<ul>
<li>SQL Server 需使用<strong>特定功能</strong>，如<strong>原生备份</strong>和<strong>数据质量服务</strong>。</li>
<li>需要在<strong>各层之间共享用于处理的文件</strong>。</li>
<li>目标：设计满足要求的架构。</li>
</ul>
<p><u>在 Amazon EC2 实例上托管所有三层。使用适用于 Windows 文件服务器的 Amazon FSx 实现文件共享</u></p>
<ol>
<li>SQL Server 需使用原生备份、数据质量服务 → 这些是 SQL Server 的高级功能，<strong>Amazon RDS for SQL Server 不完全支持</strong>（例如数据质量服务 DQS 通常不支持）。因此数据库层很可能需要托管在 <strong>EC2 实例（自行安装 SQL Server）</strong> 上。</li>
<li>各层之间需要共享文件 → 需要<strong>共享文件系统</strong>，且应用是 Windows 环境，需兼容 SMB 协议。</li>
</ol>
<p><br>288 公司需将一组基于 Linux 的 Web 服务器迁移到 AWS。</p>
<ul>
<li>这些 Web 服务器必须访问<strong>共享文件存储</strong>中的文件来获取内容。</li>
<li>限制条件：<strong>不得对应用程序进行任何更改</strong>（即应用已使用标准文件系统接口访问文件）。</li>
<li>需求：设计满足要求的共享存储方案。</li>
</ul>
<p><u>创建一个 Amazon Elastic File System（EFS）文件系统。在所有 Web 服务器上挂载该 EFS 文件系统</u></p>
<p><br>289 一个 AWS Lambda 函数需要<strong>读取</strong>同一 AWS 账户中某个 Amazon S3 存储桶的数据。</p>
<ul>
<li>目标：以<strong>最安全的方式</strong>满足此权限要求。</li>
</ul>
<p><u>为 Lambda 函数应用一个 IAM 角色，为该角色附加一个 IAM 策略，授予对该 S3 存储桶的读取权限。</u></p>
<p><br>290 场景：Web 应用托管在 EC2 实例上，实例在自动扩展组中根据用户需求扩展。</p>
<ul>
<li>需求：优化成本节约，但<strong>不做出长期承诺</strong>。</li>
<li>目标：推荐合适的 EC2 实例购买选项。</li>
</ul>
<p><u>按需实例和定价型实例（Spot Instances）的混合</u></p>
<p><br>291 媒体公司使用 <strong>CloudFront</strong> 分发公开流媒体视频，源站在 <strong>Amazon S3</strong>。</p>
<ul>
<li>需求：<strong>保护视频内容</strong>（控制访问权限）。</li>
<li>限制条件：<ol>
<li>部分用户使用<strong>不支持 Cookie 的自定义 HTTP 客户端</strong>。</li>
<li>部分用户<strong>无法更改硬编码的 URL</strong>。</li>
</ol>
</li>
<li>目标：选择满足要求且<strong>对用户影响最小</strong>的服务或方法（选两项）</li>
</ul>
<p><strong><u>签名 Cookie）</strong>：适用于支持 Cookie 的客户端，可保护内容；但对不支持 Cookie 的客户端无效。</u></p>
<p><u><strong>（签名 URL）</strong>：适用于可以接收动态 URL 的客户端（如通过应用后端生成），但对硬编码 URL 的用户无效。</u></p>
<ul>
<li><ol>
<li>保护 S3 中的视频内容 → 需使用 CloudFront 的访问控制功能，防止未授权用户直接访问 S3 或 CloudFront URL。</li>
<li>部分客户端<strong>不支持 Cookie</strong> → 不能用依赖 Cookie 的认证方式（如 Signed Cookies）。</li>
<li>部分用户<strong>无法更改硬编码 URL</strong> → 若使用签名 URL（Signed URLs），URL 本身包含参数，硬编码的 URL 无法动态更新签名参数，因此<strong>签名 URL 也不适用</strong>。</li>
<li>“对用户影响最小” → 应尽量兼容现有客户端，不改动用户端配置或代码。</li>
</ol>
</li>
<li><strong>矛盾点</strong>：<ul>
<li>常见的 CloudFront 访问控制方法是 <strong>签名 URL</strong> 或 <strong>签名 Cookie</strong>。</li>
<li>但签名 URL 需要 URL 带签名参数，硬编码 URL 的用户无法更新参数；签名 Cookie 需要客户端支持 Cookie。</li>
<li>题目要求同时满足两类用户（不支持 Cookie + 硬编码 URL） → 似乎没有一种单一方法能同时满足。</li>
<li>但题目是<strong>选两项</strong> → 可能组合两种方法覆盖不同用户群体，使总体影响最小</li>
</ul>
</li>
</ul>
<p><br>292 公司构建新的数据平台，接收<strong>多个来源的实时流数据</strong>。</p>
<ul>
<li>需求：<ol>
<li>在将数据写入 <strong>Amazon S3</strong> 之前进行<strong>转换</strong>。</li>
<li>能够使用 <strong>SQL</strong> 查询转换后的数据（在 S3 中）。</li>
</ol>
</li>
<li>目标：选择满足要求的解决方案（选两项）</li>
</ul>
<p><u>使用 Amazon Kinesis Data Streams 流式传输数据 → Amazon Kinesis Data Analytics 转换数据 → Amazon Kinesis Data Firehose 写入 S3 → Amazon Athena 查询 S3 数据</u></p>
<p> <u>使用 Amazon MSK（Managed Streaming for Apache Kafka）流式传输数据 → AWS Glue 转换数据并写入 S3 → Amazon Athena 查询 S3 数据</u></p>
<ul>
<li><strong>关键需求分析</strong>：<ol>
<li><strong>实时流数据</strong> → 需使用流式处理服务（Kinesis Data Streams、MSK、Kinesis Data Firehose 等）。</li>
<li><strong>转换数据</strong> → 需有流式处理或批处理转换能力（Kinesis Data Analytics、AWS Glue、EMR 等）。</li>
<li><strong>写入 S3</strong> → 需有将流数据写入 S3 的组件（如 Kinesis Data Firehose、Glue、EMR 等）。</li>
<li><strong>SQL 查询转换后数据</strong> → 最终查询目标为 S3，通常使用 <strong>Amazon Athena</strong>（支持 SQL 查询 S3）。</li>
<li><strong>“在写入 S3 之前转换”</strong> → 转换步骤应在写入 S3 之前完成。</li>
</ol>
</li>
</ul>
<p><br>293 公司原本地卷备份解决方案已到寿命，希望将 <strong>AWS 作为新备份方案的一部分</strong>。</p>
<ul>
<li>要求：<ol>
<li><strong>备份到 AWS 时</strong>，仍能<strong>本地访问所有数据</strong>（即数据在本地可见&#x2F;可访问）。</li>
<li>备份到 AWS 的数据能<strong>自动且安全传输</strong>。</li>
</ol>
</li>
<li>目标：选择满足要求的解决方案。</li>
</ul>
<p><u>使用 AWS Storage Gateway 配置<strong>存储卷网关</strong>，本地运行软件设备，将网关存储卷映射到本地存储，挂载卷提供本地访问。</u></p>
<p>题目强调“备份解决方案”，且要“本地访问所有数据”。</p>
<ul>
<li><strong>D（存储卷网关）</strong> 更符合传统本地卷备份场景：数据完全在本地，快照备份到云。</li>
<li><strong>C（缓存卷网关）</strong> 适用于希望主要存储放在云上、本地留缓存的情况，但本地访问时若缓存未命中需从云拉取</li>
</ul>
<p><br>294 托管在 Amazon EC2 实例上的应用程序需要访问 Amazon S3 存储桶。</p>
<ul>
<li>关键限制：<strong>流量不得通过互联网传输</strong>。</li>
<li>目标：配置访问以满足该要求。</li>
</ul>
<p><u>在 VPC 中为 Amazon S3 设置网关 VPC 终端节点（Gateway VPC Endpoint）</u></p>
<p>在 VPC 内创建网关 VPC 终端节点（for S3）是 AWS 推荐的安全访问方式，确保流量在 AWS 骨干网内传输，不经过公共互联网。</p>
<p>NAT 网关用于让私有子网实例访问互联网，但流量仍然经过互联网到达 S3 公共端点，不满足要求 </p>
<p>VPN 连接用于本地数据中心与 VPC 互联，不适用于 VPC 内 EC2 访问 S3（S3 是 AWS 服务，可通过 VPC 终端节点直接访问，无需 VPN</p>
<p><br>295 公司有数 TB 客户数据存储在 AWS，包含 <strong>PII（个人身份信息）</strong>。</p>
<ul>
<li>三个应用程序需要使用这些数据，但<strong>只有一个应用需要处理 PII</strong>，另外两个应用在接收数据前<strong>必须移除 PII</strong>。</li>
<li>目标：以<strong>最低运营开销</strong>满足要求的解决方案。</li>
</ul>
<p><u>将数据存储在 Amazon S3 存储桶中，使用 <strong>S3 Object Lambda</strong> 在返回数据前处理和转换数据</u></p>
<p><br>296 开发团队在<strong>开发 VPC</strong>（CIDR: <code>192.168.0.0/24</code>）内运行 EC2 实例。</p>
<ul>
<li>需要在<strong>同一账户</strong>中创建一个<strong>新 VPC</strong>，并与开发 VPC 建立 VPC 对等连接。</li>
<li>需求：为新 VPC 选择一个 CIDR 块，该 CIDR 必须对 VPC 对等连接<strong>有效</strong>。</li>
<li>目标：确定满足条件的<strong>最小 CIDR 块</strong>。</li>
</ul>
<p><u><strong>（<code>10.0.1.0/24</code>）</strong></u></p>
<p><strong>VPC 对等连接的核心要求</strong>：</p>
<ul>
<li>两个 VPC 的 CIDR 范围<strong>不能重叠</strong>（否则无法建立对等连接或路由冲突）。</li>
<li>最小 CIDR 块可以是 <code>/28</code>（AWS VPC 允许的最小 CIDR 范围），但题目选项里给出的最小是 <code>/32</code>（单个 IP）。</li>
<li>注意：<code>/32</code> 是 CIDR 表示形式，在 VPC 中<strong>不能</strong>用作 VPC CIDR（AWS VPC CIDR 允许范围是 <code>/16</code> 到 <code>/28</code>），但题目选项里出现 <code>/32</code>，可能是陷阱</li>
</ul>
<p>297公司在 5 台 EC2 实例上部署应用，通过 ALB + 目标组分发流量。</p>
<ul>
<li>现状：大多数时间 CPU 使用率 &lt;10%，偶尔飙升至 65%。</li>
<li>需求：<ol>
<li>实现<strong>自动扩展</strong>。</li>
<li><strong>优化架构成本</strong>（即避免长期闲置过多实例）。</li>
<li>确保<strong>流量高峰时有足够 CPU 资源</strong>。</li>
</ol>
</li>
<li>目标：选择合适的解决方案。</li>
</ul>
<p><u>创建 EC2 自动扩展组（ASG），关联现有 ALB 和目标组 → 设置<strong>目标跟踪扩展策略</strong>（基于 ASGAverageCPUUtilization，目标值 50%），最小 2、期望 3、最大 6 实例</u></p>
<p><br>298 当前架构：</p>
<ul>
<li><p>关键业务应用程序运行在 ALB 后的 EC2 实例上，EC2 在**自动扩展组（ASG）**中。</p>
</li>
<li><p>应用访问一个 <strong>Amazon RDS 数据库实例</strong>。</p>
</li>
<li><p>问题：<strong>EC2 和 RDS 都位于单个可用区（AZ）</strong>，不满足高可用要求。</p>
</li>
<li><p>目标：更新设计以使用<strong>第二个可用区</strong>，使应用程序具有<strong>高可用性</strong>。</p>
</li>
<li><p>需选择正确解决方案。</p>
</li>
</ul>
<p> <u>在每个 AZ 配置一个子网 → ASG 跨两个 AZ 分布 EC2 实例 → 数据库实例配置为<strong>多可用区部署</strong>。</u></p>
<p><br>299 研究实验室需处理约 <strong>8 TB 数据</strong>。</p>
<ul>
<li>存储性能要求：<ul>
<li><strong>延迟低于毫秒级</strong>（亚毫秒级延迟）。</li>
<li><strong>最低吞吐量 6 GB&#x2F;秒</strong>。</li>
</ul>
</li>
<li>数百台运行 Amazon Linux 的 EC2 实例将进行<strong>分布式处理</strong>。</li>
<li>目标：选择满足性能要求的存储解决方案。</li>
</ul>
<p><u>创建 S3 存储桶 → 创建使用<strong>持久性 HDD 存储</strong>的 <strong>Amazon FSx for Lustre</strong> → 选择从 S3 导入&#x2F;导出 → 挂载到 EC2</u></p>
<p>对于高吞吐、低延迟、数百台 EC2 并行处理的场景，<strong>Amazon FSx for Lustre（持久性 SSD）</strong> 是最佳选择，且支持从 S3 导入数据。</p>
<p><br>300 公司需将<strong>遗留应用程序</strong>从本地迁移到 AWS。</p>
<ul>
<li>应用特点：<strong>7x24 小时运行</strong>，数据存储量<strong>随时间不断增长</strong>。</li>
<li>目标：<strong>最具成本效益</strong>地满足要求。</li>
</ul>
<p><strong>选项</strong><br>A. 应用层迁移到 <strong>Amazon EC2 Spot 实例</strong>，数据存储层迁移到 <strong>Amazon S3</strong>。<br>B. 应用层迁移到 <strong>Amazon EC2 预留实例</strong>，数据存储层迁移到 <strong>Amazon RDS 按需实例</strong>。<br>C. <u>应用层迁移到 <strong>Amazon EC2 预留实例</strong>，数据存储层迁移到 <strong>Amazon Aurora</strong></u>。<br>D. 应用层迁移到 <strong>Amazon EC2 按需实例</strong>，数据存储层迁移到 <strong>Amazon RDS 预留实例</strong></p>
<ol>
<li><strong>7x24 小时运行</strong> → 需要持续稳定的计算资源，不能使用可能中断的 Spot 实例（除非应用可容错）。</li>
<li><strong>数据存储随时间增长</strong> → 存储需可扩展且成本可控。</li>
<li><strong>最具成本效益</strong> → 对长期稳定运行的工作负载，预留实例（RI）或 Savings Plans 通常比按需实例更省钱。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T200/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CodeShine">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | CodeShine's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/29/AWS%E6%9E%B6%E6%9E%84%E5%B8%88T200/" class="post-title-link" itemprop="url">AWS架构师T200</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-29 09:40:02 / 修改时间：10:10:45" itemprop="dateCreated datePublished" datetime="2025-12-29T09:40:02+08:00">2025-12-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="AWS架构师T200"><a href="#AWS架构师T200" class="headerlink" title="AWS架构师T200"></a>AWS架构师T200</h1><p><br>101 架构师正在设计一个包含公有子网和私有子网的 VPC。该 VPC 和子网使用 IPv4 CIDR 块。为实现高可用性，三个可用区（AZ）中各有一个公有子网和一个私有子网。解决方案架构师应如何操作才能为私有子网启用互联网访问</p>
<p>创建三个 NAT <strong>网关</strong>，每个可用区的每个公有子网各一个。为每个可用区创建一个私有路由表，将非 VPC 流量转发到其所在可用区的 NAT 网关。</p>
<ol>
<li><strong>需求分析</strong>：私有子网中的EC2实例需要发起到互联网的出站连接（如下载更新），但必须阻止来自互联网的未经请求的入站连接，保持其私有性。</li>
<li><strong>核心架构原则</strong>：<ul>
<li><strong>公有子网</strong>：通过互联网网关直接与互联网双向通信</li>
<li><strong>私有子网</strong>：通过NAT设备间接访问互联网，只允许出站连接</li>
<li><strong>高可用性</strong>：三个AZ需要避免单点故障</li>
</ul>
</li>
</ol>
<p><br>102 公司使用AWS服务自动将200GB数据从本地NFS文件系统迁移到Amazon EC2实例上的EFS文件系统。</p>
<p><strong>在本地数据中心安装 AWS DataSync 代理</strong>。 - 在本地数据中心安装AWS DataSync代理是使用DataSync服务从本地迁移数据到AWS的必要步骤</p>
<p><strong>使用 AWS DataSync 为本地 SFTP 服务器创建合适的位置配置</strong> - 包括指定源位置（本地NFS共享的路径和访问凭证）和目标位置（EFS文件系统的ID）。</p>
<p><br>103 公司有一个 AWS Glue 提取、转换和加载（ETL）作业，该作业每天在同一时间运行。此作业处理位于 Amazon S3 存储桶中的 XML 数据。每天都会有新数据添加到 S3 存储桶中。一位解决方案架构师发现，AWS Glue 在每次运行时都会处理所有数据。应采取什么措施来<strong>防止 AWS Glue 重新处理旧数据</strong></p>
<p>编辑作业以使用作业书签。- <strong>AWS Glue作业书签</strong> 正是为解决此类问题而设计的功能。它可以跟踪先前作业运行中已处理过的数据，确保后续运行时只处理新数据</p>
<p><br>104 架构师必须为一个网站设计高可用性的基础设施。该网站由运行在 Amazon EC2 实例上的 Windows Web 服务器提供支持。解决方案架构师必须实施一种解决方案，以缓解源自数千个 IP 地址的大规模 DDoS 攻击。该网站不允许出现停机情况</p>
<p><strong>AWS Shield Advanced</strong> 是一项专门针对DDoS攻击的托管服务</p>
<p><strong>Amazon CloudFront</strong> 是一个内容分发网络（CDN）。将其用于静态<strong>和动态</strong>内容（通过动态内容加速），可以将源站（EC2实例）隐藏在CloudFront的全球边缘站点之后。CloudFront本身具有巨大的带宽容量，可以吸收和分散DDoS攻击流量。</p>
<p><br>105 架构师必须运用最小权限原则来配置将用于运行 AWS Lambda 函数的权限。Amazon EventBridge（Amazon CloudWatch Events）规则将调用该函数。哪种解决方案能满足这些要求？</p>
<p> <strong>为函数添加一个基于资源的策略</strong>，其中操作设为 <strong>lambda:InvokeFunction</strong>，主体设为 Service:<a target="_blank" rel="noopener" href="https://events.amazonaws.com/">events.amazonaws.com</a>。</p>
<ul>
<li><strong>执行角色（Execution Role）</strong>：这是一个<strong>IAM角色</strong>，被附加到Lambda函数上。它定义了Lambda函数在执行时<strong>可以访问哪些其他AWS服务或资源</strong>（例如，写入DynamoDB、从S3读取）。它回答的是“这个函数被允许做什么？”。</li>
<li><strong>基于资源的策略（Resource-based Policy）</strong>：这是一种直接附加到资源（如Lambda函数、S3存储桶）上的策略。它定义了<strong>谁或什么服务有权访问该资源本身</strong>。它回答的是“谁被允许调用或访问这个函数</li>
</ul>
<p><br>106 公司正准备将机密数据存储在 Amazon S3 中。出于合规原因，这些数据在静态时必须进行加密。为了审计目的，加密密钥的使用情况必须记录日志。密钥必须每年轮换一次。哪种解决方案能满足这些要求</p>
<p>使用带自动轮换的 AWS KMS 密钥进行服务器端加密（SSE-KMS）</p>
<p><br>107 共享单车公司正在开发一种多层架构，以在高峰运营时段追踪自行车的位置。该公司希望在其现有的分析平台中使用这些数据点。解决方案架构师必须确定最可行的多层选项来支持这种架构。这些数据点必须能从 REST API 获取。哪种操作能满足这些存储和检索位置数据的要求</p>
<p>使用 Amazon API Gateway 搭配 AWS Lambda。</p>
<p><strong>Amazon Kinesis Data Analytics</strong> 是一个用于对<strong>正在流动的数据流</strong>进行实时SQL分析的服务。它本身<strong>不是一个用于通过REST API接收数据的入口点</strong>。</p>
<p><br>108 公司拥有一个汽车销售网站，其 listings 存储在 Amazon RDS 的数据库中。当一辆汽车售出后，需要从网站上移除该 listing，并且必须将数据发送到多个目标系统。解决方案架构师应该推荐哪种设计</p>
<p>创建一个 AWS Lambda 函数，当 Amazon RDS 上的数据库更新时触发，将信息发送到 Amazon Simple Queue Service（Amazon SQS）队列，供目标端消费。-单个<strong>SQS队列。SQS队列是点对点通信模型</strong>。一条消息只能被一个消费者获取和处理</p>
<p>订阅 RDS 事件通知，并将 Amazon Simple Notification Service（Amazon SNS）主题扇出到多个 Amazon Simple Queue Service（Amazon SQS）队列。使用 AWS Lambda 函数更新目标。</p>
<p><br>109 公司需要在 Amazon S3 中存储数据，并且必须防止这些数据被更改。该公司希望上传到 Amazon S3 的新对象在一段不确定的时间内保持不可更改，直到公司决定修改这些对象。只有该公司 AWS 账户中的特定用户能够拥有删除这些对象的权限</p>
<p>创建一个启用了 <strong>S3 对象锁定</strong>的 S3 存储桶。启用版本控制。为**对象添加法律保留。**向需要删除对象的用户的 IAM 策略添加 s3:PutObjectLegalHold 权限。</p>
<ul>
<li><strong>Amazon S3 Object Lock</strong>：这是实现S3对象不可变性的核心功能。它提供两种锁定机制：<ul>
<li><strong>保留期限（Retention Period）</strong>：为对象设置一个固定的保护期限，在到期之前对象无法被覆盖或删除。</li>
<li><strong>法律保留（Legal Hold）</strong>：为对象设置一个无限期的保护，没有到期日。只要法律保留生效，对象就受到保护。<strong>法律保留的开关（放置&#x2F;解除）是一个独立的权限</strong>。</li>
</ul>
</li>
<li><strong>版本控制（Versioning）</strong>：S3 Object Lock 要求存储桶必须启用版本控制。它是在对象版本级别上应用锁定的。</li>
</ul>
<p><br>110 媒体公司允许用户向其网站上传图片。该网站运行在亚马逊 EC2 实例上。在处理上传请求时，网站会将图片调整为标准尺寸，并将调整后的图片存储在亚马逊 S3 中。用户现在遇到向该网站上传请求缓慢的问题。该公司需要减少应用程序内部的耦合性并提高网站性能。</p>
<p><strong>当前架构问题</strong>：用户上传图片慢，因为所有流量（可能包含大文件）都先经过EC2实例，EC2实例需要同时处理接收原始图片和调整图片大小这两个任务。这造成了<strong>性能瓶颈</strong>和<strong>紧密耦合</strong></p>
<ul>
<li>理想的解耦架构是：<ol>
<li><strong>前端直接上传</strong>：让用户的浏览器绕过Web服务器，直接、安全地将图片上传到S3。</li>
<li><strong>后端异步处理</strong>：当图片到达S3后，自动触发一个独立的、无服务器的函数来处理图片（如调整大小）。</li>
</ol>
</li>
</ul>
<p><strong>配置应用程序，通过使用预签名 URL</strong>，让每个用户的浏览器直接将图像上传到 Amazon S3。<br><strong>配置 S3 事件通知，以便在上传图像时调用 AWS Lambda 函数</strong>。使用该函数来调整图像大小。</p>
<p>结合 <strong>C（使用S3预签名URL实现直接上传）</strong> 和 <strong>D（使用S3事件触发Lambda进行异步处理）</strong> 构建了一个高度可扩展、高性能且完全解耦的图片处理流水线。</p>
<p><br>111 公司最近将一个消息处理系统迁移到了 AWS。该系统将消息接收到运行在 Amazon EC2 实例上的 ActiveMQ 队列中。消息由运行在 Amazon EC2 上的消费者应用程序处理。消费者应用程序处理消息并将结果写入运行在 Amazon EC2 上的 MySQL 数据库。该公司希望此应用程序具有高可用性且运营复杂性低。哪种架构能提供最高的可用性</p>
<p>当前的系统是这样的：</p>
<ul>
<li><strong>消息队列</strong>：自己在EC2上安装、运维ActiveMQ。<strong>问题</strong>：如果这台EC2所在的机房（可用区AZ）挂了，整个消息接收就停了。</li>
<li><strong>处理程序</strong>：自己在EC2上写消费者程序。<strong>问题</strong>：如果这台EC2挂了，或者处理不过来，消息就堆积了，需要手动去处理。</li>
<li><strong>数据库</strong>：自己在EC2上安装、运维MySQL。<strong>问题</strong>：如果这台EC2或硬盘坏了，数据可能丢失，服务中断。</li>
</ul>
<p> 使用两个可用区配置了主 &#x2F; 备用代理的 Amazon MQ。为分布在两个可用区的消费者 EC2 实例添加一个自动扩展组。使用启用了多可用区的 Amazon RDS for MySQL</p>
<ul>
<li><strong>消息队列</strong>：<code>Amazon MQ (主/备)</code> -&gt; <strong>托管，跨AZ，自动故障转移</strong></li>
<li><strong>处理程序</strong>：<code>自动扩展组 (跨两个AZ)</code> -&gt; <strong>托管，跨AZ，自动恢复，自动伸缩</strong></li>
<li><strong>数据库</strong>：<code>Multi-AZ RDS</code> -&gt; <strong>托管，跨AZ，自动故障转移</strong></li>
</ul>
<p><br>112 公司在一组本地服务器上托管了一个容器化的 Web 应用程序，这些服务器用于处理传入的请求。请求数量正迅速增长。本地服务器无法处理增加的请求数量。该公司希望将应用程序迁移到 AWS，同时尽量减少代码更改和开发工作。</p>
<p>在亚马逊弹性容器服务（Amazon ECS）上使用 AWS Fargate，通过服务自动扩展来运行容器化的 Web 应用程序。使用应用程序负载均衡器来分配传入的请求。</p>
<p><strong>Amazon ECS with AWS Fargate</strong> 是一个<strong>无服务器</strong>的容器计算引擎。你只需要提供容器镜像，Fargate负责所有底层EC2服务器的 provisioning、打补丁和管理工作。这实现了<strong>最少的运营开销</strong></p>
<p><br>113 公司使用 50 TB 的数据进行报告。该公司希望将这些数据从本地迁移到 AWS。公司数据中心的一个自定义应用程序每周运行一次数据转换作业。该公司计划暂停该应用程序，直到数据传输完成，并且需要尽快开始传输过程。<strong>数据中心没有任何可用的网络带宽来处理额外的工作负载</strong>。解决方案架构师必须传输数据，并配置转换作业以继续在 AWS 云中运行。哪种解决方案能以最少的运营开销满足这些要求</p>
<p>订购一台 AWS Snowball Edge 存储优化型设备。将数据复制到该设备。使用 AWS Glue 创建自定义转换作业</p>
<ul>
<li>AWS提供了<strong>物理设备离线迁移</strong>服务，即 <strong>AWS Snow Family</strong>（包括Snowcone, Snowball, Snowmobile）。</li>
<li>对于50TB的数据量，<strong>AWS Snowball Edge</strong> 是最合适的选择。每个Snowball Edge设备可以提供数十TB的存储容量</li>
<li><strong>AWS Snowcone</strong> 是Snow系列中最小的设备，存储容量较小（通常8TB或14TB）</li>
</ul>
<p><br>114 公司开发了一款图像分析应用，用户可以在该应用中上传照片并为自己的图片添加相框，该应用使用单个亚马逊 EC2 实例和亚马逊 DynamoDB 来存储元数据。用户数量在不断增加，且并发用户数量会根据一天中的不同时段和一周中的不同日期而发生显著变化。</p>
<p>使用 AWS Lambda 处理照片。将照片存储在 Amazon S3 中。保留 DynamoDB 以存储元数据。</p>
<ul>
<li><strong>AWS Lambda处理照片</strong>：完美解决了扩展性问题。每当有新图片上传时，可以自动触发一个Lambda函数来执行添加相框的图像处理任务。Lambda会根据上传请求的数量自动扩展，从零到成千上万个并发，无需任何运维工作。</li>
<li><strong>Amazon S3存储照片</strong>：S3是存储图片等二进制大文件的理想选择。它成本低廉、持久性极高，并且与Lambda无缝集成（例如，可以通过S3事件通知触发Lambda）。</li>
<li><strong>DynamoDB存储元数据</strong>：保留DynamoDB来存储相框类型、用户ID等元数据是正确的，因为它可以提供毫秒级的查询速度，并能随流量自动扩展。</li>
</ul>
<p>D选项最大的问题是使用<strong>EBS卷来存储照片</strong>。EBS卷是附加到单个EC2实例的<strong>块存储</strong>。无法在多个实例间共享</p>
<p><br>115 医疗记录公司在 Amazon EC2 实例上托管了一个应用程序。该应用程序处理存储在 Amazon S3 上的客户数据文件。这些 EC2 实例托管在公共子网中，新要求规定，文件传输的网络流量必须采用私有路径，而不是通过互联网发送</p>
<p><strong>将 EC2 实例移至私有子网。为 Amazon S3 创建一个 VPC 终端节点，并将该终端节点链接到私有子网的路由表</strong></p>
<p>要确保VPC内资源访问AWS公共服务（如S3）的流量不经过公共互联网，最标准、最经济高效的方法是使用 <strong>VPC终端节点</strong></p>
<p><br>116 公司为其企业网站使用了一款流行的内容管理系统（CMS）。然而，所需的补丁更新和维护工作十分繁琐。该公司正在重新设计其网站，并希望采用新的解决方案。该网站每年会更新四次，且<strong>不需要任何动态内容。解决方案必须具备高可扩展性和增强的安全性</strong></p>
<p>在网站前配置 Amazon CloudFront 以使用 HTTPS 功能。</p>
<p>创建新网站和一个 Amazon S3 存储桶。在启用了静态网站托管的 S3 存储桶上部署该网站。</p>
<p>对于静态网站，AWS的最佳实践是使用 <strong>Amazon S3</strong> 进行存储和托管，并结合 <strong>Amazon CloudFront</strong>（内容分发网络）进行分发</p>
<p><br>117 公司将其应用程序日志存储在 Amazon CloudWatch Logs 日志组中。一项新政策要求该公司近乎实时地将所有应用程序日志存储在 Amazon OpenSearch Service（Amazon Elasticsearch Service）中。</p>
<p>配置 CloudWatch 日志订阅，将日志流式传输到 Amazon OpenSearch Service（Amazon Elasticsearch Service）</p>
<p><br>118 公司正在构建一个应用程序，在多个可用区的 Amazon EC2 实例上运行。提供对一个文本文档库的访问，该文档库的总大小约为 900 TB。需要满足可以扩展以及成本问题</p>
<p><strong>亚马逊 S3</strong></p>
<p><strong>AWS存储服务对比</strong>：</p>
<ul>
<li><strong>A. Amazon EBS</strong>：<strong>块存储</strong>服务。EBS卷只能挂载到<strong>同一个可用区内</strong>的一个EC2实例。它无法被跨AZ的多个实例共享。要满足需求，需要在每个AZ的每个实例上都存一份900TB的数据，成本极高且数据一致性无法保证。<strong>完全不适用</strong>。</li>
<li><strong>B. Amazon EFS</strong>：<strong>网络文件系统</strong>。它可以被跨AZ的多个EC2实例同时挂载和访问。满足共享需求。然而，EFS的成本（尤其是吞吐量配置成本）相对于存储大容量静态文件（如文本文档库）而言<strong>通常高于S3</strong>。EFS更适合需要低延迟、强一致性的文件系统接口的场景（如代码共享、主页目录）。</li>
<li><strong>C. Amazon OpenSearch Service</strong>：这是一个<strong>搜索和分析引擎</strong>，基于Elasticsearch。它专为日志分析、全文搜索等场景设计，而不是作为一个通用的、成本最优的大容量文档存储库。将900TB的原始文档全部存入OpenSearch，存储成本和计算成本都会极其高昂。这是一个<strong>错误的工具选择</strong>。</li>
<li><strong>D. Amazon S3</strong>：<strong>对象存储</strong>服务。这是最符合要求的方案：<ul>
<li><strong>无限扩展</strong>：S3的存储容量实际上是无限的，可以轻松容纳900TB并持续增长。</li>
<li><strong>高并发访问</strong>：S3专为高吞吐量和并发访问而设计，可以轻松应对高需求时期的流量洪峰。</li>
<li><strong>跨AZ可用性</strong>：数据在多个AZ冗余存储，天然支持从任何AZ的EC2实例进行访问。</li>
<li><strong>成本效益</strong>：在AWS的所有存储服务中，S3是存储海量静态数据（如文档、图片、视频）<strong>单位成本最低</strong>的选择。它的设计初衷就是为此类场景服务的。</li>
</ul>
</li>
</ul>
<p><br>119 公司正在使用位于<strong>多个区域</strong>（us-east-1, ap-southeast-2）和<strong>多个AWS账户</strong>中的 <strong>Amazon API Gateway REST API</strong>。解决方案架构师必须设计一个方案，以保护多个账户中由 API Gateway 管理的这些 REST API 免受 SQL 注入和跨站脚本攻击</p>
<p><strong>在两个区域中设置AWS Firewall Manager。集中配置AWS WAF规则。</strong></p>
<p><strong>AWS Firewall Manager</strong>：这是解决上述管理挑战的<strong>关键服务</strong>。它是一个<strong>安全管理服务</strong>，允许你在<strong>一个中心账户</strong>中为多个账户和资源集中配置和管理AWS WAF规则</p>
<p>AWS WAF：这是防御SQL注入和XSS等Web攻击的核心服务，但是需要在<strong>每个区域</strong>、<strong>每个账户</strong>中分别手动创建和配置相同的WAF规则</p>
<p><strong>AWS Shield</strong> 是一项专门用于防御<strong>DDoS（分布式拒绝服务）</strong> 攻击的服务。</p>
<p><br>120 公司在美西 2 区域的网络负载均衡器（NLB）后面的三台亚马逊 EC2 实例上部署了一个自管理的 DNS 解决方案。该公司的大多数用户位于美国和欧洲。公司希望提高该解决方案的性能和可用性，于是在欧西 1 区域启动并配置了三台 EC2 实例，并将这些 EC2 实例添加为新 NLB 的目标。</p>
<p><strong>AWS Global Accelerator</strong> 是专门为此类场景设计的服务。它通过使用AWS全球网络边缘站点和静态Anycast IP地址，为应用程序提供性能优化和高可用性。</p>
<p>DNS服务通常不通过CloudFront（CDN）加速，因为CDN主要用于缓存和加速HTTP&#x2F;HTTPS内容。DNS查询是实时、非缓存的交互式请求</p>
<p><br>121 公司正在 AWS 上运行在线事务处理（OLTP）工作负载。该工作负载使用一个未加密的 Amazon RDS 数据库实例，采用多可用区部署。每天会从该实例拍摄数据库快照。解决方案架构师应采取什么措施，以确保数据库和快照从现在起始终处于加密状态</p>
<p><strong>加密最新数据库快照的副本。通过恢复加密快照来替换现有数据库实例</strong></p>
<p>AWS RDS <strong>不支持</strong>对现有的、正在运行的数据库实例<strong>直接启用</strong>加密</p>
<p><br>122 一家公司希望构建一个<strong>可扩展的密钥管理基础设施</strong>，以支持需要在其应用程序中加密数据的开发人员。解决方案架构师应采取什么措施来减轻运营负担</p>
<p><strong>使用 AWS 密钥管理服务（AWS KMS）来保护加密密钥</strong></p>
<p><br>123 公司有一个动态 Web 应用程序，托管在两台 Amazon EC2 实例上。该公司拥有自己的 SSL 证书，最近流量有所增加，运营团队确定 SSL 加密和解密导致 Web 服务器的<strong>计算能力达到了最大限制</strong>。</p>
<p><strong>将 SSL 证书导入 AWS Certificate Manager（ACM）</strong>。创建一个带有 HTTPS 监听器的应<strong>用程序负载均衡器</strong>，该监听器使用来自 ACM 的 SSL 证书</p>
<ul>
<li>SSL终止是指在负载均衡器或代理服务器处解密传入的HTTPS流量，然后将未加密的HTTP流量转发给后端服务器。</li>
<li>将消耗大量CPU的SSL终止任务从Web服务器（EC2实例）上卸载到专门的托管服务上</li>
<li>当SSL&#x2F;TLS处理成为Web服务器的性能瓶颈时，标准的解决方案是使用<strong>应用程序负载均衡器（ALB）</strong> 或 <strong>网络负载均衡器（NLB）</strong> 在负载均衡器层进行<strong>SSL终止</strong>。结合 <strong>AWS Certificate Manager (ACM)</strong> 来管理证书</li>
</ul>
<p><br>124 公司有一个高度动态的批次处理作业，它使用许多 Amazon EC2 实例来完成它。<strong>该作业本质上是无状态的，可以在任何给定时间启动和停止</strong>，没有负面影响，通常总共需要 60 <strong>分钟以上才能完成</strong>。该公司要求解决方案架构师设计一个可扩展且具有成本效益的解决方案</p>
<p><strong>EC2 Spot 实例</strong>：这是利用AWS闲置容量的实例，价格比按需实例低很多（通常可节省达90%）。缺点是AWS可能会提前两分钟发出通知并<strong>中断（回收）</strong> 实例。由于该批处理作业<strong>能够容忍中断</strong>且是<strong>无状态</strong>的，它可以利用检查点机制或工作队列</p>
<ul>
<li><strong>B. EC2 保留实例</strong>：这是一种<strong>长期承诺</strong>（1年或3年）的计费模式，适用于有稳定、可预测基线的稳态工作负载。对于“高度动态”的批处理作业，购买预留实例要么会浪费大量容量（买多了），要么无法满足峰值需求（买少了），<strong>既不灵活也不具成本效益</strong>。</li>
<li><strong>C. EC2 按需实例</strong>：无需承诺，按秒计费。它提供了灵活性，但成本是标准定价，<strong>远高于Spot实例</strong>。对于这种可以容忍中断的工作负载，使用按需实例意味着放弃了巨大的成本优化机会。</li>
<li><strong>AWS Lambda</strong>：Lambda是一种事件驱动的无服务器计算服务，单次执行最长超时为<strong>15分钟</strong>。</li>
</ul>
<p><br>125 公司在 AWS 上运行其两层电子商务网站。Web 层包含一个负载均衡器，该负载均衡器将流量发送到 Amazon EC2 实例。数据库层使用 Amazon RDS 数据库实例。<strong>EC2 实例和 RDS 数据库实例不应暴露在公共互联网</strong>上。EC2 实例需要互联网访问权限，以通过第三方 Web 服务完成订单的支付处理。该应用程序必须具有高可用性。</p>
<p><strong>使用自动扩展组在私有子网中启动 EC2 实例。在私有子网中部署 RDS 多可用区数据库实例。</strong> - 满足不暴露公网</p>
<p><strong>配置一个包含两个公有子网、两个私有子网以及跨两个可用区的两个 NAT 网关的 VPC。在公有子网中部署一个应用程序负载均衡器</strong></p>
<ul>
<li><code>配置包含两个公有子网、两个私有子网...的VPC</code>：这为所有资源提供了跨AZ部署的基础，满足高可用性。</li>
<li><code>跨两个可用区的两个NAT网关</code>：在每个AZ的公有子网部署一个NAT网关，确保一个AZ的NAT网关故障不会影响另一个AZ的私有子网出站流量。</li>
<li><code>在公有子网中部署应用程序负载均衡器</code>：正确地将负载均衡器放置在可被互联网访问的位置。</li>
</ul>
<p><br>126  公司的所有数据都存储在Amazon S3标准存储类别中。公司必须将所有数据至少保存25年。最近2年的数据必须具有高可用性且可立即检索，要降低成本</p>
<p>设置S3生命周期策略，将对象在2年后转存至S3 Glacier Deep Archive</p>
<p><br>127 媒体公司正在评估将其系统迁移到 AWS 云的可能性。该公司需要至少 10 TB 的存储，以获得视频处理所需的最高 I&#x2F;O 性能；300 TB 的高耐用性存储，用于存储媒体内容；以及 900 TB 的存储，以满足不再使用的归档媒体的需求。</p>
<p>用于实现最高性能的Amazon EC2实例存储、用于持久数据存储的Amazon S3，以及用于归档存储的Amazon S3 Glacier</p>
<ul>
<li><strong>热数据（处理中）</strong>：<strong>Amazon EC2实例存储</strong>（最高性能）</li>
<li><strong>温数据（活跃资产）</strong>：<strong>Amazon S3</strong>（高持久、可扩展）</li>
<li><strong>冷数据（归档）</strong>：<strong>Amazon S3 Glacier</strong>（最低成本）</li>
</ul>
<p><br>128 公司希望在 AWS 云中以容器形式运行应用程序。这些应用程序是无状态的，能够承受底层基础设施出现的中断。该公司需要一个能最大限度降低成本和运营开销的解决方案</p>
<p>在 Amazon Elastic Kubernetes Service（Amazon EKS）托管节点组中使用 Spot 实例。</p>
<p><strong>最大限度降低成本</strong>：这强烈指向使用 <strong>EC2 Spot实例</strong>，</p>
<p><strong>最大限度降低运营开销</strong>：这强烈指向使用<strong>托管服务</strong>，<strong>Amazon EKS</strong>：AWS托管的Kubernetes服务。</p>
<p><br>129 公司正在本地运行一个多层 Web 应用程序。主机连接到一个包含用户记录的 PostgreSQL 数据库。维护基础设施和进行容量规划的运营开销限制了公司的发展。解决方案架构师必须改进该应用程序的基础设施。</p>
<p> <strong>将 PostgreSQL 数据库迁移到 Amazon Aurora。</strong></p>
<p><strong>将 Web 应用程序迁移到由 Amazon Elastic Container Service（Amazon ECS）托管的 AWS Fargate 上</strong></p>
<ul>
<li><p><strong>Amazon Aurora</strong> 是一个与PostgreSQL和MySQL兼容的<strong>完全托管的关系型数据库</strong>。</p>
</li>
<li><p><strong>AWS Fargate</strong> 是一个用于容器的<strong>无服务器计算引擎</strong>。它与<strong>Amazon ECS</strong>（弹性容器服务）结合，可以运行容器而无需预置或管理服务器。</p>
</li>
</ul>
<p><br>130 应用程序在多个可用区的 Amazon EC2 实例上运行。这些实例在应用程序负载均衡器后的 Amazon EC2 自动扩展组中运行。当 EC2 实例的 CPU 利用率达到或接近 40% 时，该应用程序的性能最佳</p>
<p>使用目标跟踪策略动态扩展自动扩展组。</p>
<ul>
<li><strong>自动扩展</strong>的核心是选择一个能够直接、自动地维持特定资源利用率目标的策略。</li>
<li><strong>简单扩展策略</strong> 依赖于 CloudWatch 警报</li>
<li><strong>将指定的指标维持在指定的目标值附近</strong>。你只需要指定目标值（这里就是40%的平均CPU利用率）。</li>
</ul>
<p><br>131 公司正在开发一个文件共享应用程序，该应用程序将使用 Amazon S3 存储桶进行存储。该公司希望通过 Amazon CloudFront 分发来提供所有文件，且不希望通过直接访问 S3 URL 就能获取这些文件</p>
<p>创建源访问标识（OAI）。将 OAI 分配给 CloudFront 分发。配置 S3 存储桶权限，仅允许 OAI 拥有读取权限</p>
<ul>
<li>默认情况下，如果S3存储桶是公开的，任何人都可以通过CloudFront URL和S3 URL访问内容。</li>
<li>要实现只允许通过CloudFront访问，必须将S3存储桶设置为<strong>私有</strong>，然后只授予CloudFront服务代表用户访问该存储桶的特殊权限</li>
<li><strong>OAI 就是一个专门为CloudFront创建的特殊身份，让你可以精确地授权“只有这个特定的CloudFront分发”能够访问你私有的S3存储桶</strong></li>
</ul>
<p><br>132 公司的网站为用户提供可下载的历史业绩报告。该网站需要一个能扩展以满足公司<strong>全球网站需求</strong>的解决方案。此解决方案应<strong>具有成本效益</strong>，限制基础设施资源的配置，并提供<strong>尽可能快的响应时间</strong></p>
<p>Amazon CloudFront and Amazon S3 </p>
<ul>
<li>对于<strong>静态内容分发</strong>，最标准、最高效的AWS架构是结合 <strong>Amazon S3</strong> 和 <strong>Amazon CloudFront</strong>。</li>
</ul>
<p><br>133 公司在本地运行着一个 Oracle 数据库。作为该公司向 AWS 迁移计划的一部分，它希望将数据库升级到最新版本，同时为数据库设置灾难恢复（DR）。该公司需要<strong>最大限度地减少正常运营和灾难恢复设置的运营开销</strong>，并且还需要保持对<strong>数据库底层操作系统的访问权限</strong></p>
<p>将 Oracle 数据库迁移到适用于 Oracle 的 <strong>Amazon RDS Custom</strong>。在另一个 AWS 区域为该数据库创建一个<strong>只读副本</strong></p>
<ul>
<li>RDS是一个托管服务，<strong>不允许用户访问底层操作系统</strong>。这是RDS的主要限制之一。</li>
<li><strong>RDS Custom for Oracle</strong>：在提供<strong>较低运营开销</strong>的同时，<strong>允许访问底层操作系统</strong>。</li>
<li><strong>在另一个区域创建只读副本</strong>：这是为数据库设置<strong>跨区域灾难恢复</strong>的有效且高效的方法</li>
</ul>
<p><br>134 公司希望将其应用程序迁移到<strong>无服务器解决方案</strong>。该无服务器解决方案需要使用 SQL 分析现有数据和新数据。该公司将数据存储在 Amazon S3 存储桶中。这些数据需要加密，并且必须复制到另一个 AWS 区域</p>
<p>将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制（CRR）将加密对象复制到另一个区域的 S3 存储桶。使用带有 Amazon S3 托管加密密钥（SSE-S3）的服务器端加密。使用 Amazon Athena 查询数据</p>
<ul>
<li><strong>数据复制</strong>：<strong>S3跨区域复制（CRR）</strong> 是满足跨区域复制需求的<strong>标准、自动化、托管</strong>的服务，运营开销极低。</li>
<li><strong>数据加密</strong>：<ul>
<li><strong>SSE-S3</strong>：使用由AWS完全管理的S3主密钥。这是<strong>运营开销最低</strong>的加密选项，你无需管理任何密钥。</li>
<li><strong>SSE-KMS</strong>：使用AWS KMS服务管理的密钥。虽然功能更强大（如审计、轮换），但需要管理KMS密钥和权限，<strong>运营开销高于SSE-S3</strong>。特别是对于跨区域复制，如果使用SSE-KMS，需要配置复杂的<strong>多区域密钥</strong>，否则复制会失败。这显著增加了复杂性。</li>
</ul>
</li>
<li><strong>SQL查询引擎</strong>：<ul>
<li><strong>Amazon Athena</strong>：是一个<strong>无服务器</strong>的交互式查询服务，可直接使用标准SQL分析S3中的数据。它完美契合“无服务器”和“最少运营开销”的要求。</li>
<li><strong>Amazon RDS</strong>：是一个<strong>关系型数据库服务</strong>。它要求你将数据<strong>从S3加载到数据库表中</strong>才能进行查询。这引入了额外且持续的ETL步骤、数据库管理和容量规划，<strong>运营开销远高于Athena</strong>。</li>
</ul>
</li>
</ul>
<p><br>135 公司在 AWS 上运行工作负载。该公司需要连接外部提供商的一项服务，该服务托管在提供商的 VPC 中。根据该公司安全团队的要求，连接必须是私有的，且必须仅限于目标服务，并且连接只能从该公司的 VPC 发起</p>
<p>要求提供商为目标服务创建一个 VPC 终端节点服务。使用 AWS PrivateLink 连接到目标服务</p>
<ul>
<li><strong>AWS PrivateLink</strong> 是专门为这种场景设计的服务。它允许你在VPC中创建一个<strong>终端节点服务</strong>，使其他VPC能够通过<strong>接口VPC终端节点</strong>以私有方式连接到你的服务，而无需使用公有IP、NAT设备或VPC对等连接。</li>
</ul>
<p><br>136 公司正将其本地 PostgreSQL 数据库迁移到 Amazon Aurora PostgreSQL。迁移期间，本地数据库必须保持在线且可访问。Aurora 数据库必须与本地数据库保持同步。</p>
<p><strong>创建持续的复制任务。</strong></p>
<p><strong>创建一个 AWS 数据库迁移服务（AWS DMS）复制服务器</strong></p>
<ul>
<li><strong>关键要求</strong>：<ul>
<li>迁移期间，<strong>本地源数据库必须保持在线且可访问</strong>（意味着不能停机）。</li>
<li><strong>Aurora数据库必须与本地数据库保持同步</strong>。</li>
</ul>
</li>
<li>这描述的是一个 <strong>零停机迁移</strong> 或 <strong>持续复制</strong> 场景</li>
</ul>
<p><br>137 公司使用 AWS Organizations 为每个业务部门创建专用的 AWS 账户，以便应要求独立管理每个业务部门的账户。该公司希望确保未来所有通知都不会被遗漏。未来的通知必须仅限于账户管理员</p>
<p>将所有 AWS 账户根用户电子邮件地址配置为分发列表，发送给少数能够响应警报的管理员。<strong>在 AWS Organizations 控制台中或以编程方式配置 AWS 账户</strong>备用联系人</p>
<ul>
<li><strong>确保通知不被遗漏</strong>：需要一个可靠的机制来接收所有重要通知。</li>
<li><strong>通知仅限于账户管理员</strong>：通知应只发送给有权处理这些警报的少数管理员，而不是所有人</li>
</ul>
<p><br>138 公司在 AWS 上运行其电子商务应用程序。每笔新订单都会作为消息发布到一个 RabbitMQ 队列中，该队列运行在单个可用区的 Amazon EC2 实例上。这些消息由运行在另一个 EC2 实例上的不同应用程序处理。此应用程序将详细信息存储在另一个 EC2 实例上的 PostgreSQL 数据库。所有 EC2 实例都位于同一个可用区。该公司需要重新设计其架构，以最低的运营开销提供最高的可用性。</p>
<p>将队列迁移到 Amazon MQ 上的一对冗余（主用 &#x2F; 备用）RabbitMQ 实例。为托管应用程序的 EC2 实例创建一个多可用区自动扩展组。将数据库迁移到运行于多可用区部署的 Amazon RDS for PostgreSQL 上</p>
<ul>
<li><p><code>Amazon MQ (主/备)</code>：提供高可用的托管消息队列。</p>
</li>
<li><p><code>多可用区自动扩展组</code>：提供高可用的、可扩展的计算层。</p>
</li>
<li><p><code>多可用区 Amazon RDS for PostgreSQL</code>：提供高可用的托管数据库</p>
</li>
<li><p><strong>消息队列（RabbitMQ）</strong>：</p>
<ul>
<li><strong>自建高可用</strong>：在EC2上自建RabbitMQ集群（选项C和D）需要深厚的专业知识，配置复杂，运维负担重。</li>
<li><strong>托管高可用</strong>：<strong>Amazon MQ</strong> 是AWS托管的消息队列服务，兼容RabbitMQ。其“主用&#x2F;备用”配置<strong>原生在多个可用区部署</strong>，并提供<strong>自动故障转移</strong>，极大地降低了运营开销。</li>
</ul>
</li>
<li><p><strong>应用程序（计算层）</strong>：</p>
<ul>
<li>使用 <strong>多可用区自动扩展组</strong> 是正确的方案。它确保在一个可用区故障时，应用程序实例可以在其他可用区自动启动，提供了高可用性和可扩展性。</li>
</ul>
</li>
<li><p><strong>数据库（PostgreSQL）</strong>：</p>
<ul>
<li><strong>自建高可用</strong>：在EC2上使用自动扩展组来部署数据库（选项A和D）是<strong>错误且极其复杂的</strong>。数据库是有状态的，自动扩展组无法自动处理数据复制、故障转移和一致性。这是一个反模式。</li>
<li><strong>托管高可用</strong>：<strong>Amazon RDS for PostgreSQL</strong> 的 <strong>多可用区部署</strong> 是标准解决方案。它会自动在另一个可用区部署一个同步备用副本，并<strong>自动处理故障转移</strong>，通常在一两分钟内完成。这是一个完全托管的解决方案，运营开销最低。</li>
</ul>
</li>
</ul>
<p><br>139 告团队每天都会在 Amazon S3 存储桶中收到文件。该报告团队每天会在同一时间手动检查这些文件，并将其从这个初始 S3 存储桶复制到一个分析 S3 存储桶，以便与 Amazon QuickSight 配合使用。其他团队开始向这个初始 S3 存储桶发送更多更大的文件。报告团队希望在文件进入初始 S3 存储桶时，能自动将其移动到分析 S3 存储桶。报告团队还希望使用 AWS Lambda 函数对复制的数据运行模式匹配代码。此外，报告团队希望将数据文件发送到 Amazon SageMaker Pipelines 中的一个管道。解决方案架构师应如何以最少的运营开销满足这些需求？</p>
<p>在 S3 存储桶之间配置 S3 复制。将分析 S3 存储桶配置为向 Amazon EventBridge (Amazon CloudWatch Events) 发送事件通知。在 EventBridge (CloudWatch Events) 中配置 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为该规则的目标</p>
<ul>
<li><p><strong>需求1</strong>：当文件进入“初始S3存储桶”时，<strong>自动将其复制&#x2F;移动到“分析S3存储桶”</strong>。</p>
</li>
<li><p><strong>需求2</strong>：对<strong>复制到分析桶的数据</strong>运行一个 <strong>Lambda函数</strong>（模式匹配代码）。</p>
</li>
<li><p><strong>需求3</strong>：将<strong>复制到分析桶的数据</strong>发送到 <strong>Amazon SageMaker Pipelines</strong>。</p>
</li>
<li><p><strong>总体要求</strong>：以<strong>最少的运营开销</strong>实现。</p>
</li>
<li><p><code>配置 S3 复制</code>：使用S3原生功能自动处理文件复制，无需编写代码。</p>
</li>
<li><p><code>将分析 S3 存储桶配置为向 Amazon EventBridge 发送事件通知</code>：这建立了更现代化、更灵活的事件驱动基础。</p>
</li>
<li><p><code>在 EventBridge 中配置 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为该规则的目标</code>：通过<strong>一条统一的规则</strong>，轻松地将事件<strong>同时路由到两个下游服务</strong>，实现了高效的一对多集成，管理非常简单</p>
</li>
</ul>
<p><br>140 公司EC2 实例将运行应用程序的数据接入层。EC2 的使用情况将是<strong>零散且不可预测的</strong>。在 EC2 实例上运行的工作负载<strong>可能会在任何时候被中断</strong>。应用程序的前端将在 Fargate 上运行，而 Lambda 将为 API 层提供服务。在未来一年中，前端的使用率和 API 层的使用率将是可预测的。提供最具成本效益的解决方案</p>
<p><strong>为数据接入层使用Spot实例</strong></p>
<p><strong>为前端和API层购买1年期计算节省计划</strong></p>
<ul>
<li><strong>数据接入层（EC2实例）</strong>：<ul>
<li><strong>特性</strong>：使用情况 <strong>零散且不可预测</strong>，工作负载 <strong>可被中断</strong>。</li>
<li><strong>策略</strong>：对于这种<strong>可中断、无状态、不可预测</strong>的工作负载，最具成本效益的选择是 <strong>EC2 Spot实例</strong>。Spot实例价格远低于按需实例（通常可节省达90%），完美契合可中断的特性。</li>
</ul>
</li>
<li><strong>前端（Fargate）和API层（Lambda）</strong>：<ul>
<li><strong>特性</strong>：使用率在<strong>未来一年中是可预测的</strong>。</li>
<li><strong>策略</strong>：对于<strong>稳定、可预测</strong>的使用量，通过<strong>承诺</strong>来换取折扣是最佳选择。<strong>计算节省计划</strong> 是覆盖Fargate和Lambda（以及EC2）使用量的最灵活承诺计划。</li>
</ul>
</li>
</ul>
<p><br>141 公司运营着一个基于网络的门户网站，为用户提供全球突发新闻、本地警报和天气更新。该<strong>门户网站通过结合静态和动态内容</strong>，为每位用户提供个性化视图。该公司希望门户网站能尽快向全球用户提供这些内容</p>
<p>在单个 AWS 区域部署应用程序栈。通过将 ALB 指定为源，使用 Amazon CloudFront 提供所有静态和动态内容</p>
<p>一个常见的误解是 CDN 只对静态内容有效。实际上，CloudFront 通过 <strong>动态内容加速</strong> 技术也能显著降低动态内容的延迟</p>
<p><br>142 应用程序运行在经过修改的 Linux 内核上，且仅支持基于 UDP 的流量。该公司要求前端层提供尽可能好的用户体验。这一层必须具有低延迟，能将流量路由到最近的边缘位置，并提供静态 IP 地址以用于接入应用程序端点。</p>
<p>配置 AWS Global Accelerator 以将请求转发到网络负载均衡器。在 EC2 Auto Scaling 组中为应用程序使用 Amazon EC2 实例</p>
<ul>
<li><strong>全局流量调度</strong>：<strong>AWS Global Accelerator</strong></li>
<li><strong>负载均衡</strong>：<strong>网络负载均衡器</strong></li>
<li><strong>计算</strong>：<strong>Amazon EC2 Auto Scaling 组</strong></li>
</ul>
<p><strong>计算服务选择</strong>：</p>
<ul>
<li><p><strong>Amazon Route 53</strong>：这是一个 DNS 服务。它可以根据延迟将用户解析到不同区域的 IP 地址，但它本身不提供<strong>静态 IP</strong>，也不加速流量。</p>
</li>
<li><p><strong>Amazon CloudFront</strong>：这是一个 CDN，主要为 <strong>HTTP&#x2F;HTTPS</strong> 流量优化。它对原始的 <strong>UDP 流量</strong> 支持有限或不适配。</p>
</li>
<li><p><strong>Amazon API Gateway</strong>：这是一个完全托管的 API 管理服务，<strong>仅支持 HTTP&#x2F;HTTPS</strong> 协议，不适用于 UDP。</p>
</li>
<li><p><strong>AWS Global Accelerator</strong>：这是满足所有网络层面要求的<strong>唯一正确服务</strong>。</p>
<ul>
<li><strong>静态 IP 地址</strong>：它直接提供<strong>两个固定的静态 Anycast IP 地址</strong>作为应用程序的入口点。</li>
<li><strong>低延迟与就近路由</strong>：用户连接到这两个静态 IP，流量首先进入 Global Accelerator 的全球边缘站点。然后，通过 AWS 的优化内部网络，将流量路由到<strong>延迟最低</strong>的健康终端节点（如 NLB）。</li>
<li><strong>协议无关性</strong>：它在<strong>传输层（TCP&#x2F;UDP）</strong> 工作，完美支持游戏常用的 UDP 协议。</li>
</ul>
</li>
<li><p>由于使用 UDP 协议，必须使用 <strong>网络负载均衡器（NLB）</strong>。NLB 在第四层（传输层）运行，支持 UDP。应用程序负载均衡器（ALB）是第七层（应用层）的，仅支持 HTTP&#x2F;HTTPS。</p>
</li>
</ul>
<p><br>143 公司希望将其现有的本地单体应用迁移到 AWS。<strong>该公司希望尽可能保留大部分前端代码和后端代码。<strong>不过，该公司希望将这个应用</strong>拆分为更小的应用</strong>，每个应用将由不同的团队进行管理。该公司需要一个高度可扩展且能最大限度减少运营开销的解决方案</p>
<p><strong>在亚马逊弹性容器服务（Amazon ECS）上托管应用程序。设置一个以亚马逊弹性容器服务为目标的应用程序负载均衡器</strong></p>
<p>​	<strong>Amazon ECS</strong> 是AWS提供的托管容器编排服务</p>
<p>​	在 <strong>EC2 实例</strong>上托管应用是一种“直接迁移”策略。虽然它保留了现有代码，但它<strong>无法自然地支持应用拆分</strong></p>
<p>​	<strong>AWS Amplify</strong> 主要用于托管<strong>现代Web应用框架（如React, Vue）的前端</strong>。</p>
<p><br>144 公司使用 Amazon Aurora 用作数据存储。当运行大型报告时，开发人员反馈电子商务应用程序性能不佳。在查看 Amazon CloudWatch 中的指标后，解决方案架构师发现，在运行月度报告时，ReadIOPS 和 CPUUtilization 指标出现峰值。</p>
<p><strong>将月度报告迁移到 Aurora 只读副本</strong>。</p>
<ul>
<li><strong>性能影响时机</strong>：仅在<strong>运行大型月度报告</strong>时，电子商务应用程序性能下降。</li>
</ul>
<p><br>145 司在单个亚马逊 EC2 按需实例上托管了一个网站分析应用程序。该分析软件采用 PHP 编写，并使用 MySQL 数据库。分析软件、提供 PHP 支持的 Web 服务器以及数据库服务器均托管在该 EC2 实例上。在繁忙时段，该应用程序出现了性能下降的迹象，并出现 5xx 错误。公司需要让该应用程序实现无缝扩展</p>
<p>将数据库迁移到 Amazon Aurora MySQL 数据库实例。为 Web 应用程序创建一个 AMI。将该 AMI 应用于启动模板。使用启动模板创建一个自动扩展组。配置启动模板以使用 Spot Fleet。将应用程序负载均衡器附加到自动扩展组。</p>
<ul>
<li><code>将数据库迁移到Amazon Aurora</code>：Aurora相比RDS MySQL通常具有更好的性能和成本效益。</li>
<li><code>为Web应用程序创建一个AMI...创建一个自动扩展组</code>：这实现了Web层的<strong>水平扩展</strong>，可以根据负载<strong>自动</strong>增减实例，真正实现了“无缝扩展”。</li>
<li><code>配置启动模板以使用Spot Fleet</code>：这是<strong>成本效益</strong>的关键。Spot实例价格远低于按需实例，可以节省高达90%的计算成本。虽然Spot实例可能中断，但对于无状态的、可重新部署的Web层来说，结合自动扩展组可以很好地容忍这种中断。</li>
<li><code>将应用程序负载均衡器附加到自动扩展组</code>：确保流量被均匀、高效地分发到所有健康的Web实例。</li>
</ul>
<p><br>146 无状态 Web 应用程序，该程序部署在一组亚马逊 EC2 按需实例上，位于应用程序负载均衡器之后。每个<strong>工作日，该应用程序在 8 小时内会经历高负载使用</strong>。夜<strong>间的应用程序使用量适中且稳定</strong>。<strong>周末期间，应用程序的使用量较低</strong>。该公司希望在不影响应用程序可用性的情况下，最大限度地降低 EC2 成本。</p>
<p>为基准使用量采用预留实例。为应用程序所需的任何额外容量采用竞价型实例</p>
<p><strong>EC2成本优化策略</strong>：</p>
<ul>
<li><strong>对于稳定、可预测的基准负载</strong>：最经济的购买选项是 <strong>预留实例</strong>。通过支付预付款或承诺使用一年&#x2F;三年，可以获得大幅折扣（通常比按需实例价格低40%-70%）。</li>
<li><strong>对于可变、不可预测的峰值负载</strong>：最经济的购买选项是 <strong>Spot实例</strong>。Spot实例利用AWS的闲置容量，提供极大的折扣（通常比按需实例价格低70%-90%）。虽然Spot实例可能被中断，但对于无状态、由自动扩展组管理的Web层，结合多个实例分布在不同可用区，可以很好地管理这种风险，<strong>不影响整体应用程序的可用性</strong>。</li>
</ul>
<p>对于具有<strong>可预测基准负载</strong>和<strong>可变峰值负载</strong>的生产无状态应用程序，实现成本最优和可用性平衡的最佳实践是：</p>
<ul>
<li><strong>预留实例</strong> 覆盖基准负载。</li>
<li><strong>Spot实例</strong> 覆盖峰值负载。</li>
</ul>
<p><br>147 公司需要为一个关键应用<strong>保留 10 年</strong>的应用日志文件。应用团队会<strong>定期访问过去一个月的日志以进行故障排查</strong>，但很少访问超过一个月的日志。该应用每月生成超过 <strong>10TB</strong> 的日志。哪种存储选项能最具成本效益</p>
<p>将日志存储在 Amazon S3 中。使用 S3 生命周期策略将超过 1 个月的日志转移到 S3 Glacier Deep Archive。</p>
<ol>
<li><strong>AWS存储服务选择</strong>：<ul>
<li><strong>近期日志（频繁访问）</strong>：需要<strong>即时检索</strong>和较高的可用性。<ul>
<li><strong>Amazon S3 标准存储</strong> 或 <strong>Amazon CloudWatch Logs</strong> 都适合。</li>
</ul>
</li>
<li><strong>远期日志（长期归档）</strong>：核心要求是<strong>最低存储成本</strong>。<ul>
<li><strong>Amazon S3 Glacier Deep Archive</strong> 是AWS中<strong>成本最低</strong>的存储类别，专为很少访问且需要保存数年甚至数十年的数据设计。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><br>148 公司有一个数据摄入工作流，其中包括以下组件：一个接收有关新数据交付通知的 Amazon SNS主题，一个处理和存储数据的 AWS Lambda 函数。由于网络连接问题，该摄入工作流偶尔会失败。当失败发生时，除非公司手动重新运行作业，否则相应的数据不会被摄入。</p>
<p>将 Amazon Simple Queue Service（Amazon SQS）队列配置为失败时的目标。修改 Lambda 函数以处理队列中的消息</p>
<ul>
<li><p><strong>失败原因</strong>：<strong>网络连接问题</strong>。这是一种<strong>瞬时性故障</strong>，意味着它可能是暂时的，重试后可能会成功。</p>
</li>
<li><p>当前架构是 <strong>SNS -&gt; Lambda</strong>。这是一个“推送”模型。如果Lambda处理失败，消息就丢失了。</p>
</li>
<li><p>需要一个<strong>缓冲区和重试机制</strong>。标准的AWS模式是引入 <strong>Amazon SQS</strong>（简单队列服务）。</p>
</li>
<li><p>正确的架构应改为 <strong>SNS -&gt; SQS -&gt; Lambda</strong>。</p>
</li>
</ul>
<p><br>149 公司有一项生成事件数据的服务。该公司希望使用 AWS 在接收事件数据时对其进行处理。<strong>这些数据按特定顺序写入，且在整个处理过程中必须保持该顺序</strong>。公司希望实施一种能最大限度减少运营开销</p>
<p>创建一个 Amazon Simple Queue Service（Amazon SQS）FIFO 队列来存储消息。设置一个 AWS Lambda 函数来处理队列中的消息</p>
<ul>
<li><strong>保证消息顺序</strong>：<ul>
<li><strong>Amazon SQS 标准队列</strong>：提供<strong>尽力而为</strong>的排序，但<strong>不保证</strong>严格的先进先出顺序。多个消费者可能以乱序处理消息。</li>
<li><strong>Amazon SQS FIFO 队列</strong>：<strong>严格保证</strong>消息的发送和接收顺序，并且<strong>仅处理一次</strong>。这是满足“必须保持该顺序”要求的<strong>唯一选择</strong>。</li>
</ul>
</li>
<li><strong>实时处理与低运维</strong>：<ul>
<li><strong>AWS Lambda</strong> 是一个无服务器计算服务，可以设置为由SQS队列触发。当消息到达FIFO队列时，它会自动调用Lambda函数进行处理。这实现了实时处理，并且由于是无服务器的，<strong>运营开销极低</strong>（无需管理服务器）</li>
</ul>
</li>
</ul>
<p><br>150 司正将一个应用程序从本地服务器迁移到 Amazon EC2 实例。如果 CPU 利用率超过 50%，同时磁盘的读取 IOPS 较高，公司则需要尽快采取行动。解决方案架构师还必须减少误报。</p>
<p>尽可能创建 Amazon CloudWatch 复合告警。</p>
<p><strong>减少误报</strong>：如果只有其中一个条件发生（例如，只有CPU高，但IOPS正常），则<strong>不应触发</strong>告警。这正是题目中“减少误报”的核心要求</p>
<p><br>151 公司希望将其本地数据中心迁移到 AWS。根据该公司的合规要求，其只能使用亚太地区（东京）区域（ap-northeast-3）。公司管理员不允许将虚拟私有云（VPC）连接到互联网</p>
<p><strong>使用 AWS Control Tower 实施数据驻留防护措施，以拒绝互联网访问，并拒绝除亚太东北 3 区外所有 AWS 区域的访问。</strong></p>
<p><strong>使用 AWS Organizations 配置服务控制策略（SCPS），以阻止虚拟私有云（VPC）获取互联网访问权限。拒绝除亚太东北 3 区之外的所有 AWS 区域的访问权限。</strong></p>
<ul>
<li><p><strong>A (正确)</strong>：<strong>AWS Control Tower</strong> 是设置和管理安全、合规的多账户AWS环境的<strong>最佳实践服务</strong>。它通过“防护措施”来实施强制性策略。</p>
<ul>
<li><code>数据驻留防护措施</code>：可以配置为<strong>拒绝创建互联网网关</strong>，从而阻止VPC连接到互联网。</li>
<li>它同样可以配置为<strong>拒绝在除指定区域（ap-northeast-3）外的任何区域访问或创建资源</strong>。</li>
<li>Control Tower 在后台利用 AWS Organizations 的服务控制策略（SCP）来实现这些防护，提供了一个更易于使用的管理界面。</li>
</ul>
</li>
<li><p><strong>C (正确)</strong>：<strong>使用 AWS Organizations 服务控制策略（SCP）</strong> 是实现这些要求的<strong>核心底层机制</strong>。</p>
<ul>
<li>SCP是一种策略，可以<strong>集中控制</strong>组织内所有账户对AWS服务和资源的访问权限。</li>
<li>可以编写SCP来<strong>显式拒绝</strong> <code>ec2:AttachInternetGateway</code> 和 <code>ec2:CreateInternetGateway</code> 等操作，从而阻止VPC连接互联网。</li>
<li>同样可以编写SCP来<strong>拒绝所有不在ap-northeast-3区域的服务调用</strong>，强制所有资源部署在该区域。</li>
</ul>
</li>
</ul>
<p><br>152 公司使用三层 Web 应用程序为新员工提供培训，该应用每天只运行 12 小时。他们使用 Amazon RDS for MySQL 数据库存储数据，并希望尽量降低成本。</p>
<p><strong>使用 Lambda 函数启停 RDS，用 EventBridge 定时触发</strong></p>
<p>在 AWS 中，RDS 实例在不使用时可以通过<strong>停止</strong>来节省费用（计算资源不再计费，只收存储费用）。<br>由于应用有固定的运行时间（12 小时&#x2F;天），可以在非使用时段停止数据库，并在需要时启动。</p>
<p><br>153 公司销售由流行歌曲片段制作的铃声，文件存储在 Amazon S3 Standard 中，大小至少 128 KB。文件数量数百万，超过 90 天的铃声下载频率很低。公司需要在节省存储成本的同时，确保用户能随时获取访问量最大的文件</p>
<p><strong>实施 S3 生命周期策略，90 天后转移到 S3 Standard-IA</strong></p>
<p>新对象保留在 Standard（访问频繁），90 天后自动移到 Standard-IA 标准不频繁访问存储（访问少，存储费低），仍然可随时低延迟访问，无需额外管理</p>
<p><br>154 公司需要将医学试验结果保存到 Amazon S3 存储库，要求：</p>
<ul>
<li>少数科学家可以添加新文件</li>
<li>其他用户只能只读访问</li>
<li>任何用户都不能修改或删除文件</li>
<li>每个文件自创建之日起至少保留 1 年</li>
</ul>
<p><strong>合规模式下的 S3 对象锁定，保留期 365 天</strong></p>
<ul>
<li><p>合规模式下，在保留期内<strong>任何人（包括根用户）</strong> 都无法修改或删除对象，完全满足“任何用户都不能修改或删除”的要求</p>
</li>
<li><p>治理模式允许特定权限的用户在特殊情况下（有特定权限）覆盖保留设置，不满足“任何用户都不能修改或删除”的严格需求</p>
</li>
</ul>
<p><br>155 公司在 AWS 上托管 Web 应用程序，希望缓存机密媒体文件，以便全球用户能够可靠且快速地访问这些文件。内容存储在 Amazon S3 存储桶中，要求无论用户来自哪个地理位置，都必须快速交付内容</p>
<p><strong>Amazon CloudFront + S3</strong></p>
<p><br>156 公司有来自不同数据库的批量数据，以及来自网络传感器和 API 的实时流数据。需要将所有数据整合到一个地方进行业务分析。处理后存储到不同的 S3 存储桶，之后各团队运行一次性查询导入到商业工具以进行展示</p>
<p><strong>Amazon Athena（无服务器查询 S3 数据） + Amazon QuickSight（BI 仪表板）</strong></p>
<p><strong>AWS Lake Formation 蓝图识别数据 + AWS Glue 爬取数据并转为 Parquet 存入 S3</strong></p>
<ul>
<li>Athena 适合一次性查询，QuickSight 直接连接 Athena 或 S3 展示 KPI，完全托管</li>
<li>Lake Formation 可用于构建数据湖，Glue 是托管 ETL&#x2F;爬虫服务，将数据统一存入 S3 并转为列式格式（Parquet），便于 Athena 查询，符合“整合数据”和“最少运营开销”。</li>
</ul>
<p><br>157 公司使用 Amazon Aurora PostgreSQL 数据库集群</p>
<ul>
<li>所有数据存储 5 年，5 年后删除</li>
<li>无限期保留数据库内执行操作的审计日志</li>
<li>目前已配置 Aurora 自动备份</li>
</ul>
<p>解析：</p>
<ul>
<li><strong>为数据库集群配置 Amazon CloudWatch 日志导出</strong><ul>
<li>可以将 Aurora 审计日志（如 PostgreSQL 的日志）发送到 CloudWatch Logs，然后设置无限期保留或导出到 S3 进行长期归档，满足“无限期保留审计日志”。</li>
</ul>
</li>
<li>使<strong>用 AWS Backup 进行备份并将备份保留 5 年</strong><ul>
<li>AWS Backup 支持 Aurora 备份，可设置备份策略保留 5 年，到期自动删除，满足数据保留 5 年后删除的需求</li>
</ul>
</li>
</ul>
<p><br>158 架构师正在为一场即将到来的音乐活动优化网站。演出视频将进行实时流媒体传输，之后还会提供点播服务。预计<strong>观众来自全球</strong>。问哪种服务可以同时提升实时流媒体和点播流媒体的性能</p>
<p><strong>Amazon CloudFront</strong></p>
<p><br>159 公司运行一个使用 Amazon API Gateway 和 AWS Lambda 的公开无服务器应用。最近因<strong>僵尸网络的欺诈性请求导致流量激增</strong>。<br>问解决方案架构师应采取哪两项步骤来阻止未授权用户的请求。</p>
<p><strong>创建使用计划，包含仅与真实用户共享的 API 密钥</strong></p>
<p><strong>实施 AWS WAF 规则针对恶意请求并过滤</strong></p>
<p><br>160 一家电子商务公司的分析应用程序每月生成约 300MB 的 JSON 数据，需要灾难恢复备份方案。要求：</p>
<ul>
<li>数据在需要时能<strong>毫秒级访问</strong></li>
<li>数据必须保留 <strong>30 天</strong></li>
<li><strong>最具成本效益</strong></li>
</ul>
<p><strong>Amazon S3 Standard</strong> - 数据量小（300MB&#x2F;月），S3 标准存储成本很低，可设置生命周期策略在 30 天后删除或转储到更便宜的层（但这里只是保留 30 天，直接存 S3 Standard 总费用也很低）</p>
<p><br>161 公司有一个小型 Python 应用程序，处理 JSON 文档并输出到本地 SQL 数据库。每天运行数千次。希望迁移到 AWS，需要高可用，最大化可扩展性，最小化运营开销</p>
<p> 将JSON文档放入Amazon S3存储桶中。创建一个AWS Lambda函数，运行Python代码以在文档到达S3存储桶时对其进行处理。将结果存储在Amazon Aurora数据库集群中。</p>
<p>S3 + Lambda（Python） + Aurora</p>
<p><br>162 公司希望在 AWS 上使用 HPC 基础设施进行金融风险建模，工作负载运行在 Linux 上。特点：</p>
<ul>
<li>每个 HPC 工作流使用数百个 EC2 Spot 实例</li>
<li>实例生命周期短</li>
<li>生成数千个输出文件，需存入持久存储用于分析和长期使用</li>
<li>需要将本地数据复制到长期持久存储，且所有 EC2 实例能获取数据</li>
<li>需要一个高性能文件系统，与持久存储集成，用于读写数据集和输出文件</li>
</ul>
<p><strong>Amazon FSx for Lustre + Amazon S3</strong></p>
<p>FSx for Lustre 是高性能并行文件系统，专为 HPC 设计，与 S3 集成</p>
<p><br>163 公司正在本地构建容器化应用，决定迁移到 AWS。应用很快会有数千用户。公司不确定如何大规模管理容器部署。要求：高可用架构以及最小化运营开销</p>
<p>Amazon ECR + Amazon ECS（Fargate 启动类型） + 目标跟踪自动扩展</p>
<p><br>164 一家公司有两个应用：</p>
<ul>
<li>发送方应用：发送包含待处理负载的消息</li>
<li>处理应用：接收并处理这些消息</li>
</ul>
<p>要求：</p>
<ul>
<li>发送方每小时约 1000 条消息</li>
<li>消息可能需要长达 2 天才能被处理</li>
<li>如果消息处理失败，必须保留且不影响其他消息处理</li>
<li>需要最高运营效率</li>
</ul>
<p><strong>Amazon SQS + 死信队列</strong></p>
<ul>
<li><p>SQS 是托管消息队列，支持消息保留最多 14 天（满足 2 天要求）</p>
</li>
<li><p><strong>死信队列（Dead-Letter Queue，DLQ）</strong> 是一种用于接收和处理<strong>无法正常消费的消息</strong>的中间队列。</p>
</li>
<li><p><strong>简单来说，死信队列就是一个“消息的隔离区”，专门存放反复处理失败的消息，保证主队列的正常运转</strong></p>
</li>
</ul>
<p><br>165 解决方案架构师需要设计一个使用 CloudFront + S3 的静态网站方案。安全策略要求：所有网站流量必须经过 AWS WAF 检查</p>
<p><strong>配置 CloudFront 和 S3 使用 OAI（Origin Access Identity）限制 S3 访问，并在分发上启用 AWS WAF</strong></p>
<ol>
<li>OAI 确保用户只能通过 CloudFront 访问 S3，不能直接访问 S3（防止绕过 WAF）- 在 CloudFront 分发中创建一个 OAI（本质是一个特殊的 AWS IAM 角色）。</li>
<li>在 CloudFront 分发上启用 AWS WAF Web ACL，所有经过 CloudFront 的流量都会经过 WAF 检查</li>
</ol>
<p><br>166 活动组织者需要发布每日报告（静态 HTML 页面），预计全球用户有数百万次浏览。文件存储在 Amazon S3 中。要求设计一个<strong>高效且有效</strong>的解决方案。</p>
<p><u><strong>将 Amazon S3 存储桶作为源，使用 Amazon CloudFront</strong></u></p>
<p><br>167 一家公司在 EC2 实例上运行生产应用程序，从 SQS 队列读取并并行处理消息。特点：</p>
<ul>
<li>消息量不可预测，流量断断续续</li>
<li>必须持续处理消息，不能停机</li>
</ul>
<p><u><strong>基准容量用预留实例 + 额外容量用按需实例</strong></u></p>
<ul>
<li>Spot 实例可能被中断，会导致处理中断，不满足“不能有任何停机时间”</li>
</ul>
<p><br>168 一个安全团队希望限制该团队<strong>所有 AWS 账户</strong>中特定服务或操作的访问。</p>
<ul>
<li>所有账户属于 AWS Organizations 中的一个组织</li>
<li>解决方案需要<strong>可扩展</strong></li>
<li>需要<strong>单点维护权限</strong></li>
</ul>
<p><u><strong>在根组织单元（OU）中创建服务控制策略（SCP）以拒绝访问相关服务或操作</strong></u></p>
<ul>
<li>访问控制列表（ACL是网络层（VPC 子网）或 S3 存储桶级别的权限控制，不用于账户级别的服务访问限制</li>
<li>安全组用于 EC2 实例网络流量控制，不用于管理 AWS 服务 API 访问权限 </li>
<li>账户角色用于授权其他账户访问本账户资源，不是用来限制服务使用</li>
</ul>
<p><br>169 一家公司担心其公共 Web 应用程序遭受 DDoS 攻击，该应用程序使用应用程序负载均衡器（ALB）。<br>要求：<strong>降低 DDoS 攻击风险</strong>。</p>
<p><strong><u>启用 AWS Shield Advanced 以防止攻击</u></strong></p>
<ul>
<li><p>Amazon Macie用于发现和保护敏感数据（利用机器学习识别 PII 等）的服</p>
</li>
<li><p>GuardDuty 是威胁检测服务，通过分析 VPC 流日志、CloudTrail 事件等识别恶意活动，但它主要是检测和告警</p>
</li>
</ul>
<p><br>170 公司的 Web 应用程序运行在 ALB 后面的 EC2 实例上。<br>新政策要求：<strong>只能从一个特定国家访问应用程序</strong></p>
<p><u>在 ALB 上配置 AWS WAF</u></p>
<ul>
<li>AWS WAF 支持 <strong>地理匹配条件（Geo Match Condition）</strong>，可允许或阻止特定国家的流量</li>
</ul>
<p><br>171 公司提供 API，根据商品价格自动计算税费。<br>特点：</p>
<ul>
<li>仅在节假日期间有大量查询</li>
<li>流量突发导致响应变慢<br>要求：</li>
<li>设计<strong>可扩展</strong>和<strong>弹性</strong>的解决方案</li>
</ul>
<p><strong><u>API Gateway + Lambda</u></strong></p>
<ul>
<li>API Gateway 自动处理高并发 API 请求</li>
<li>Lambda 按执行计费，无流量时无成本，突发时自动扩展，毫秒级扩容</li>
<li>完全托管，无需管理服务器</li>
</ul>
<p><br>172 解决方案架构师为应用程序创建 CloudFront 分发，用户提交的部分信息属于敏感信息。应用程序使用 HTTPS，需要<strong>另一层安全保护</strong></p>
<p><strong><u>配置 CloudFront 字段级加密配置文件</u></strong></p>
<ul>
<li><strong>字段级加密</strong> 在 CloudFront 边缘节点对指定表单字段在转发到源站之前进行加密</li>
</ul>
<p><br>173 一家游戏公司在 AWS 上托管基于浏览器的应用，用户消耗大量存储在 S3 中的视频和图像。全球数百万用户访问，目标：在为用户提供文件的同时，减轻源站（S3）负载</p>
<p><strong><u>在 S3 存储桶前部署 Amazon CloudFront Web 分发</u></strong></p>
<p><br>174 一家公司有多层应用程序，架构为：应用程序负载均衡器（ALB）后面，单个可用区中的 EC2 自动扩展组，运行六个前端 Web 服务器</p>
<p><strong><u>修改自动扩展组，在两个可用区中各用三个实例</u></strong></p>
<p><br>175 一家电商公司的订单处理应用使用，API Gateway + Lambda，Aurora PostgreSQL 数据库，促销期间订单激增，客户遇到超时，促销期间订单激增，客户遇到超时，要求防止超时错误和尽可能少修改应用程序</p>
<ul>
<li>根本原因：Lambda 函数并发高时，每个函数可能打开一个数据库连接，导致数据库连接数暴增，资源耗尽</li>
<li>要求少改应用 → 最好只改连接配置，不重写业务逻辑</li>
</ul>
<p><strong><u>使用 Amazon RDS Proxy 创建代理，修改 Lambda 使用代理端点</u></strong></p>
<ul>
<li><strong>RDS Proxy</strong> 专门用于数据库连接池和管理，可复用连接，防止数据库被大量并发连接压垮</li>
<li>Lambda 只需改连接字符串（端点），几乎不修改业务逻辑</li>
</ul>
<p><br>176 应用程序在私有子网的 EC2 实例上运行，需要访问 Amazon DynamoDB 表。<br>要求：确保流量不离开 AWS 网络，最安全的方式</p>
<p><strong><u>使用 DynamoDB 的 VPC 终端节点（VPC Endpoint for DynamoDB</u></strong>）</p>
<p>NAT 网关可使私有子网实例访问互联网</p>
<p><br>177 娱乐公司使用 Amazon DynamoDB 存储媒体元数据。<br>问题：</p>
<ul>
<li>读操作密集，遭遇延迟</li>
<li>没有人员处理额外运营开销</li>
<li>不重新配置应用程序</li>
<li>需要提高 DynamoDB 性能效率</li>
</ul>
<p><u><strong>使用 Amazon DynamoDB Accelerator (DAX)</strong></u></p>
<ul>
<li>DAX 是 DynamoDB 的完全托管内存缓存</li>
<li>与 DynamoDB API 兼容，只需更改端点，几乎无需修改应用程序代码</li>
<li>大幅降低读取延迟（微秒级）</li>
<li>Memcached 不是完全兼容 DynamoDB API，运营开销大于 DAX</li>
</ul>
<p><br>178 公司的基础设施在单个 AWS 区域中有 EC2 实例和 RDS 数据库实例。<br>目标：在另一个区域备份数据，最少的运营开销</p>
<p><u><strong>使用 AWS Backup，将 EC2 备份和 RDS 备份复制到另一个区域</strong></u></p>
<ul>
<li>可配置跨区域复制备份，完全托管，自动化执行</li>
</ul>
<p><br>179 解决方案架构师需要安全存储应用程序访问 RDS 数据库的用户名和密码。</p>
<ul>
<li>应用程序运行在 EC2 实例上</li>
<li>使用 <strong>AWS Systems Manager Parameter Store</strong> 存储安全参数<br>问需要采取什么措施满足要求。</li>
</ul>
<p><u><strong>创建对 Parameter Store 参数具有读取权限的 IAM 角色，允许对加密参数的 KMS 密钥进行解密访问，将此 IAM 角色分配给 EC2 实例</strong></u></p>
<ul>
<li>对于<strong>不需要轮换的应用程序机密信息</strong>，<strong>Parameter Store</strong> 是<strong>更具成本效益</strong>的选择。</li>
<li>对于<strong>需要自动轮换的数据库凭证、API 密钥等</strong>，应使用 <strong>Secrets Manager</strong>。</li>
</ul>
<p><br>180 公司设计 API 驱动的云通信平台，架构为：</p>
<ul>
<li>外部用户 → <strong>Amazon API Gateway</strong> → <strong>网络负载均衡器 (NLB)</strong> → <strong>EC2 实例</strong><br>要求：</li>
<li>保护平台免受 <strong>SQL 注入等网络攻击</strong></li>
<li>检测并缓解 <strong>大规模、复杂 DDoS 攻击</strong></li>
<li>选择两项提供<strong>最强保护</strong>的组合</li>
</ul>
<p><u><strong>将 AWS Shield Advanced 与 NLB 配合使用</strong></u></p>
<p><u><strong>使用 AWS WAF 保护 Amazon API Gateway</strong></u></p>
<ol>
<li><strong>防御 SQL 注入等 Web 攻击</strong> → 需要 <strong>AWS WAF</strong>（Web 应用防火墙）</li>
<li><strong>防御大规模复杂 DDoS 攻击</strong> → 需要 <strong>AWS Shield Advanced</strong>（提供高级 DDoS 防护、24&#x2F;7 DRT 支持、成本保护等）</li>
<li>AWS WAF <strong>不能</strong> 直接与 NLB 集成。WAF 仅支持 ALB、CloudFront 分发、API Gateway</li>
<li>GuardDuty 是威胁检测服务（监控可疑 API 调用、未经授权的部署等），不是实时防护；Shield Standard 自动启用但不提供复杂 DDoS 高级缓解</li>
<li>用户流量路径：Internet → (Shield Standard 自动保护 API Gateway) → WAF on API Gateway (防 Web 攻击) → NLB (Shield Advanced 防 DDoS) → EC2</li>
</ol>
<p><br>181 一家公司有一个遗留数据处理应用，目前在 EC2 上按顺序处理数据，但结果顺序不重要。应用是单体架构，只能垂直扩展（增大实例）。<br>现在决定重写为在 <strong>Amazon ECS 上运行的微服务架构</strong>。<br>问解决方案架构师应为微服务之间的通信推荐什么方案。</p>
<p><strong><u>创建 Amazon SQS 队列，生产者发送数据到队列，消费者从队列处理数据</u></strong></p>
<p><br>182 公司希望将 MySQL 数据库从本地迁移到 AWS。<br>背景：最近遭遇数据库宕机，对业务影响严重。<br>要求：</p>
<ul>
<li>获得可靠的数据库解决方案</li>
<li><strong>最大限度地减少数据丢失</strong></li>
<li><strong>将每笔交易存储在至少两个节点上</strong></li>
</ul>
<p><strong><u>创建一个启用了多可用区（Multi-AZ） 的 Amazon RDS MySQL 数据库实例，以同步复制数据</u></strong></p>
<ul>
<li>RDS 不支持<strong>三节点同步复制</strong>（这是 Aurora 的特性）</li>
<li><strong>跨区域只读副本是异步复制</strong>，不是同步</li>
</ul>
<p><br>183 公司构建新的动态订购网站，要求：</p>
<ul>
<li>尽可能减少服务器维护和补丁更新</li>
<li>高可用性</li>
<li>能够尽快扩展读写容量以满足用户需求变化</li>
</ul>
<p><strong><u>在Amazon S3中托管静态内容。通过Amazon API Gateway和AWS Lambda托管动态内容。将Amazon DynamoDB与按需容量一起用于数据库。配置Amazon CloudFront来交付网站内容。</u></strong></p>
<p><strong>Aurora 数据库</strong> → 虽然 Aurora 自动扩展可以增加只读副本，但<strong>写容量扩展较慢</strong></p>
<p><br>184 公司有一个 AWS 账户，通过 <strong>一对 Direct Connect</strong> 连接访问本地数据中心。所有非 VPC 流量路由到虚拟专用网关。<br>开发团队通过控制台创建了一个 <strong>Lambda 函数</strong>，需要让该函数访问在<strong>本地数据中心私有子网中运行的数据库</strong>。</p>
<p><strong><u>将 Lambda 函数配置为在其有适当安全组的 VPC 中运行</u></strong></p>
<ul>
<li><p>Lambda 在 VPC 中运行时，会获得一个 VPC 内的 IP 地址，可通过 VPC 路由表经由 Direct Connect 访问本地网络</p>
</li>
<li><p>安全组控制出站规则</p>
</li>
<li><p>完全利用现有 Direct Connect 连接，无需新建 VPN</p>
</li>
<li><p><strong>现状</strong>：公司已经有一个VPC，并且这个VPC通过虚拟专用网关和Direct Connect连接到了本地数据中心。</p>
</li>
<li><p><strong>问题</strong>：Lambda函数默认不在任何VPC中运行，所以它“站在云的外面”，无法进入这个通往本地数据中心的“私人网络通道”。</p>
</li>
<li><p><strong>解决方案</strong>：将Lambda函数配置到那个特定的VPC中。一旦进入VPC，Lambda函数就能“看到”通往本地网络的路由，从而可以通过Direct Connect访问本地的数据库。</p>
</li>
</ul>
<p><br>185 公司使用 <strong>Amazon ECS</strong> 运行一个应用程序。该应用程序会创建原始图像的缩放版本，然后调用 <strong>Amazon S3 API</strong> 将处理后的图像存储到 <strong>Amazon S3</strong>。<br>解决方案架构师需要确保应用程序有权访问 Amazon S3。</p>
<p><u><strong>创建一个具有 S3 权限的 IAM 角色，然后在任务定义中将该角色指定为 taskRoleArn。</strong></u></p>
<ol>
<li>创建一个 IAM 角色，并附加授予必要 S3 权限的策略。</li>
<li>在 ECS <strong>任务定义</strong> 中，通过 <code>taskRoleArn</code> 字段将该角色分配给任务。</li>
<li>运行该任务定义的任何容器都将自动继承该角色的权限，从而可以调用 S3 API。S</li>
</ol>
<p><br>186 公司有一个基于 <strong>Windows</strong> 的应用程序需要迁移到 AWS。该应用程序需要使用一个<strong>共享的 Windows 文件系统</strong>，该文件系统必须连接到<strong>部署在多个可用区中的多个 Amazon EC2 Windows 实例</strong>。</p>
<p> <strong><u>配置适用于 Windows 文件服务器的 Amazon FSx。将 Amazon FSx 文件系统挂载到每个 Windows 实例</u></strong></p>
<ul>
<li><strong>mazon FSx for Windows File Server</strong> 是专门为 Windows 环境构建的、完全托管的原生文件共享服务。</li>
<li>它原生支持 <strong>SMB 协议</strong> 和 <strong>Windows NTFS</strong> 权限、 Active Directory 集成等。</li>
<li>它本身就是<strong>多可用区高可用</strong>架构，可以同时被多个可用区中的 Windows 实例挂载</li>
<li><strong>Amazon Elastic File System（Amazon EFS）配置文件系统</strong>是基于 <strong>NFS</strong> 协议的文件存储服务，主要面向 <strong>Linux</strong> 工作负载。</li>
</ul>
<p><br>187 公司正在开发一个电子商务应用程序，架构包含：</p>
<ul>
<li>负载均衡的前端</li>
<li>基于容器的应用</li>
<li>关系型数据库</li>
</ul>
<p>要求：</p>
<ul>
<li>创建<strong>高可用性</strong>解决方案</li>
<li>运行<strong>尽可能减少人工干预</strong></li>
</ul>
<p><u><strong>在多可用区模式下创建一个</strong> Amazon RDS 数据库实例</u></p>
<p><u><strong>创建一个采用 Fargate 启动类型的 Amazon ECS 集群，以处理动态应用负载</strong></u></p>
<ul>
<li><strong>RDS Multi-AZ</strong> 在另一个可用区同步维护一个备用副本，主实例故障时自动故障转移，提供高可用性。完全托管，自动处理故障转移</li>
<li><strong>Amazon ECS on Fargate</strong> 是无服务器计算引擎，无需管理 EC2 实例（服务器、补丁、扩缩）。</li>
</ul>
<p><br>188 公司使用 Amazon S3 作为其数据湖。该公司有一个新合作伙伴，该合作伙伴必须使用 SFTP 来上传数据文件。一位解决方案架构师需要实施一个高可用的 SFTP 解决方案，同时最大限度地减少运营开销</p>
<p><u><strong>使用 AWS Transfer Family 配置具有可公开访问端点的启用 SFTP 的服务器。选择 S3 数据湖作为目的地</strong></u></p>
<ul>
<li><strong>AWS Transfer Family</strong> 是 AWS 提供的<strong>完全托管</strong>的服务，专门用于通过 SFTP、FTPS、FTP 协议在 Amazon S3 或 Amazon EFS 之间传输文件。</li>
<li>Amazon S3 File Gateway 提供了一个 <strong>NFS 或 SMB</strong> 协议接口，用于将文件存储到 S3。它<strong>本身并不是一个 SFTP 服务器</strong>，无法直接处理 SFTP 连接。</li>
</ul>
<p><br>189 公司需要存储合同文件，合同有效期为5年。要求如下：</p>
<ol>
<li>在5年期间，文件<strong>不能被覆盖或删除</strong>。</li>
<li>需要对静态文件进行<strong>加密</strong>。</li>
<li>需要<strong>每年自动轮换加密密钥</strong>。</li>
<li>解决方案需要<strong>使运营开销最小</strong></li>
</ol>
<p><u><strong>将文档存储在Amazon S3中。使用合规模式下的S3对象锁定</strong></u></p>
<p><u><strong>使用带有AWS密钥管理服务（AWS KMS）客户管理密钥的服务器端加密。配置密钥轮换。</strong></u></p>
<p><strong>治理模式</strong>下，拥有<code>s3:BypassGovernanceRetention</code>权限的<strong>用户可以在特殊情况下覆盖或删除</strong>处于保留状态的对象</p>
<p><strong>合规模式</strong>下，在保留期限内<strong>任何人都无法覆盖或删除</strong>被锁定的对象，包括根用户。这提供了最强的不可变性保证</p>
<p><strong>对于导入的密钥材料，KMS不支持自动轮换</strong>。轮换需要手动操作</p>
<p><br>190 公司有一个基于 <strong>Java 和 PHP</strong> 的 Web 应用程序，计划从本地迁移到 AWS。要求如下：</p>
<ol>
<li>能够<strong>频繁测试新的网站功能</strong>。</li>
<li>需要一个<strong>高可用</strong>的解决方案。</li>
<li>需要一个<strong>托管</strong>的解决方案。</li>
<li>要求将<strong>运营开销降至最低</strong>。</li>
</ol>
<p><u><strong>将 Web 应用程序部署到 AWS Elastic Beanstalk 环境中。使用 URL 交换在多个 Elastic Beanstalk 环境之间切换以进行功能测试</strong></u></p>
<p><strong>Elastic Beanstalk</strong> 是一个<strong>托管服务</strong>，专门用于部署和扩展Web应用程序。它自动处理容量配置</p>
<p><br>191 公司的订单应用程序将数据存储在 <strong>Amazon RDS for MySQL</strong> 中。<br><strong>问题</strong>：在正常工作时间，员工运行的报告查询（一次性查询）耗时过长，导致订单处理过程出现超时。</p>
<p><strong><u>创建一个只读副本。将报表查询移至只读副本。</u></strong></p>
<p><br>192 医院希望将其大量的历史书面记录数字化，并且每天还会新增数百份文档。数据团队会扫描并上传这些文档到 AWS。<br><strong>要求</strong>：</p>
<ol>
<li>实施一个解决方案，用于<strong>分析文档、提取医疗信息</strong>。</li>
<li><strong>存储文档</strong>，以便应用程序能够对这些数据<strong>运行 SQL 查询</strong>。</li>
<li>解决方案必须<strong>最大限度地提高可扩展性和运营效率</strong>。</li>
</ol>
<p><strong><u>将文档信息写入 Amazon S3 存储桶。使用 Amazon Athena 查询数据</u></strong></p>
<p><strong><u>创建一个 AWS Lambda 函数，在上传新文档时运行。使用 Amazon Textract 将文档转换为原始文本。使用 Amazon Comprehend Medical 从文本中检测并提取相关医疗信息</u></strong></p>
<ul>
<li><p><strong>Amazon S3</strong> 是可无限扩展、高持久性的对象存储，适合存储原始文档和处理后的数据。</p>
</li>
<li><p><strong>Amazon Athena</strong> 是无服务器的交互式查询服务，允许使用标准 SQL 直接分析 S3 中的数据</p>
</li>
<li><p><strong>Amazon Textract</strong> 是专门用于从扫描文档和图像中<strong>提取文本、表格和表单</strong>的服务。</p>
</li>
<li><p><strong>Amazon Comprehend Medical</strong> 是专门用于从文本中<strong>检测和提取医疗信息</strong>（如药物、病情、治疗、保护健康信息PHI）的自然语言处理服务。</p>
</li>
<li><p><strong>AWS Lambda</strong> 提供无服务器的事件驱动执行，在上传新文档时自动触发处理流程，<strong>可扩展性高，运营效率高</strong></p>
</li>
</ul>
<p><br>193 公司在 Amazon EC2 实例上运行一个批处理应用程序，该应用程序包含一个后端和多个 Amazon RDS 数据库。<br><strong>问题</strong>：应用程序导致数据库上的<strong>读取次数过多</strong>。</p>
<ol>
<li><strong>减少数据库读取次数</strong>。</li>
<li><strong>确保高可用性</strong>。</li>
</ol>
<p><strong><u>添加 Amazon RDS 只读副本。</u></strong> —？ 无法减少读取次数</p>
<p><strong><u>使用 Amazon ElastiCache for Redis</u></strong></p>
<ul>
<li><strong>ElastiCache</strong> 是一个<strong>托管的内存缓存服务</strong>。</li>
<li>将频繁读取的、相对静态的或计算结果数据<strong>缓存</strong>在内存中</li>
</ul>
<p><br>194 一家公司需要在 AWS 上运行一个关键应用程序，并使用 <strong>Amazon EC2 来运行应用程序的数据库</strong>。<br><strong>要求</strong>：</p>
<ol>
<li>数据库必须具备<strong>高可用性</strong>。</li>
<li>在发生中断性事件时能够<strong>自动进行故障转移</strong>。</li>
</ol>
<p><u><strong>启动两个 EC2 实例，每个位于同一 AWS 区域的不同可用区中。在两个 EC2 实例上安装数据库，配置为集群，并设置数据库复制</strong></u></p>
<p> <strong>单实例 + AMI 备份 + CloudFormation 恢复</strong> -  这是一个<strong>灾难恢复</strong>方案，而不是<strong>高可用</strong>方案</p>
<p><br>195 公司的订单系统将客户请求发送到 Amazon EC2 实例，这些实例处理订单后将其存储在 Amazon RDS 数据库中。<br><strong>问题</strong>：当系统出现故障时，用户必须<strong>重新处理订单</strong>。<br><strong>要求</strong>：<br>获得一个<strong>具有弹性的解决方案</strong>，以便在系统发生中断时能够<strong>自动处理订单</strong>。</p>
<p><strong><u>. 将 EC2 实例移入 Auto Scaling 组。配置订单系统向 Amazon Simple Queue Service 队列发送消息。配置 EC2 实例从该队列消费消息。</u></strong></p>
<ul>
<li>SNS 是推送服务，如果 Lambda 或 EC2 实例不可用，消息可能丢失（除非配合 SQS）。</li>
</ul>
<p><br>196 公司在大量 EC2 实例上运行一个应用程序，该应用程序向 <strong>Amazon DynamoDB</strong> 表读写数据。<br><strong>现状</strong>：DynamoDB 表持续增长，但应用程序<strong>只需要过去 30 天的数据</strong>。<br><strong>要求</strong>：需要一个能<strong>最大限度降低成本和开发工作量</strong>的解决方案。</p>
<p><strong><u>扩展应用程序，为表中创建的每个新项目添加一个属性，其值为当前时间戳加上 30 天。配置 DynamoDB 以使用该属性作为 TTL 属性。</u></strong></p>
<ol>
<li><strong>完全托管</strong>：启用 TTL 后，DynamoDB 服务会自动在后台扫描并删除过期项，<strong>无需任何服务器、脚本或持续管理</strong>。</li>
</ol>
<p><br>197 公司有一个运行在本地 <strong>Windows Server</strong> 上的 <strong>Microsoft .NET</strong> 应用程序，该应用程序使用 <strong>Oracle Database Standard Edition</strong> 服务器存储数据。公司计划迁移到 AWS，要求如下：</p>
<ol>
<li>在迁移应用程序时<strong>尽量减少开发变更</strong>。</li>
<li>AWS 应用程序环境应具备<strong>高可用性</strong>。</li>
</ol>
<p><u><strong>在多可用区部署中，将应用程序重新托管在采用 .NET 平台的 AWS Elastic Beanstalk 中。</strong></u></p>
<p><u><strong>使用 AWS DMS 将 Oracle 数据库迁移到多可用区部署中的 Amazon RDS for Oracle。</strong></u></p>
<p><br>198 公司在本地数据中心的 <strong>Kubernetes 集群</strong> 上运行一个<strong>容器化应用程序</strong>，并使用 <strong>MongoDB</strong> 数据库。公司希望将部分环境迁移到 AWS，要求如下：</p>
<ol>
<li><strong>目前无法进行任何代码更改或部署方法更改</strong>。</li>
<li>需要一个能<strong>最大限度减少运营开销</strong>的解决方案。</li>
</ol>
<p><strong><u>使用 Amazon Elastic Kubernetes Service (EKS) 搭配 AWS Fargate 进行计算，并使用 Amazon DocumentDB（兼容 MongoDB） 进行数据存储。</u></strong></p>
<ul>
<li><strong>EKS</strong> 托管了 Kubernetes 控制平面。</li>
<li><strong>Fargate</strong> 提供无服务器计算，无需管理 EC2 节点（节点补丁、扩缩容）。</li>
<li><strong>DocumentDB</strong> 是完全托管的数据库，自动处理备份、修补和扩展</li>
</ul>
<p><br>199 一家电话营销公司需要在 AWS 上设计客户呼叫中心功能，要求如下：</p>
<ol>
<li>需要一个能提供<strong>多说话人识别</strong>并<strong>生成转录文件</strong>的解决方案。</li>
<li>希望<strong>查询这些转录文件</strong>以分析业务模式。</li>
<li>为满足审计需求，转录文件必须<strong>存储 7 年</strong>。</li>
</ol>
<p><strong><u>使用 Amazon Transcribe 进行多说话人识别。使用 Amazon Athena 进行转录文件分析</u></strong></p>
<p><strong>Amazon Athena</strong> 是一个无服务器的交互式查询服务，允许使用<strong>标准 SQL</strong> 直接分析 S3 中的数据</p>
<p><strong>Amazon Rekognition</strong> 是用于<strong>图像和视频分析</strong>的服务（如对象检测、人脸识别），<strong>不能处理音频或进行语音转文本</strong></p>
<p>Redshift 是数据仓库，用于分析高度结构化的数据。将非结构化的转录文本直接存入 Redshift 并不高效</p>
<p><br>200 公司在 AWS 上托管应用程序，使用 <strong>Amazon Cognito</strong> 管理用户。用户登录后，应用程序通过 <strong>Amazon API Gateway</strong> 中的 REST API 从 <strong>Amazon DynamoDB</strong> 获取数据。<br><strong>要求</strong>：<br>希望有一种 <strong>AWS 托管解决方案</strong> 来控制对 REST API 的访问，以<strong>减少开发工作量</strong>，且<strong>运营开销最小</strong>。</p>
<p><strong><u>在 API 网关中配置 Amazon Cognito 用户池授权方，以允许 Amazon Cognito 验证每个请求</u></strong></p>
<p><strong>AWS 托管解决方案</strong>：这是 API Gateway 与 Cognito <strong>原生集成</strong>的功能，是一个<strong>完全托管</strong>的授权机制，无需编写任何代码</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">CodeShine</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
